{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning tweeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T20:15:16.045902Z",
     "start_time": "2019-06-15T20:15:15.812387Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T19:50:57.872434Z",
     "start_time": "2019-06-15T19:50:53.957998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import cufflinks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "seed = 5\n",
    "np.random.seed(seed)\n",
    "\n",
    "sys.path.append('..')\n",
    "cufflinks.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T19:51:06.435918Z",
     "start_time": "2019-06-15T19:51:04.512382Z"
    }
   },
   "outputs": [],
   "source": [
    "from Corpus.Corpus import get_corpus, filter_binary_pn, filter_corpus_small\n",
    "from auxiliar.VectorizerHelper import vectorizer, vectorizerIdf, tokenize, procesar_corpus\n",
    "from auxiliar import parameters\n",
    "from sklearn.model_selection import KFold\n",
    "from auxiliar.HtmlParser import HtmlParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T22:43:04.376436Z",
     "start_time": "2019-06-15T22:43:01.823928Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T19:51:07.447711Z",
     "start_time": "2019-06-15T19:51:04.884Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import Levenshtein as lv\n",
    "from nltk.stem import SnowballStemmer\n",
    "from gensim.models import Doc2Vec\n",
    "import gensim\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Corpus.Corpus import get_corpus, filter_binary_pn, filter_corpus_small\n",
    "from time import time, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:10.231246Z",
     "start_time": "2019-06-14T06:36:10.179510Z"
    }
   },
   "outputs": [],
   "source": [
    "polarity_dim = 2\n",
    "# clasificadores=['lstm', '2lstm', '2dcnn', '2dcnn+lstm', 'cnn+lstm', 'bidirectionalLstm']\n",
    "clasificadores=['lstm']\n",
    "idf = True\n",
    "target_names=['Neg', 'Pos']\n",
    "kfolds = 10\n",
    "base_dir = '2-clases' if polarity_dim == 2 else ('3-clases' if polarity_dim == 3 else '5-clases')\n",
    "name = 'deep_learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:10.370286Z",
     "start_time": "2019-06-14T06:36:10.235910Z"
    }
   },
   "outputs": [],
   "source": [
    "w2vec_file = 'data/w2vec.bin'\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.setLevel(logging.DEBUG)\n",
    "handler = logging.FileHandler('entrenamiento-%s.log' % strftime(\"%d-%m-%Y-%H-%M\"), 'w', 'utf-8')  # or whatever\n",
    "handler.setFormatter = logging.Formatter('%(name)s %(message)s')  # or whatever\n",
    "root_logger.addHandler(handler)\n",
    "stemmer = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos los datos para realizar el entrenamiento y lo dividimos en dos subconjuntos: train y test\n",
    "\n",
    "Dado que nuestro corpus de datos es muy pequeño, 4700 ejemplos para polaridades pos y neg, vamos a dividir el conjunto de datos de forma que utilicemos solo 100 ejemplos para el conjunto de test, asi no penalizaremos al conjunto de entrenamiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:10.628849Z",
     "start_time": "2019-06-14T06:36:10.371592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Intentando obtener datos del archivo csv...\n",
      "/home/suampa/Documentos/AnalysisCV/Corpus/../data/general-corpus.csv\n",
      "#Datos recuperados!\n"
     ]
    }
   ],
   "source": [
    "# cine = HtmlParser(200, \"http://www.muchocine.net/criticas_ultimas.php\", 1)\n",
    "data_corpus = get_corpus('general-corpus', 'general-corpus', 1, None)\n",
    "\n",
    "if polarity_dim == 2:\n",
    "    data_corpus = filter_binary_pn(data_corpus)\n",
    "#     cine = filter_binary_pn(cine.get_corpus())\n",
    "elif polarity_dim == 3:\n",
    "    data_corpus = filter_corpus_small(data_corpus)\n",
    "#     cine = filter_corpus_small(cine.get_corpus())\n",
    "# used_data = cine[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:12.042427Z",
     "start_time": "2019-06-14T06:36:10.630497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "marker": {
          "color": "rgba(255, 153, 51, 0.6)",
          "line": {
           "color": "rgba(255, 153, 51, 1.0)",
           "width": 1
          }
         },
         "name": "index",
         "orientation": "v",
         "text": "",
         "type": "bar",
         "uid": "c068b667-7b60-40b3-b788-b81524aa40b0",
         "x": [
          0,
          1
         ],
         "y": [
          1986,
          2714
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"aa98c3ef-0642-43ae-9614-cb35c237a87c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"aa98c3ef-0642-43ae-9614-cb35c237a87c\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'aa98c3ef-0642-43ae-9614-cb35c237a87c',\n",
       "                        [{\"marker\": {\"color\": \"rgba(255, 153, 51, 0.6)\", \"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"width\": 1}}, \"name\": \"index\", \"orientation\": \"v\", \"text\": \"\", \"type\": \"bar\", \"uid\": \"c068b667-7b60-40b3-b788-b81524aa40b0\", \"x\": [0, 1], \"y\": [1986, 2714]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('aa98c3ef-0642-43ae-9614-cb35c237a87c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_corpus.groupby('polarity').agg({'index': 'count'}).iplot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos la función axiliar prepro (VectorizerHelper.procesar_corpus) con los siguientes parámetros:\n",
    "\n",
    "text, tagger, process_text, stop_words, negation, repeated_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:12.938699Z",
     "start_time": "2019-06-14T06:36:12.043948Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_prepro(data):\n",
    "    return procesar_corpus(data, None, True, True, False, True)\n",
    "data_corpus.content = data_corpus.content.apply(apply_prepro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T21:03:35.049784Z",
     "start_time": "2019-02-07T21:03:35.045787Z"
    }
   },
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:35.271600Z",
     "start_time": "2019-06-14T06:36:12.939948Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0618 18:43:55.337981 139968762341184 utils_any2vec.py:341] loading projection weights from data/w2vec.bin\n",
      "I0618 18:43:55.341667 139968762341184 smart_open_lib.py:293] {'uri': 'data/w2vec.bin', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': {}}\n",
      "I0618 18:44:14.323171 139968762341184 utils_any2vec.py:405] loaded (1000653, 300) matrix from data/w2vec.bin\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(w2vec_file, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos la funciona auxiliar tokenize que utiliza como parametros el conjunto de datos y un flag para activar el stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tokenization(data):\n",
    "    return tokenize(data, False)\n",
    "tokens = data_corpus.content.apply(apply_tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df = pd.DataFrame([x for x in tokens]).transpose()\n",
    "token_df.columns = pd.MultiIndex.from_arrays([data_corpus.polarity, token_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "palabras totales 41522\n",
      "media de palabras por texto 8.834468085106383\n"
     ]
    }
   ],
   "source": [
    "print('palabras totales', token_df.count().sum())\n",
    "print('media de palabras por texto', token_df.count().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "histfunc": "count",
         "histnorm": "",
         "marker": {
          "color": "rgba(255, 153, 51, 1.0)",
          "line": {
           "color": "#4D5663",
           "width": 1.3
          }
         },
         "opacity": 0.8,
         "orientation": "v",
         "type": "histogram",
         "uid": "50d858e7-57bb-4794-8384-16999520e854",
         "x": [
          2,
          15,
          8,
          6,
          15,
          4,
          19,
          14,
          2,
          2,
          6,
          8,
          9,
          8,
          9,
          16,
          10,
          14,
          10,
          7,
          9,
          8,
          9,
          7,
          7,
          8,
          4,
          10,
          16,
          1,
          3,
          6,
          3,
          14,
          6,
          9,
          7,
          15,
          6,
          6,
          10,
          14,
          10,
          15,
          15,
          6,
          8,
          12,
          9,
          4,
          11,
          11,
          14,
          10,
          16,
          9,
          7,
          11,
          14,
          6,
          8,
          4,
          5,
          5,
          13,
          4,
          7,
          8,
          9,
          10,
          13,
          8,
          16,
          11,
          3,
          7,
          4,
          2,
          10,
          11,
          13,
          13,
          9,
          6,
          5,
          10,
          1,
          7,
          11,
          6,
          8,
          4,
          7,
          12,
          9,
          12,
          13,
          10,
          5,
          15,
          7,
          4,
          7,
          11,
          14,
          9,
          3,
          13,
          10,
          6,
          2,
          11,
          3,
          3,
          10,
          4,
          2,
          15,
          13,
          10,
          6,
          8,
          9,
          16,
          6,
          9,
          9,
          11,
          8,
          10,
          11,
          8,
          12,
          6,
          8,
          10,
          9,
          9,
          8,
          10,
          15,
          7,
          6,
          8,
          12,
          7,
          13,
          9,
          5,
          12,
          4,
          10,
          4,
          10,
          14,
          7,
          12,
          7,
          14,
          11,
          5,
          8,
          14,
          12,
          8,
          10,
          9,
          2,
          11,
          7,
          7,
          6,
          14,
          4,
          10,
          7,
          13,
          13,
          13,
          14,
          18,
          8,
          7,
          7,
          3,
          4,
          9,
          11,
          9,
          12,
          14,
          7,
          7,
          10,
          7,
          7,
          7,
          6,
          7,
          12,
          9,
          8,
          10,
          13,
          4,
          7,
          14,
          5,
          12,
          11,
          4,
          5,
          9,
          2,
          7,
          7,
          9,
          9,
          11,
          14,
          7,
          13,
          3,
          6,
          10,
          11,
          12,
          15,
          10,
          12,
          15,
          15,
          5,
          8,
          9,
          9,
          11,
          10,
          3,
          3,
          9,
          2,
          15,
          9,
          14,
          7,
          10,
          6,
          5,
          12,
          3,
          8,
          7,
          5,
          9,
          11,
          12,
          16,
          11,
          12,
          12,
          8,
          13,
          11,
          5,
          9,
          8,
          9,
          12,
          11,
          11,
          17,
          11,
          11,
          10,
          5,
          10,
          14,
          12,
          7,
          5,
          11,
          10,
          9,
          5,
          9,
          4,
          6,
          2,
          14,
          15,
          1,
          12,
          13,
          2,
          1,
          6,
          6,
          9,
          13,
          4,
          5,
          11,
          11,
          5,
          10,
          6,
          3,
          11,
          12,
          10,
          4,
          13,
          10,
          3,
          8,
          15,
          12,
          9,
          4,
          12,
          8,
          10,
          12,
          7,
          10,
          7,
          10,
          11,
          15,
          9,
          7,
          12,
          15,
          4,
          4,
          5,
          4,
          11,
          5,
          7,
          5,
          8,
          13,
          12,
          14,
          12,
          11,
          11,
          11,
          5,
          13,
          9,
          11,
          12,
          9,
          9,
          14,
          14,
          9,
          9,
          9,
          15,
          6,
          14,
          14,
          9,
          10,
          14,
          11,
          11,
          6,
          8,
          13,
          4,
          9,
          6,
          6,
          6,
          8,
          10,
          8,
          6,
          13,
          11,
          12,
          9,
          10,
          9,
          13,
          8,
          9,
          6,
          6,
          6,
          9,
          7,
          14,
          11,
          12,
          9,
          10,
          7,
          11,
          13,
          14,
          5,
          7,
          8,
          8,
          14,
          7,
          7,
          11,
          9,
          9,
          1,
          4,
          9,
          12,
          8,
          13,
          8,
          9,
          9,
          11,
          8,
          5,
          14,
          8,
          11,
          6,
          8,
          6,
          13,
          5,
          14,
          5,
          8,
          2,
          13,
          8,
          7,
          13,
          14,
          7,
          16,
          12,
          9,
          6,
          6,
          10,
          10,
          7,
          11,
          7,
          11,
          9,
          10,
          14,
          11,
          6,
          9,
          8,
          9,
          8,
          7,
          14,
          10,
          8,
          10,
          8,
          10,
          7,
          16,
          14,
          4,
          13,
          8,
          3,
          8,
          8,
          8,
          11,
          9,
          7,
          11,
          4,
          12,
          12,
          6,
          3,
          5,
          6,
          10,
          1,
          13,
          13,
          7,
          12,
          3,
          5,
          12,
          10,
          8,
          11,
          12,
          12,
          13,
          13,
          10,
          13,
          2,
          8,
          9,
          11,
          10,
          14,
          7,
          8,
          7,
          15,
          13,
          10,
          13,
          7,
          11,
          4,
          12,
          6,
          6,
          12,
          3,
          4,
          9,
          6,
          8,
          7,
          2,
          14,
          13,
          8,
          15,
          13,
          14,
          10,
          11,
          13,
          9,
          7,
          8,
          8,
          10,
          7,
          5,
          17,
          12,
          6,
          4,
          7,
          9,
          9,
          9,
          9,
          13,
          4,
          15,
          13,
          7,
          18,
          14,
          5,
          4,
          6,
          12,
          4,
          3,
          9,
          11,
          10,
          9,
          13,
          5,
          11,
          12,
          6,
          10,
          11,
          1,
          14,
          11,
          12,
          6,
          9,
          10,
          7,
          16,
          10,
          6,
          7,
          15,
          10,
          12,
          12,
          10,
          13,
          13,
          10,
          11,
          10,
          11,
          9,
          11,
          9,
          13,
          9,
          9,
          9,
          4,
          12,
          8,
          10,
          7,
          14,
          12,
          10,
          8,
          10,
          12,
          12,
          14,
          10,
          14,
          7,
          15,
          14,
          9,
          10,
          16,
          13,
          14,
          12,
          11,
          11,
          11,
          9,
          7,
          7,
          10,
          13,
          6,
          7,
          6,
          11,
          9,
          12,
          13,
          17,
          7,
          8,
          10,
          14,
          7,
          12,
          11,
          5,
          13,
          14,
          13,
          13,
          6,
          12,
          8,
          15,
          11,
          8,
          9,
          15,
          4,
          8,
          7,
          6,
          13,
          8,
          11,
          10,
          13,
          13,
          12,
          9,
          9,
          12,
          4,
          11,
          15,
          4,
          4,
          7,
          9,
          6,
          12,
          5,
          10,
          9,
          16,
          5,
          5,
          5,
          7,
          10,
          5,
          1,
          9,
          9,
          12,
          9,
          9,
          7,
          11,
          8,
          6,
          6,
          14,
          5,
          10,
          9,
          11,
          11,
          9,
          4,
          13,
          6,
          14,
          8,
          11,
          14,
          6,
          10,
          1,
          6,
          7,
          10,
          5,
          6,
          11,
          10,
          8,
          10,
          7,
          11,
          7,
          7,
          13,
          3,
          13,
          7,
          6,
          7,
          10,
          7,
          12,
          3,
          4,
          10,
          8,
          8,
          6,
          10,
          3,
          8,
          13,
          11,
          8,
          12,
          7,
          10,
          14,
          3,
          6,
          12,
          12,
          4,
          3,
          8,
          4,
          8,
          13,
          10,
          3,
          11,
          13,
          8,
          7,
          5,
          12,
          8,
          4,
          6,
          7,
          8,
          10,
          9,
          15,
          11,
          4,
          9,
          9,
          9,
          8,
          5,
          14,
          6,
          4,
          9,
          9,
          5,
          6,
          6,
          5,
          9,
          9,
          6,
          9,
          8,
          11,
          11,
          6,
          11,
          6,
          12,
          7,
          13,
          9,
          8,
          4,
          4,
          10,
          10,
          11,
          4,
          4,
          2,
          5,
          4,
          10,
          4,
          12,
          9,
          6,
          7,
          13,
          13,
          5,
          11,
          7,
          8,
          9,
          7,
          13,
          13,
          12,
          7,
          13,
          5,
          12,
          8,
          12,
          10,
          10,
          7,
          6,
          5,
          3,
          3,
          5,
          3,
          3,
          21,
          10,
          13,
          9,
          12,
          15,
          8,
          2,
          12,
          13,
          8,
          10,
          14,
          12,
          13,
          8,
          10,
          5,
          13,
          10,
          12,
          12,
          10,
          12,
          12,
          8,
          13,
          8,
          14,
          12,
          7,
          9,
          9,
          12,
          3,
          11,
          8,
          10,
          9,
          5,
          1,
          6,
          15,
          9,
          12,
          6,
          11,
          10,
          3,
          8,
          6,
          7,
          9,
          7,
          11,
          8,
          12,
          11,
          12,
          9,
          14,
          11,
          12,
          5,
          6,
          7,
          11,
          5,
          8,
          13,
          7,
          14,
          6,
          11,
          12,
          11,
          9,
          4,
          9,
          12,
          11,
          8,
          12,
          8,
          10,
          10,
          12,
          6,
          13,
          10,
          12,
          5,
          8,
          14,
          11,
          8,
          8,
          11,
          14,
          6,
          11,
          6,
          3,
          7,
          14,
          10,
          6,
          7,
          14,
          6,
          13,
          5,
          9,
          3,
          13,
          12,
          10,
          11,
          10,
          9,
          1,
          13,
          5,
          4,
          13,
          7,
          10,
          12,
          14,
          9,
          11,
          13,
          11,
          13,
          6,
          14,
          16,
          7,
          12,
          11,
          13,
          14,
          7,
          13,
          12,
          5,
          8,
          7,
          8,
          8,
          3,
          9,
          9,
          5,
          13,
          10,
          8,
          14,
          11,
          14,
          1,
          11,
          12,
          4,
          11,
          9,
          13,
          11,
          6,
          9,
          10,
          9,
          9,
          9,
          12,
          3,
          10,
          14,
          9,
          11,
          4,
          13,
          1,
          8,
          14,
          4,
          10,
          1,
          2,
          11,
          6,
          13,
          7,
          12,
          11,
          15,
          4,
          5,
          10,
          7,
          7,
          9,
          14,
          4,
          10,
          5,
          8,
          11,
          13,
          11,
          13,
          6,
          8,
          9,
          16,
          4,
          8,
          12,
          7,
          5,
          9,
          9,
          5,
          9,
          9,
          13,
          10,
          5,
          10,
          10,
          14,
          7,
          9,
          13,
          12,
          15,
          9,
          11,
          5,
          8,
          4,
          6,
          9,
          15,
          9,
          8,
          13,
          7,
          2,
          4,
          4,
          10,
          8,
          15,
          11,
          13,
          12,
          2,
          9,
          12,
          7,
          13,
          9,
          3,
          9,
          7,
          9,
          6,
          11,
          15,
          13,
          11,
          6,
          1,
          7,
          9,
          5,
          8,
          8,
          7,
          6,
          6,
          2,
          1,
          10,
          3,
          6,
          2,
          5,
          7,
          5,
          7,
          7,
          4,
          5,
          8,
          6,
          6,
          14,
          14,
          9,
          9,
          9,
          5,
          14,
          10,
          7,
          7,
          11,
          6,
          11,
          12,
          11,
          11,
          8,
          12,
          9,
          6,
          3,
          9,
          7,
          3,
          9,
          14,
          11,
          14,
          3,
          8,
          5,
          12,
          7,
          13,
          11,
          5,
          10,
          7,
          5,
          4,
          18,
          5,
          13,
          6,
          10,
          9,
          4,
          8,
          8,
          7,
          9,
          10,
          10,
          11,
          3,
          13,
          13,
          10,
          12,
          7,
          3,
          12,
          4,
          14,
          11,
          7,
          11,
          8,
          8,
          6,
          15,
          7,
          9,
          12,
          10,
          13,
          8,
          7,
          9,
          6,
          9,
          8,
          9,
          13,
          4,
          10,
          6,
          7,
          10,
          11,
          12,
          12,
          10,
          13,
          8,
          3,
          6,
          10,
          9,
          6,
          13,
          5,
          7,
          8,
          3,
          15,
          7,
          3,
          6,
          6,
          2,
          7,
          6,
          8,
          8,
          15,
          8,
          10,
          8,
          7,
          4,
          9,
          3,
          13,
          13,
          9,
          8,
          8,
          3,
          13,
          10,
          8,
          16,
          4,
          9,
          13,
          14,
          9,
          7,
          4,
          8,
          12,
          12,
          7,
          6,
          7,
          3,
          14,
          8,
          10,
          11,
          3,
          15,
          3,
          8,
          14,
          12,
          2,
          5,
          14,
          10,
          10,
          7,
          5,
          8,
          9,
          16,
          7,
          5,
          6,
          8,
          10,
          11,
          10,
          12,
          9,
          14,
          5,
          10,
          6,
          5,
          5,
          10,
          5,
          5,
          6,
          7,
          13,
          5,
          7,
          14,
          7,
          11,
          13,
          9,
          15,
          7,
          10,
          6,
          11,
          2,
          4,
          6,
          11,
          13,
          5,
          9,
          3,
          2,
          3,
          5,
          7,
          12,
          5,
          13,
          9,
          7,
          13,
          10,
          13,
          7,
          11,
          11,
          5,
          10,
          9,
          17,
          7,
          12,
          15,
          13,
          12,
          1,
          5,
          11,
          3,
          10,
          7,
          7,
          4,
          6,
          16,
          13,
          8,
          6,
          8,
          8,
          10,
          7,
          13,
          7,
          9,
          15,
          10,
          11,
          10,
          12,
          10,
          12,
          8,
          10,
          12,
          14,
          5,
          7,
          12,
          10,
          3,
          10,
          10,
          10,
          8,
          4,
          7,
          9,
          9,
          9,
          11,
          8,
          11,
          10,
          8,
          5,
          2,
          13,
          8,
          16,
          13,
          8,
          7,
          7,
          8,
          10,
          1,
          16,
          6,
          4,
          6,
          6,
          3,
          12,
          5,
          9,
          12,
          5,
          10,
          7,
          10,
          7,
          9,
          11,
          12,
          11,
          8,
          9,
          15,
          10,
          9,
          3,
          3,
          10,
          11,
          12,
          8,
          4,
          10,
          6,
          12,
          7,
          2,
          15,
          10,
          10,
          7,
          15,
          4,
          9,
          9,
          13,
          13,
          12,
          12,
          5,
          8,
          10,
          5,
          5,
          13,
          11,
          10,
          5,
          8,
          6,
          7,
          8,
          6,
          10,
          5,
          6,
          5,
          15,
          7,
          3,
          9,
          8,
          2,
          5,
          10,
          14,
          4,
          7,
          10,
          8,
          4,
          12,
          3,
          8,
          8,
          3,
          17,
          13,
          14,
          17,
          3,
          6,
          12,
          6,
          10,
          1,
          12,
          8,
          9,
          2,
          7,
          12,
          10,
          9,
          12,
          11,
          6,
          11,
          6,
          8,
          10,
          12,
          5,
          12,
          10,
          3,
          10,
          11,
          13,
          15,
          14,
          2,
          4,
          10,
          7,
          11,
          6,
          9,
          4,
          6,
          13,
          11,
          5,
          13,
          4,
          12,
          9,
          11,
          10,
          1,
          11,
          5,
          15,
          8,
          8,
          4,
          15,
          5,
          5,
          4,
          18,
          6,
          10,
          6,
          9,
          11,
          10,
          14,
          10,
          13,
          3,
          5,
          8,
          6,
          9,
          13,
          8,
          8,
          9,
          6,
          6,
          10,
          16,
          9,
          6,
          16,
          11,
          1,
          12,
          5,
          9,
          16,
          13,
          8,
          12,
          8,
          9,
          11,
          11,
          8,
          9,
          8,
          10,
          6,
          13,
          4,
          8,
          14,
          15,
          9,
          13,
          4,
          7,
          9,
          9,
          12,
          8,
          3,
          3,
          5,
          11,
          10,
          13,
          13,
          10,
          10,
          4,
          6,
          6,
          14,
          8,
          15,
          12,
          9,
          11,
          4,
          5,
          10,
          8,
          14,
          12,
          11,
          5,
          9,
          12,
          10,
          14,
          7,
          4,
          7,
          6,
          4,
          4,
          6,
          11,
          11,
          7,
          10,
          7,
          8,
          7,
          11,
          10,
          8,
          10,
          12,
          14,
          8,
          8,
          7,
          6,
          7,
          9,
          4,
          6,
          13,
          13,
          12,
          12,
          6,
          5,
          9,
          10,
          1,
          10,
          10,
          11,
          3,
          7,
          12,
          8,
          5,
          9,
          3,
          7,
          2,
          11,
          9,
          9,
          13,
          10,
          10,
          7,
          9,
          8,
          10,
          8,
          10,
          8,
          6,
          12,
          3,
          9,
          6,
          0,
          6,
          13,
          7,
          12,
          3,
          14,
          7,
          11,
          8,
          5,
          6,
          7,
          9,
          7,
          5,
          9,
          2,
          4,
          7,
          7,
          9,
          5,
          10,
          12,
          8,
          18,
          11,
          7,
          5,
          2,
          12,
          10,
          11,
          14,
          4,
          6,
          10,
          13,
          10,
          10,
          12,
          10,
          11,
          1,
          8,
          4,
          12,
          9,
          9,
          12,
          8,
          9,
          6,
          10,
          8,
          6,
          11,
          4,
          15,
          11,
          12,
          6,
          12,
          6,
          7,
          11,
          11,
          8,
          6,
          12,
          12,
          10,
          10,
          15,
          12,
          10,
          15,
          11,
          10,
          11,
          8,
          10,
          14,
          10,
          6,
          4,
          10,
          8,
          8,
          6,
          9,
          12,
          13,
          12,
          7,
          8,
          14,
          7,
          11,
          11,
          11,
          4,
          6,
          6,
          13,
          12,
          9,
          10,
          11,
          8,
          9,
          11,
          9,
          14,
          8,
          5,
          10,
          3,
          10,
          12,
          8,
          6,
          9,
          12,
          9,
          11,
          11,
          8,
          9,
          15,
          4,
          13,
          1,
          12,
          10,
          6,
          4,
          14,
          9,
          14,
          15,
          5,
          9,
          8,
          13,
          9,
          7,
          5,
          8,
          12,
          6,
          9,
          8,
          8,
          8,
          3,
          8,
          5,
          9,
          4,
          6,
          7,
          8,
          8,
          3,
          7,
          11,
          12,
          6,
          7,
          9,
          2,
          5,
          12,
          6,
          8,
          12,
          12,
          16,
          12,
          5,
          16,
          13,
          7,
          8,
          7,
          15,
          4,
          13,
          10,
          9,
          4,
          6,
          4,
          8,
          10,
          13,
          11,
          9,
          4,
          8,
          8,
          8,
          12,
          6,
          8,
          5,
          11,
          8,
          10,
          12,
          10,
          6,
          13,
          6,
          8,
          8,
          10,
          9,
          14,
          14,
          28,
          9,
          14,
          4,
          4,
          6,
          10,
          5,
          3,
          16,
          4,
          13,
          9,
          9,
          15,
          7,
          14,
          13,
          11,
          14,
          9,
          10,
          8,
          11,
          14,
          6,
          11,
          10,
          11,
          11,
          14,
          9,
          15,
          6,
          9,
          14,
          9,
          8,
          13,
          9,
          16,
          12,
          8,
          15,
          10,
          4,
          12,
          11,
          4,
          3,
          14,
          11,
          15,
          4,
          8,
          8,
          6,
          5,
          12,
          5,
          11,
          11,
          10,
          9,
          13,
          9,
          11,
          7,
          15,
          9,
          7,
          2,
          13,
          4,
          13,
          7,
          11,
          11,
          11,
          11,
          5,
          4,
          2,
          8,
          7,
          8,
          15,
          11,
          11,
          4,
          5,
          7,
          12,
          9,
          7,
          11,
          5,
          9,
          12,
          6,
          9,
          8,
          15,
          8,
          13,
          9,
          11,
          12,
          9,
          12,
          6,
          9,
          6,
          8,
          16,
          11,
          12,
          9,
          12,
          9,
          10,
          8,
          9,
          12,
          8,
          5,
          2,
          2,
          11,
          9,
          9,
          12,
          4,
          8,
          11,
          10,
          9,
          10,
          12,
          10,
          10,
          9,
          11,
          12,
          12,
          10,
          10,
          10,
          14,
          12,
          7,
          6,
          9,
          4,
          12,
          10,
          6,
          10,
          8,
          9,
          3,
          17,
          7,
          14,
          10,
          7,
          8,
          10,
          8,
          10,
          1,
          2,
          5,
          3,
          12,
          13,
          9,
          13,
          13,
          9,
          4,
          10,
          7,
          5,
          4,
          4,
          8,
          14,
          16,
          8,
          8,
          8,
          9,
          12,
          1,
          13,
          4,
          7,
          8,
          12,
          10,
          6,
          10,
          11,
          11,
          6,
          10,
          7,
          14,
          12,
          8,
          9,
          13,
          5,
          10,
          14,
          15,
          11,
          5,
          12,
          9,
          8,
          12,
          4,
          7,
          14,
          9,
          5,
          5,
          7,
          13,
          6,
          4,
          11,
          5,
          8,
          12,
          7,
          1,
          11,
          12,
          6,
          14,
          8,
          7,
          7,
          8,
          3,
          11,
          13,
          12,
          8,
          11,
          4,
          10,
          6,
          12,
          11,
          11,
          4,
          6,
          14,
          7,
          8,
          14,
          7,
          5,
          6,
          6,
          10,
          7,
          7,
          14,
          10,
          8,
          2,
          3,
          4,
          12,
          11,
          13,
          5,
          4,
          16,
          9,
          11,
          15,
          9,
          10,
          6,
          12,
          12,
          9,
          9,
          6,
          10,
          10,
          10,
          13,
          13,
          10,
          10,
          16,
          2,
          10,
          14,
          10,
          4,
          4,
          10,
          5,
          9,
          6,
          12,
          9,
          10,
          5,
          4,
          7,
          4,
          12,
          10,
          4,
          12,
          13,
          7,
          10,
          13,
          12,
          3,
          6,
          11,
          13,
          2,
          7,
          7,
          13,
          12,
          10,
          6,
          7,
          12,
          12,
          13,
          14,
          3,
          13,
          11,
          1,
          10,
          11,
          10,
          12,
          5,
          5,
          6,
          3,
          3,
          9,
          7,
          15,
          6,
          7,
          9,
          7,
          9,
          8,
          12,
          5,
          7,
          3,
          2,
          3,
          3,
          4,
          16,
          14,
          7,
          11,
          3,
          10,
          12,
          4,
          10,
          12,
          7,
          5,
          4,
          8,
          9,
          13,
          12,
          8,
          5,
          6,
          8,
          6,
          11,
          7,
          3,
          12,
          17,
          3,
          3,
          11,
          5,
          9,
          8,
          18,
          11,
          10,
          2,
          6,
          13,
          5,
          6,
          6,
          11,
          16,
          5,
          3,
          8,
          11,
          7,
          5,
          4,
          12,
          2,
          17,
          9,
          14,
          11,
          10,
          7,
          4,
          8,
          12,
          8,
          11,
          6,
          8,
          6,
          12,
          15,
          9,
          9,
          8,
          9,
          6,
          2,
          11,
          5,
          5,
          15,
          9,
          10,
          13,
          9,
          3,
          9,
          14,
          14,
          10,
          8,
          6,
          12,
          5,
          1,
          5,
          11,
          10,
          9,
          11,
          11,
          11,
          13,
          14,
          12,
          13,
          10,
          6,
          8,
          4,
          7,
          8,
          5,
          5,
          8,
          13,
          14,
          10,
          9,
          11,
          4,
          9,
          11,
          10,
          12,
          14,
          8,
          15,
          15,
          13,
          10,
          10,
          9,
          9,
          5,
          7,
          4,
          8,
          3,
          7,
          11,
          9,
          9,
          4,
          4,
          18,
          8,
          13,
          11,
          12,
          8,
          16,
          14,
          11,
          8,
          6,
          13,
          12,
          12,
          7,
          11,
          13,
          11,
          9,
          6,
          12,
          7,
          13,
          7,
          14,
          11,
          6,
          8,
          9,
          12,
          10,
          10,
          17,
          5,
          9,
          4,
          9,
          8,
          15,
          7,
          4,
          4,
          6,
          15,
          16,
          18,
          7,
          10,
          7,
          11,
          14,
          10,
          13,
          8,
          9,
          11,
          12,
          5,
          9,
          11,
          3,
          9,
          11,
          10,
          4,
          9,
          8,
          12,
          7,
          12,
          6,
          4,
          14,
          7,
          14,
          9,
          4,
          4,
          4,
          3,
          4,
          13,
          8,
          6,
          10,
          7,
          7,
          12,
          17,
          17,
          3,
          8,
          3,
          8,
          8,
          9,
          10,
          4,
          3,
          12,
          11,
          17,
          9,
          9,
          5,
          12,
          10,
          4,
          5,
          12,
          9,
          2,
          10,
          8,
          5,
          4,
          11,
          12,
          13,
          12,
          7,
          7,
          13,
          4,
          7,
          9,
          10,
          13,
          12,
          8,
          14,
          15,
          6,
          4,
          5,
          5,
          8,
          6,
          6,
          11,
          10,
          8,
          10,
          6,
          3,
          9,
          11,
          6,
          11,
          8,
          11,
          9,
          0,
          6,
          10,
          9,
          5,
          8,
          8,
          7,
          8,
          12,
          11,
          12,
          5,
          12,
          10,
          5,
          10,
          11,
          16,
          3,
          11,
          6,
          9,
          9,
          12,
          12,
          11,
          13,
          8,
          16,
          9,
          16,
          8,
          11,
          6,
          9,
          5,
          7,
          10,
          15,
          4,
          15,
          6,
          9,
          15,
          14,
          12,
          9,
          2,
          4,
          7,
          12,
          10,
          4,
          12,
          15,
          15,
          4,
          1,
          10,
          13,
          16,
          8,
          12,
          11,
          5,
          11,
          7,
          3,
          11,
          7,
          10,
          12,
          8,
          6,
          10,
          10,
          7,
          11,
          5,
          11,
          6,
          7,
          2,
          8,
          5,
          7,
          11,
          8,
          8,
          13,
          9,
          9,
          6,
          11,
          10,
          7,
          13,
          9,
          6,
          13,
          11,
          10,
          13,
          11,
          12,
          12,
          6,
          2,
          14,
          2,
          6,
          9,
          10,
          5,
          9,
          8,
          8,
          13,
          14,
          7,
          10,
          4,
          12,
          10,
          12,
          8,
          13,
          7,
          10,
          14,
          3,
          13,
          13,
          4,
          10,
          5,
          15,
          12,
          3,
          9,
          5,
          9,
          7,
          9,
          7,
          3,
          8,
          5,
          13,
          8,
          6,
          9,
          8,
          11,
          13,
          10,
          7,
          7,
          11,
          13,
          7,
          6,
          10,
          13,
          10,
          6,
          9,
          10,
          6,
          5,
          12,
          7,
          11,
          13,
          6,
          6,
          9,
          16,
          13,
          3,
          7,
          11,
          7,
          14,
          5,
          5,
          10,
          11,
          4,
          8,
          17,
          5,
          8,
          2,
          12,
          10,
          4,
          4,
          15,
          13,
          3,
          13,
          8,
          8,
          11,
          6,
          14,
          9,
          11,
          3,
          12,
          8,
          12,
          7,
          11,
          12,
          4,
          7,
          6,
          11,
          3,
          1,
          5,
          2,
          10,
          11,
          5,
          6,
          14,
          3,
          5,
          11,
          8,
          3,
          4,
          12,
          4,
          9,
          11,
          2,
          11,
          5,
          3,
          9,
          5,
          9,
          9,
          11,
          5,
          5,
          7,
          6,
          11,
          8,
          3,
          12,
          4,
          9,
          9,
          11,
          11,
          11,
          9,
          10,
          7,
          12,
          10,
          9,
          4,
          8,
          9,
          10,
          2,
          16,
          0,
          7,
          11,
          6,
          2,
          11,
          10,
          11,
          8,
          6,
          9,
          7,
          10,
          13,
          5,
          7,
          9,
          6,
          16,
          14,
          7,
          7,
          1,
          2,
          16,
          13,
          8,
          12,
          11,
          2,
          10,
          12,
          4,
          8,
          16,
          6,
          7,
          11,
          6,
          8,
          7,
          3,
          11,
          12,
          7,
          10,
          12,
          7,
          3,
          12,
          11,
          5,
          15,
          4,
          8,
          4,
          10,
          8,
          8,
          9,
          12,
          7,
          11,
          7,
          15,
          5,
          8,
          15,
          12,
          12,
          8,
          2,
          12,
          11,
          14,
          5,
          6,
          11,
          12,
          11,
          6,
          9,
          6,
          6,
          4,
          10,
          7,
          7,
          12,
          13,
          4,
          10,
          7,
          4,
          7,
          2,
          9,
          8,
          14,
          8,
          6,
          11,
          5,
          9,
          11,
          5,
          0,
          5,
          4,
          8,
          2,
          3,
          13,
          10,
          8,
          4,
          2,
          7,
          8,
          10,
          5,
          10,
          6,
          6,
          10,
          8,
          12,
          5,
          7,
          9,
          10,
          7,
          8,
          14,
          4,
          13,
          5,
          7,
          6,
          8,
          4,
          10,
          11,
          6,
          11,
          10,
          7,
          10,
          6,
          14,
          9,
          7,
          6,
          10,
          4,
          8,
          11,
          3,
          9,
          3,
          8,
          8,
          15,
          7,
          13,
          11,
          10,
          3,
          9,
          11,
          13,
          10,
          10,
          9,
          2,
          4,
          8,
          11,
          6,
          6,
          4,
          7,
          5,
          14,
          9,
          13,
          12,
          6,
          15,
          3,
          5,
          5,
          12,
          17,
          14,
          13,
          15,
          12,
          14,
          11,
          10,
          15,
          13,
          0,
          10,
          9,
          7,
          8,
          13,
          11,
          10,
          6,
          10,
          11,
          9,
          11,
          15,
          11,
          11,
          15,
          5,
          12,
          13,
          14,
          13,
          11,
          10,
          5,
          7,
          9,
          13,
          11,
          6,
          14,
          11,
          3,
          11,
          12,
          11,
          10,
          13,
          15,
          8,
          3,
          12,
          13,
          8,
          7,
          13,
          5,
          16,
          4,
          2,
          11,
          11,
          7,
          10,
          9,
          3,
          12,
          12,
          13,
          13,
          8,
          10,
          10,
          9,
          8,
          13,
          7,
          8,
          13,
          13,
          13,
          7,
          9,
          7,
          11,
          10,
          5,
          3,
          7,
          11,
          12,
          14,
          14,
          6,
          1,
          3,
          8,
          9,
          6,
          10,
          14,
          6,
          6,
          4,
          12,
          3,
          13,
          5,
          12,
          10,
          10,
          13,
          13,
          7,
          2,
          10,
          7,
          8,
          2,
          9,
          11,
          10,
          10,
          12,
          7,
          12,
          8,
          7,
          8,
          9,
          9,
          6,
          15,
          7,
          4,
          11,
          7,
          14,
          4,
          2,
          13,
          9,
          14,
          10,
          14,
          5,
          6,
          12,
          13,
          13,
          15,
          5,
          9,
          4,
          15,
          5,
          8,
          8,
          7,
          8,
          9,
          13,
          7,
          11,
          13,
          13,
          5,
          12,
          5,
          10,
          9,
          12,
          5,
          13,
          6,
          11,
          10,
          5,
          14,
          9,
          16,
          2,
          12,
          3,
          2,
          9,
          11,
          4,
          3,
          10,
          7,
          4,
          3,
          9,
          15,
          8,
          8,
          7,
          10,
          11,
          10,
          7,
          7,
          15,
          6,
          5,
          12,
          9,
          11,
          12,
          5,
          12,
          13,
          10,
          8,
          10,
          2,
          12,
          11,
          9,
          14,
          7,
          13,
          10,
          7,
          12,
          8,
          10,
          4,
          2,
          10,
          9,
          6,
          11,
          7,
          16,
          11,
          15,
          5,
          16,
          4,
          3,
          9,
          14,
          10,
          2,
          12,
          7,
          9,
          7,
          5,
          6,
          9,
          8,
          5,
          11,
          7,
          12,
          14,
          10,
          14,
          4,
          15,
          7,
          13,
          5,
          9,
          15,
          12,
          9,
          6,
          14,
          8,
          6,
          13,
          9,
          10,
          10,
          10,
          10,
          2,
          9,
          11,
          1,
          12,
          7,
          6,
          12,
          10,
          11,
          7,
          9,
          13,
          14,
          10,
          10,
          6,
          7,
          8,
          5,
          8,
          11,
          13,
          8,
          15,
          2,
          4,
          10,
          8,
          4,
          11,
          2,
          13,
          9,
          8,
          13,
          9,
          6,
          5,
          12,
          5,
          2,
          9,
          17,
          10,
          9,
          7,
          13,
          6,
          4,
          4,
          15,
          10,
          13,
          12,
          10,
          8,
          7,
          5,
          11,
          10,
          13,
          4,
          12,
          9,
          7,
          6,
          12,
          13,
          8,
          8,
          11,
          6,
          12,
          13,
          11,
          6,
          5,
          9,
          3,
          13,
          9,
          13,
          15,
          4,
          4,
          7,
          10,
          11,
          14,
          7,
          9,
          9,
          3,
          1,
          9,
          6,
          5,
          7,
          7,
          15,
          12,
          9,
          11,
          10,
          8,
          12,
          19,
          9,
          2,
          9,
          11,
          8,
          5,
          4,
          6,
          8,
          11,
          7,
          13,
          15,
          10,
          11,
          9,
          11,
          4,
          5,
          10,
          10,
          5,
          12,
          9,
          5,
          5,
          8,
          9,
          9,
          1,
          5,
          11,
          7,
          10,
          2,
          1,
          8,
          9,
          11,
          13,
          4,
          4,
          15,
          12,
          9,
          4,
          8,
          9,
          9,
          11,
          8,
          7,
          10,
          9,
          7,
          12,
          10,
          10,
          9,
          4,
          7,
          3,
          4,
          4,
          6,
          13,
          11,
          8,
          9,
          1,
          2,
          5,
          6,
          16,
          10,
          8,
          10,
          7,
          9,
          8,
          6,
          4,
          11,
          8,
          16,
          11,
          6,
          6,
          8,
          3,
          7,
          14,
          15,
          8,
          9,
          9,
          6,
          11,
          11,
          5,
          4,
          8,
          10,
          6,
          3,
          5,
          1,
          12,
          10,
          10,
          13,
          12,
          12,
          11,
          5,
          4,
          2,
          3,
          5,
          8,
          11,
          12,
          6,
          13,
          12,
          15,
          3,
          2,
          11,
          8,
          5,
          14,
          7,
          11,
          12,
          11,
          14,
          11,
          12,
          9,
          16,
          10,
          6,
          13,
          16,
          6,
          8,
          11,
          15,
          8,
          9,
          10,
          12,
          11,
          11,
          1,
          11,
          5,
          11,
          13,
          2,
          8,
          2,
          5,
          10,
          12,
          10,
          16,
          13,
          8,
          12,
          10,
          14,
          16,
          12,
          3,
          5,
          13,
          6,
          10,
          9,
          5,
          2,
          10,
          5,
          11,
          11,
          13,
          14,
          8,
          13,
          8,
          5,
          12,
          6,
          8,
          7,
          7,
          15,
          11,
          10,
          10,
          5,
          11,
          6,
          1,
          3,
          11,
          5,
          10,
          4,
          1,
          13,
          10,
          10,
          9,
          8,
          10,
          10,
          9,
          12,
          4,
          6,
          9,
          5,
          13,
          6,
          2,
          10,
          2,
          8,
          14,
          6,
          9,
          11,
          9,
          12,
          11,
          8,
          9,
          3,
          3,
          6,
          3,
          1,
          8,
          12,
          14,
          10,
          10,
          11,
          4,
          8,
          8,
          8,
          7,
          11,
          1,
          6,
          13,
          8,
          13,
          9,
          2,
          6,
          8,
          4,
          6,
          12,
          5,
          9,
          6,
          4,
          5,
          9,
          4,
          10,
          13,
          8,
          7,
          11,
          10,
          12,
          4,
          9,
          9,
          4,
          6,
          12,
          13,
          15,
          10,
          14,
          10,
          9,
          4,
          8,
          3,
          10,
          3,
          7,
          3,
          12,
          12,
          7,
          8,
          7,
          9,
          14,
          8,
          12,
          9,
          6,
          12,
          8,
          8,
          13,
          3,
          7,
          7,
          9,
          10,
          12,
          8,
          10,
          13,
          9,
          9,
          6,
          12,
          9,
          9,
          9,
          4,
          8,
          11,
          6,
          8,
          3,
          7,
          11,
          9,
          10,
          7,
          8,
          7,
          7,
          2,
          5,
          6,
          15,
          10,
          4,
          11,
          12,
          9,
          7,
          6,
          11,
          12,
          11,
          8,
          7,
          5,
          9,
          5,
          4,
          11,
          12,
          9,
          9,
          13,
          9,
          4,
          7,
          4,
          4,
          11,
          11,
          9,
          10,
          8,
          8,
          10,
          4,
          8,
          3,
          10,
          9,
          9,
          13,
          11,
          8,
          4,
          12,
          10,
          11,
          6,
          14,
          6,
          11,
          12,
          11,
          15,
          10,
          4,
          7,
          11,
          4,
          10,
          5,
          11,
          3,
          10,
          9,
          9,
          3,
          9,
          11,
          14,
          8,
          17,
          6,
          9,
          7,
          10,
          10,
          2,
          11,
          3,
          7,
          5,
          8,
          6,
          2,
          6,
          9,
          10,
          13,
          10,
          10,
          11,
          5,
          6,
          7,
          6,
          9,
          7,
          10,
          13,
          11,
          14,
          2,
          12,
          12,
          9,
          14,
          2,
          7,
          8,
          6,
          10,
          7,
          10,
          6,
          8,
          9,
          8,
          9,
          12,
          15,
          10,
          2,
          5,
          11,
          6,
          6,
          9,
          8,
          7,
          4,
          9,
          12,
          3,
          10,
          7,
          11,
          10,
          9,
          13,
          4,
          4,
          10,
          11,
          10,
          5,
          5,
          10,
          12,
          11,
          4,
          5,
          9,
          8,
          5,
          10,
          5,
          9,
          8,
          10,
          11,
          2,
          7,
          6,
          8,
          6,
          10,
          11,
          11,
          11,
          5,
          8,
          6,
          6,
          7,
          14,
          12,
          9,
          8,
          13,
          12,
          13,
          11,
          8,
          10,
          5,
          11,
          3,
          10,
          16,
          6,
          10,
          5,
          9,
          12,
          5,
          10,
          12,
          6,
          8,
          5,
          12,
          14,
          15,
          12,
          9,
          4,
          3,
          10,
          11,
          9,
          8,
          6,
          16,
          4,
          11,
          10,
          10,
          15,
          6,
          7,
          6,
          11,
          14,
          7,
          7,
          5,
          7,
          15,
          4,
          7,
          13,
          13,
          6,
          8,
          11,
          12,
          8,
          6,
          7,
          13,
          8,
          8,
          12,
          4,
          13,
          12,
          6,
          6,
          8,
          5,
          4,
          11,
          11,
          10,
          2,
          16,
          7,
          6,
          12,
          8,
          4,
          7,
          9,
          7,
          8,
          2,
          7,
          3,
          7,
          7,
          8,
          9,
          10,
          4,
          4,
          6,
          5,
          7,
          11,
          8,
          10,
          9,
          11,
          3,
          1,
          4,
          10,
          2,
          8,
          8,
          10,
          11,
          8,
          8,
          8,
          10,
          1,
          6,
          9,
          7,
          5,
          10,
          11,
          11,
          11,
          9,
          10,
          4,
          16,
          7,
          5,
          12,
          13,
          12,
          17,
          14,
          6,
          11,
          11,
          9,
          6,
          11,
          13,
          11,
          15,
          7,
          9,
          12,
          6,
          11,
          7,
          12,
          15,
          12,
          3,
          3,
          3,
          4,
          11,
          10,
          18,
          10,
          7,
          8,
          6,
          12,
          13,
          4,
          9,
          7,
          4,
          16,
          8,
          10,
          3,
          9,
          3,
          10,
          7,
          2,
          16,
          10,
          11,
          6,
          9,
          11,
          12,
          9,
          9,
          14,
          11,
          7,
          9,
          3,
          9,
          11,
          12,
          5,
          6,
          11,
          10,
          15,
          15,
          10,
          9,
          16,
          7,
          2,
          5,
          11,
          9,
          9,
          7,
          11,
          12,
          15,
          6,
          4,
          8,
          12,
          13,
          8,
          3,
          3,
          12,
          8,
          13,
          10,
          12,
          14,
          13,
          12,
          10,
          9,
          8,
          13,
          10,
          12,
          13,
          5,
          2,
          11,
          14,
          9,
          9,
          12,
          12,
          8,
          16,
          7,
          13,
          13,
          11,
          11,
          9,
          8,
          9,
          8,
          8,
          13,
          9,
          8,
          5,
          5,
          13,
          13,
          3,
          6,
          8,
          11,
          8,
          7,
          7,
          12,
          8,
          12,
          11,
          11,
          7,
          8,
          7,
          9,
          6,
          9,
          3,
          9,
          8,
          7,
          11,
          5,
          11,
          12,
          6,
          16,
          3,
          5,
          8,
          9,
          4,
          5,
          12,
          8,
          11,
          9,
          16,
          13,
          9,
          8,
          6,
          2,
          12,
          12,
          10,
          5,
          9,
          10,
          10,
          13,
          11,
          4,
          7,
          8,
          11,
          3,
          3,
          13,
          7,
          10,
          10,
          12,
          4,
          2,
          6,
          3,
          13,
          11,
          6,
          10,
          11,
          6,
          13,
          7,
          3,
          5,
          4,
          12,
          11,
          7,
          7,
          10,
          10,
          4,
          12,
          8,
          10,
          11,
          11,
          12,
          10,
          9,
          16,
          5,
          3,
          12,
          11,
          10,
          4,
          4,
          4,
          9,
          7,
          14,
          6,
          10,
          11,
          5,
          13,
          12,
          7,
          10,
          15,
          4,
          7,
          11,
          5,
          8,
          4,
          10,
          8,
          8,
          12,
          10,
          6,
          7,
          8,
          13,
          6,
          6,
          13,
          3,
          5,
          10,
          8,
          14,
          13,
          3,
          5,
          8,
          6,
          12,
          8,
          8,
          4,
          2,
          11,
          16,
          4,
          7,
          8,
          5,
          8,
          12,
          8,
          6,
          10,
          13,
          7,
          10,
          13,
          2,
          3,
          4,
          10,
          9,
          11,
          9,
          15,
          9,
          7,
          10,
          11,
          8,
          5,
          5,
          12,
          2,
          5,
          7,
          7,
          11,
          11,
          14,
          9,
          10,
          13,
          2,
          5,
          8,
          9,
          14,
          4,
          12,
          11,
          9,
          6,
          7,
          2,
          7,
          11,
          6,
          7,
          8,
          11,
          6,
          13,
          12,
          11,
          9,
          11,
          14,
          5,
          13,
          9,
          6,
          11,
          13,
          15,
          1,
          6,
          9,
          6,
          16,
          5,
          10,
          12,
          10,
          3,
          14,
          6,
          8,
          10,
          10,
          9,
          14,
          7,
          8,
          12,
          8,
          5,
          8,
          12,
          6,
          14,
          9,
          3,
          10,
          6,
          12,
          6,
          5,
          9,
          12,
          7,
          5,
          8,
          2,
          8,
          11,
          15,
          9,
          14,
          8,
          10,
          12,
          10,
          8,
          15,
          8,
          8,
          12,
          5,
          10,
          10,
          13,
          5,
          13,
          13,
          13,
          11,
          15,
          14,
          8,
          12,
          9,
          12,
          6,
          11,
          14,
          14,
          6,
          4,
          9,
          14,
          11,
          6,
          9,
          10,
          4,
          7,
          16,
          4,
          6,
          5,
          17,
          9,
          15,
          2,
          14,
          13,
          11,
          5,
          14,
          11,
          10,
          11,
          10,
          4,
          8,
          8,
          8,
          9,
          11,
          4,
          10,
          8,
          10,
          11,
          15,
          12,
          7,
          18,
          13,
          12,
          14,
          11,
          7,
          11,
          2,
          11,
          10,
          16,
          10,
          10,
          7,
          9,
          6,
          7,
          7,
          3,
          9,
          4,
          7,
          9,
          10,
          8,
          10,
          10,
          11,
          8,
          6,
          11,
          14,
          15,
          8,
          12,
          14,
          13,
          6,
          3,
          12,
          10,
          6,
          3,
          8,
          8,
          4,
          6,
          5,
          8
         ]
        }
       ],
       "layout": {
        "barmode": "overlay",
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"abb31a9c-c5df-456c-9212-5b417ba20223\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"abb31a9c-c5df-456c-9212-5b417ba20223\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'abb31a9c-c5df-456c-9212-5b417ba20223',\n",
       "                        [{\"histfunc\": \"count\", \"histnorm\": \"\", \"marker\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"line\": {\"color\": \"#4D5663\", \"width\": 1.3}}, \"opacity\": 0.8, \"orientation\": \"v\", \"type\": \"histogram\", \"uid\": \"50d858e7-57bb-4794-8384-16999520e854\", \"x\": [2, 15, 8, 6, 15, 4, 19, 14, 2, 2, 6, 8, 9, 8, 9, 16, 10, 14, 10, 7, 9, 8, 9, 7, 7, 8, 4, 10, 16, 1, 3, 6, 3, 14, 6, 9, 7, 15, 6, 6, 10, 14, 10, 15, 15, 6, 8, 12, 9, 4, 11, 11, 14, 10, 16, 9, 7, 11, 14, 6, 8, 4, 5, 5, 13, 4, 7, 8, 9, 10, 13, 8, 16, 11, 3, 7, 4, 2, 10, 11, 13, 13, 9, 6, 5, 10, 1, 7, 11, 6, 8, 4, 7, 12, 9, 12, 13, 10, 5, 15, 7, 4, 7, 11, 14, 9, 3, 13, 10, 6, 2, 11, 3, 3, 10, 4, 2, 15, 13, 10, 6, 8, 9, 16, 6, 9, 9, 11, 8, 10, 11, 8, 12, 6, 8, 10, 9, 9, 8, 10, 15, 7, 6, 8, 12, 7, 13, 9, 5, 12, 4, 10, 4, 10, 14, 7, 12, 7, 14, 11, 5, 8, 14, 12, 8, 10, 9, 2, 11, 7, 7, 6, 14, 4, 10, 7, 13, 13, 13, 14, 18, 8, 7, 7, 3, 4, 9, 11, 9, 12, 14, 7, 7, 10, 7, 7, 7, 6, 7, 12, 9, 8, 10, 13, 4, 7, 14, 5, 12, 11, 4, 5, 9, 2, 7, 7, 9, 9, 11, 14, 7, 13, 3, 6, 10, 11, 12, 15, 10, 12, 15, 15, 5, 8, 9, 9, 11, 10, 3, 3, 9, 2, 15, 9, 14, 7, 10, 6, 5, 12, 3, 8, 7, 5, 9, 11, 12, 16, 11, 12, 12, 8, 13, 11, 5, 9, 8, 9, 12, 11, 11, 17, 11, 11, 10, 5, 10, 14, 12, 7, 5, 11, 10, 9, 5, 9, 4, 6, 2, 14, 15, 1, 12, 13, 2, 1, 6, 6, 9, 13, 4, 5, 11, 11, 5, 10, 6, 3, 11, 12, 10, 4, 13, 10, 3, 8, 15, 12, 9, 4, 12, 8, 10, 12, 7, 10, 7, 10, 11, 15, 9, 7, 12, 15, 4, 4, 5, 4, 11, 5, 7, 5, 8, 13, 12, 14, 12, 11, 11, 11, 5, 13, 9, 11, 12, 9, 9, 14, 14, 9, 9, 9, 15, 6, 14, 14, 9, 10, 14, 11, 11, 6, 8, 13, 4, 9, 6, 6, 6, 8, 10, 8, 6, 13, 11, 12, 9, 10, 9, 13, 8, 9, 6, 6, 6, 9, 7, 14, 11, 12, 9, 10, 7, 11, 13, 14, 5, 7, 8, 8, 14, 7, 7, 11, 9, 9, 1, 4, 9, 12, 8, 13, 8, 9, 9, 11, 8, 5, 14, 8, 11, 6, 8, 6, 13, 5, 14, 5, 8, 2, 13, 8, 7, 13, 14, 7, 16, 12, 9, 6, 6, 10, 10, 7, 11, 7, 11, 9, 10, 14, 11, 6, 9, 8, 9, 8, 7, 14, 10, 8, 10, 8, 10, 7, 16, 14, 4, 13, 8, 3, 8, 8, 8, 11, 9, 7, 11, 4, 12, 12, 6, 3, 5, 6, 10, 1, 13, 13, 7, 12, 3, 5, 12, 10, 8, 11, 12, 12, 13, 13, 10, 13, 2, 8, 9, 11, 10, 14, 7, 8, 7, 15, 13, 10, 13, 7, 11, 4, 12, 6, 6, 12, 3, 4, 9, 6, 8, 7, 2, 14, 13, 8, 15, 13, 14, 10, 11, 13, 9, 7, 8, 8, 10, 7, 5, 17, 12, 6, 4, 7, 9, 9, 9, 9, 13, 4, 15, 13, 7, 18, 14, 5, 4, 6, 12, 4, 3, 9, 11, 10, 9, 13, 5, 11, 12, 6, 10, 11, 1, 14, 11, 12, 6, 9, 10, 7, 16, 10, 6, 7, 15, 10, 12, 12, 10, 13, 13, 10, 11, 10, 11, 9, 11, 9, 13, 9, 9, 9, 4, 12, 8, 10, 7, 14, 12, 10, 8, 10, 12, 12, 14, 10, 14, 7, 15, 14, 9, 10, 16, 13, 14, 12, 11, 11, 11, 9, 7, 7, 10, 13, 6, 7, 6, 11, 9, 12, 13, 17, 7, 8, 10, 14, 7, 12, 11, 5, 13, 14, 13, 13, 6, 12, 8, 15, 11, 8, 9, 15, 4, 8, 7, 6, 13, 8, 11, 10, 13, 13, 12, 9, 9, 12, 4, 11, 15, 4, 4, 7, 9, 6, 12, 5, 10, 9, 16, 5, 5, 5, 7, 10, 5, 1, 9, 9, 12, 9, 9, 7, 11, 8, 6, 6, 14, 5, 10, 9, 11, 11, 9, 4, 13, 6, 14, 8, 11, 14, 6, 10, 1, 6, 7, 10, 5, 6, 11, 10, 8, 10, 7, 11, 7, 7, 13, 3, 13, 7, 6, 7, 10, 7, 12, 3, 4, 10, 8, 8, 6, 10, 3, 8, 13, 11, 8, 12, 7, 10, 14, 3, 6, 12, 12, 4, 3, 8, 4, 8, 13, 10, 3, 11, 13, 8, 7, 5, 12, 8, 4, 6, 7, 8, 10, 9, 15, 11, 4, 9, 9, 9, 8, 5, 14, 6, 4, 9, 9, 5, 6, 6, 5, 9, 9, 6, 9, 8, 11, 11, 6, 11, 6, 12, 7, 13, 9, 8, 4, 4, 10, 10, 11, 4, 4, 2, 5, 4, 10, 4, 12, 9, 6, 7, 13, 13, 5, 11, 7, 8, 9, 7, 13, 13, 12, 7, 13, 5, 12, 8, 12, 10, 10, 7, 6, 5, 3, 3, 5, 3, 3, 21, 10, 13, 9, 12, 15, 8, 2, 12, 13, 8, 10, 14, 12, 13, 8, 10, 5, 13, 10, 12, 12, 10, 12, 12, 8, 13, 8, 14, 12, 7, 9, 9, 12, 3, 11, 8, 10, 9, 5, 1, 6, 15, 9, 12, 6, 11, 10, 3, 8, 6, 7, 9, 7, 11, 8, 12, 11, 12, 9, 14, 11, 12, 5, 6, 7, 11, 5, 8, 13, 7, 14, 6, 11, 12, 11, 9, 4, 9, 12, 11, 8, 12, 8, 10, 10, 12, 6, 13, 10, 12, 5, 8, 14, 11, 8, 8, 11, 14, 6, 11, 6, 3, 7, 14, 10, 6, 7, 14, 6, 13, 5, 9, 3, 13, 12, 10, 11, 10, 9, 1, 13, 5, 4, 13, 7, 10, 12, 14, 9, 11, 13, 11, 13, 6, 14, 16, 7, 12, 11, 13, 14, 7, 13, 12, 5, 8, 7, 8, 8, 3, 9, 9, 5, 13, 10, 8, 14, 11, 14, 1, 11, 12, 4, 11, 9, 13, 11, 6, 9, 10, 9, 9, 9, 12, 3, 10, 14, 9, 11, 4, 13, 1, 8, 14, 4, 10, 1, 2, 11, 6, 13, 7, 12, 11, 15, 4, 5, 10, 7, 7, 9, 14, 4, 10, 5, 8, 11, 13, 11, 13, 6, 8, 9, 16, 4, 8, 12, 7, 5, 9, 9, 5, 9, 9, 13, 10, 5, 10, 10, 14, 7, 9, 13, 12, 15, 9, 11, 5, 8, 4, 6, 9, 15, 9, 8, 13, 7, 2, 4, 4, 10, 8, 15, 11, 13, 12, 2, 9, 12, 7, 13, 9, 3, 9, 7, 9, 6, 11, 15, 13, 11, 6, 1, 7, 9, 5, 8, 8, 7, 6, 6, 2, 1, 10, 3, 6, 2, 5, 7, 5, 7, 7, 4, 5, 8, 6, 6, 14, 14, 9, 9, 9, 5, 14, 10, 7, 7, 11, 6, 11, 12, 11, 11, 8, 12, 9, 6, 3, 9, 7, 3, 9, 14, 11, 14, 3, 8, 5, 12, 7, 13, 11, 5, 10, 7, 5, 4, 18, 5, 13, 6, 10, 9, 4, 8, 8, 7, 9, 10, 10, 11, 3, 13, 13, 10, 12, 7, 3, 12, 4, 14, 11, 7, 11, 8, 8, 6, 15, 7, 9, 12, 10, 13, 8, 7, 9, 6, 9, 8, 9, 13, 4, 10, 6, 7, 10, 11, 12, 12, 10, 13, 8, 3, 6, 10, 9, 6, 13, 5, 7, 8, 3, 15, 7, 3, 6, 6, 2, 7, 6, 8, 8, 15, 8, 10, 8, 7, 4, 9, 3, 13, 13, 9, 8, 8, 3, 13, 10, 8, 16, 4, 9, 13, 14, 9, 7, 4, 8, 12, 12, 7, 6, 7, 3, 14, 8, 10, 11, 3, 15, 3, 8, 14, 12, 2, 5, 14, 10, 10, 7, 5, 8, 9, 16, 7, 5, 6, 8, 10, 11, 10, 12, 9, 14, 5, 10, 6, 5, 5, 10, 5, 5, 6, 7, 13, 5, 7, 14, 7, 11, 13, 9, 15, 7, 10, 6, 11, 2, 4, 6, 11, 13, 5, 9, 3, 2, 3, 5, 7, 12, 5, 13, 9, 7, 13, 10, 13, 7, 11, 11, 5, 10, 9, 17, 7, 12, 15, 13, 12, 1, 5, 11, 3, 10, 7, 7, 4, 6, 16, 13, 8, 6, 8, 8, 10, 7, 13, 7, 9, 15, 10, 11, 10, 12, 10, 12, 8, 10, 12, 14, 5, 7, 12, 10, 3, 10, 10, 10, 8, 4, 7, 9, 9, 9, 11, 8, 11, 10, 8, 5, 2, 13, 8, 16, 13, 8, 7, 7, 8, 10, 1, 16, 6, 4, 6, 6, 3, 12, 5, 9, 12, 5, 10, 7, 10, 7, 9, 11, 12, 11, 8, 9, 15, 10, 9, 3, 3, 10, 11, 12, 8, 4, 10, 6, 12, 7, 2, 15, 10, 10, 7, 15, 4, 9, 9, 13, 13, 12, 12, 5, 8, 10, 5, 5, 13, 11, 10, 5, 8, 6, 7, 8, 6, 10, 5, 6, 5, 15, 7, 3, 9, 8, 2, 5, 10, 14, 4, 7, 10, 8, 4, 12, 3, 8, 8, 3, 17, 13, 14, 17, 3, 6, 12, 6, 10, 1, 12, 8, 9, 2, 7, 12, 10, 9, 12, 11, 6, 11, 6, 8, 10, 12, 5, 12, 10, 3, 10, 11, 13, 15, 14, 2, 4, 10, 7, 11, 6, 9, 4, 6, 13, 11, 5, 13, 4, 12, 9, 11, 10, 1, 11, 5, 15, 8, 8, 4, 15, 5, 5, 4, 18, 6, 10, 6, 9, 11, 10, 14, 10, 13, 3, 5, 8, 6, 9, 13, 8, 8, 9, 6, 6, 10, 16, 9, 6, 16, 11, 1, 12, 5, 9, 16, 13, 8, 12, 8, 9, 11, 11, 8, 9, 8, 10, 6, 13, 4, 8, 14, 15, 9, 13, 4, 7, 9, 9, 12, 8, 3, 3, 5, 11, 10, 13, 13, 10, 10, 4, 6, 6, 14, 8, 15, 12, 9, 11, 4, 5, 10, 8, 14, 12, 11, 5, 9, 12, 10, 14, 7, 4, 7, 6, 4, 4, 6, 11, 11, 7, 10, 7, 8, 7, 11, 10, 8, 10, 12, 14, 8, 8, 7, 6, 7, 9, 4, 6, 13, 13, 12, 12, 6, 5, 9, 10, 1, 10, 10, 11, 3, 7, 12, 8, 5, 9, 3, 7, 2, 11, 9, 9, 13, 10, 10, 7, 9, 8, 10, 8, 10, 8, 6, 12, 3, 9, 6, 0, 6, 13, 7, 12, 3, 14, 7, 11, 8, 5, 6, 7, 9, 7, 5, 9, 2, 4, 7, 7, 9, 5, 10, 12, 8, 18, 11, 7, 5, 2, 12, 10, 11, 14, 4, 6, 10, 13, 10, 10, 12, 10, 11, 1, 8, 4, 12, 9, 9, 12, 8, 9, 6, 10, 8, 6, 11, 4, 15, 11, 12, 6, 12, 6, 7, 11, 11, 8, 6, 12, 12, 10, 10, 15, 12, 10, 15, 11, 10, 11, 8, 10, 14, 10, 6, 4, 10, 8, 8, 6, 9, 12, 13, 12, 7, 8, 14, 7, 11, 11, 11, 4, 6, 6, 13, 12, 9, 10, 11, 8, 9, 11, 9, 14, 8, 5, 10, 3, 10, 12, 8, 6, 9, 12, 9, 11, 11, 8, 9, 15, 4, 13, 1, 12, 10, 6, 4, 14, 9, 14, 15, 5, 9, 8, 13, 9, 7, 5, 8, 12, 6, 9, 8, 8, 8, 3, 8, 5, 9, 4, 6, 7, 8, 8, 3, 7, 11, 12, 6, 7, 9, 2, 5, 12, 6, 8, 12, 12, 16, 12, 5, 16, 13, 7, 8, 7, 15, 4, 13, 10, 9, 4, 6, 4, 8, 10, 13, 11, 9, 4, 8, 8, 8, 12, 6, 8, 5, 11, 8, 10, 12, 10, 6, 13, 6, 8, 8, 10, 9, 14, 14, 28, 9, 14, 4, 4, 6, 10, 5, 3, 16, 4, 13, 9, 9, 15, 7, 14, 13, 11, 14, 9, 10, 8, 11, 14, 6, 11, 10, 11, 11, 14, 9, 15, 6, 9, 14, 9, 8, 13, 9, 16, 12, 8, 15, 10, 4, 12, 11, 4, 3, 14, 11, 15, 4, 8, 8, 6, 5, 12, 5, 11, 11, 10, 9, 13, 9, 11, 7, 15, 9, 7, 2, 13, 4, 13, 7, 11, 11, 11, 11, 5, 4, 2, 8, 7, 8, 15, 11, 11, 4, 5, 7, 12, 9, 7, 11, 5, 9, 12, 6, 9, 8, 15, 8, 13, 9, 11, 12, 9, 12, 6, 9, 6, 8, 16, 11, 12, 9, 12, 9, 10, 8, 9, 12, 8, 5, 2, 2, 11, 9, 9, 12, 4, 8, 11, 10, 9, 10, 12, 10, 10, 9, 11, 12, 12, 10, 10, 10, 14, 12, 7, 6, 9, 4, 12, 10, 6, 10, 8, 9, 3, 17, 7, 14, 10, 7, 8, 10, 8, 10, 1, 2, 5, 3, 12, 13, 9, 13, 13, 9, 4, 10, 7, 5, 4, 4, 8, 14, 16, 8, 8, 8, 9, 12, 1, 13, 4, 7, 8, 12, 10, 6, 10, 11, 11, 6, 10, 7, 14, 12, 8, 9, 13, 5, 10, 14, 15, 11, 5, 12, 9, 8, 12, 4, 7, 14, 9, 5, 5, 7, 13, 6, 4, 11, 5, 8, 12, 7, 1, 11, 12, 6, 14, 8, 7, 7, 8, 3, 11, 13, 12, 8, 11, 4, 10, 6, 12, 11, 11, 4, 6, 14, 7, 8, 14, 7, 5, 6, 6, 10, 7, 7, 14, 10, 8, 2, 3, 4, 12, 11, 13, 5, 4, 16, 9, 11, 15, 9, 10, 6, 12, 12, 9, 9, 6, 10, 10, 10, 13, 13, 10, 10, 16, 2, 10, 14, 10, 4, 4, 10, 5, 9, 6, 12, 9, 10, 5, 4, 7, 4, 12, 10, 4, 12, 13, 7, 10, 13, 12, 3, 6, 11, 13, 2, 7, 7, 13, 12, 10, 6, 7, 12, 12, 13, 14, 3, 13, 11, 1, 10, 11, 10, 12, 5, 5, 6, 3, 3, 9, 7, 15, 6, 7, 9, 7, 9, 8, 12, 5, 7, 3, 2, 3, 3, 4, 16, 14, 7, 11, 3, 10, 12, 4, 10, 12, 7, 5, 4, 8, 9, 13, 12, 8, 5, 6, 8, 6, 11, 7, 3, 12, 17, 3, 3, 11, 5, 9, 8, 18, 11, 10, 2, 6, 13, 5, 6, 6, 11, 16, 5, 3, 8, 11, 7, 5, 4, 12, 2, 17, 9, 14, 11, 10, 7, 4, 8, 12, 8, 11, 6, 8, 6, 12, 15, 9, 9, 8, 9, 6, 2, 11, 5, 5, 15, 9, 10, 13, 9, 3, 9, 14, 14, 10, 8, 6, 12, 5, 1, 5, 11, 10, 9, 11, 11, 11, 13, 14, 12, 13, 10, 6, 8, 4, 7, 8, 5, 5, 8, 13, 14, 10, 9, 11, 4, 9, 11, 10, 12, 14, 8, 15, 15, 13, 10, 10, 9, 9, 5, 7, 4, 8, 3, 7, 11, 9, 9, 4, 4, 18, 8, 13, 11, 12, 8, 16, 14, 11, 8, 6, 13, 12, 12, 7, 11, 13, 11, 9, 6, 12, 7, 13, 7, 14, 11, 6, 8, 9, 12, 10, 10, 17, 5, 9, 4, 9, 8, 15, 7, 4, 4, 6, 15, 16, 18, 7, 10, 7, 11, 14, 10, 13, 8, 9, 11, 12, 5, 9, 11, 3, 9, 11, 10, 4, 9, 8, 12, 7, 12, 6, 4, 14, 7, 14, 9, 4, 4, 4, 3, 4, 13, 8, 6, 10, 7, 7, 12, 17, 17, 3, 8, 3, 8, 8, 9, 10, 4, 3, 12, 11, 17, 9, 9, 5, 12, 10, 4, 5, 12, 9, 2, 10, 8, 5, 4, 11, 12, 13, 12, 7, 7, 13, 4, 7, 9, 10, 13, 12, 8, 14, 15, 6, 4, 5, 5, 8, 6, 6, 11, 10, 8, 10, 6, 3, 9, 11, 6, 11, 8, 11, 9, 0, 6, 10, 9, 5, 8, 8, 7, 8, 12, 11, 12, 5, 12, 10, 5, 10, 11, 16, 3, 11, 6, 9, 9, 12, 12, 11, 13, 8, 16, 9, 16, 8, 11, 6, 9, 5, 7, 10, 15, 4, 15, 6, 9, 15, 14, 12, 9, 2, 4, 7, 12, 10, 4, 12, 15, 15, 4, 1, 10, 13, 16, 8, 12, 11, 5, 11, 7, 3, 11, 7, 10, 12, 8, 6, 10, 10, 7, 11, 5, 11, 6, 7, 2, 8, 5, 7, 11, 8, 8, 13, 9, 9, 6, 11, 10, 7, 13, 9, 6, 13, 11, 10, 13, 11, 12, 12, 6, 2, 14, 2, 6, 9, 10, 5, 9, 8, 8, 13, 14, 7, 10, 4, 12, 10, 12, 8, 13, 7, 10, 14, 3, 13, 13, 4, 10, 5, 15, 12, 3, 9, 5, 9, 7, 9, 7, 3, 8, 5, 13, 8, 6, 9, 8, 11, 13, 10, 7, 7, 11, 13, 7, 6, 10, 13, 10, 6, 9, 10, 6, 5, 12, 7, 11, 13, 6, 6, 9, 16, 13, 3, 7, 11, 7, 14, 5, 5, 10, 11, 4, 8, 17, 5, 8, 2, 12, 10, 4, 4, 15, 13, 3, 13, 8, 8, 11, 6, 14, 9, 11, 3, 12, 8, 12, 7, 11, 12, 4, 7, 6, 11, 3, 1, 5, 2, 10, 11, 5, 6, 14, 3, 5, 11, 8, 3, 4, 12, 4, 9, 11, 2, 11, 5, 3, 9, 5, 9, 9, 11, 5, 5, 7, 6, 11, 8, 3, 12, 4, 9, 9, 11, 11, 11, 9, 10, 7, 12, 10, 9, 4, 8, 9, 10, 2, 16, 0, 7, 11, 6, 2, 11, 10, 11, 8, 6, 9, 7, 10, 13, 5, 7, 9, 6, 16, 14, 7, 7, 1, 2, 16, 13, 8, 12, 11, 2, 10, 12, 4, 8, 16, 6, 7, 11, 6, 8, 7, 3, 11, 12, 7, 10, 12, 7, 3, 12, 11, 5, 15, 4, 8, 4, 10, 8, 8, 9, 12, 7, 11, 7, 15, 5, 8, 15, 12, 12, 8, 2, 12, 11, 14, 5, 6, 11, 12, 11, 6, 9, 6, 6, 4, 10, 7, 7, 12, 13, 4, 10, 7, 4, 7, 2, 9, 8, 14, 8, 6, 11, 5, 9, 11, 5, 0, 5, 4, 8, 2, 3, 13, 10, 8, 4, 2, 7, 8, 10, 5, 10, 6, 6, 10, 8, 12, 5, 7, 9, 10, 7, 8, 14, 4, 13, 5, 7, 6, 8, 4, 10, 11, 6, 11, 10, 7, 10, 6, 14, 9, 7, 6, 10, 4, 8, 11, 3, 9, 3, 8, 8, 15, 7, 13, 11, 10, 3, 9, 11, 13, 10, 10, 9, 2, 4, 8, 11, 6, 6, 4, 7, 5, 14, 9, 13, 12, 6, 15, 3, 5, 5, 12, 17, 14, 13, 15, 12, 14, 11, 10, 15, 13, 0, 10, 9, 7, 8, 13, 11, 10, 6, 10, 11, 9, 11, 15, 11, 11, 15, 5, 12, 13, 14, 13, 11, 10, 5, 7, 9, 13, 11, 6, 14, 11, 3, 11, 12, 11, 10, 13, 15, 8, 3, 12, 13, 8, 7, 13, 5, 16, 4, 2, 11, 11, 7, 10, 9, 3, 12, 12, 13, 13, 8, 10, 10, 9, 8, 13, 7, 8, 13, 13, 13, 7, 9, 7, 11, 10, 5, 3, 7, 11, 12, 14, 14, 6, 1, 3, 8, 9, 6, 10, 14, 6, 6, 4, 12, 3, 13, 5, 12, 10, 10, 13, 13, 7, 2, 10, 7, 8, 2, 9, 11, 10, 10, 12, 7, 12, 8, 7, 8, 9, 9, 6, 15, 7, 4, 11, 7, 14, 4, 2, 13, 9, 14, 10, 14, 5, 6, 12, 13, 13, 15, 5, 9, 4, 15, 5, 8, 8, 7, 8, 9, 13, 7, 11, 13, 13, 5, 12, 5, 10, 9, 12, 5, 13, 6, 11, 10, 5, 14, 9, 16, 2, 12, 3, 2, 9, 11, 4, 3, 10, 7, 4, 3, 9, 15, 8, 8, 7, 10, 11, 10, 7, 7, 15, 6, 5, 12, 9, 11, 12, 5, 12, 13, 10, 8, 10, 2, 12, 11, 9, 14, 7, 13, 10, 7, 12, 8, 10, 4, 2, 10, 9, 6, 11, 7, 16, 11, 15, 5, 16, 4, 3, 9, 14, 10, 2, 12, 7, 9, 7, 5, 6, 9, 8, 5, 11, 7, 12, 14, 10, 14, 4, 15, 7, 13, 5, 9, 15, 12, 9, 6, 14, 8, 6, 13, 9, 10, 10, 10, 10, 2, 9, 11, 1, 12, 7, 6, 12, 10, 11, 7, 9, 13, 14, 10, 10, 6, 7, 8, 5, 8, 11, 13, 8, 15, 2, 4, 10, 8, 4, 11, 2, 13, 9, 8, 13, 9, 6, 5, 12, 5, 2, 9, 17, 10, 9, 7, 13, 6, 4, 4, 15, 10, 13, 12, 10, 8, 7, 5, 11, 10, 13, 4, 12, 9, 7, 6, 12, 13, 8, 8, 11, 6, 12, 13, 11, 6, 5, 9, 3, 13, 9, 13, 15, 4, 4, 7, 10, 11, 14, 7, 9, 9, 3, 1, 9, 6, 5, 7, 7, 15, 12, 9, 11, 10, 8, 12, 19, 9, 2, 9, 11, 8, 5, 4, 6, 8, 11, 7, 13, 15, 10, 11, 9, 11, 4, 5, 10, 10, 5, 12, 9, 5, 5, 8, 9, 9, 1, 5, 11, 7, 10, 2, 1, 8, 9, 11, 13, 4, 4, 15, 12, 9, 4, 8, 9, 9, 11, 8, 7, 10, 9, 7, 12, 10, 10, 9, 4, 7, 3, 4, 4, 6, 13, 11, 8, 9, 1, 2, 5, 6, 16, 10, 8, 10, 7, 9, 8, 6, 4, 11, 8, 16, 11, 6, 6, 8, 3, 7, 14, 15, 8, 9, 9, 6, 11, 11, 5, 4, 8, 10, 6, 3, 5, 1, 12, 10, 10, 13, 12, 12, 11, 5, 4, 2, 3, 5, 8, 11, 12, 6, 13, 12, 15, 3, 2, 11, 8, 5, 14, 7, 11, 12, 11, 14, 11, 12, 9, 16, 10, 6, 13, 16, 6, 8, 11, 15, 8, 9, 10, 12, 11, 11, 1, 11, 5, 11, 13, 2, 8, 2, 5, 10, 12, 10, 16, 13, 8, 12, 10, 14, 16, 12, 3, 5, 13, 6, 10, 9, 5, 2, 10, 5, 11, 11, 13, 14, 8, 13, 8, 5, 12, 6, 8, 7, 7, 15, 11, 10, 10, 5, 11, 6, 1, 3, 11, 5, 10, 4, 1, 13, 10, 10, 9, 8, 10, 10, 9, 12, 4, 6, 9, 5, 13, 6, 2, 10, 2, 8, 14, 6, 9, 11, 9, 12, 11, 8, 9, 3, 3, 6, 3, 1, 8, 12, 14, 10, 10, 11, 4, 8, 8, 8, 7, 11, 1, 6, 13, 8, 13, 9, 2, 6, 8, 4, 6, 12, 5, 9, 6, 4, 5, 9, 4, 10, 13, 8, 7, 11, 10, 12, 4, 9, 9, 4, 6, 12, 13, 15, 10, 14, 10, 9, 4, 8, 3, 10, 3, 7, 3, 12, 12, 7, 8, 7, 9, 14, 8, 12, 9, 6, 12, 8, 8, 13, 3, 7, 7, 9, 10, 12, 8, 10, 13, 9, 9, 6, 12, 9, 9, 9, 4, 8, 11, 6, 8, 3, 7, 11, 9, 10, 7, 8, 7, 7, 2, 5, 6, 15, 10, 4, 11, 12, 9, 7, 6, 11, 12, 11, 8, 7, 5, 9, 5, 4, 11, 12, 9, 9, 13, 9, 4, 7, 4, 4, 11, 11, 9, 10, 8, 8, 10, 4, 8, 3, 10, 9, 9, 13, 11, 8, 4, 12, 10, 11, 6, 14, 6, 11, 12, 11, 15, 10, 4, 7, 11, 4, 10, 5, 11, 3, 10, 9, 9, 3, 9, 11, 14, 8, 17, 6, 9, 7, 10, 10, 2, 11, 3, 7, 5, 8, 6, 2, 6, 9, 10, 13, 10, 10, 11, 5, 6, 7, 6, 9, 7, 10, 13, 11, 14, 2, 12, 12, 9, 14, 2, 7, 8, 6, 10, 7, 10, 6, 8, 9, 8, 9, 12, 15, 10, 2, 5, 11, 6, 6, 9, 8, 7, 4, 9, 12, 3, 10, 7, 11, 10, 9, 13, 4, 4, 10, 11, 10, 5, 5, 10, 12, 11, 4, 5, 9, 8, 5, 10, 5, 9, 8, 10, 11, 2, 7, 6, 8, 6, 10, 11, 11, 11, 5, 8, 6, 6, 7, 14, 12, 9, 8, 13, 12, 13, 11, 8, 10, 5, 11, 3, 10, 16, 6, 10, 5, 9, 12, 5, 10, 12, 6, 8, 5, 12, 14, 15, 12, 9, 4, 3, 10, 11, 9, 8, 6, 16, 4, 11, 10, 10, 15, 6, 7, 6, 11, 14, 7, 7, 5, 7, 15, 4, 7, 13, 13, 6, 8, 11, 12, 8, 6, 7, 13, 8, 8, 12, 4, 13, 12, 6, 6, 8, 5, 4, 11, 11, 10, 2, 16, 7, 6, 12, 8, 4, 7, 9, 7, 8, 2, 7, 3, 7, 7, 8, 9, 10, 4, 4, 6, 5, 7, 11, 8, 10, 9, 11, 3, 1, 4, 10, 2, 8, 8, 10, 11, 8, 8, 8, 10, 1, 6, 9, 7, 5, 10, 11, 11, 11, 9, 10, 4, 16, 7, 5, 12, 13, 12, 17, 14, 6, 11, 11, 9, 6, 11, 13, 11, 15, 7, 9, 12, 6, 11, 7, 12, 15, 12, 3, 3, 3, 4, 11, 10, 18, 10, 7, 8, 6, 12, 13, 4, 9, 7, 4, 16, 8, 10, 3, 9, 3, 10, 7, 2, 16, 10, 11, 6, 9, 11, 12, 9, 9, 14, 11, 7, 9, 3, 9, 11, 12, 5, 6, 11, 10, 15, 15, 10, 9, 16, 7, 2, 5, 11, 9, 9, 7, 11, 12, 15, 6, 4, 8, 12, 13, 8, 3, 3, 12, 8, 13, 10, 12, 14, 13, 12, 10, 9, 8, 13, 10, 12, 13, 5, 2, 11, 14, 9, 9, 12, 12, 8, 16, 7, 13, 13, 11, 11, 9, 8, 9, 8, 8, 13, 9, 8, 5, 5, 13, 13, 3, 6, 8, 11, 8, 7, 7, 12, 8, 12, 11, 11, 7, 8, 7, 9, 6, 9, 3, 9, 8, 7, 11, 5, 11, 12, 6, 16, 3, 5, 8, 9, 4, 5, 12, 8, 11, 9, 16, 13, 9, 8, 6, 2, 12, 12, 10, 5, 9, 10, 10, 13, 11, 4, 7, 8, 11, 3, 3, 13, 7, 10, 10, 12, 4, 2, 6, 3, 13, 11, 6, 10, 11, 6, 13, 7, 3, 5, 4, 12, 11, 7, 7, 10, 10, 4, 12, 8, 10, 11, 11, 12, 10, 9, 16, 5, 3, 12, 11, 10, 4, 4, 4, 9, 7, 14, 6, 10, 11, 5, 13, 12, 7, 10, 15, 4, 7, 11, 5, 8, 4, 10, 8, 8, 12, 10, 6, 7, 8, 13, 6, 6, 13, 3, 5, 10, 8, 14, 13, 3, 5, 8, 6, 12, 8, 8, 4, 2, 11, 16, 4, 7, 8, 5, 8, 12, 8, 6, 10, 13, 7, 10, 13, 2, 3, 4, 10, 9, 11, 9, 15, 9, 7, 10, 11, 8, 5, 5, 12, 2, 5, 7, 7, 11, 11, 14, 9, 10, 13, 2, 5, 8, 9, 14, 4, 12, 11, 9, 6, 7, 2, 7, 11, 6, 7, 8, 11, 6, 13, 12, 11, 9, 11, 14, 5, 13, 9, 6, 11, 13, 15, 1, 6, 9, 6, 16, 5, 10, 12, 10, 3, 14, 6, 8, 10, 10, 9, 14, 7, 8, 12, 8, 5, 8, 12, 6, 14, 9, 3, 10, 6, 12, 6, 5, 9, 12, 7, 5, 8, 2, 8, 11, 15, 9, 14, 8, 10, 12, 10, 8, 15, 8, 8, 12, 5, 10, 10, 13, 5, 13, 13, 13, 11, 15, 14, 8, 12, 9, 12, 6, 11, 14, 14, 6, 4, 9, 14, 11, 6, 9, 10, 4, 7, 16, 4, 6, 5, 17, 9, 15, 2, 14, 13, 11, 5, 14, 11, 10, 11, 10, 4, 8, 8, 8, 9, 11, 4, 10, 8, 10, 11, 15, 12, 7, 18, 13, 12, 14, 11, 7, 11, 2, 11, 10, 16, 10, 10, 7, 9, 6, 7, 7, 3, 9, 4, 7, 9, 10, 8, 10, 10, 11, 8, 6, 11, 14, 15, 8, 12, 14, 13, 6, 3, 12, 10, 6, 3, 8, 8, 4, 6, 5, 8]}],\n",
       "                        {\"barmode\": \"overlay\", \"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('abb31a9c-c5df-456c-9212-5b417ba20223');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_df.count().iplot(kind='histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de que la mayoría de documentos tienen un máximo de 10 palabras, vamos a utilizar las 28 de máximo debido a la poca cantidad de datos de entrenamiento de la que disponemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:36.526034Z",
     "start_time": "2019-06-14T06:36:36.185672Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "marker": {
          "color": "rgba(255, 153, 51, 0.6)",
          "line": {
           "color": "rgba(255, 153, 51, 1.0)",
           "width": 1
          }
         },
         "name": "0",
         "orientation": "v",
         "text": "",
         "type": "bar",
         "uid": "645e6236-c4bf-4ae8-8669-5fc0ac0eed07",
         "x": [
          0,
          1
         ],
         "y": [
          19513,
          22009
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"a24044e9-6b77-4d08-8fac-3dbdbbf49584\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"a24044e9-6b77-4d08-8fac-3dbdbbf49584\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'a24044e9-6b77-4d08-8fac-3dbdbbf49584',\n",
       "                        [{\"marker\": {\"color\": \"rgba(255, 153, 51, 0.6)\", \"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"width\": 1}}, \"name\": \"0\", \"orientation\": \"v\", \"text\": \"\", \"type\": \"bar\", \"uid\": \"645e6236-c4bf-4ae8-8669-5fc0ac0eed07\", \"x\": [0, 1], \"y\": [19513, 22009]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a24044e9-6b77-4d08-8fac-3dbdbbf49584');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame([token_df[x].count().sum() for x in token_df.columns.levels[0]]).iplot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cantidad de palabras por polaridad es bastante similar, aunque la diferencia puede llegar a suponer un problema en el resultado final según la distribución de los conjuntos de entrenamiento y de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w2vec process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos las palabras que no se encuentran en el diccionario, probablemente por estar mal escritas como enorahuena en lugar de enhorabuena, en este caso los stems serían enorahuen y enhorabuen respectivamente, como vemos hay una diferencia de dos letras\n",
    "\n",
    "Basandonos en esto vamos a establecer una diferencia máxima de 3 letras para considerar la palabra sustituible por la palabra correcta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem_vocab = np.array([stemmer.stem(x) for x in model.vocab])\n",
    "stem_vocab = np.array([x for x in model.vocab])\n",
    "stem_vocab_dict = dict.fromkeys(stem_vocab, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "asci_codes = [np.array([ord(x) for x in y]) for y in stem_vocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La palabra más larga del español según la RAE es electroencefalografista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"electroencefalografista\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_asci_codes = tf.keras.preprocessing.sequence.pad_sequences(asci_codes, maxlen=23, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0618 18:01:31.216591 139968762341184 callbacks.py:1475] `batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
      "W0618 18:01:31.219434 139968762341184 callbacks.py:1479] `embeddings_layer_names` is not supported in TensorFlow 2.0. Instead, all `Embedding` layers will be visualized.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(len(word_index), 300, input_length=12, weights=[weight_matrix], name='Embedding', trainable=False),\n",
    "    tf.keras.layers.LSTM(64, activation='relu', name='lstm'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid' ,name='dense')\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir, embeddings_freq=1, write_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No encontradas en vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:41.131383Z",
     "start_time": "2019-06-14T06:36:37.415416Z"
    }
   },
   "outputs": [],
   "source": [
    "not_in_vocab = pd.concat([token_df[d][token_df[d].apply(lambda x: x not in stem_vocab_dict)] for d in token_df.columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:41.149870Z",
     "start_time": "2019-06-14T06:36:41.134066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total de palabras no encontradas en el vocabulario 1935\n",
      "media de palabras no encontradas en el conjunto 0.4117021276595745\n"
     ]
    }
   ],
   "source": [
    "print('total de palabras no encontradas en el vocabulario', not_in_vocab.count().sum())\n",
    "print('media de palabras no encontradas en el conjunto', not_in_vocab.count().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:41.486824Z",
     "start_time": "2019-06-14T06:36:41.151019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "marker": {
          "color": "rgba(255, 153, 51, 0.6)",
          "line": {
           "color": "rgba(255, 153, 51, 1.0)",
           "width": 1
          }
         },
         "name": "0",
         "orientation": "v",
         "text": "",
         "type": "bar",
         "uid": "42c9dd68-5a04-4729-8543-d68dde0724cb",
         "x": [
          0,
          1
         ],
         "y": [
          771,
          1164
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"57b2b2fa-34ba-40d9-a024-0aa18f8ec8ac\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"57b2b2fa-34ba-40d9-a024-0aa18f8ec8ac\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '57b2b2fa-34ba-40d9-a024-0aa18f8ec8ac',\n",
       "                        [{\"marker\": {\"color\": \"rgba(255, 153, 51, 0.6)\", \"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"width\": 1}}, \"name\": \"0\", \"orientation\": \"v\", \"text\": \"\", \"type\": \"bar\", \"uid\": \"42c9dd68-5a04-4729-8543-d68dde0724cb\", \"x\": [0, 1], \"y\": [771, 1164]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('57b2b2fa-34ba-40d9-a024-0aa18f8ec8ac');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame([not_in_vocab[x].count().sum() for x in not_in_vocab.columns.levels[0]]).iplot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:41.491271Z",
     "start_time": "2019-06-14T06:36:41.488319Z"
    }
   },
   "outputs": [],
   "source": [
    "not_in_vocab.columns = not_in_vocab.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:42.838212Z",
     "start_time": "2019-06-14T06:36:41.492591Z"
    }
   },
   "outputs": [],
   "source": [
    "not_in_vocab_words = pd.DataFrame(\n",
    "    [x for sublist in [not_in_vocab[y].dropna().values for y in not_in_vocab.columns] for x in sublist]\n",
    ").drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encontradas en vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:46.445962Z",
     "start_time": "2019-06-14T06:36:42.839575Z"
    }
   },
   "outputs": [],
   "source": [
    "in_vocab = pd.concat([token_df[d][token_df[d].apply(lambda x: x in stem_vocab_dict)] for d in token_df.columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:46.454545Z",
     "start_time": "2019-06-14T06:36:46.449381Z"
    }
   },
   "outputs": [],
   "source": [
    "in_vocab.columns = in_vocab.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:47.763268Z",
     "start_time": "2019-06-14T06:36:46.455762Z"
    }
   },
   "outputs": [],
   "source": [
    "in_vocab_words = pd.DataFrame(\n",
    "    [x for sublist in [in_vocab[y].dropna().values for y in in_vocab.columns] for x in sublist]\n",
    ").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4690</th>\n",
       "      <th>4691</th>\n",
       "      <th>4692</th>\n",
       "      <th>4693</th>\n",
       "      <th>4694</th>\n",
       "      <th>4695</th>\n",
       "      <th>4696</th>\n",
       "      <th>4697</th>\n",
       "      <th>4698</th>\n",
       "      <th>4699</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gracias</td>\n",
       "      <td>off</td>\n",
       "      <td>conozco</td>\n",
       "      <td>toca</td>\n",
       "      <td>buen</td>\n",
       "      <td>escaño</td>\n",
       "      <td>buenos</td>\n",
       "      <td>sistema</td>\n",
       "      <td>caca</td>\n",
       "      <td>buen</td>\n",
       "      <td>...</td>\n",
       "      <td>ya</td>\n",
       "      <td>rajoy</td>\n",
       "      <td>rick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nace</td>\n",
       "      <td>muy</td>\n",
       "      <td>más</td>\n",
       "      <td>crean</td>\n",
       "      <td>sorprendente</td>\n",
       "      <td>está</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mar</td>\n",
       "      <td>pensando</td>\n",
       "      <td>adicto</td>\n",
       "      <td>grabación</td>\n",
       "      <td>día</td>\n",
       "      <td>listo</td>\n",
       "      <td>días</td>\n",
       "      <td>económico</td>\n",
       "      <td>ajuste</td>\n",
       "      <td>viernes</td>\n",
       "      <td>...</td>\n",
       "      <td>dos</td>\n",
       "      <td>da</td>\n",
       "      <td>santorum</td>\n",
       "      <td>será</td>\n",
       "      <td>jirafa</td>\n",
       "      <td>indignante</td>\n",
       "      <td>pobres</td>\n",
       "      <td>banco</td>\n",
       "      <td>huída</td>\n",
       "      <td>muy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>regalito</td>\n",
       "      <td>drama</td>\n",
       "      <td>especial</td>\n",
       "      <td>primero</td>\n",
       "      <td>empezar</td>\n",
       "      <td>em</td>\n",
       "      <td>recorta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ganas</td>\n",
       "      <td>espalda</td>\n",
       "      <td>retira</td>\n",
       "      <td>presidente</td>\n",
       "      <td>primera</td>\n",
       "      <td>si</td>\n",
       "      <td>discriminar</td>\n",
       "      <td>productos</td>\n",
       "      <td>hoy</td>\n",
       "      <td>bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>sinde</td>\n",
       "      <td>ja</td>\n",
       "      <td>navideño</td>\n",
       "      <td>mandar</td>\n",
       "      <td>congreso</td>\n",
       "      <td>no</td>\n",
       "      <td>dinero</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>verte</td>\n",
       "      <td>post</td>\n",
       "      <td>campaña</td>\n",
       "      <td>NaN</td>\n",
       "      <td>su</td>\n",
       "      <td>repara</td>\n",
       "      <td>mujer</td>\n",
       "      <td>mujeres</td>\n",
       "      <td>senado</td>\n",
       "      <td>versión</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>va</td>\n",
       "      <td>ja</td>\n",
       "      <td>mari</td>\n",
       "      <td>abrazo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ira</td>\n",
       "      <td>prestaciones</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>rt</td>\n",
       "      <td>buzón</td>\n",
       "      <td>primarias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>especie</td>\n",
       "      <td>hoy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cáncer</td>\n",
       "      <td>rajoy</td>\n",
       "      <td>gallega</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1        2          3        4         5       6     \\\n",
       "0  gracias       off  conozco       toca     buen    escaño  buenos   \n",
       "1      mar  pensando   adicto  grabación      día     listo    días   \n",
       "2      NaN  regalito    drama   especial  primero   empezar      em   \n",
       "3      NaN     sinde       ja   navideño   mandar  congreso      no   \n",
       "4      NaN        va       ja       mari   abrazo       NaN     ira   \n",
       "\n",
       "           7       8        9     ...   4690     4691       4692        4693  \\\n",
       "0       sistema    caca     buen  ...     ya    rajoy       rick         NaN   \n",
       "1     económico  ajuste  viernes  ...    dos       da   santorum        será   \n",
       "2       recorta     NaN      NaN  ...  ganas  espalda     retira  presidente   \n",
       "3        dinero     NaN      NaN  ...  verte     post    campaña         NaN   \n",
       "4  prestaciones     NaN      NaN  ...     rt    buzón  primarias         NaN   \n",
       "\n",
       "      4694        4695         4696       4697          4698     4699  \n",
       "0     nace         muy          más      crean  sorprendente     está  \n",
       "1   jirafa  indignante       pobres      banco         huída      muy  \n",
       "2  primera          si  discriminar  productos           hoy     bien  \n",
       "3       su      repara        mujer    mujeres        senado  versión  \n",
       "4  especie         hoy          NaN     cáncer         rajoy  gallega  \n",
       "\n",
       "[5 rows x 4700 columns]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_vocab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:47.873341Z",
     "start_time": "2019-06-14T06:36:47.764447Z"
    }
   },
   "outputs": [],
   "source": [
    "def replace_words(w):\n",
    "    found_positions = np.where(stem_vocab == w)[0]\n",
    "    return model[vocab_keys[found_positions[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_levenshtein(word, dictionary):\n",
    "    ascii_matrix = np.repeat([word], [dictionary.shape[0]], axis=0)\n",
    "    difference = ascii_matrix - dictionary\n",
    "    difference = np.where(difference != 0, 1, difference)\n",
    "    difference_sum = np.sum(difference, axis=1)\n",
    "    minval = np.min(difference_sum)\n",
    "    minidx = np.argmin(difference_sum)\n",
    "    if minval < 2 and minval > 0:\n",
    "        return minidx\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:36:47.960876Z",
     "start_time": "2019-06-14T06:36:47.878384Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_coincidences(word, dictionary):\n",
    "    min_len = max(len(word) - 1, 1)\n",
    "    max_len = len(word) + 1\n",
    "    dist = np.array([lv.distance(x, word) - x.startswith(word) if len(x) > min_len and len(x) < max_len else 999 for x in dictionary])\n",
    "    minval = np.min(dist)\n",
    "    if minval < 2 and minval > 0:\n",
    "        minidx = np.argmin(dist)\n",
    "#         root_logger.info('current word %s - found_distance %s - idx to replace %s word', word, minval, minidx)\n",
    "        return dictionary[minidx], np.delete(dictionary, minidx)\n",
    "    else:\n",
    "        return None, dictionary\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:44:06.603946Z",
     "start_time": "2019-06-14T06:36:47.963915Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000653/1000653 [12:42<00:00, 1312.29it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = not_in_vocab_words.values.reshape(1,-1)[0]\n",
    "ascii_dictionary = np.array([np.array([ord(x) for x in y]) for y in dictionary])\n",
    "padded_dictionary = tf.keras.preprocessing.sequence.pad_sequences(ascii_dictionary, maxlen=23, padding=\"post\")\n",
    "\n",
    "found = dict()\n",
    "with tqdm(total=len(padded_asci_codes)) as pbar:\n",
    "    for i, val in enumerate(padded_asci_codes):\n",
    "        pbar.update(1)\n",
    "        coincidence = custom_levenshtein(val, padded_dictionary)\n",
    "        if coincidence:\n",
    "            found[dictionary[coincidence]] = model[stem_vocab[i]]\n",
    "        if len(found) == dictionary.shape[0]:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33990"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:37.827806Z",
     "start_time": "2019-06-14T06:44:06.605281Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10833/10833 [00:00<00:00, 59712.08it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = in_vocab_words.values.reshape(1,-1)[0]\n",
    "w2vec_found = dict()\n",
    "with tqdm(total=len(dictionary)) as pbar:\n",
    "    for word in dictionary:\n",
    "        pbar.update(1)\n",
    "        w2vec_found[word] = model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:38.506010Z",
     "start_time": "2019-06-14T06:52:37.829308Z"
    }
   },
   "outputs": [],
   "source": [
    "in_vocab_replaced = in_vocab.applymap(lambda x: w2vec_found[x] if x in w2vec_found else math.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:39.090980Z",
     "start_time": "2019-06-14T06:52:38.507906Z"
    }
   },
   "outputs": [],
   "source": [
    "not_in_vocab_replaced = not_in_vocab.applymap(lambda x: found[x] if x in found else math.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:39.753783Z",
     "start_time": "2019-06-14T06:52:39.092538Z"
    }
   },
   "outputs": [],
   "source": [
    "in_vocab_replaced.update(not_in_vocab_replaced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace nan positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los textos deben tener la misma longitud, por lo que aquellos textos que no tienen la longitud indicanda deben rellenarse con arrays de 0 de una dimension establecida (la misma para todas las palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:40.627911Z",
     "start_time": "2019-06-14T06:52:39.874214Z"
    }
   },
   "outputs": [],
   "source": [
    "nan_pos = pd.DataFrame([in_vocab_replaced[c].isna() for c in in_vocab_replaced.columns]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:42.638459Z",
     "start_time": "2019-06-14T06:52:40.629336Z"
    }
   },
   "outputs": [],
   "source": [
    "features = 300\n",
    "zeros = np.zeros((features))\n",
    "in_vocab_replaced.update(nan_pos.applymap(lambda x: zeros if x else math.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_vocab_replaced.to_pickle('tweeter_wemb.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vocab_replaced = pd.read_pickle('tweeter_wemb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4690</th>\n",
       "      <th>4691</th>\n",
       "      <th>4692</th>\n",
       "      <th>4693</th>\n",
       "      <th>4694</th>\n",
       "      <th>4695</th>\n",
       "      <th>4696</th>\n",
       "      <th>4697</th>\n",
       "      <th>4698</th>\n",
       "      <th>4699</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.123253495, 0.047755074, 0.18744704, -0.0576...</td>\n",
       "      <td>[-0.03825481, 0.4745884, 0.06159374, -0.211678...</td>\n",
       "      <td>[0.08140966, -0.2937571, 0.09323869, -0.070561...</td>\n",
       "      <td>[-0.08855907, -0.04540643, -0.03799705, 0.1179...</td>\n",
       "      <td>[-0.24166, -0.31998757, 0.05182405, -0.0511, 0...</td>\n",
       "      <td>[-0.30192834, -0.091402225, -0.07635854, -0.32...</td>\n",
       "      <td>[0.16187154, -0.15262279, 0.15911105, 0.136880...</td>\n",
       "      <td>[-0.03385875, -0.05679143, 0.15936868, 0.03850...</td>\n",
       "      <td>[0.08511154, -0.5224435, -0.1114207, -0.029714...</td>\n",
       "      <td>[-0.24166, -0.31998757, 0.05182405, -0.0511, 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.08881656, -0.08638146, 0.19055837, 0.011414...</td>\n",
       "      <td>[0.24844696, -0.045677852, 0.023781389, -0.055...</td>\n",
       "      <td>[0.028837433, -0.1533759, -0.15925558, -0.0515...</td>\n",
       "      <td>[0.084870994, 0.018372163, -0.19153509, -0.140...</td>\n",
       "      <td>[0.19372217, -0.00981669, 0.0936164, 0.0327220...</td>\n",
       "      <td>[0.2661146, 0.10789581, 0.24465632, 0.09246798...</td>\n",
       "      <td>[0.0937914, -0.06750509, 0.11355269, -0.071939...</td>\n",
       "      <td>[0.05255723, -0.173229, -0.043076243, -0.07914...</td>\n",
       "      <td>[0.08545774, -0.18351299, 0.040896367, -0.2875...</td>\n",
       "      <td>[0.19491133, 0.13588089, 0.26361302, 0.0549132...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.27860123, -0.0073691155, 0.07620924, -0.18...</td>\n",
       "      <td>[-0.13225149, 0.007982017, -0.15443377, -0.041...</td>\n",
       "      <td>[-0.22758521, 0.119482145, 0.07687994, -0.1562...</td>\n",
       "      <td>[0.19492386, 0.34440613, 0.05423296, 0.1994891...</td>\n",
       "      <td>[0.11887759, -0.062084418, 0.24743606, 0.08697...</td>\n",
       "      <td>[-0.03682754, 0.124864206, 0.08532753, 0.11072...</td>\n",
       "      <td>[0.29450724, -0.08953724, 0.22900815, -0.13844...</td>\n",
       "      <td>[-0.01992176, -0.38204813, 0.08824053, 0.02404...</td>\n",
       "      <td>[0.032929733, 0.071419924, -0.063104734, -0.08...</td>\n",
       "      <td>[0.16452287, 0.04510333, 0.17681116, -0.175676...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.15753947, -0.11052575, 0.026150983, -0.0067...</td>\n",
       "      <td>[0.18700868, -0.04345352, -0.21399334, -0.0299...</td>\n",
       "      <td>[-0.115100406, 0.04057121, -0.051373735, -0.14...</td>\n",
       "      <td>[0.008335834, -0.13954785, 0.07759602, -0.0191...</td>\n",
       "      <td>[0.057889074, -0.0860811, 0.005500754, 0.19180...</td>\n",
       "      <td>[-0.09766652, -0.055921096, -0.18628502, -0.33...</td>\n",
       "      <td>[-0.14751814, 0.014919235, -0.06650046, -0.193...</td>\n",
       "      <td>[0.20185633, 0.16108106, 0.17906275, 0.0547961...</td>\n",
       "      <td>[-0.015799766, 0.09396541, 0.08841807, -0.0635...</td>\n",
       "      <td>[0.2661146, 0.10789581, 0.24465632, 0.09246798...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.1472689, 0.035210133, -0.0905985, 0.235152...</td>\n",
       "      <td>[-0.19423386, -0.1605221, -0.122799665, -0.226...</td>\n",
       "      <td>[0.010192282, 0.011454537, -0.024294477, -0.14...</td>\n",
       "      <td>[-0.016709665, 0.04634203, 0.12317722, -0.1102...</td>\n",
       "      <td>[0.015565158, 0.013814226, 0.2070413, -0.10364...</td>\n",
       "      <td>[0.23736276, 0.31505284, -0.36881423, 0.341764...</td>\n",
       "      <td>[-0.2906534, 0.38485017, -0.32198793, -0.46555...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.15636458, -0.14417209, 0.15087254, -0.0876...</td>\n",
       "      <td>[-0.18826456, -0.26298478, -0.30475214, -0.043...</td>\n",
       "      <td>[-0.32796225, 0.12644982, 0.1373805, -0.328892...</td>\n",
       "      <td>[-0.021904068, -0.28292415, 0.036686286, -0.12...</td>\n",
       "      <td>[0.31308195, 0.28671673, 0.061079856, -0.18517...</td>\n",
       "      <td>[0.060204167, -0.17087598, 0.2108287, -0.02707...</td>\n",
       "      <td>[-0.09252765, -0.06127216, -0.21862276, -0.010...</td>\n",
       "      <td>[0.10744205, 0.0075490335, -0.28650734, 0.2955...</td>\n",
       "      <td>[0.025537454, -0.1880749, 0.1568079, -0.178805...</td>\n",
       "      <td>[-0.06769281, -0.30116892, 0.08937262, 0.08235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.038064547, -0.045823276, -0.07485215, -0.07...</td>\n",
       "      <td>[0.25501376, -0.011608973, -0.27930972, 0.3525...</td>\n",
       "      <td>[-0.18029697, 0.08496069, 0.01006801, -9.25252...</td>\n",
       "      <td>[-0.25586495, 0.28853804, 0.059111107, -0.0686...</td>\n",
       "      <td>[0.055961747, 0.03338554, 0.17965522, -0.18108...</td>\n",
       "      <td>[-0.0312227, -0.05622646, 0.2197303, -0.072537...</td>\n",
       "      <td>[-0.17901269, -0.015474343, 0.004863352, 0.029...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.2848985, -0.20139082, -0.099536225, 0.1538...</td>\n",
       "      <td>[0.08226747, 0.031416256, 0.0009123865, -0.560...</td>\n",
       "      <td>[0.40826887, -0.085287675, 0.13206185, -0.1375...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.16144432, -0.056896593, -0.029683227, -0.1...</td>\n",
       "      <td>[-0.21747229, -0.19461995, 0.11051066, -0.0933...</td>\n",
       "      <td>[-0.001835166, -0.24167489, 0.1767869, 0.11757...</td>\n",
       "      <td>[0.109622784, 0.012106776, 0.24526607, 0.17946...</td>\n",
       "      <td>[-0.099428646, 0.39090794, -0.092911236, -0.35...</td>\n",
       "      <td>[0.28721282, 0.26410416, 0.026493348, -0.04709...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.11524121, 0.048132487, 0.16708641, 0.080564...</td>\n",
       "      <td>[0.25501376, -0.011608973, -0.27930972, 0.3525...</td>\n",
       "      <td>[0.04357922, -0.36061037, -0.74110204, 0.37670...</td>\n",
       "      <td>[6.7697583e-06, -0.39855585, 0.1004604, -0.018...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.15381046, -0.13758525, 0.09431736, -0.5013...</td>\n",
       "      <td>[-0.324229, 0.33888578, -0.41092703, 0.3568749...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.5313497, -0.14747444, -0.03454075, -0.03119...</td>\n",
       "      <td>[-0.38848424, -0.050834656, 0.008239044, 0.219...</td>\n",
       "      <td>[0.10601474, -0.044864, -0.20512107, -0.215069...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.23924325, 0.06999114, 0.06436243, -0.126434...</td>\n",
       "      <td>[0.025537454, -0.1880749, 0.1568079, -0.178805...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.44580138, 0.09412842, 0.27231395, -0.158739...</td>\n",
       "      <td>[0.24844696, -0.045677852, 0.023781389, -0.055...</td>\n",
       "      <td>[-0.13998565, 0.21335681, 0.119549684, -0.1903...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0     \\\n",
       "0  [0.123253495, 0.047755074, 0.18744704, -0.0576...   \n",
       "1  [-0.27860123, -0.0073691155, 0.07620924, -0.18...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                1     \\\n",
       "0  [-0.03825481, 0.4745884, 0.06159374, -0.211678...   \n",
       "1  [-0.13225149, 0.007982017, -0.15443377, -0.041...   \n",
       "2  [-0.1472689, 0.035210133, -0.0905985, 0.235152...   \n",
       "3  [0.038064547, -0.045823276, -0.07485215, -0.07...   \n",
       "4  [0.11524121, 0.048132487, 0.16708641, 0.080564...   \n",
       "\n",
       "                                                2     \\\n",
       "0  [0.08140966, -0.2937571, 0.09323869, -0.070561...   \n",
       "1  [-0.22758521, 0.119482145, 0.07687994, -0.1562...   \n",
       "2  [-0.19423386, -0.1605221, -0.122799665, -0.226...   \n",
       "3  [0.25501376, -0.011608973, -0.27930972, 0.3525...   \n",
       "4  [0.25501376, -0.011608973, -0.27930972, 0.3525...   \n",
       "\n",
       "                                                3     \\\n",
       "0  [-0.08855907, -0.04540643, -0.03799705, 0.1179...   \n",
       "1  [0.19492386, 0.34440613, 0.05423296, 0.1994891...   \n",
       "2  [0.010192282, 0.011454537, -0.024294477, -0.14...   \n",
       "3  [-0.18029697, 0.08496069, 0.01006801, -9.25252...   \n",
       "4  [0.04357922, -0.36061037, -0.74110204, 0.37670...   \n",
       "\n",
       "                                                4     \\\n",
       "0  [-0.24166, -0.31998757, 0.05182405, -0.0511, 0...   \n",
       "1  [0.11887759, -0.062084418, 0.24743606, 0.08697...   \n",
       "2  [-0.016709665, 0.04634203, 0.12317722, -0.1102...   \n",
       "3  [-0.25586495, 0.28853804, 0.059111107, -0.0686...   \n",
       "4  [6.7697583e-06, -0.39855585, 0.1004604, -0.018...   \n",
       "\n",
       "                                                5     \\\n",
       "0  [-0.30192834, -0.091402225, -0.07635854, -0.32...   \n",
       "1  [-0.03682754, 0.124864206, 0.08532753, 0.11072...   \n",
       "2  [0.015565158, 0.013814226, 0.2070413, -0.10364...   \n",
       "3  [0.055961747, 0.03338554, 0.17965522, -0.18108...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                6     \\\n",
       "0  [0.16187154, -0.15262279, 0.15911105, 0.136880...   \n",
       "1  [0.29450724, -0.08953724, 0.22900815, -0.13844...   \n",
       "2  [0.23736276, 0.31505284, -0.36881423, 0.341764...   \n",
       "3  [-0.0312227, -0.05622646, 0.2197303, -0.072537...   \n",
       "4  [-0.15381046, -0.13758525, 0.09431736, -0.5013...   \n",
       "\n",
       "                                                7     \\\n",
       "0  [-0.03385875, -0.05679143, 0.15936868, 0.03850...   \n",
       "1  [-0.01992176, -0.38204813, 0.08824053, 0.02404...   \n",
       "2  [-0.2906534, 0.38485017, -0.32198793, -0.46555...   \n",
       "3  [-0.17901269, -0.015474343, 0.004863352, 0.029...   \n",
       "4  [-0.324229, 0.33888578, -0.41092703, 0.3568749...   \n",
       "\n",
       "                                                8     \\\n",
       "0  [0.08511154, -0.5224435, -0.1114207, -0.029714...   \n",
       "1  [0.032929733, 0.071419924, -0.063104734, -0.08...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                9     ...  \\\n",
       "0  [-0.24166, -0.31998757, 0.05182405, -0.0511, 0...  ...   \n",
       "1  [0.16452287, 0.04510333, 0.17681116, -0.175676...  ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ...   \n",
       "\n",
       "                                                4690  \\\n",
       "0  [0.08881656, -0.08638146, 0.19055837, 0.011414...   \n",
       "1  [0.15753947, -0.11052575, 0.026150983, -0.0067...   \n",
       "2  [-0.15636458, -0.14417209, 0.15087254, -0.0876...   \n",
       "3  [-0.2848985, -0.20139082, -0.099536225, 0.1538...   \n",
       "4  [0.5313497, -0.14747444, -0.03454075, -0.03119...   \n",
       "\n",
       "                                                4691  \\\n",
       "0  [0.24844696, -0.045677852, 0.023781389, -0.055...   \n",
       "1  [0.18700868, -0.04345352, -0.21399334, -0.0299...   \n",
       "2  [-0.18826456, -0.26298478, -0.30475214, -0.043...   \n",
       "3  [0.08226747, 0.031416256, 0.0009123865, -0.560...   \n",
       "4  [-0.38848424, -0.050834656, 0.008239044, 0.219...   \n",
       "\n",
       "                                                4692  \\\n",
       "0  [0.028837433, -0.1533759, -0.15925558, -0.0515...   \n",
       "1  [-0.115100406, 0.04057121, -0.051373735, -0.14...   \n",
       "2  [-0.32796225, 0.12644982, 0.1373805, -0.328892...   \n",
       "3  [0.40826887, -0.085287675, 0.13206185, -0.1375...   \n",
       "4  [0.10601474, -0.044864, -0.20512107, -0.215069...   \n",
       "\n",
       "                                                4693  \\\n",
       "0  [0.084870994, 0.018372163, -0.19153509, -0.140...   \n",
       "1  [0.008335834, -0.13954785, 0.07759602, -0.0191...   \n",
       "2  [-0.021904068, -0.28292415, 0.036686286, -0.12...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                4694  \\\n",
       "0  [0.19372217, -0.00981669, 0.0936164, 0.0327220...   \n",
       "1  [0.057889074, -0.0860811, 0.005500754, 0.19180...   \n",
       "2  [0.31308195, 0.28671673, 0.061079856, -0.18517...   \n",
       "3  [-0.16144432, -0.056896593, -0.029683227, -0.1...   \n",
       "4  [0.23924325, 0.06999114, 0.06436243, -0.126434...   \n",
       "\n",
       "                                                4695  \\\n",
       "0  [0.2661146, 0.10789581, 0.24465632, 0.09246798...   \n",
       "1  [-0.09766652, -0.055921096, -0.18628502, -0.33...   \n",
       "2  [0.060204167, -0.17087598, 0.2108287, -0.02707...   \n",
       "3  [-0.21747229, -0.19461995, 0.11051066, -0.0933...   \n",
       "4  [0.025537454, -0.1880749, 0.1568079, -0.178805...   \n",
       "\n",
       "                                                4696  \\\n",
       "0  [0.0937914, -0.06750509, 0.11355269, -0.071939...   \n",
       "1  [-0.14751814, 0.014919235, -0.06650046, -0.193...   \n",
       "2  [-0.09252765, -0.06127216, -0.21862276, -0.010...   \n",
       "3  [-0.001835166, -0.24167489, 0.1767869, 0.11757...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                4697  \\\n",
       "0  [0.05255723, -0.173229, -0.043076243, -0.07914...   \n",
       "1  [0.20185633, 0.16108106, 0.17906275, 0.0547961...   \n",
       "2  [0.10744205, 0.0075490335, -0.28650734, 0.2955...   \n",
       "3  [0.109622784, 0.012106776, 0.24526607, 0.17946...   \n",
       "4  [0.44580138, 0.09412842, 0.27231395, -0.158739...   \n",
       "\n",
       "                                                4698  \\\n",
       "0  [0.08545774, -0.18351299, 0.040896367, -0.2875...   \n",
       "1  [-0.015799766, 0.09396541, 0.08841807, -0.0635...   \n",
       "2  [0.025537454, -0.1880749, 0.1568079, -0.178805...   \n",
       "3  [-0.099428646, 0.39090794, -0.092911236, -0.35...   \n",
       "4  [0.24844696, -0.045677852, 0.023781389, -0.055...   \n",
       "\n",
       "                                                4699  \n",
       "0  [0.19491133, 0.13588089, 0.26361302, 0.0549132...  \n",
       "1  [0.2661146, 0.10789581, 0.24465632, 0.09246798...  \n",
       "2  [-0.06769281, -0.30116892, 0.08937262, 0.08235...  \n",
       "3  [0.28721282, 0.26410416, 0.026493348, -0.04709...  \n",
       "4  [-0.13998565, 0.21335681, 0.119549684, -0.1903...  \n",
       "\n",
       "[5 rows x 4700 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_vocab_replaced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que solo tenemos 4700 elementos, lo que resulta ser un corpus bastante pequeño, vamos a quedarnos con solo 100 elementos como conjunto de test y utilizaremos el resto como conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = in_vocab_replaced.shape[1] * 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:42.883596Z",
     "start_time": "2019-06-14T06:52:42.791761Z"
    }
   },
   "outputs": [],
   "source": [
    "train_corpus = in_vocab_replaced.loc[:, :split - 1]\n",
    "test_corpus = in_vocab_replaced.loc[:, split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:43.000799Z",
     "start_time": "2019-06-14T06:52:42.885760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus shape  (28, 4700)\n",
      "train_corpus shape  (28, 3290)\n",
      "test_corpus shape  (28, 1410)\n"
     ]
    }
   ],
   "source": [
    "print(\"corpus shape \", in_vocab_replaced.shape)\n",
    "print(\"train_corpus shape \", train_corpus.shape)\n",
    "print(\"test_corpus shape \", test_corpus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:43.123113Z",
     "start_time": "2019-06-14T06:52:43.006671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features  300\n",
      "timesteps  28\n",
      "elements  3290\n"
     ]
    }
   ],
   "source": [
    "features=train_corpus[0][0].shape[0]\n",
    "timesteps=train_corpus.shape[0]\n",
    "elements=train_corpus.shape[1]\n",
    "print(\"features \", features)\n",
    "print(\"timesteps \", timesteps)\n",
    "print(\"elements \", elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:44.025733Z",
     "start_time": "2019-06-14T06:52:43.128619Z"
    }
   },
   "outputs": [],
   "source": [
    "wemb_x = np.array([np.concatenate(train_corpus[x].values) for x in train_corpus.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:44.041933Z",
     "start_time": "2019-06-14T06:52:44.029214Z"
    }
   },
   "outputs": [],
   "source": [
    "wemb_test = np.array([np.concatenate(test_corpus[x].values) for x in test_corpus.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(data_corpus.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(data_corpus.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=28, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4700, 28)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tokenizer.word_index.items(), columns=[\"word\", \"idx\"]).to_pickle('word_index.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get final train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3290, 8400)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wemb_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:44.218211Z",
     "start_time": "2019-06-14T06:52:44.129076Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = wemb_x.reshape(elements, timesteps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:44.323414Z",
     "start_time": "2019-06-14T06:52:44.220326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3290, 28, 300)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:44.420819Z",
     "start_time": "2019-06-14T06:52:44.328351Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test = wemb_test.reshape(test_corpus.shape[1], timesteps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:44.527635Z",
     "start_time": "2019-06-14T06:52:44.425515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1410, 28, 300)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:44.618551Z",
     "start_time": "2019-06-14T06:52:44.532817Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:44.710043Z",
     "start_time": "2019-06-14T06:52:44.621127Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_Y(corpus, polarity_dim=polarity_dim):\n",
    "    if polarity_dim == 2:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(corpus.polarity.values)\n",
    "        Y = encoder.transform(corpus.polarity.values)\n",
    "        return Y\n",
    "    else:\n",
    "        return to_categorical([x for x in train.polarity.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:44.809913Z",
     "start_time": "2019-06-14T06:52:44.715022Z"
    }
   },
   "outputs": [],
   "source": [
    "Y = get_Y(data_corpus, polarity_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:44.901488Z",
     "start_time": "2019-06-14T06:52:44.814706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4700,)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:44.995831Z",
     "start_time": "2019-06-14T06:52:44.906322Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = Y[:3290]\n",
    "y_test = Y[3290:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:45.090160Z",
     "start_time": "2019-06-14T06:52:44.997532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape  (3290,)\n",
      "y_test shape  (1410,)\n"
     ]
    }
   ],
   "source": [
    "print('y_train shape ', y_train.shape)\n",
    "print('y_test shape ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "histfunc": "count",
         "histnorm": "",
         "marker": {
          "color": "rgba(255, 153, 51, 1.0)",
          "line": {
           "color": "#4D5663",
           "width": 1.3
          }
         },
         "name": "0",
         "opacity": 0.8,
         "orientation": "v",
         "type": "histogram",
         "uid": "a85636ef-3c9b-4b51-8b9b-63af943a147f",
         "x": [
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1
         ]
        }
       ],
       "layout": {
        "barmode": "overlay",
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"96759147-c89a-4f7f-ae80-2dab9ce3d230\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"96759147-c89a-4f7f-ae80-2dab9ce3d230\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '96759147-c89a-4f7f-ae80-2dab9ce3d230',\n",
       "                        [{\"histfunc\": \"count\", \"histnorm\": \"\", \"marker\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"line\": {\"color\": \"#4D5663\", \"width\": 1.3}}, \"name\": \"0\", \"opacity\": 0.8, \"orientation\": \"v\", \"type\": \"histogram\", \"uid\": \"a85636ef-3c9b-4b51-8b9b-63af943a147f\", \"x\": [1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1]}],\n",
       "                        {\"barmode\": \"overlay\", \"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('96759147-c89a-4f7f-ae80-2dab9ce3d230');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).iplot(kind='histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "histfunc": "count",
         "histnorm": "",
         "marker": {
          "color": "rgba(255, 153, 51, 1.0)",
          "line": {
           "color": "#4D5663",
           "width": 1.3
          }
         },
         "name": "0",
         "opacity": 0.8,
         "orientation": "v",
         "type": "histogram",
         "uid": "1c453953-cd60-46b9-8ee0-3e9580c47696",
         "x": [
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          0,
          1,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          0,
          0,
          1,
          0,
          0,
          1,
          1,
          0,
          0,
          1,
          0,
          1
         ]
        }
       ],
       "layout": {
        "barmode": "overlay",
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"d4468b10-cf41-4cfb-9965-5fa6c7aaf399\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"d4468b10-cf41-4cfb-9965-5fa6c7aaf399\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'd4468b10-cf41-4cfb-9965-5fa6c7aaf399',\n",
       "                        [{\"histfunc\": \"count\", \"histnorm\": \"\", \"marker\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"line\": {\"color\": \"#4D5663\", \"width\": 1.3}}, \"name\": \"0\", \"opacity\": 0.8, \"orientation\": \"v\", \"type\": \"histogram\", \"uid\": \"1c453953-cd60-46b9-8ee0-3e9580c47696\", \"x\": [1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1]}],\n",
       "                        {\"barmode\": \"overlay\", \"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d4468b10-cf41-4cfb-9965-5fa6c7aaf399');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(y_test).iplot(kind='histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:04:58.467526Z",
     "start_time": "2019-02-04T21:04:58.463187Z"
    }
   },
   "source": [
    "## Model baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero comprobamos como se comportaria la medida \"loss\" en un conjunto de validación. Para ello dividimos el conjunto de entrenamiento en un 90% entrenamiento 10% validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:52:45.173789Z",
     "start_time": "2019-06-14T06:52:45.095764Z"
    }
   },
   "outputs": [],
   "source": [
    "colors=['red', 'blue','red', 'blue','red', 'blue','red', 'blue','red', 'blue','red', 'blue','red', 'blue','red', 'blue','red', 'blue','red', 'blue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:53:26.196968Z",
     "start_time": "2019-06-14T06:52:45.175288Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-e7a85741c775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_base = tf.keras.Sequential([\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dense_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dense'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "model_base = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(65, activation='relu', name='dense_1'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid' ,name='dense')\n",
    "])\n",
    "model_base.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "logdir=\"logs/fit/base/base\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir, embeddings_freq=1, write_images=True)\n",
    "hist_base = model_base.fit(sequences[:-100], y_train, validation_split=0.2, shuffle=False, epochs=30,\\\n",
    "                           verbose=2, batch_size=128, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 300)           3644700   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 65)                546065    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 66        \n",
      "=================================================================\n",
      "Total params: 4,190,831\n",
      "Trainable params: 546,131\n",
      "Non-trainable params: 3,644,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:53:27.139957Z",
     "start_time": "2019-06-14T06:53:27.106603Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=kfolds, shuffle=True, random_state=None) # realización de k-folds\n",
    "folds = kf.split(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:53:27.268782Z",
     "start_time": "2019-06-14T06:53:27.145098Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = [(x, y) for (x, y) in folds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:53:27.503497Z",
     "start_time": "2019-06-14T06:53:27.383545Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_df(hist):\n",
    "    cols = pd.MultiIndex.from_product([[\"step1\", \"step2\", \"step3\", \"step4\", \"step5\", \"step6\", \"step7\", \"step8\", \"step9\", \"step10\"], hist[0].history.keys()])\n",
    "    hist_df = pd.concat([pd.DataFrame(x.history) for x in  hist], axis=1)\n",
    "    hist_df.columns = cols\n",
    "    hist_df.head()\n",
    "    return hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_train_sequences(model_func, model_name, **params):\n",
    "    evaluations = list()\n",
    "    hists = list()\n",
    "    i = 0\n",
    "    for train_index, val_index in folds:\n",
    "        i += 1\n",
    "        model = model_func()\n",
    "        train_x = sequences[train_index]\n",
    "        train_y = y_train[train_index]\n",
    "        val_x = sequences[val_index]\n",
    "        val_y = y_train[val_index]\n",
    "        \n",
    "        logdir=\"logs/fit/\"+ model_name+\"/kfold\" + str(i)\n",
    "        print(logdir)\n",
    "        tensorboard_callback = TensorBoard(log_dir=logdir, embeddings_freq=1, write_images=True)\n",
    "\n",
    "        hist = model.fit(train_x, train_y, validation_data=(val_x, val_y), callbacks=[tensorboard_callback], **params)\n",
    "        \n",
    "        hists.append(hist)\n",
    "        evaluations.append(model.evaluate(x_test, y_test))\n",
    "    hist_df = convert_to_df(hists)\n",
    "    hist_df.to_pickle('data/results/'+name+'/cine/' + base_dir + '/'+model_name+'_lstm.pkl')\n",
    "    evas_df = pd.DataFrame(evaluations)\n",
    "    evas_df.to_pickle('data/results/'+name+'/cine/' + base_dir + '/'+model_name+'_lstm_evas.pkl')\n",
    "    return hist_df, evas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T19:28:05.902275Z",
     "start_time": "2019-06-14T19:28:05.895691Z"
    }
   },
   "outputs": [],
   "source": [
    "def kfold_train(model_func, model_name, **params):\n",
    "    evaluations = list()\n",
    "    hists = list()\n",
    "    i = 0\n",
    "    for train_index, val_index in folds:\n",
    "        i += 1\n",
    "        model = model_func()\n",
    "        train_x = x_train[train_index]\n",
    "        train_y = y_train[train_index]\n",
    "        val_x = x_train[val_index]\n",
    "        val_y = y_train[val_index]\n",
    "        \n",
    "        logdir=\"logs/fit/\"+ model_name+\"/kfold\" + str(i)\n",
    "        print(logdir)\n",
    "        tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "        hist = model.fit(train_x, train_y, validation_data=(val_x, val_y), callbacks=[tensorboard_callback], **params)\n",
    "        \n",
    "        hists.append(hist)\n",
    "        evaluations.append(model.evaluate(x_test, y_test))\n",
    "    hist_df = convert_to_df(hists)\n",
    "    hist_df.to_pickle('data/results/'+name+'/cine/' + base_dir + '/'+model_name+'_lstm.pkl')\n",
    "    evas_df = pd.DataFrame(evaluations)\n",
    "    evas_df.to_pickle('data/results/'+name+'/cine/' + base_dir + '/'+model_name+'_lstm_evas.pkl')\n",
    "    return hist_df, evas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T06:53:27.588065Z",
     "start_time": "2019-06-14T06:53:27.508116Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(hist_df):\n",
    "    hist_df.loc[:, pd.IndexSlice[:, ['loss', 'val_loss']]].iplot(colors=colors)\n",
    "    print('mean ', hist_df.stack(level=0).mean())\n",
    "    print('std ', hist_df.stack(level=0).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:54:20.561543Z",
     "start_time": "2019-06-14T13:54:20.558428Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_val(evas_df):\n",
    "    evas_df[1].iplot()\n",
    "    print('media ', evas_df[1].mean())\n",
    "    print('std ', evas_df[1].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:55:58.307732Z",
     "start_time": "2019-06-14T13:55:58.303068Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_results(hist, evas):\n",
    "    plot_loss(hist)\n",
    "    plot_val(evas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T14:09:36.417142Z",
     "start_time": "2019-06-14T13:56:14.514360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/lstm_val/kfold1\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 5s - loss: 0.6875 - acc: 0.5727 - val_loss: 0.6763 - val_acc: 0.5739\n",
      "Epoch 2/30\n",
      "4140/4140 - 1s - loss: 0.7066 - acc: 0.6278 - val_loss: 0.6767 - val_acc: 0.6435\n",
      "Epoch 3/30\n",
      "4140/4140 - 1s - loss: 0.6711 - acc: 0.6304 - val_loss: 0.6087 - val_acc: 0.6978\n",
      "Epoch 4/30\n",
      "4140/4140 - 1s - loss: 0.6654 - acc: 0.7275 - val_loss: 0.6014 - val_acc: 0.7348\n",
      "Epoch 5/30\n",
      "4140/4140 - 1s - loss: 0.5932 - acc: 0.7408 - val_loss: 0.5504 - val_acc: 0.7652\n",
      "Epoch 6/30\n",
      "4140/4140 - 1s - loss: 0.5066 - acc: 0.7819 - val_loss: 0.4295 - val_acc: 0.7978\n",
      "Epoch 7/30\n",
      "4140/4140 - 1s - loss: 0.4089 - acc: 0.8092 - val_loss: 0.4255 - val_acc: 0.7870\n",
      "Epoch 8/30\n",
      "4140/4140 - 1s - loss: 0.3736 - acc: 0.8329 - val_loss: 0.4199 - val_acc: 0.8087\n",
      "Epoch 9/30\n",
      "4140/4140 - 1s - loss: 0.3552 - acc: 0.8386 - val_loss: 0.4245 - val_acc: 0.8043\n",
      "Epoch 10/30\n",
      "4140/4140 - 1s - loss: 0.3447 - acc: 0.8440 - val_loss: 0.4374 - val_acc: 0.8000\n",
      "Epoch 11/30\n",
      "4140/4140 - 1s - loss: 0.3404 - acc: 0.8471 - val_loss: 0.4305 - val_acc: 0.8087\n",
      "Epoch 12/30\n",
      "4140/4140 - 1s - loss: 0.3390 - acc: 0.8457 - val_loss: 0.3979 - val_acc: 0.8217\n",
      "Epoch 13/30\n",
      "4140/4140 - 1s - loss: 0.3466 - acc: 0.8440 - val_loss: 0.3984 - val_acc: 0.8174\n",
      "Epoch 14/30\n",
      "4140/4140 - 1s - loss: 0.3530 - acc: 0.8389 - val_loss: 0.4194 - val_acc: 0.8413\n",
      "Epoch 15/30\n",
      "4140/4140 - 1s - loss: 0.3182 - acc: 0.8582 - val_loss: 0.4380 - val_acc: 0.8391\n",
      "Epoch 16/30\n",
      "4140/4140 - 1s - loss: 0.3063 - acc: 0.8638 - val_loss: 0.4744 - val_acc: 0.8435\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.2919 - acc: 0.8684 - val_loss: 0.5308 - val_acc: 0.8391\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.2763 - acc: 0.8773 - val_loss: 0.4986 - val_acc: 0.8391\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.2612 - acc: 0.8831 - val_loss: 0.4663 - val_acc: 0.8283\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.2476 - acc: 0.8906 - val_loss: 0.5053 - val_acc: 0.8174\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.2368 - acc: 0.8971 - val_loss: 0.5383 - val_acc: 0.8087\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.2453 - acc: 0.8949 - val_loss: 0.5117 - val_acc: 0.8130\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.2324 - acc: 0.9089 - val_loss: 0.6254 - val_acc: 0.8348\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.2314 - acc: 0.9092 - val_loss: 0.9466 - val_acc: 0.8370\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.2121 - acc: 0.9162 - val_loss: 0.6054 - val_acc: 0.7674\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.2228 - acc: 0.9118 - val_loss: 0.5305 - val_acc: 0.8413\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.2012 - acc: 0.9210 - val_loss: 0.5799 - val_acc: 0.8348\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.1678 - acc: 0.9379 - val_loss: 0.6011 - val_acc: 0.8370\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.1588 - acc: 0.9442 - val_loss: 0.6205 - val_acc: 0.8370\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.1440 - acc: 0.9507 - val_loss: 0.6543 - val_acc: 0.8326\n",
      "100/100 [==============================] - 0s 893us/sample - loss: 0.4136 - acc: 0.8500\n",
      "logs/fit/lstm_val/kfold2\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 24s - loss: 0.6824 - acc: 0.5732 - val_loss: 0.6751 - val_acc: 0.5696\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.6834 - acc: 0.6184 - val_loss: 0.6232 - val_acc: 0.6609\n",
      "Epoch 3/30\n",
      "4140/4140 - 8s - loss: 0.6311 - acc: 0.5838 - val_loss: 0.6031 - val_acc: 0.5717\n",
      "Epoch 4/30\n",
      "4140/4140 - 8s - loss: 0.5772 - acc: 0.5872 - val_loss: 0.5207 - val_acc: 0.6370\n",
      "Epoch 5/30\n",
      "4140/4140 - 7s - loss: 0.5008 - acc: 0.7543 - val_loss: 0.4714 - val_acc: 0.8348\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.6042 - acc: 0.7316 - val_loss: 0.5866 - val_acc: 0.6370\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.5394 - acc: 0.6966 - val_loss: 0.5922 - val_acc: 0.7543\n",
      "Epoch 8/30\n",
      "4140/4140 - 8s - loss: 0.5230 - acc: 0.7609 - val_loss: 0.4726 - val_acc: 0.8196\n",
      "Epoch 9/30\n",
      "4140/4140 - 3s - loss: 0.7175 - acc: 0.7568 - val_loss: 0.5977 - val_acc: 0.7522\n",
      "Epoch 10/30\n",
      "4140/4140 - 1s - loss: 0.5423 - acc: 0.6722 - val_loss: 0.5094 - val_acc: 0.7196\n",
      "Epoch 11/30\n",
      "4140/4140 - 1s - loss: 0.4905 - acc: 0.7633 - val_loss: 0.4928 - val_acc: 0.7978\n",
      "Epoch 12/30\n",
      "4140/4140 - 1s - loss: 0.4762 - acc: 0.7833 - val_loss: 0.4855 - val_acc: 0.8152\n",
      "Epoch 13/30\n",
      "4140/4140 - 1s - loss: 0.4630 - acc: 0.7920 - val_loss: 0.4753 - val_acc: 0.8196\n",
      "Epoch 14/30\n",
      "4140/4140 - 1s - loss: 0.4484 - acc: 0.8080 - val_loss: 0.4584 - val_acc: 0.8326\n",
      "Epoch 15/30\n",
      "4140/4140 - 1s - loss: 0.4184 - acc: 0.8319 - val_loss: 0.4304 - val_acc: 0.8370\n",
      "Epoch 16/30\n",
      "4140/4140 - 1s - loss: 0.3834 - acc: 0.8454 - val_loss: 0.3855 - val_acc: 0.8239\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.3379 - acc: 0.8616 - val_loss: 0.3602 - val_acc: 0.8478\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.3030 - acc: 0.8800 - val_loss: 0.3600 - val_acc: 0.8543\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.2794 - acc: 0.8889 - val_loss: 0.3592 - val_acc: 0.8565\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.2533 - acc: 0.9034 - val_loss: 0.3676 - val_acc: 0.8652\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.2287 - acc: 0.9184 - val_loss: 0.3847 - val_acc: 0.8674\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.2266 - acc: 0.9193 - val_loss: 0.4023 - val_acc: 0.8457\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.2138 - acc: 0.9244 - val_loss: 0.4418 - val_acc: 0.8261\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.2210 - acc: 0.9196 - val_loss: 0.4145 - val_acc: 0.8413\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.2581 - acc: 0.8976 - val_loss: 0.4377 - val_acc: 0.7891\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.2659 - acc: 0.8937 - val_loss: 0.4511 - val_acc: 0.8391\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.2638 - acc: 0.9046 - val_loss: 0.3950 - val_acc: 0.8457\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.2962 - acc: 0.8826 - val_loss: 0.4493 - val_acc: 0.8587\n",
      "Epoch 29/30\n",
      "4140/4140 - 2s - loss: 0.2609 - acc: 0.8988 - val_loss: 0.5160 - val_acc: 0.8413\n",
      "Epoch 30/30\n",
      "4140/4140 - 3s - loss: 0.2170 - acc: 0.9232 - val_loss: 0.5096 - val_acc: 0.8478\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.5040 - acc: 0.8200\n",
      "logs/fit/lstm_val/kfold3\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 30s - loss: 0.9245 - acc: 0.5768 - val_loss: 0.6701 - val_acc: 0.6630\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.6805 - acc: 0.6758 - val_loss: 0.6691 - val_acc: 0.6609\n",
      "Epoch 3/30\n",
      "4140/4140 - 7s - loss: 0.6888 - acc: 0.6188 - val_loss: 0.6832 - val_acc: 0.6217\n",
      "Epoch 4/30\n",
      "4140/4140 - 8s - loss: 0.6847 - acc: 0.5831 - val_loss: 0.6807 - val_acc: 0.6152\n",
      "Epoch 5/30\n",
      "4140/4140 - 7s - loss: 0.6829 - acc: 0.5795 - val_loss: 0.6782 - val_acc: 0.6152\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.6809 - acc: 0.5814 - val_loss: 0.6754 - val_acc: 0.6196\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.6781 - acc: 0.5944 - val_loss: 0.6712 - val_acc: 0.6457\n",
      "Epoch 8/30\n",
      "4140/4140 - 7s - loss: 0.6676 - acc: 0.6585 - val_loss: 0.6377 - val_acc: 0.7000\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.6490 - acc: 0.6872 - val_loss: 0.6571 - val_acc: 0.6804\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.6503 - acc: 0.6850 - val_loss: 0.6220 - val_acc: 0.7022\n",
      "Epoch 11/30\n",
      "4140/4140 - 7s - loss: 0.6249 - acc: 0.7036 - val_loss: 0.6473 - val_acc: 0.6630\n",
      "Epoch 12/30\n",
      "4140/4140 - 2s - loss: 0.6358 - acc: 0.6870 - val_loss: 0.6041 - val_acc: 0.7217\n",
      "Epoch 13/30\n",
      "4140/4140 - 1s - loss: 0.5772 - acc: 0.7599 - val_loss: 0.5744 - val_acc: 0.7761\n",
      "Epoch 14/30\n",
      "4140/4140 - 1s - loss: 0.5373 - acc: 0.8034 - val_loss: 0.5900 - val_acc: 0.8022\n",
      "Epoch 15/30\n",
      "4140/4140 - 1s - loss: 0.5041 - acc: 0.8278 - val_loss: 0.5530 - val_acc: 0.8326\n",
      "Epoch 16/30\n",
      "4140/4140 - 1s - loss: 0.5034 - acc: 0.8229 - val_loss: 0.5380 - val_acc: 0.8109\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.5026 - acc: 0.8099 - val_loss: 0.5403 - val_acc: 0.8174\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.4613 - acc: 0.8345 - val_loss: 0.5197 - val_acc: 0.8261\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.4268 - acc: 0.8469 - val_loss: 0.4938 - val_acc: 0.8348\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.3834 - acc: 0.8582 - val_loss: 0.4455 - val_acc: 0.8326\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.3415 - acc: 0.8630 - val_loss: 0.4100 - val_acc: 0.8478\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.3222 - acc: 0.8684 - val_loss: 0.3889 - val_acc: 0.8565\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.3118 - acc: 0.8783 - val_loss: 0.4185 - val_acc: 0.8370\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.3007 - acc: 0.8838 - val_loss: 0.4428 - val_acc: 0.8326\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.2920 - acc: 0.8874 - val_loss: 0.4007 - val_acc: 0.8391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.2813 - acc: 0.8911 - val_loss: 0.3962 - val_acc: 0.8500\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.2741 - acc: 0.8973 - val_loss: 0.3975 - val_acc: 0.8543\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.2615 - acc: 0.9019 - val_loss: 0.4328 - val_acc: 0.8348\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.2471 - acc: 0.9104 - val_loss: 0.4341 - val_acc: 0.8348\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.2310 - acc: 0.9200 - val_loss: 0.4721 - val_acc: 0.8261\n",
      "100/100 [==============================] - 0s 684us/sample - loss: 0.3213 - acc: 0.8500\n",
      "logs/fit/lstm_val/kfold4\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 24s - loss: 0.7066 - acc: 0.5746 - val_loss: 0.6834 - val_acc: 0.5978\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.6857 - acc: 0.5771 - val_loss: 0.6798 - val_acc: 0.6413\n",
      "Epoch 3/30\n",
      "4140/4140 - 7s - loss: 0.6869 - acc: 0.6118 - val_loss: 0.6780 - val_acc: 0.5978\n",
      "Epoch 4/30\n",
      "4140/4140 - 7s - loss: 0.6793 - acc: 0.5768 - val_loss: 0.6701 - val_acc: 0.5978\n",
      "Epoch 5/30\n",
      "4140/4140 - 8s - loss: 0.6737 - acc: 0.5768 - val_loss: 0.6546 - val_acc: 0.5978\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.6289 - acc: 0.5802 - val_loss: 0.5877 - val_acc: 0.6804\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.6118 - acc: 0.6693 - val_loss: 0.5786 - val_acc: 0.6022\n",
      "Epoch 8/30\n",
      "4140/4140 - 8s - loss: 0.5972 - acc: 0.5802 - val_loss: 0.4926 - val_acc: 0.6761\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.5047 - acc: 0.7899 - val_loss: 0.4455 - val_acc: 0.8196\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.4694 - acc: 0.8147 - val_loss: 0.4214 - val_acc: 0.8413\n",
      "Epoch 11/30\n",
      "4140/4140 - 7s - loss: 0.4209 - acc: 0.8176 - val_loss: 0.4251 - val_acc: 0.8109\n",
      "Epoch 12/30\n",
      "4140/4140 - 7s - loss: 0.4157 - acc: 0.8292 - val_loss: 0.3834 - val_acc: 0.8435\n",
      "Epoch 13/30\n",
      "4140/4140 - 7s - loss: 0.3612 - acc: 0.8447 - val_loss: 0.4641 - val_acc: 0.8348\n",
      "Epoch 14/30\n",
      "4140/4140 - 7s - loss: 0.3322 - acc: 0.8553 - val_loss: 0.5120 - val_acc: 0.8304\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.3106 - acc: 0.8679 - val_loss: 0.5596 - val_acc: 0.8087\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.2981 - acc: 0.8773 - val_loss: 0.6697 - val_acc: 0.8000\n",
      "Epoch 17/30\n",
      "4140/4140 - 8s - loss: 0.2977 - acc: 0.8804 - val_loss: 0.8711 - val_acc: 0.7891\n",
      "Epoch 18/30\n",
      "4140/4140 - 7s - loss: 0.2852 - acc: 0.8865 - val_loss: 0.8258 - val_acc: 0.8109\n",
      "Epoch 19/30\n",
      "4140/4140 - 4s - loss: 0.2595 - acc: 0.8971 - val_loss: 0.8672 - val_acc: 0.8065\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.2312 - acc: 0.9133 - val_loss: 0.9398 - val_acc: 0.8087\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.2157 - acc: 0.9196 - val_loss: 0.7435 - val_acc: 0.8087\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.1942 - acc: 0.9266 - val_loss: 0.7551 - val_acc: 0.8370\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.3020 - acc: 0.8829 - val_loss: 0.4067 - val_acc: 0.8391\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.2278 - acc: 0.9145 - val_loss: 0.5800 - val_acc: 0.8348\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.2015 - acc: 0.9234 - val_loss: 0.6500 - val_acc: 0.8239\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.1763 - acc: 0.9362 - val_loss: 0.6150 - val_acc: 0.8217\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.1627 - acc: 0.9423 - val_loss: 0.6254 - val_acc: 0.8304\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.1683 - acc: 0.9382 - val_loss: 0.6040 - val_acc: 0.8348\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.2146 - acc: 0.9138 - val_loss: 0.4208 - val_acc: 0.8348\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.2591 - acc: 0.8957 - val_loss: 0.5170 - val_acc: 0.8326\n",
      "100/100 [==============================] - 0s 645us/sample - loss: 0.4965 - acc: 0.7500\n",
      "logs/fit/lstm_val/kfold5\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 6s - loss: 0.7043 - acc: 0.5749 - val_loss: 0.6804 - val_acc: 0.5609\n",
      "Epoch 2/30\n",
      "4140/4140 - 2s - loss: 0.6795 - acc: 0.6604 - val_loss: 0.6619 - val_acc: 0.6783\n",
      "Epoch 3/30\n",
      "4140/4140 - 4s - loss: 0.6403 - acc: 0.7034 - val_loss: 0.6494 - val_acc: 0.7326\n",
      "Epoch 4/30\n",
      "4140/4140 - 4s - loss: 0.6118 - acc: 0.7307 - val_loss: 0.5909 - val_acc: 0.7500\n",
      "Epoch 5/30\n",
      "4140/4140 - 5s - loss: 0.5240 - acc: 0.7737 - val_loss: 0.4972 - val_acc: 0.7978\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.4447 - acc: 0.7662 - val_loss: 0.4334 - val_acc: 0.7870\n",
      "Epoch 7/30\n",
      "4140/4140 - 8s - loss: 0.4221 - acc: 0.7879 - val_loss: 0.3985 - val_acc: 0.8000\n",
      "Epoch 8/30\n",
      "4140/4140 - 8s - loss: 0.3934 - acc: 0.8097 - val_loss: 0.3958 - val_acc: 0.8152\n",
      "Epoch 9/30\n",
      "4140/4140 - 8s - loss: 0.3669 - acc: 0.8283 - val_loss: 0.3825 - val_acc: 0.8283\n",
      "Epoch 10/30\n",
      "4140/4140 - 8s - loss: 0.3478 - acc: 0.8432 - val_loss: 0.3782 - val_acc: 0.8435\n",
      "Epoch 11/30\n",
      "4140/4140 - 8s - loss: 0.3342 - acc: 0.8500 - val_loss: 0.3740 - val_acc: 0.8587\n",
      "Epoch 12/30\n",
      "4140/4140 - 8s - loss: 0.3233 - acc: 0.8563 - val_loss: 0.3720 - val_acc: 0.8543\n",
      "Epoch 13/30\n",
      "4140/4140 - 7s - loss: 0.3128 - acc: 0.8626 - val_loss: 0.3709 - val_acc: 0.8565\n",
      "Epoch 14/30\n",
      "4140/4140 - 8s - loss: 0.3022 - acc: 0.8662 - val_loss: 0.3689 - val_acc: 0.8565\n",
      "Epoch 15/30\n",
      "4140/4140 - 8s - loss: 0.2842 - acc: 0.8734 - val_loss: 0.3748 - val_acc: 0.8457\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.2679 - acc: 0.8841 - val_loss: 0.3811 - val_acc: 0.8500\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.2490 - acc: 0.8911 - val_loss: 0.3856 - val_acc: 0.8478\n",
      "Epoch 18/30\n",
      "4140/4140 - 8s - loss: 0.2620 - acc: 0.8853 - val_loss: 0.3779 - val_acc: 0.8413\n",
      "Epoch 19/30\n",
      "4140/4140 - 7s - loss: 0.2464 - acc: 0.8988 - val_loss: 0.4471 - val_acc: 0.7935\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.2549 - acc: 0.8942 - val_loss: 0.4138 - val_acc: 0.8543\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.2203 - acc: 0.9121 - val_loss: 0.4605 - val_acc: 0.8500\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.2043 - acc: 0.9186 - val_loss: 0.4969 - val_acc: 0.8435\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.1819 - acc: 0.9331 - val_loss: 0.5775 - val_acc: 0.8457\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.1822 - acc: 0.9319 - val_loss: 0.6280 - val_acc: 0.8413\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.1668 - acc: 0.9403 - val_loss: 0.6290 - val_acc: 0.8304\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.1574 - acc: 0.9473 - val_loss: 0.5271 - val_acc: 0.8370\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.1491 - acc: 0.9478 - val_loss: 0.5854 - val_acc: 0.8413\n",
      "Epoch 28/30\n",
      "4140/4140 - 3s - loss: 0.1382 - acc: 0.9541 - val_loss: 0.5657 - val_acc: 0.8391\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.1505 - acc: 0.9444 - val_loss: 0.7616 - val_acc: 0.8326\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.1245 - acc: 0.9577 - val_loss: 0.8136 - val_acc: 0.8261\n",
      "100/100 [==============================] - 0s 593us/sample - loss: 0.4997 - acc: 0.8400\n",
      "logs/fit/lstm_val/kfold6\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 5s - loss: 0.6819 - acc: 0.5797 - val_loss: 0.6726 - val_acc: 0.5717\n",
      "Epoch 2/30\n",
      "4140/4140 - 1s - loss: 0.6646 - acc: 0.5797 - val_loss: 0.6335 - val_acc: 0.6043\n",
      "Epoch 3/30\n",
      "4140/4140 - 1s - loss: 0.6291 - acc: 0.5986 - val_loss: 0.6112 - val_acc: 0.5739\n",
      "Epoch 4/30\n",
      "4140/4140 - 1s - loss: 0.5431 - acc: 0.6225 - val_loss: 0.5098 - val_acc: 0.6652\n",
      "Epoch 5/30\n",
      "4140/4140 - 1s - loss: 0.4933 - acc: 0.7862 - val_loss: 0.4808 - val_acc: 0.8217\n",
      "Epoch 6/30\n",
      "4140/4140 - 1s - loss: 0.4703 - acc: 0.8275 - val_loss: 0.4671 - val_acc: 0.8326\n",
      "Epoch 7/30\n",
      "4140/4140 - 1s - loss: 0.4526 - acc: 0.8370 - val_loss: 0.4540 - val_acc: 0.8391\n",
      "Epoch 8/30\n",
      "4140/4140 - 1s - loss: 0.4363 - acc: 0.8476 - val_loss: 0.4467 - val_acc: 0.8370\n",
      "Epoch 9/30\n",
      "4140/4140 - 1s - loss: 0.4214 - acc: 0.8546 - val_loss: 0.4434 - val_acc: 0.8370\n",
      "Epoch 10/30\n",
      "4140/4140 - 2s - loss: 0.4062 - acc: 0.8640 - val_loss: 0.4451 - val_acc: 0.8435\n",
      "Epoch 11/30\n",
      "4140/4140 - 3s - loss: 0.3882 - acc: 0.8722 - val_loss: 0.4377 - val_acc: 0.8413\n",
      "Epoch 12/30\n",
      "4140/4140 - 4s - loss: 0.3699 - acc: 0.8790 - val_loss: 0.4443 - val_acc: 0.8326\n",
      "Epoch 13/30\n",
      "4140/4140 - 4s - loss: 0.3591 - acc: 0.8841 - val_loss: 0.4317 - val_acc: 0.8370\n",
      "Epoch 14/30\n",
      "4140/4140 - 5s - loss: 0.3816 - acc: 0.8597 - val_loss: 0.4171 - val_acc: 0.8457\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.3874 - acc: 0.8652 - val_loss: 0.4557 - val_acc: 0.8022\n",
      "Epoch 16/30\n",
      "4140/4140 - 8s - loss: 0.3563 - acc: 0.8780 - val_loss: 0.4537 - val_acc: 0.8457\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.3231 - acc: 0.8976 - val_loss: 0.5073 - val_acc: 0.8370\n",
      "Epoch 18/30\n",
      "4140/4140 - 7s - loss: 0.3096 - acc: 0.9002 - val_loss: 0.4858 - val_acc: 0.8435\n",
      "Epoch 19/30\n",
      "4140/4140 - 8s - loss: 0.2923 - acc: 0.9092 - val_loss: 0.5802 - val_acc: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.3009 - acc: 0.8964 - val_loss: 0.5251 - val_acc: 0.8239\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.3290 - acc: 0.8821 - val_loss: 0.4310 - val_acc: 0.8087\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.2813 - acc: 0.9114 - val_loss: 0.4637 - val_acc: 0.7783\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.2712 - acc: 0.9104 - val_loss: 0.4800 - val_acc: 0.7957\n",
      "Epoch 24/30\n",
      "4140/4140 - 8s - loss: 0.2576 - acc: 0.9147 - val_loss: 0.5295 - val_acc: 0.8152\n",
      "Epoch 25/30\n",
      "4140/4140 - 8s - loss: 0.2610 - acc: 0.9097 - val_loss: 0.4899 - val_acc: 0.8304\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.2462 - acc: 0.9123 - val_loss: 0.4705 - val_acc: 0.8087\n",
      "Epoch 27/30\n",
      "4140/4140 - 8s - loss: 0.2739 - acc: 0.8932 - val_loss: 0.4412 - val_acc: 0.8370\n",
      "Epoch 28/30\n",
      "4140/4140 - 7s - loss: 0.3151 - acc: 0.8829 - val_loss: 0.8931 - val_acc: 0.8326\n",
      "Epoch 29/30\n",
      "4140/4140 - 7s - loss: 0.2752 - acc: 0.9005 - val_loss: 0.5902 - val_acc: 0.8478\n",
      "Epoch 30/30\n",
      "4140/4140 - 7s - loss: 0.2238 - acc: 0.9217 - val_loss: 0.5516 - val_acc: 0.8565\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 0.4647 - acc: 0.8400\n",
      "logs/fit/lstm_val/kfold7\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 25s - loss: 0.7051 - acc: 0.5879 - val_loss: 0.9099 - val_acc: 0.7152\n",
      "Epoch 2/30\n",
      "4140/4140 - 1s - loss: 0.6889 - acc: 0.6106 - val_loss: 0.6819 - val_acc: 0.5717\n",
      "Epoch 3/30\n",
      "4140/4140 - 1s - loss: 0.6772 - acc: 0.5800 - val_loss: 0.6746 - val_acc: 0.5717\n",
      "Epoch 4/30\n",
      "4140/4140 - 1s - loss: 0.6500 - acc: 0.6565 - val_loss: 0.6186 - val_acc: 0.7630\n",
      "Epoch 5/30\n",
      "4140/4140 - 1s - loss: 0.4838 - acc: 0.7829 - val_loss: 0.4674 - val_acc: 0.7957\n",
      "Epoch 6/30\n",
      "4140/4140 - 1s - loss: 0.4053 - acc: 0.8174 - val_loss: 0.4258 - val_acc: 0.8217\n",
      "Epoch 7/30\n",
      "4140/4140 - 1s - loss: 0.3688 - acc: 0.8377 - val_loss: 0.4121 - val_acc: 0.8326\n",
      "Epoch 8/30\n",
      "4140/4140 - 1s - loss: 0.3475 - acc: 0.8510 - val_loss: 0.4009 - val_acc: 0.8348\n",
      "Epoch 9/30\n",
      "4140/4140 - 1s - loss: 0.3352 - acc: 0.8577 - val_loss: 0.4015 - val_acc: 0.8152\n",
      "Epoch 10/30\n",
      "4140/4140 - 1s - loss: 0.3246 - acc: 0.8669 - val_loss: 0.4095 - val_acc: 0.8087\n",
      "Epoch 11/30\n",
      "4140/4140 - 1s - loss: 0.3186 - acc: 0.8720 - val_loss: 0.4317 - val_acc: 0.7870\n",
      "Epoch 12/30\n",
      "4140/4140 - 1s - loss: 0.3114 - acc: 0.8696 - val_loss: 0.3983 - val_acc: 0.8348\n",
      "Epoch 13/30\n",
      "4140/4140 - 1s - loss: 0.2796 - acc: 0.8882 - val_loss: 0.3973 - val_acc: 0.8348\n",
      "Epoch 14/30\n",
      "4140/4140 - 1s - loss: 0.2594 - acc: 0.8993 - val_loss: 0.4592 - val_acc: 0.7848\n",
      "Epoch 15/30\n",
      "4140/4140 - 1s - loss: 0.2493 - acc: 0.9041 - val_loss: 0.4431 - val_acc: 0.8261\n",
      "Epoch 16/30\n",
      "4140/4140 - 1s - loss: 0.2385 - acc: 0.9099 - val_loss: 0.4703 - val_acc: 0.8065\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.2083 - acc: 0.9254 - val_loss: 0.7290 - val_acc: 0.7543\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.2277 - acc: 0.9169 - val_loss: 0.6243 - val_acc: 0.7500\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.2599 - acc: 0.9027 - val_loss: 0.6286 - val_acc: 0.8022\n",
      "Epoch 20/30\n",
      "4140/4140 - 2s - loss: 0.3307 - acc: 0.8684 - val_loss: 0.5076 - val_acc: 0.8435\n",
      "Epoch 21/30\n",
      "4140/4140 - 2s - loss: 0.2712 - acc: 0.8843 - val_loss: 0.6302 - val_acc: 0.8217\n",
      "Epoch 22/30\n",
      "4140/4140 - 4s - loss: 0.2293 - acc: 0.9094 - val_loss: 0.6184 - val_acc: 0.8348\n",
      "Epoch 23/30\n",
      "4140/4140 - 4s - loss: 0.2192 - acc: 0.9140 - val_loss: 0.6021 - val_acc: 0.8413\n",
      "Epoch 24/30\n",
      "4140/4140 - 5s - loss: 0.1796 - acc: 0.9343 - val_loss: 0.5656 - val_acc: 0.8413\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.1527 - acc: 0.9464 - val_loss: 0.5708 - val_acc: 0.8391\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.1385 - acc: 0.9524 - val_loss: 0.6332 - val_acc: 0.8370\n",
      "Epoch 27/30\n",
      "4140/4140 - 8s - loss: 0.1244 - acc: 0.9599 - val_loss: 0.7575 - val_acc: 0.8326\n",
      "Epoch 28/30\n",
      "4140/4140 - 7s - loss: 0.1374 - acc: 0.9541 - val_loss: 0.7120 - val_acc: 0.8304\n",
      "Epoch 29/30\n",
      "4140/4140 - 7s - loss: 0.1285 - acc: 0.9589 - val_loss: 0.6088 - val_acc: 0.8435\n",
      "Epoch 30/30\n",
      "4140/4140 - 7s - loss: 0.1515 - acc: 0.9442 - val_loss: 0.6008 - val_acc: 0.8326\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.4985 - acc: 0.8200\n",
      "logs/fit/lstm_val/kfold8\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 32s - loss: 0.7234 - acc: 0.5804 - val_loss: 0.6771 - val_acc: 0.5652\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.6823 - acc: 0.5804 - val_loss: 0.6838 - val_acc: 0.5652\n",
      "Epoch 3/30\n",
      "4140/4140 - 8s - loss: 0.6747 - acc: 0.5944 - val_loss: 8.5817 - val_acc: 0.6978\n",
      "Epoch 4/30\n",
      "4140/4140 - 8s - loss: 1.0346 - acc: 0.5915 - val_loss: 0.6667 - val_acc: 0.5652\n",
      "Epoch 5/30\n",
      "4140/4140 - 8s - loss: 0.6362 - acc: 0.5804 - val_loss: 0.6388 - val_acc: 0.5652\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.6062 - acc: 0.5804 - val_loss: 0.5947 - val_acc: 0.5652\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.5941 - acc: 0.5804 - val_loss: 0.5947 - val_acc: 0.5652\n",
      "Epoch 8/30\n",
      "4140/4140 - 8s - loss: 0.5422 - acc: 0.5804 - val_loss: 0.5624 - val_acc: 0.5652\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.5337 - acc: 0.5995 - val_loss: 0.5438 - val_acc: 0.5913\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.5317 - acc: 0.6606 - val_loss: 0.5418 - val_acc: 0.6609\n",
      "Epoch 11/30\n",
      "4140/4140 - 8s - loss: 0.4820 - acc: 0.7399 - val_loss: 0.5320 - val_acc: 0.7913\n",
      "Epoch 12/30\n",
      "4140/4140 - 7s - loss: 0.4691 - acc: 0.7911 - val_loss: 0.5250 - val_acc: 0.8087\n",
      "Epoch 13/30\n",
      "4140/4140 - 4s - loss: 0.4565 - acc: 0.8087 - val_loss: 0.5386 - val_acc: 0.8043\n",
      "Epoch 14/30\n",
      "4140/4140 - 1s - loss: 0.4426 - acc: 0.8140 - val_loss: 0.5684 - val_acc: 0.8065\n",
      "Epoch 15/30\n",
      "4140/4140 - 1s - loss: 0.4332 - acc: 0.8155 - val_loss: 0.6221 - val_acc: 0.8043\n",
      "Epoch 16/30\n",
      "4140/4140 - 1s - loss: 0.4231 - acc: 0.8167 - val_loss: 0.6906 - val_acc: 0.8109\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.4099 - acc: 0.8200 - val_loss: 0.8028 - val_acc: 0.8087\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.4162 - acc: 0.8121 - val_loss: 1.2267 - val_acc: 0.8196\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.4279 - acc: 0.8092 - val_loss: 0.8180 - val_acc: 0.8065\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.4414 - acc: 0.7913 - val_loss: 1.2488 - val_acc: 0.7848\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.4347 - acc: 0.8191 - val_loss: 0.5056 - val_acc: 0.8130\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.3724 - acc: 0.8534 - val_loss: 0.5390 - val_acc: 0.8130\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.3438 - acc: 0.8594 - val_loss: 0.6689 - val_acc: 0.8283\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.3185 - acc: 0.8679 - val_loss: 0.6952 - val_acc: 0.8065\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.2929 - acc: 0.8754 - val_loss: 0.6203 - val_acc: 0.7891\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.2913 - acc: 0.8746 - val_loss: 0.5304 - val_acc: 0.7630\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.3128 - acc: 0.8655 - val_loss: 0.5345 - val_acc: 0.8087\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.2775 - acc: 0.8879 - val_loss: 0.4849 - val_acc: 0.8152\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.2405 - acc: 0.9068 - val_loss: 0.5632 - val_acc: 0.8152\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.2111 - acc: 0.9213 - val_loss: 0.6400 - val_acc: 0.8087\n",
      "100/100 [==============================] - 0s 592us/sample - loss: 0.5201 - acc: 0.8200\n",
      "logs/fit/lstm_val/kfold9\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 24s - loss: 0.6926 - acc: 0.6022 - val_loss: 0.6876 - val_acc: 0.5609\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.7195 - acc: 0.5855 - val_loss: 0.6790 - val_acc: 0.5957\n",
      "Epoch 3/30\n",
      "4140/4140 - 7s - loss: 0.6657 - acc: 0.6829 - val_loss: 0.6380 - val_acc: 0.7217\n",
      "Epoch 4/30\n",
      "4140/4140 - 7s - loss: 1.1519 - acc: 0.7217 - val_loss: 0.6305 - val_acc: 0.7087\n",
      "Epoch 5/30\n",
      "4140/4140 - 7s - loss: 0.6437 - acc: 0.7017 - val_loss: 0.6526 - val_acc: 0.7065\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.6386 - acc: 0.7014 - val_loss: 0.6587 - val_acc: 0.6630\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.6417 - acc: 0.6983 - val_loss: 0.6428 - val_acc: 0.7326\n",
      "Epoch 8/30\n",
      "4140/4140 - 8s - loss: 0.6191 - acc: 0.7336 - val_loss: 0.6072 - val_acc: 0.7435\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.5919 - acc: 0.7539 - val_loss: 0.5821 - val_acc: 0.7652\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.5732 - acc: 0.7645 - val_loss: 0.5729 - val_acc: 0.7717\n",
      "Epoch 11/30\n",
      "4140/4140 - 7s - loss: 0.5551 - acc: 0.7734 - val_loss: 0.5607 - val_acc: 0.7870\n",
      "Epoch 12/30\n",
      "4140/4140 - 7s - loss: 0.5429 - acc: 0.7848 - val_loss: 0.5484 - val_acc: 0.7717\n",
      "Epoch 13/30\n",
      "4140/4140 - 7s - loss: 0.5375 - acc: 0.7833 - val_loss: 0.5608 - val_acc: 0.7435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "4140/4140 - 8s - loss: 0.5215 - acc: 0.8039 - val_loss: 0.5445 - val_acc: 0.7630\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.5058 - acc: 0.8106 - val_loss: 0.5343 - val_acc: 0.7696\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.4915 - acc: 0.8222 - val_loss: 0.5255 - val_acc: 0.7630\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.4770 - acc: 0.8278 - val_loss: 0.5126 - val_acc: 0.7761\n",
      "Epoch 18/30\n",
      "4140/4140 - 8s - loss: 0.4619 - acc: 0.8350 - val_loss: 0.4891 - val_acc: 0.8217\n",
      "Epoch 19/30\n",
      "4140/4140 - 8s - loss: 0.4522 - acc: 0.8386 - val_loss: 0.4791 - val_acc: 0.8283\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.4406 - acc: 0.8420 - val_loss: 0.4734 - val_acc: 0.8283\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.4323 - acc: 0.8447 - val_loss: 0.4718 - val_acc: 0.8065\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.4290 - acc: 0.8425 - val_loss: 0.4794 - val_acc: 0.7870\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.4481 - acc: 0.8256 - val_loss: 0.5326 - val_acc: 0.7261\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.3776 - acc: 0.8473 - val_loss: 0.4075 - val_acc: 0.8326\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.3591 - acc: 0.8623 - val_loss: 0.4243 - val_acc: 0.8022\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.3301 - acc: 0.8643 - val_loss: 0.4411 - val_acc: 0.7870\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.3190 - acc: 0.8705 - val_loss: 0.4736 - val_acc: 0.7935\n",
      "Epoch 28/30\n",
      "4140/4140 - 7s - loss: 0.3081 - acc: 0.8749 - val_loss: 0.5059 - val_acc: 0.7891\n",
      "Epoch 29/30\n",
      "4140/4140 - 7s - loss: 0.3008 - acc: 0.8792 - val_loss: 0.5095 - val_acc: 0.7891\n",
      "Epoch 30/30\n",
      "4140/4140 - 4s - loss: 0.2960 - acc: 0.8816 - val_loss: 0.5298 - val_acc: 0.7674\n",
      "100/100 [==============================] - 0s 613us/sample - loss: 1.0243 - acc: 0.7700\n",
      "logs/fit/lstm_val/kfold10\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 6s - loss: 0.6853 - acc: 0.5708 - val_loss: 0.6610 - val_acc: 0.6370\n",
      "Epoch 2/30\n",
      "4140/4140 - 1s - loss: 0.6599 - acc: 0.6758 - val_loss: 0.6657 - val_acc: 0.6761\n",
      "Epoch 3/30\n",
      "4140/4140 - 1s - loss: 0.6357 - acc: 0.6889 - val_loss: 0.6543 - val_acc: 0.6522\n",
      "Epoch 4/30\n",
      "4140/4140 - 1s - loss: 0.6084 - acc: 0.7147 - val_loss: 0.6003 - val_acc: 0.7196\n",
      "Epoch 5/30\n",
      "4140/4140 - 1s - loss: 0.5319 - acc: 0.7599 - val_loss: 0.5130 - val_acc: 0.7761\n",
      "Epoch 6/30\n",
      "4140/4140 - 1s - loss: 0.4513 - acc: 0.7879 - val_loss: 0.4177 - val_acc: 0.8000\n",
      "Epoch 7/30\n",
      "4140/4140 - 1s - loss: 0.4070 - acc: 0.8097 - val_loss: 0.3727 - val_acc: 0.8196\n",
      "Epoch 8/30\n",
      "4140/4140 - 1s - loss: 0.3909 - acc: 0.8205 - val_loss: 0.3856 - val_acc: 0.8130\n",
      "Epoch 9/30\n",
      "4140/4140 - 1s - loss: 0.3671 - acc: 0.8386 - val_loss: 0.3981 - val_acc: 0.8239\n",
      "Epoch 10/30\n",
      "4140/4140 - 1s - loss: 0.3497 - acc: 0.8522 - val_loss: 0.3951 - val_acc: 0.8261\n",
      "Epoch 11/30\n",
      "4140/4140 - 2s - loss: 0.3295 - acc: 0.8587 - val_loss: 0.3805 - val_acc: 0.8283\n",
      "Epoch 12/30\n",
      "4140/4140 - 2s - loss: 0.3127 - acc: 0.8669 - val_loss: 0.3748 - val_acc: 0.8413\n",
      "Epoch 13/30\n",
      "4140/4140 - 4s - loss: 0.2939 - acc: 0.8758 - val_loss: 0.3764 - val_acc: 0.8152\n",
      "Epoch 14/30\n",
      "4140/4140 - 4s - loss: 0.2759 - acc: 0.8841 - val_loss: 0.3866 - val_acc: 0.8152\n",
      "Epoch 15/30\n",
      "4140/4140 - 5s - loss: 0.2605 - acc: 0.8935 - val_loss: 0.3865 - val_acc: 0.8217\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.2450 - acc: 0.8952 - val_loss: 0.4642 - val_acc: 0.8087\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.2455 - acc: 0.8959 - val_loss: 0.4567 - val_acc: 0.7826\n",
      "Epoch 18/30\n",
      "4140/4140 - 7s - loss: 0.2672 - acc: 0.8923 - val_loss: 0.4912 - val_acc: 0.7500\n",
      "Epoch 19/30\n",
      "4140/4140 - 7s - loss: 0.3062 - acc: 0.8691 - val_loss: 0.3542 - val_acc: 0.8391\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.2743 - acc: 0.8853 - val_loss: 0.3716 - val_acc: 0.8435\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.2689 - acc: 0.8911 - val_loss: 0.6384 - val_acc: 0.8239\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.2492 - acc: 0.8983 - val_loss: 0.7704 - val_acc: 0.8370\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.2378 - acc: 0.9068 - val_loss: 0.6688 - val_acc: 0.8500\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.2081 - acc: 0.9203 - val_loss: 0.5653 - val_acc: 0.8522\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.1840 - acc: 0.9329 - val_loss: 0.5820 - val_acc: 0.8435\n",
      "Epoch 26/30\n",
      "4140/4140 - 8s - loss: 0.1654 - acc: 0.9391 - val_loss: 0.5978 - val_acc: 0.8391\n",
      "Epoch 27/30\n",
      "4140/4140 - 8s - loss: 0.1680 - acc: 0.9348 - val_loss: 0.4654 - val_acc: 0.8522\n",
      "Epoch 28/30\n",
      "4140/4140 - 7s - loss: 0.1610 - acc: 0.9413 - val_loss: 0.5735 - val_acc: 0.8283\n",
      "Epoch 29/30\n",
      "4140/4140 - 7s - loss: 0.1516 - acc: 0.9471 - val_loss: 0.5558 - val_acc: 0.8326\n",
      "Epoch 30/30\n",
      "4140/4140 - 8s - loss: 0.1483 - acc: 0.9423 - val_loss: 0.5573 - val_acc: 0.8543\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.3921 - acc: 0.8600\n"
     ]
    }
   ],
   "source": [
    "def create_lstm_val():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(64, kernel_initializer='normal', activation='relu', input_shape=(28, 300), name='lstm'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='normal', name='dense')\n",
    "    ])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "val_hist, val_evas = kfold_train(create_lstm_val, 'lstm_val', batch_size=128, epochs=30, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T14:09:36.424181Z",
     "start_time": "2019-06-14T13:56:18.260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "c3333708-e2f9-4613-817d-dbca9151a1c7",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6874701833955331,
          0.706623169419846,
          0.6710963219260248,
          0.6654274631813528,
          0.5932213718764447,
          0.5066218578297159,
          0.4088702054703293,
          0.3736141609972802,
          0.35522300324578215,
          0.3446812367381681,
          0.34036095211471334,
          0.3389648830545121,
          0.34663786067478897,
          0.3530307231317972,
          0.3181690387967704,
          0.3062730876719894,
          0.2919342741298215,
          0.27630485670578075,
          0.26121587926062984,
          0.24756211271320563,
          0.2368259363560285,
          0.2452618421131862,
          0.23242599815850096,
          0.2313622709489675,
          0.212091049451183,
          0.22275689920941413,
          0.2012147375638934,
          0.16777770882067472,
          0.1587878191816634,
          0.14400953479147188
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "78368e42-84ac-4021-ba99-a93137956a8d",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6763016700744628,
          0.6766908609348795,
          0.6087349591047867,
          0.6013861194900845,
          0.5503660150196241,
          0.4294813412687053,
          0.425452511984369,
          0.41990426960198773,
          0.42449004909266597,
          0.43739850780238276,
          0.4305491921694382,
          0.39785806070203367,
          0.3983637071174124,
          0.419414660723313,
          0.43797571296277255,
          0.474428985948148,
          0.5308328633723052,
          0.4985606960628344,
          0.46628528859304347,
          0.5053104566491169,
          0.5382607662159463,
          0.5116602125375167,
          0.6254202593927798,
          0.9466186769630598,
          0.6054310420285101,
          0.5304933882277945,
          0.5798910726671633,
          0.6010946403379026,
          0.6204700039780658,
          0.6543489067450814
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "7aa57d5c-8f67-427d-9d9a-342aacdd1381",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6823500026827273,
          0.6833853118085631,
          0.6310736833563173,
          0.57717384238174,
          0.5007655725386984,
          0.6042266359651722,
          0.5394310467485068,
          0.5230097873775279,
          0.7174976309140523,
          0.5423218728263597,
          0.4905447703628724,
          0.47621077201216694,
          0.46296844157043865,
          0.4484039879363516,
          0.4184318901548063,
          0.3834125961370514,
          0.33792678756990296,
          0.3029792961579014,
          0.279368985188756,
          0.2532667852974168,
          0.22865038085099004,
          0.22661030485434233,
          0.2138480523502193,
          0.2210313126516803,
          0.2581116509322383,
          0.2658555751261504,
          0.263757640555285,
          0.29618159526788096,
          0.2609046134395876,
          0.21701469356599062
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "2275886f-c7a7-439d-bf73-002a627615ee",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6751018213189166,
          0.6232141831646795,
          0.6030505299568176,
          0.5207040377285169,
          0.4714425636374432,
          0.5865776201953059,
          0.5921820744224217,
          0.4726422019626783,
          0.5976794724879058,
          0.5094486070715862,
          0.4927714640679567,
          0.48548291066418525,
          0.4752537286799887,
          0.4584055351174396,
          0.430359889631686,
          0.38547089721845545,
          0.36017296158749124,
          0.3600198058978371,
          0.35917294129081395,
          0.3676412976306418,
          0.38467085361480713,
          0.40232870630595996,
          0.4418146799439969,
          0.41445850911347765,
          0.43770429232846136,
          0.4511113415593686,
          0.39495931449143784,
          0.44927720531173376,
          0.516049131103184,
          0.5096315342447032
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "4bd4cb9c-d840-43f0-94e7-f68fc8f346ff",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.9245325119599052,
          0.6804881872762228,
          0.688758743615542,
          0.6847241847987336,
          0.6829255597602918,
          0.6809271774430206,
          0.6780568005958041,
          0.6676343104689594,
          0.6489839562471362,
          0.6502684393942644,
          0.6248870251259366,
          0.6358015177330533,
          0.5772302892473009,
          0.5373128290337641,
          0.5040568483912427,
          0.5033573849189684,
          0.502583432543105,
          0.4612991322353842,
          0.4268133887634185,
          0.38338006464179586,
          0.3414983403567531,
          0.3221879728462385,
          0.3118180024019186,
          0.30070557172459683,
          0.2920030656500139,
          0.2813331100243877,
          0.27414006209315883,
          0.2615203419457311,
          0.24710903648593,
          0.2310062382316244
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "ce3210f5-cfea-4c22-918c-080bd52ee3ee",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6700830775758494,
          0.6691184520721436,
          0.6831856919371564,
          0.680699430341306,
          0.6782019423401874,
          0.6754275840261709,
          0.6712079141450965,
          0.6376797878223917,
          0.657114841627038,
          0.6219550651052724,
          0.6472818353901739,
          0.6041322448979254,
          0.5743937331697215,
          0.5899609788604404,
          0.5529725116232167,
          0.5380449828894242,
          0.540323007106781,
          0.5196624172770459,
          0.49379521815673166,
          0.445497829499452,
          0.4099966676338859,
          0.3889024283574975,
          0.41847152424895245,
          0.4427933234235515,
          0.4006693049617436,
          0.396182003746862,
          0.39754630171734356,
          0.4327701897724815,
          0.4341354318287062,
          0.47209198112073153
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "2fdac90d-f725-40c5-bcc6-3b27aa0cfc7a",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.7066485666422452,
          0.6857101208921792,
          0.6868763980658158,
          0.6793091279297059,
          0.6737215429688421,
          0.6289346588406586,
          0.6118076095834446,
          0.5971765142132118,
          0.5047484190279735,
          0.46943653001301533,
          0.4209130987165055,
          0.41568907196970956,
          0.36121766921402754,
          0.33219932663267937,
          0.31064928502276323,
          0.2981270567230556,
          0.2977356071489445,
          0.2851623719153197,
          0.25945571017438085,
          0.23119020821967562,
          0.21571935478615875,
          0.1942151985882561,
          0.30204626866008927,
          0.227834224211421,
          0.20153712782882838,
          0.17634078723508956,
          0.1627097229450797,
          0.16827384057828193,
          0.21457585552752306,
          0.2590966393118319
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "44de8247-1f27-4b5e-a68a-70b4a467d744",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6833691928697669,
          0.6798181450885276,
          0.6779982152192489,
          0.6701065903124602,
          0.6546256153479867,
          0.5876989095107369,
          0.5785552859306335,
          0.4926465065582939,
          0.44552860415500145,
          0.4214374803978464,
          0.42511996989664824,
          0.3834386330583821,
          0.4640515514042067,
          0.5120287343211796,
          0.5595911772354789,
          0.6696761525195578,
          0.8710989848427151,
          0.8258008192414823,
          0.8671508382196011,
          0.9398291582646577,
          0.7434561527293662,
          0.7550521871317988,
          0.4067420410073322,
          0.5799531128095544,
          0.6499879697094793,
          0.6149585749792016,
          0.6254315707994544,
          0.6039751913236535,
          0.42075998109319934,
          0.5169785618782043
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "fb057b28-07b0-4ab3-b442-07a4f6e19831",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.704293329704211,
          0.6794737371845522,
          0.6403393342875052,
          0.6117860583867428,
          0.5239551685282574,
          0.4446709668290788,
          0.4220685082645232,
          0.3933501564650144,
          0.3668859998673057,
          0.34783287396753465,
          0.33422024848956416,
          0.32326618415721947,
          0.31284020427920395,
          0.30223849245891476,
          0.2841511188497866,
          0.2678961748806175,
          0.24904424515035417,
          0.2619894682209273,
          0.24636061347049215,
          0.25493482662283856,
          0.2202871549244664,
          0.20428752602586422,
          0.18194502341574517,
          0.18218704767993107,
          0.1668440722828902,
          0.15735207885359798,
          0.14905366259784514,
          0.13817116998963885,
          0.150534920387222,
          0.12451459513122333
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "742587c8-5c93-4585-a753-8c0a9000d245",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6804138105848562,
          0.6619357072788736,
          0.6494013407955999,
          0.590853968910549,
          0.49717492253884027,
          0.4333924169125764,
          0.39854863130527995,
          0.3958205461502075,
          0.3824748140314351,
          0.3782014776831088,
          0.37404585066048995,
          0.3720497683338497,
          0.3708727038424948,
          0.36887165359828783,
          0.37484238562376604,
          0.3811151483784551,
          0.3855621910613516,
          0.37788659930229185,
          0.44706638040749924,
          0.4137749728949174,
          0.46049108971720154,
          0.49694770678229955,
          0.577515161037445,
          0.6280048875705055,
          0.6290415053782256,
          0.5271235212035801,
          0.5853965163230896,
          0.565734684985617,
          0.7615740444349206,
          0.8135996481646662
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "efa4c945-96cf-4b74-9c7b-37f6a39f21a1",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6818604407679055,
          0.6645724630010301,
          0.6290667485499728,
          0.5431427742548035,
          0.49333470740180085,
          0.4703099134175674,
          0.4525569972208733,
          0.4362680398899576,
          0.4213932810774172,
          0.40623814000023734,
          0.3882355169685566,
          0.36988273576837805,
          0.3590735455929945,
          0.3815754050217965,
          0.38743732807716885,
          0.3563324777400436,
          0.3230692297940093,
          0.3095616328255566,
          0.29228162371018085,
          0.3009290647679481,
          0.3290495154650315,
          0.2813075702547451,
          0.2712425296145361,
          0.2575598873521971,
          0.2610092038549663,
          0.24619584424772126,
          0.27392019737457884,
          0.3151334320721419,
          0.27523037435639885,
          0.22378628652740792
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "ca8535ca-3cc4-40aa-9baa-d164bbae5386",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6725895549940026,
          0.6334776867990909,
          0.6111835329428963,
          0.5098202705383301,
          0.48082488334697226,
          0.467072745250619,
          0.4540376004965409,
          0.44674139411553093,
          0.4433938796105592,
          0.4451470680858778,
          0.43765482461970784,
          0.4442687348179195,
          0.43168501024660855,
          0.41705899290416554,
          0.45573754103287406,
          0.45374595445135363,
          0.5072618100954138,
          0.4857965031395788,
          0.5802431456420732,
          0.5250800591448079,
          0.43099266757135807,
          0.4637180911458057,
          0.4800135394801264,
          0.5295434866262518,
          0.48987891829532126,
          0.47053926924000616,
          0.44124968414721283,
          0.8930751588033593,
          0.5902064162751902,
          0.5516195820725482
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "59713081-008d-4882-8d21-bc80ad6b210f",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.7050617256026337,
          0.6889201819032863,
          0.6772480547140186,
          0.6499899886656498,
          0.4837652265449653,
          0.405300473936514,
          0.3687719111281317,
          0.3475186053969434,
          0.33515160708611713,
          0.3245882057337369,
          0.3186434909629361,
          0.3114146280115929,
          0.27962462487428086,
          0.25939147216110414,
          0.24926760118940602,
          0.23850977364657583,
          0.20830487816230112,
          0.22769161873105642,
          0.25993005496580246,
          0.3306839050302183,
          0.27118549692458,
          0.22934925597934908,
          0.21916532358109664,
          0.17955565346755845,
          0.1526859012922803,
          0.1385176930954491,
          0.12435501841243339,
          0.1373857261693996,
          0.1285131111957025,
          0.1515344365567401
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "3ca34703-bc0c-4fc0-8af8-fa6ee7197418",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.909928089639415,
          0.6818808488223864,
          0.6746236350225365,
          0.6186244259709898,
          0.4674381740715193,
          0.4258303364981776,
          0.4120736609334531,
          0.40089704938556836,
          0.4015027898809184,
          0.4095442468705385,
          0.4316627896350363,
          0.39832323971002,
          0.39729089140892027,
          0.45915986040364143,
          0.4430524776811185,
          0.47029323059579603,
          0.7289860093075297,
          0.6242985227833624,
          0.6285750808923141,
          0.5075763075248055,
          0.6302109251851621,
          0.6183782898861429,
          0.6021053692568903,
          0.5655509614426156,
          0.5707732713740805,
          0.6331986862680187,
          0.7575441671454388,
          0.7120006742684738,
          0.6088210155134616,
          0.6008457147556803
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "e0f32e94-b213-4337-9ba2-5d499cb95314",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.7234389348882408,
          0.6823100765546163,
          0.6746993149536243,
          1.0346070602896134,
          0.6362279861445588,
          0.6062024114788442,
          0.5940936840674728,
          0.5421932664470396,
          0.5337150959001071,
          0.5316704812257186,
          0.4819642619234352,
          0.4690989305719661,
          0.4565121930866426,
          0.4426185396846366,
          0.43321841612530215,
          0.4230560306189717,
          0.40991966266562974,
          0.41620609305331097,
          0.42793484327297854,
          0.44138314306448045,
          0.4346785725314836,
          0.3723699601088169,
          0.3437813215497611,
          0.3184814861431214,
          0.2928542787038186,
          0.2913408348813725,
          0.3127858862064887,
          0.27753200434544234,
          0.24048875364416464,
          0.21106474798370675
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "e65109ab-420e-4dcb-9350-f1a873e3cc38",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6771340370178223,
          0.6837722379228343,
          8.581675042276798,
          0.6666913452355758,
          0.6388135153314342,
          0.5946741757185563,
          0.5947284724401392,
          0.5623751977215643,
          0.5438447211099707,
          0.5417719841003418,
          0.5319671457228453,
          0.5249532603699228,
          0.5386492609977722,
          0.568394294510717,
          0.6220880259638247,
          0.6906219534252,
          0.8027853405993918,
          1.2266860438429792,
          0.8180023654647496,
          1.2488467071367346,
          0.5056305615798287,
          0.5389956806017004,
          0.6689421581185382,
          0.6951859847359035,
          0.6202701775924019,
          0.5304025981737219,
          0.5344974445260089,
          0.4848685285319453,
          0.5631998663363249,
          0.6400369721910227
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "79f15b5d-99ca-4dc8-8641-c5a28242e120",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6925849027103848,
          0.7195077941037606,
          0.6657317501911219,
          1.151862483266471,
          0.6437109582090147,
          0.6385714431315804,
          0.6417484179211124,
          0.6191356307642472,
          0.5918513971826305,
          0.5731524828551472,
          0.5551386921302132,
          0.5429300060594715,
          0.5375193432333388,
          0.5215304197896505,
          0.5058027914180848,
          0.4914588541224383,
          0.4770177271055139,
          0.4619335915155457,
          0.452190827747474,
          0.44058339745526154,
          0.43230502994164177,
          0.4289746502171392,
          0.44812408639612983,
          0.3775797769643258,
          0.359080961332229,
          0.33008696935027115,
          0.3190040949750062,
          0.30811570528624715,
          0.300781145936625,
          0.2959529143024758
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "4d89d3df-d2e6-4ffd-8822-57a027540fb6",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6875770760619122,
          0.6789976835250855,
          0.6380235117414723,
          0.6304910908574644,
          0.6525910750679348,
          0.6586928694144539,
          0.6428005757539169,
          0.6072151178899019,
          0.5820643352425616,
          0.5729194516720979,
          0.5606634601302769,
          0.5484262746313344,
          0.5608401422915251,
          0.5444950528766798,
          0.5343117926431739,
          0.5255330521127451,
          0.5125504851341247,
          0.4891230132268823,
          0.47910785208577694,
          0.4734384394210318,
          0.47176809025847394,
          0.4794466409994208,
          0.5326101075048032,
          0.40748179684514585,
          0.42428884609885836,
          0.44107645076254137,
          0.47361898474071334,
          0.5059121784956558,
          0.5095031476539115,
          0.529774676716846
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "8fb630dc-1c6c-4e76-813a-353582a481f4",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6852841722216583,
          0.6598710159172758,
          0.6356874083551232,
          0.6083653133272549,
          0.5319286202462975,
          0.45133171493304525,
          0.4069948135366762,
          0.3908644856462156,
          0.36709743827437435,
          0.3497156880328045,
          0.3295171316983043,
          0.3126741814872493,
          0.293901661110385,
          0.2758920263696984,
          0.26054370996456794,
          0.24503966139422523,
          0.24549795515871278,
          0.2671659494943665,
          0.30621192701484845,
          0.2743348545498318,
          0.26888518851736315,
          0.24916947862664282,
          0.23782503917309397,
          0.20812398231979728,
          0.18397377378122817,
          0.16541043503416908,
          0.16804767764996792,
          0.1610165413811011,
          0.1516467151074594,
          0.1483003795650846
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "2a0887c1-a18b-4c6b-8a54-fc1a33a91d0a",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.661036205291748,
          0.6657302452170331,
          0.6542632439862127,
          0.6002701754155366,
          0.5129631182421809,
          0.4176908721094546,
          0.3727490533953128,
          0.38560090764709143,
          0.3981081511663354,
          0.39512561404186747,
          0.380516452115515,
          0.37482996505239735,
          0.3764482355636099,
          0.3866364862607873,
          0.3864826124647389,
          0.4642000418642293,
          0.4566889109818832,
          0.4911520771358324,
          0.3542473971843719,
          0.37162249813909115,
          0.6383858198704927,
          0.7703869959582453,
          0.6688327493874923,
          0.565308087805043,
          0.5819662503574206,
          0.5978324045305666,
          0.4653977173825969,
          0.5734645916068035,
          0.5558154930239139,
          0.5573097480380017
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"18ff3614-40d2-4a21-88b0-fa9803ff800d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"18ff3614-40d2-4a21-88b0-fa9803ff800d\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '18ff3614-40d2-4a21-88b0-fa9803ff800d',\n",
       "                        [{\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"c3333708-e2f9-4613-817d-dbca9151a1c7\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6874701833955331, 0.706623169419846, 0.6710963219260248, 0.6654274631813528, 0.5932213718764447, 0.5066218578297159, 0.4088702054703293, 0.3736141609972802, 0.35522300324578215, 0.3446812367381681, 0.34036095211471334, 0.3389648830545121, 0.34663786067478897, 0.3530307231317972, 0.3181690387967704, 0.3062730876719894, 0.2919342741298215, 0.27630485670578075, 0.26121587926062984, 0.24756211271320563, 0.2368259363560285, 0.2452618421131862, 0.23242599815850096, 0.2313622709489675, 0.212091049451183, 0.22275689920941413, 0.2012147375638934, 0.16777770882067472, 0.1587878191816634, 0.14400953479147188]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"78368e42-84ac-4021-ba99-a93137956a8d\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6763016700744628, 0.6766908609348795, 0.6087349591047867, 0.6013861194900845, 0.5503660150196241, 0.4294813412687053, 0.425452511984369, 0.41990426960198773, 0.42449004909266597, 0.43739850780238276, 0.4305491921694382, 0.39785806070203367, 0.3983637071174124, 0.419414660723313, 0.43797571296277255, 0.474428985948148, 0.5308328633723052, 0.4985606960628344, 0.46628528859304347, 0.5053104566491169, 0.5382607662159463, 0.5116602125375167, 0.6254202593927798, 0.9466186769630598, 0.6054310420285101, 0.5304933882277945, 0.5798910726671633, 0.6010946403379026, 0.6204700039780658, 0.6543489067450814]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"7aa57d5c-8f67-427d-9d9a-342aacdd1381\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6823500026827273, 0.6833853118085631, 0.6310736833563173, 0.57717384238174, 0.5007655725386984, 0.6042266359651722, 0.5394310467485068, 0.5230097873775279, 0.7174976309140523, 0.5423218728263597, 0.4905447703628724, 0.47621077201216694, 0.46296844157043865, 0.4484039879363516, 0.4184318901548063, 0.3834125961370514, 0.33792678756990296, 0.3029792961579014, 0.279368985188756, 0.2532667852974168, 0.22865038085099004, 0.22661030485434233, 0.2138480523502193, 0.2210313126516803, 0.2581116509322383, 0.2658555751261504, 0.263757640555285, 0.29618159526788096, 0.2609046134395876, 0.21701469356599062]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"2275886f-c7a7-439d-bf73-002a627615ee\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6751018213189166, 0.6232141831646795, 0.6030505299568176, 0.5207040377285169, 0.4714425636374432, 0.5865776201953059, 0.5921820744224217, 0.4726422019626783, 0.5976794724879058, 0.5094486070715862, 0.4927714640679567, 0.48548291066418525, 0.4752537286799887, 0.4584055351174396, 0.430359889631686, 0.38547089721845545, 0.36017296158749124, 0.3600198058978371, 0.35917294129081395, 0.3676412976306418, 0.38467085361480713, 0.40232870630595996, 0.4418146799439969, 0.41445850911347765, 0.43770429232846136, 0.4511113415593686, 0.39495931449143784, 0.44927720531173376, 0.516049131103184, 0.5096315342447032]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"4bd4cb9c-d840-43f0-94e7-f68fc8f346ff\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.9245325119599052, 0.6804881872762228, 0.688758743615542, 0.6847241847987336, 0.6829255597602918, 0.6809271774430206, 0.6780568005958041, 0.6676343104689594, 0.6489839562471362, 0.6502684393942644, 0.6248870251259366, 0.6358015177330533, 0.5772302892473009, 0.5373128290337641, 0.5040568483912427, 0.5033573849189684, 0.502583432543105, 0.4612991322353842, 0.4268133887634185, 0.38338006464179586, 0.3414983403567531, 0.3221879728462385, 0.3118180024019186, 0.30070557172459683, 0.2920030656500139, 0.2813331100243877, 0.27414006209315883, 0.2615203419457311, 0.24710903648593, 0.2310062382316244]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"ce3210f5-cfea-4c22-918c-080bd52ee3ee\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6700830775758494, 0.6691184520721436, 0.6831856919371564, 0.680699430341306, 0.6782019423401874, 0.6754275840261709, 0.6712079141450965, 0.6376797878223917, 0.657114841627038, 0.6219550651052724, 0.6472818353901739, 0.6041322448979254, 0.5743937331697215, 0.5899609788604404, 0.5529725116232167, 0.5380449828894242, 0.540323007106781, 0.5196624172770459, 0.49379521815673166, 0.445497829499452, 0.4099966676338859, 0.3889024283574975, 0.41847152424895245, 0.4427933234235515, 0.4006693049617436, 0.396182003746862, 0.39754630171734356, 0.4327701897724815, 0.4341354318287062, 0.47209198112073153]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"2fdac90d-f725-40c5-bcc6-3b27aa0cfc7a\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.7066485666422452, 0.6857101208921792, 0.6868763980658158, 0.6793091279297059, 0.6737215429688421, 0.6289346588406586, 0.6118076095834446, 0.5971765142132118, 0.5047484190279735, 0.46943653001301533, 0.4209130987165055, 0.41568907196970956, 0.36121766921402754, 0.33219932663267937, 0.31064928502276323, 0.2981270567230556, 0.2977356071489445, 0.2851623719153197, 0.25945571017438085, 0.23119020821967562, 0.21571935478615875, 0.1942151985882561, 0.30204626866008927, 0.227834224211421, 0.20153712782882838, 0.17634078723508956, 0.1627097229450797, 0.16827384057828193, 0.21457585552752306, 0.2590966393118319]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"44de8247-1f27-4b5e-a68a-70b4a467d744\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6833691928697669, 0.6798181450885276, 0.6779982152192489, 0.6701065903124602, 0.6546256153479867, 0.5876989095107369, 0.5785552859306335, 0.4926465065582939, 0.44552860415500145, 0.4214374803978464, 0.42511996989664824, 0.3834386330583821, 0.4640515514042067, 0.5120287343211796, 0.5595911772354789, 0.6696761525195578, 0.8710989848427151, 0.8258008192414823, 0.8671508382196011, 0.9398291582646577, 0.7434561527293662, 0.7550521871317988, 0.4067420410073322, 0.5799531128095544, 0.6499879697094793, 0.6149585749792016, 0.6254315707994544, 0.6039751913236535, 0.42075998109319934, 0.5169785618782043]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"fb057b28-07b0-4ab3-b442-07a4f6e19831\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.704293329704211, 0.6794737371845522, 0.6403393342875052, 0.6117860583867428, 0.5239551685282574, 0.4446709668290788, 0.4220685082645232, 0.3933501564650144, 0.3668859998673057, 0.34783287396753465, 0.33422024848956416, 0.32326618415721947, 0.31284020427920395, 0.30223849245891476, 0.2841511188497866, 0.2678961748806175, 0.24904424515035417, 0.2619894682209273, 0.24636061347049215, 0.25493482662283856, 0.2202871549244664, 0.20428752602586422, 0.18194502341574517, 0.18218704767993107, 0.1668440722828902, 0.15735207885359798, 0.14905366259784514, 0.13817116998963885, 0.150534920387222, 0.12451459513122333]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"742587c8-5c93-4585-a753-8c0a9000d245\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6804138105848562, 0.6619357072788736, 0.6494013407955999, 0.590853968910549, 0.49717492253884027, 0.4333924169125764, 0.39854863130527995, 0.3958205461502075, 0.3824748140314351, 0.3782014776831088, 0.37404585066048995, 0.3720497683338497, 0.3708727038424948, 0.36887165359828783, 0.37484238562376604, 0.3811151483784551, 0.3855621910613516, 0.37788659930229185, 0.44706638040749924, 0.4137749728949174, 0.46049108971720154, 0.49694770678229955, 0.577515161037445, 0.6280048875705055, 0.6290415053782256, 0.5271235212035801, 0.5853965163230896, 0.565734684985617, 0.7615740444349206, 0.8135996481646662]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"efa4c945-96cf-4b74-9c7b-37f6a39f21a1\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6818604407679055, 0.6645724630010301, 0.6290667485499728, 0.5431427742548035, 0.49333470740180085, 0.4703099134175674, 0.4525569972208733, 0.4362680398899576, 0.4213932810774172, 0.40623814000023734, 0.3882355169685566, 0.36988273576837805, 0.3590735455929945, 0.3815754050217965, 0.38743732807716885, 0.3563324777400436, 0.3230692297940093, 0.3095616328255566, 0.29228162371018085, 0.3009290647679481, 0.3290495154650315, 0.2813075702547451, 0.2712425296145361, 0.2575598873521971, 0.2610092038549663, 0.24619584424772126, 0.27392019737457884, 0.3151334320721419, 0.27523037435639885, 0.22378628652740792]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"ca8535ca-3cc4-40aa-9baa-d164bbae5386\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6725895549940026, 0.6334776867990909, 0.6111835329428963, 0.5098202705383301, 0.48082488334697226, 0.467072745250619, 0.4540376004965409, 0.44674139411553093, 0.4433938796105592, 0.4451470680858778, 0.43765482461970784, 0.4442687348179195, 0.43168501024660855, 0.41705899290416554, 0.45573754103287406, 0.45374595445135363, 0.5072618100954138, 0.4857965031395788, 0.5802431456420732, 0.5250800591448079, 0.43099266757135807, 0.4637180911458057, 0.4800135394801264, 0.5295434866262518, 0.48987891829532126, 0.47053926924000616, 0.44124968414721283, 0.8930751588033593, 0.5902064162751902, 0.5516195820725482]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"59713081-008d-4882-8d21-bc80ad6b210f\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.7050617256026337, 0.6889201819032863, 0.6772480547140186, 0.6499899886656498, 0.4837652265449653, 0.405300473936514, 0.3687719111281317, 0.3475186053969434, 0.33515160708611713, 0.3245882057337369, 0.3186434909629361, 0.3114146280115929, 0.27962462487428086, 0.25939147216110414, 0.24926760118940602, 0.23850977364657583, 0.20830487816230112, 0.22769161873105642, 0.25993005496580246, 0.3306839050302183, 0.27118549692458, 0.22934925597934908, 0.21916532358109664, 0.17955565346755845, 0.1526859012922803, 0.1385176930954491, 0.12435501841243339, 0.1373857261693996, 0.1285131111957025, 0.1515344365567401]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"3ca34703-bc0c-4fc0-8af8-fa6ee7197418\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.909928089639415, 0.6818808488223864, 0.6746236350225365, 0.6186244259709898, 0.4674381740715193, 0.4258303364981776, 0.4120736609334531, 0.40089704938556836, 0.4015027898809184, 0.4095442468705385, 0.4316627896350363, 0.39832323971002, 0.39729089140892027, 0.45915986040364143, 0.4430524776811185, 0.47029323059579603, 0.7289860093075297, 0.6242985227833624, 0.6285750808923141, 0.5075763075248055, 0.6302109251851621, 0.6183782898861429, 0.6021053692568903, 0.5655509614426156, 0.5707732713740805, 0.6331986862680187, 0.7575441671454388, 0.7120006742684738, 0.6088210155134616, 0.6008457147556803]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"e0f32e94-b213-4337-9ba2-5d499cb95314\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.7234389348882408, 0.6823100765546163, 0.6746993149536243, 1.0346070602896134, 0.6362279861445588, 0.6062024114788442, 0.5940936840674728, 0.5421932664470396, 0.5337150959001071, 0.5316704812257186, 0.4819642619234352, 0.4690989305719661, 0.4565121930866426, 0.4426185396846366, 0.43321841612530215, 0.4230560306189717, 0.40991966266562974, 0.41620609305331097, 0.42793484327297854, 0.44138314306448045, 0.4346785725314836, 0.3723699601088169, 0.3437813215497611, 0.3184814861431214, 0.2928542787038186, 0.2913408348813725, 0.3127858862064887, 0.27753200434544234, 0.24048875364416464, 0.21106474798370675]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"e65109ab-420e-4dcb-9350-f1a873e3cc38\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6771340370178223, 0.6837722379228343, 8.581675042276798, 0.6666913452355758, 0.6388135153314342, 0.5946741757185563, 0.5947284724401392, 0.5623751977215643, 0.5438447211099707, 0.5417719841003418, 0.5319671457228453, 0.5249532603699228, 0.5386492609977722, 0.568394294510717, 0.6220880259638247, 0.6906219534252, 0.8027853405993918, 1.2266860438429792, 0.8180023654647496, 1.2488467071367346, 0.5056305615798287, 0.5389956806017004, 0.6689421581185382, 0.6951859847359035, 0.6202701775924019, 0.5304025981737219, 0.5344974445260089, 0.4848685285319453, 0.5631998663363249, 0.6400369721910227]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"79f15b5d-99ca-4dc8-8641-c5a28242e120\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6925849027103848, 0.7195077941037606, 0.6657317501911219, 1.151862483266471, 0.6437109582090147, 0.6385714431315804, 0.6417484179211124, 0.6191356307642472, 0.5918513971826305, 0.5731524828551472, 0.5551386921302132, 0.5429300060594715, 0.5375193432333388, 0.5215304197896505, 0.5058027914180848, 0.4914588541224383, 0.4770177271055139, 0.4619335915155457, 0.452190827747474, 0.44058339745526154, 0.43230502994164177, 0.4289746502171392, 0.44812408639612983, 0.3775797769643258, 0.359080961332229, 0.33008696935027115, 0.3190040949750062, 0.30811570528624715, 0.300781145936625, 0.2959529143024758]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"4d89d3df-d2e6-4ffd-8822-57a027540fb6\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6875770760619122, 0.6789976835250855, 0.6380235117414723, 0.6304910908574644, 0.6525910750679348, 0.6586928694144539, 0.6428005757539169, 0.6072151178899019, 0.5820643352425616, 0.5729194516720979, 0.5606634601302769, 0.5484262746313344, 0.5608401422915251, 0.5444950528766798, 0.5343117926431739, 0.5255330521127451, 0.5125504851341247, 0.4891230132268823, 0.47910785208577694, 0.4734384394210318, 0.47176809025847394, 0.4794466409994208, 0.5326101075048032, 0.40748179684514585, 0.42428884609885836, 0.44107645076254137, 0.47361898474071334, 0.5059121784956558, 0.5095031476539115, 0.529774676716846]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"8fb630dc-1c6c-4e76-813a-353582a481f4\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6852841722216583, 0.6598710159172758, 0.6356874083551232, 0.6083653133272549, 0.5319286202462975, 0.45133171493304525, 0.4069948135366762, 0.3908644856462156, 0.36709743827437435, 0.3497156880328045, 0.3295171316983043, 0.3126741814872493, 0.293901661110385, 0.2758920263696984, 0.26054370996456794, 0.24503966139422523, 0.24549795515871278, 0.2671659494943665, 0.30621192701484845, 0.2743348545498318, 0.26888518851736315, 0.24916947862664282, 0.23782503917309397, 0.20812398231979728, 0.18397377378122817, 0.16541043503416908, 0.16804767764996792, 0.1610165413811011, 0.1516467151074594, 0.1483003795650846]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"2a0887c1-a18b-4c6b-8a54-fc1a33a91d0a\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.661036205291748, 0.6657302452170331, 0.6542632439862127, 0.6002701754155366, 0.5129631182421809, 0.4176908721094546, 0.3727490533953128, 0.38560090764709143, 0.3981081511663354, 0.39512561404186747, 0.380516452115515, 0.37482996505239735, 0.3764482355636099, 0.3866364862607873, 0.3864826124647389, 0.4642000418642293, 0.4566889109818832, 0.4911520771358324, 0.3542473971843719, 0.37162249813909115, 0.6383858198704927, 0.7703869959582453, 0.6688327493874923, 0.565308087805043, 0.5819662503574206, 0.5978324045305666, 0.4653977173825969, 0.5734645916068035, 0.5558154930239139, 0.5573097480380017]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('18ff3614-40d2-4a21-88b0-fa9803ff800d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean  acc         0.817654\n",
      "loss        0.397367\n",
      "val_acc     0.782565\n",
      "val_loss    0.569382\n",
      "dtype: float64\n",
      "std  acc         0.111895\n",
      "loss        0.178906\n",
      "val_acc     0.081457\n",
      "val_loss    0.482332\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "1",
         "text": "",
         "type": "scatter",
         "uid": "5b7469f8-7d0c-4756-9489-ddc9333b6ded",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.8500000238418579,
          0.8199999928474426,
          0.8500000238418579,
          0.75,
          0.8399999737739563,
          0.8399999737739563,
          0.8199999928474426,
          0.8199999928474426,
          0.7699999809265137,
          0.8600000143051147
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"5c5d1946-835c-4e0e-a8a5-61ecde51fcca\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"5c5d1946-835c-4e0e-a8a5-61ecde51fcca\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '5c5d1946-835c-4e0e-a8a5-61ecde51fcca',\n",
       "                        [{\"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"1\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"5b7469f8-7d0c-4756-9489-ddc9333b6ded\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.8500000238418579, 0.8199999928474426, 0.8500000238418579, 0.75, 0.8399999737739563, 0.8399999737739563, 0.8199999928474426, 0.8199999928474426, 0.7699999809265137, 0.8600000143051147]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('5c5d1946-835c-4e0e-a8a5-61ecde51fcca');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media  0.8219999969005585\n",
      "std  0.0358391529207282\n"
     ]
    }
   ],
   "source": [
    "process_results(val_hist, val_evas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La reducción de la variable loss en el conjunto de entrenamiento produce un efecto de sobreentrenamiento que provoca un mayor error en el conjunto de validación\n",
    "\n",
    "Algunas de las opciones para reducir este efecto son:\n",
    "* Reducir la complejidad de la red neuronal\n",
    "* Aplicar alguna clase de regularización al modelo\n",
    "* Buscar una topología que se adapte mejor al problema\n",
    "* Obtener más datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducción complejidad modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.049857Z",
     "start_time": "2019-06-14T06:36:08.303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/lstm_simple/kfold1\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 10s - loss: 0.6913 - acc: 0.5773 - val_loss: 0.6691 - val_acc: 0.5957\n",
      "Epoch 2/30\n",
      "4140/4140 - 3s - loss: 0.6675 - acc: 0.5771 - val_loss: 0.6729 - val_acc: 0.5957\n",
      "Epoch 3/30\n",
      "4140/4140 - 4s - loss: 0.6523 - acc: 0.5771 - val_loss: 0.6207 - val_acc: 0.5957\n",
      "Epoch 4/30\n",
      "4140/4140 - 4s - loss: 0.6089 - acc: 0.5821 - val_loss: 0.5691 - val_acc: 0.6761\n",
      "Epoch 5/30\n",
      "4140/4140 - 7s - loss: 0.5496 - acc: 0.6601 - val_loss: 0.5520 - val_acc: 0.6500\n",
      "Epoch 6/30\n",
      "4140/4140 - 8s - loss: 0.5248 - acc: 0.7024 - val_loss: 0.5296 - val_acc: 0.7478\n",
      "Epoch 7/30\n",
      "4140/4140 - 8s - loss: 0.4890 - acc: 0.7862 - val_loss: 0.4961 - val_acc: 0.7913\n",
      "Epoch 8/30\n",
      "4140/4140 - 8s - loss: 0.4811 - acc: 0.8056 - val_loss: 0.4605 - val_acc: 0.7913\n",
      "Epoch 9/30\n",
      "4140/4140 - 8s - loss: 0.4498 - acc: 0.8116 - val_loss: 0.4297 - val_acc: 0.8000\n",
      "Epoch 10/30\n",
      "4140/4140 - 9s - loss: 0.4235 - acc: 0.8171 - val_loss: 0.4213 - val_acc: 0.8000\n",
      "Epoch 11/30\n",
      "4140/4140 - 8s - loss: 0.4083 - acc: 0.8258 - val_loss: 0.4290 - val_acc: 0.8109\n",
      "Epoch 12/30\n",
      "4140/4140 - 8s - loss: 0.3905 - acc: 0.8302 - val_loss: 0.4159 - val_acc: 0.8043\n",
      "Epoch 13/30\n",
      "4140/4140 - 8s - loss: 0.3827 - acc: 0.8348 - val_loss: 0.4139 - val_acc: 0.8109\n",
      "Epoch 14/30\n",
      "4140/4140 - 8s - loss: 0.3819 - acc: 0.8348 - val_loss: 0.4183 - val_acc: 0.8109\n",
      "Epoch 15/30\n",
      "4140/4140 - 8s - loss: 0.3726 - acc: 0.8377 - val_loss: 0.3969 - val_acc: 0.8043\n",
      "Epoch 16/30\n",
      "4140/4140 - 4s - loss: 0.3596 - acc: 0.8457 - val_loss: 0.3978 - val_acc: 0.8109\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.3524 - acc: 0.8457 - val_loss: 0.4002 - val_acc: 0.8109\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.3478 - acc: 0.8483 - val_loss: 0.4097 - val_acc: 0.8109\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.3449 - acc: 0.8488 - val_loss: 0.3865 - val_acc: 0.8196\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.3382 - acc: 0.8565 - val_loss: 0.3991 - val_acc: 0.8130\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.3372 - acc: 0.8606 - val_loss: 0.4120 - val_acc: 0.8087\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.3406 - acc: 0.8563 - val_loss: 0.4007 - val_acc: 0.8065\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.3264 - acc: 0.8635 - val_loss: 0.4170 - val_acc: 0.8174\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.3348 - acc: 0.8589 - val_loss: 0.4078 - val_acc: 0.8022\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.3247 - acc: 0.8650 - val_loss: 0.3871 - val_acc: 0.8109\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.3164 - acc: 0.8676 - val_loss: 0.3859 - val_acc: 0.8217\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.3090 - acc: 0.8708 - val_loss: 0.3857 - val_acc: 0.8043\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.3110 - acc: 0.8700 - val_loss: 0.3962 - val_acc: 0.8022\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.3158 - acc: 0.8679 - val_loss: 0.3934 - val_acc: 0.8130\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.3064 - acc: 0.8710 - val_loss: 0.4069 - val_acc: 0.8109\n",
      "100/100 [==============================] - 0s 824us/sample - loss: 0.3155 - acc: 0.8600\n",
      "logs/fit/lstm_simple/kfold2\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 50s - loss: 0.6920 - acc: 0.5797 - val_loss: 0.6911 - val_acc: 0.5609\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.6829 - acc: 0.6123 - val_loss: 0.6413 - val_acc: 0.6978\n",
      "Epoch 3/30\n",
      "4140/4140 - 8s - loss: 1.0454 - acc: 0.7138 - val_loss: 0.6750 - val_acc: 0.6783\n",
      "Epoch 4/30\n",
      "4140/4140 - 8s - loss: 0.6442 - acc: 0.7000 - val_loss: 0.6414 - val_acc: 0.6739\n",
      "Epoch 5/30\n",
      "4140/4140 - 8s - loss: 0.6342 - acc: 0.7116 - val_loss: 0.6450 - val_acc: 0.6696\n",
      "Epoch 6/30\n",
      "4140/4140 - 8s - loss: 0.6232 - acc: 0.7143 - val_loss: 0.6381 - val_acc: 0.6761\n",
      "Epoch 7/30\n",
      "4140/4140 - 8s - loss: 0.6153 - acc: 0.7186 - val_loss: 0.6294 - val_acc: 0.6826\n",
      "Epoch 8/30\n",
      "4140/4140 - 8s - loss: 0.6084 - acc: 0.7208 - val_loss: 0.6215 - val_acc: 0.6870\n",
      "Epoch 9/30\n",
      "4140/4140 - 8s - loss: 0.6012 - acc: 0.7246 - val_loss: 0.6145 - val_acc: 0.7022\n",
      "Epoch 10/30\n",
      "4140/4140 - 8s - loss: 0.5943 - acc: 0.7278 - val_loss: 0.6070 - val_acc: 0.7065\n",
      "Epoch 11/30\n",
      "4140/4140 - 8s - loss: 0.5886 - acc: 0.7314 - val_loss: 0.6016 - val_acc: 0.7130\n",
      "Epoch 12/30\n",
      "4140/4140 - 8s - loss: 0.5837 - acc: 0.7333 - val_loss: 0.5967 - val_acc: 0.7130\n",
      "Epoch 13/30\n",
      "4140/4140 - 8s - loss: 0.5778 - acc: 0.7382 - val_loss: 0.5921 - val_acc: 0.7109\n",
      "Epoch 14/30\n",
      "4140/4140 - 8s - loss: 0.5720 - acc: 0.7413 - val_loss: 0.5873 - val_acc: 0.7109\n",
      "Epoch 15/30\n",
      "4140/4140 - 8s - loss: 0.5657 - acc: 0.7437 - val_loss: 0.5837 - val_acc: 0.7174\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.5599 - acc: 0.7464 - val_loss: 0.5791 - val_acc: 0.7196\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.5545 - acc: 0.7502 - val_loss: 0.5750 - val_acc: 0.7196\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.5497 - acc: 0.7536 - val_loss: 0.5709 - val_acc: 0.7217\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.5440 - acc: 0.7546 - val_loss: 0.5692 - val_acc: 0.7217\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.5381 - acc: 0.7597 - val_loss: 0.5637 - val_acc: 0.7304\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.5317 - acc: 0.7614 - val_loss: 0.5575 - val_acc: 0.7304\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.5246 - acc: 0.7667 - val_loss: 0.5515 - val_acc: 0.7326\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.5193 - acc: 0.7703 - val_loss: 0.5464 - val_acc: 0.7391\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.5116 - acc: 0.7744 - val_loss: 0.5425 - val_acc: 0.7435\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.5088 - acc: 0.7761 - val_loss: 0.5324 - val_acc: 0.7478\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.5000 - acc: 0.7802 - val_loss: 0.5352 - val_acc: 0.7522\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.4954 - acc: 0.7848 - val_loss: 0.5302 - val_acc: 0.7587\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.4886 - acc: 0.7865 - val_loss: 0.5269 - val_acc: 0.7609\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.4806 - acc: 0.7911 - val_loss: 0.5220 - val_acc: 0.7696\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.4741 - acc: 0.7937 - val_loss: 0.5206 - val_acc: 0.7696\n",
      "100/100 [==============================] - 0s 670us/sample - loss: 0.4383 - acc: 0.7900\n",
      "logs/fit/lstm_simple/kfold3\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 49s - loss: 0.6920 - acc: 0.5725 - val_loss: 0.6889 - val_acc: 0.6130\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.6637 - acc: 0.6696 - val_loss: 0.6435 - val_acc: 0.7283\n",
      "Epoch 3/30\n",
      "4140/4140 - 7s - loss: 0.6354 - acc: 0.7130 - val_loss: 0.6216 - val_acc: 0.7435\n",
      "Epoch 4/30\n",
      "4140/4140 - 7s - loss: 0.6121 - acc: 0.7507 - val_loss: 0.5904 - val_acc: 0.7630\n",
      "Epoch 5/30\n",
      "4140/4140 - 7s - loss: 0.5747 - acc: 0.7783 - val_loss: 0.5574 - val_acc: 0.7870\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.5379 - acc: 0.7821 - val_loss: 0.5052 - val_acc: 0.7891\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.4450 - acc: 0.8138 - val_loss: 0.4055 - val_acc: 0.8152\n",
      "Epoch 8/30\n",
      "4140/4140 - 7s - loss: 0.3974 - acc: 0.8217 - val_loss: 0.3735 - val_acc: 0.8326\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.3753 - acc: 0.8304 - val_loss: 0.3700 - val_acc: 0.8239\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.3716 - acc: 0.8345 - val_loss: 0.3713 - val_acc: 0.8261\n",
      "Epoch 11/30\n",
      "4140/4140 - 7s - loss: 0.3634 - acc: 0.8365 - val_loss: 0.3641 - val_acc: 0.8370\n",
      "Epoch 12/30\n",
      "4140/4140 - 7s - loss: 0.3660 - acc: 0.8338 - val_loss: 0.4236 - val_acc: 0.8174\n",
      "Epoch 13/30\n",
      "4140/4140 - 7s - loss: 0.3459 - acc: 0.8440 - val_loss: 0.3780 - val_acc: 0.8283\n",
      "Epoch 14/30\n",
      "4140/4140 - 7s - loss: 0.3275 - acc: 0.8498 - val_loss: 0.3967 - val_acc: 0.8413\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.3218 - acc: 0.8529 - val_loss: 0.3913 - val_acc: 0.8413\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.3066 - acc: 0.8589 - val_loss: 0.4114 - val_acc: 0.8326\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.3030 - acc: 0.8609 - val_loss: 0.4457 - val_acc: 0.8391\n",
      "Epoch 18/30\n",
      "4140/4140 - 8s - loss: 0.3253 - acc: 0.8633 - val_loss: 0.5986 - val_acc: 0.8087\n",
      "Epoch 19/30\n",
      "4140/4140 - 7s - loss: 0.8096 - acc: 0.5966 - val_loss: 0.6452 - val_acc: 0.6109\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.6250 - acc: 0.7193 - val_loss: 0.5836 - val_acc: 0.7717\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.5605 - acc: 0.7640 - val_loss: 0.5166 - val_acc: 0.7957\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.5248 - acc: 0.7425 - val_loss: 0.4894 - val_acc: 0.7913\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.4952 - acc: 0.7568 - val_loss: 0.4773 - val_acc: 0.7783\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.4693 - acc: 0.7848 - val_loss: 0.4720 - val_acc: 0.8087\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4140/4140 - 1s - loss: 0.4478 - acc: 0.8007 - val_loss: 0.5140 - val_acc: 0.8022\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.4356 - acc: 0.8147 - val_loss: 0.4595 - val_acc: 0.8174\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.4269 - acc: 0.8234 - val_loss: 0.4308 - val_acc: 0.8152\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.4162 - acc: 0.8256 - val_loss: 0.4356 - val_acc: 0.8130\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.4009 - acc: 0.8319 - val_loss: 0.4198 - val_acc: 0.8239\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.4015 - acc: 0.8350 - val_loss: 0.4215 - val_acc: 0.8109\n",
      "100/100 [==============================] - 0s 651us/sample - loss: 0.4270 - acc: 0.8300\n",
      "logs/fit/lstm_simple/kfold4\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 37s - loss: 0.6919 - acc: 0.5800 - val_loss: 0.6919 - val_acc: 0.5326\n",
      "Epoch 2/30\n",
      "4140/4140 - 7s - loss: 0.6675 - acc: 0.5855 - val_loss: 0.6564 - val_acc: 0.5565\n",
      "Epoch 3/30\n",
      "4140/4140 - 7s - loss: 0.6178 - acc: 0.6621 - val_loss: 0.5967 - val_acc: 0.6413\n",
      "Epoch 4/30\n",
      "4140/4140 - 7s - loss: 0.5457 - acc: 0.7476 - val_loss: 0.4812 - val_acc: 0.7739\n",
      "Epoch 5/30\n",
      "4140/4140 - 8s - loss: 0.4681 - acc: 0.7937 - val_loss: 0.4383 - val_acc: 0.7978\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.4305 - acc: 0.8106 - val_loss: 0.4144 - val_acc: 0.8174\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.4078 - acc: 0.8234 - val_loss: 0.3952 - val_acc: 0.8326\n",
      "Epoch 8/30\n",
      "4140/4140 - 7s - loss: 0.3887 - acc: 0.8242 - val_loss: 0.3829 - val_acc: 0.8152\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.3823 - acc: 0.8275 - val_loss: 0.3688 - val_acc: 0.8326\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.3744 - acc: 0.8312 - val_loss: 0.3619 - val_acc: 0.8391\n",
      "Epoch 11/30\n",
      "4140/4140 - 7s - loss: 0.3673 - acc: 0.8382 - val_loss: 0.3593 - val_acc: 0.8457\n",
      "Epoch 12/30\n",
      "4140/4140 - 7s - loss: 0.3659 - acc: 0.8379 - val_loss: 0.3790 - val_acc: 0.8261\n",
      "Epoch 13/30\n",
      "4140/4140 - 7s - loss: 0.3524 - acc: 0.8449 - val_loss: 0.3856 - val_acc: 0.8261\n",
      "Epoch 14/30\n",
      "4140/4140 - 7s - loss: 0.3410 - acc: 0.8502 - val_loss: 0.4102 - val_acc: 0.8217\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.3411 - acc: 0.8522 - val_loss: 0.4103 - val_acc: 0.8109\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.3324 - acc: 0.8551 - val_loss: 0.4129 - val_acc: 0.8087\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.3620 - acc: 0.8452 - val_loss: 0.4706 - val_acc: 0.7696\n",
      "Epoch 18/30\n",
      "4140/4140 - 7s - loss: 0.3428 - acc: 0.8493 - val_loss: 0.4034 - val_acc: 0.8217\n",
      "Epoch 19/30\n",
      "4140/4140 - 7s - loss: 0.3226 - acc: 0.8556 - val_loss: 0.3697 - val_acc: 0.8283\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.3136 - acc: 0.8585 - val_loss: 0.3602 - val_acc: 0.8391\n",
      "Epoch 21/30\n",
      "4140/4140 - 8s - loss: 0.3041 - acc: 0.8664 - val_loss: 0.3506 - val_acc: 0.8500\n",
      "Epoch 22/30\n",
      "4140/4140 - 8s - loss: 0.2960 - acc: 0.8705 - val_loss: 0.3645 - val_acc: 0.8457\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.2912 - acc: 0.8713 - val_loss: 0.3594 - val_acc: 0.8478\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.2876 - acc: 0.8729 - val_loss: 0.3661 - val_acc: 0.8435\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.2801 - acc: 0.8775 - val_loss: 0.3792 - val_acc: 0.8348\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.2827 - acc: 0.8739 - val_loss: 0.3744 - val_acc: 0.8391\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.2770 - acc: 0.8778 - val_loss: 0.3794 - val_acc: 0.8283\n",
      "Epoch 28/30\n",
      "4140/4140 - 5s - loss: 0.2799 - acc: 0.8739 - val_loss: 0.3971 - val_acc: 0.8152\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.2931 - acc: 0.8710 - val_loss: 0.4436 - val_acc: 0.8065\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.3036 - acc: 0.8647 - val_loss: 0.4400 - val_acc: 0.8022\n",
      "100/100 [==============================] - 0s 598us/sample - loss: 0.4825 - acc: 0.7900\n",
      "logs/fit/lstm_simple/kfold5\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 11s - loss: 0.6921 - acc: 0.5720 - val_loss: 0.6907 - val_acc: 0.5804\n",
      "Epoch 2/30\n",
      "4140/4140 - 4s - loss: 0.6894 - acc: 0.5785 - val_loss: 0.6872 - val_acc: 0.5804\n",
      "Epoch 3/30\n",
      "4140/4140 - 4s - loss: 0.6748 - acc: 0.6099 - val_loss: 0.6530 - val_acc: 0.7261\n",
      "Epoch 4/30\n",
      "4140/4140 - 5s - loss: 0.5851 - acc: 0.7242 - val_loss: 0.7250 - val_acc: 0.5630\n",
      "Epoch 5/30\n",
      "4140/4140 - 7s - loss: 0.5598 - acc: 0.7297 - val_loss: 0.5355 - val_acc: 0.7348\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.4562 - acc: 0.7804 - val_loss: 0.5054 - val_acc: 0.7543\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.4270 - acc: 0.7940 - val_loss: 0.4963 - val_acc: 0.7522\n",
      "Epoch 8/30\n",
      "4140/4140 - 8s - loss: 0.4047 - acc: 0.8092 - val_loss: 0.4823 - val_acc: 0.7717\n",
      "Epoch 9/30\n",
      "4140/4140 - 8s - loss: 0.3887 - acc: 0.8200 - val_loss: 0.4775 - val_acc: 0.7761\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.3745 - acc: 0.8280 - val_loss: 0.4795 - val_acc: 0.7652\n",
      "Epoch 11/30\n",
      "4140/4140 - 7s - loss: 0.3748 - acc: 0.8261 - val_loss: 0.4720 - val_acc: 0.7783\n",
      "Epoch 12/30\n",
      "4140/4140 - 7s - loss: 0.3627 - acc: 0.8326 - val_loss: 0.4652 - val_acc: 0.7783\n",
      "Epoch 13/30\n",
      "4140/4140 - 7s - loss: 0.3573 - acc: 0.8353 - val_loss: 0.4700 - val_acc: 0.7761\n",
      "Epoch 14/30\n",
      "4140/4140 - 7s - loss: 0.3487 - acc: 0.8423 - val_loss: 0.4699 - val_acc: 0.7761\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.3434 - acc: 0.8461 - val_loss: 0.4722 - val_acc: 0.7674\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.3397 - acc: 0.8486 - val_loss: 0.4716 - val_acc: 0.7783\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.3340 - acc: 0.8529 - val_loss: 0.4715 - val_acc: 0.7761\n",
      "Epoch 18/30\n",
      "4140/4140 - 7s - loss: 0.3278 - acc: 0.8553 - val_loss: 0.4823 - val_acc: 0.7696\n",
      "Epoch 19/30\n",
      "4140/4140 - 7s - loss: 0.3263 - acc: 0.8543 - val_loss: 0.4865 - val_acc: 0.7739\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.3206 - acc: 0.8589 - val_loss: 0.4856 - val_acc: 0.7696\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.3146 - acc: 0.8652 - val_loss: 0.4945 - val_acc: 0.7674\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.3098 - acc: 0.8650 - val_loss: 0.4950 - val_acc: 0.7717\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.3110 - acc: 0.8691 - val_loss: 0.4891 - val_acc: 0.7717\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.3150 - acc: 0.8626 - val_loss: 0.4877 - val_acc: 0.7717\n",
      "Epoch 25/30\n",
      "4140/4140 - 8s - loss: 0.3152 - acc: 0.8611 - val_loss: 0.4885 - val_acc: 0.7826\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.3545 - acc: 0.8348 - val_loss: 0.4916 - val_acc: 0.7870\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.3366 - acc: 0.8447 - val_loss: 0.5192 - val_acc: 0.7870\n",
      "Epoch 28/30\n",
      "4140/4140 - 7s - loss: 0.3172 - acc: 0.8553 - val_loss: 0.5153 - val_acc: 0.7870\n",
      "Epoch 29/30\n",
      "4140/4140 - 7s - loss: 0.3101 - acc: 0.8643 - val_loss: 0.5439 - val_acc: 0.7848\n",
      "Epoch 30/30\n",
      "4140/4140 - 7s - loss: 0.3051 - acc: 0.8671 - val_loss: 0.5437 - val_acc: 0.7848\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.4551 - acc: 0.7700\n",
      "logs/fit/lstm_simple/kfold6\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 9s - loss: 0.6916 - acc: 0.5797 - val_loss: 0.6888 - val_acc: 0.5717\n",
      "Epoch 2/30\n",
      "4140/4140 - 1s - loss: 0.6756 - acc: 0.5797 - val_loss: 0.6540 - val_acc: 0.5717\n",
      "Epoch 3/30\n",
      "4140/4140 - 2s - loss: 0.6583 - acc: 0.5797 - val_loss: 0.6262 - val_acc: 0.5717\n",
      "Epoch 4/30\n",
      "4140/4140 - 2s - loss: 0.6233 - acc: 0.5797 - val_loss: 0.5800 - val_acc: 0.5717\n",
      "Epoch 5/30\n",
      "4140/4140 - 4s - loss: 0.5806 - acc: 0.5797 - val_loss: 0.5523 - val_acc: 0.5717\n",
      "Epoch 6/30\n",
      "4140/4140 - 4s - loss: 0.5592 - acc: 0.5797 - val_loss: 0.5236 - val_acc: 0.5717\n",
      "Epoch 7/30\n",
      "4140/4140 - 5s - loss: 0.7726 - acc: 0.6169 - val_loss: 0.6862 - val_acc: 0.6239\n",
      "Epoch 8/30\n",
      "4140/4140 - 7s - loss: 0.7183 - acc: 0.5464 - val_loss: 0.6997 - val_acc: 0.6000\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.6885 - acc: 0.5795 - val_loss: 0.6838 - val_acc: 0.5717\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.6706 - acc: 0.5797 - val_loss: 0.6589 - val_acc: 0.5717\n",
      "Epoch 11/30\n",
      "4140/4140 - 7s - loss: 0.6459 - acc: 0.5797 - val_loss: 0.6175 - val_acc: 0.5717\n",
      "Epoch 12/30\n",
      "4140/4140 - 8s - loss: 0.5621 - acc: 0.5797 - val_loss: 0.5384 - val_acc: 0.5717\n",
      "Epoch 13/30\n",
      "4140/4140 - 7s - loss: 0.5333 - acc: 0.5797 - val_loss: 0.5200 - val_acc: 0.5717\n",
      "Epoch 14/30\n",
      "4140/4140 - 7s - loss: 0.5183 - acc: 0.5797 - val_loss: 0.5172 - val_acc: 0.5717\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.5101 - acc: 0.7220 - val_loss: 0.5083 - val_acc: 0.8000\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.5041 - acc: 0.7903 - val_loss: 0.5004 - val_acc: 0.8087\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.4959 - acc: 0.7911 - val_loss: 0.4926 - val_acc: 0.8174\n",
      "Epoch 18/30\n",
      "4140/4140 - 7s - loss: 0.4876 - acc: 0.7915 - val_loss: 0.4863 - val_acc: 0.8174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "4140/4140 - 7s - loss: 0.4794 - acc: 0.7957 - val_loss: 0.4810 - val_acc: 0.8261\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.4715 - acc: 0.8002 - val_loss: 0.4775 - val_acc: 0.8304\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.4644 - acc: 0.8039 - val_loss: 0.4756 - val_acc: 0.8326\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.4584 - acc: 0.8051 - val_loss: 0.4726 - val_acc: 0.8326\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.4529 - acc: 0.8116 - val_loss: 0.4685 - val_acc: 0.8304\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.4482 - acc: 0.8143 - val_loss: 0.4662 - val_acc: 0.8326\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.4427 - acc: 0.8169 - val_loss: 0.4649 - val_acc: 0.8348\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.4387 - acc: 0.8208 - val_loss: 0.4618 - val_acc: 0.8348\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.4340 - acc: 0.8237 - val_loss: 0.4589 - val_acc: 0.8370\n",
      "Epoch 28/30\n",
      "4140/4140 - 8s - loss: 0.4307 - acc: 0.8258 - val_loss: 0.4600 - val_acc: 0.8370\n",
      "Epoch 29/30\n",
      "4140/4140 - 7s - loss: 0.4259 - acc: 0.8290 - val_loss: 0.4577 - val_acc: 0.8348\n",
      "Epoch 30/30\n",
      "4140/4140 - 7s - loss: 0.4205 - acc: 0.8297 - val_loss: 0.4550 - val_acc: 0.8348\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.4703 - acc: 0.8300\n",
      "logs/fit/lstm_simple/kfold7\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 9s - loss: 0.6917 - acc: 0.5814 - val_loss: 0.6907 - val_acc: 0.5565\n",
      "Epoch 2/30\n",
      "4140/4140 - 1s - loss: 0.6850 - acc: 0.5814 - val_loss: 0.6840 - val_acc: 0.5565\n",
      "Epoch 3/30\n",
      "4140/4140 - 1s - loss: 0.6572 - acc: 0.5814 - val_loss: 0.6314 - val_acc: 0.5565\n",
      "Epoch 4/30\n",
      "4140/4140 - 1s - loss: 0.5948 - acc: 0.5862 - val_loss: 0.5544 - val_acc: 0.6326\n",
      "Epoch 5/30\n",
      "4140/4140 - 1s - loss: 0.5215 - acc: 0.7432 - val_loss: 0.4717 - val_acc: 0.7783\n",
      "Epoch 6/30\n",
      "4140/4140 - 1s - loss: 0.4712 - acc: 0.7565 - val_loss: 0.4368 - val_acc: 0.7804\n",
      "Epoch 7/30\n",
      "4140/4140 - 1s - loss: 0.4352 - acc: 0.7761 - val_loss: 0.4830 - val_acc: 0.7717\n",
      "Epoch 8/30\n",
      "4140/4140 - 1s - loss: 0.4483 - acc: 0.7809 - val_loss: 0.4244 - val_acc: 0.7848\n",
      "Epoch 9/30\n",
      "4140/4140 - 1s - loss: 0.4205 - acc: 0.7940 - val_loss: 0.4132 - val_acc: 0.7891\n",
      "Epoch 10/30\n",
      "4140/4140 - 1s - loss: 0.4139 - acc: 0.7964 - val_loss: 0.4196 - val_acc: 0.7913\n",
      "Epoch 11/30\n",
      "4140/4140 - 2s - loss: 0.3998 - acc: 0.8007 - val_loss: 0.4076 - val_acc: 0.8065\n",
      "Epoch 12/30\n",
      "4140/4140 - 3s - loss: 0.4550 - acc: 0.7792 - val_loss: 0.5473 - val_acc: 0.6696\n",
      "Epoch 13/30\n",
      "4140/4140 - 4s - loss: 0.4417 - acc: 0.8053 - val_loss: 0.4206 - val_acc: 0.8000\n",
      "Epoch 14/30\n",
      "4140/4140 - 4s - loss: 0.3938 - acc: 0.8152 - val_loss: 0.4110 - val_acc: 0.8043\n",
      "Epoch 15/30\n",
      "4140/4140 - 5s - loss: 0.3867 - acc: 0.8174 - val_loss: 0.4049 - val_acc: 0.8065\n",
      "Epoch 16/30\n",
      "4140/4140 - 8s - loss: 0.3844 - acc: 0.8181 - val_loss: 0.4061 - val_acc: 0.8043\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.3771 - acc: 0.8208 - val_loss: 0.3861 - val_acc: 0.8174\n",
      "Epoch 18/30\n",
      "4140/4140 - 7s - loss: 0.3704 - acc: 0.8239 - val_loss: 0.3855 - val_acc: 0.8152\n",
      "Epoch 19/30\n",
      "4140/4140 - 7s - loss: 0.3670 - acc: 0.8239 - val_loss: 0.3834 - val_acc: 0.8152\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.3631 - acc: 0.8263 - val_loss: 0.3825 - val_acc: 0.8174\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.3596 - acc: 0.8297 - val_loss: 0.3811 - val_acc: 0.8196\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.3568 - acc: 0.8290 - val_loss: 0.3808 - val_acc: 0.8217\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.3555 - acc: 0.8331 - val_loss: 0.3795 - val_acc: 0.8196\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.3550 - acc: 0.8300 - val_loss: 0.3808 - val_acc: 0.8174\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.3505 - acc: 0.8331 - val_loss: 0.3784 - val_acc: 0.8152\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.3470 - acc: 0.8333 - val_loss: 0.3773 - val_acc: 0.8196\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.3440 - acc: 0.8336 - val_loss: 0.3775 - val_acc: 0.8239\n",
      "Epoch 28/30\n",
      "4140/4140 - 7s - loss: 0.3411 - acc: 0.8360 - val_loss: 0.3776 - val_acc: 0.8217\n",
      "Epoch 29/30\n",
      "4140/4140 - 7s - loss: 0.3383 - acc: 0.8377 - val_loss: 0.3776 - val_acc: 0.8239\n",
      "Epoch 30/30\n",
      "4140/4140 - 7s - loss: 0.3358 - acc: 0.8386 - val_loss: 0.3794 - val_acc: 0.8304\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.3624 - acc: 0.8500\n",
      "logs/fit/lstm_simple/kfold8\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 17s - loss: 0.6922 - acc: 0.5681 - val_loss: 0.6892 - val_acc: 0.6217\n",
      "Epoch 2/30\n",
      "4140/4140 - 1s - loss: 0.6896 - acc: 0.5742 - val_loss: 0.6742 - val_acc: 0.6217\n",
      "Epoch 3/30\n",
      "4140/4140 - 1s - loss: 0.6493 - acc: 0.5756 - val_loss: 0.5943 - val_acc: 0.6326\n",
      "Epoch 4/30\n",
      "4140/4140 - 1s - loss: 0.5780 - acc: 0.6908 - val_loss: 0.5185 - val_acc: 0.7239\n",
      "Epoch 5/30\n",
      "4140/4140 - 1s - loss: 0.4902 - acc: 0.7713 - val_loss: 0.4610 - val_acc: 0.7870\n",
      "Epoch 6/30\n",
      "4140/4140 - 1s - loss: 0.4404 - acc: 0.8010 - val_loss: 0.4214 - val_acc: 0.8065\n",
      "Epoch 7/30\n",
      "4140/4140 - 1s - loss: 0.4201 - acc: 0.8109 - val_loss: 0.4192 - val_acc: 0.8130\n",
      "Epoch 8/30\n",
      "4140/4140 - 1s - loss: 0.4047 - acc: 0.8184 - val_loss: 0.3889 - val_acc: 0.8130\n",
      "Epoch 9/30\n",
      "4140/4140 - 1s - loss: 0.3932 - acc: 0.8213 - val_loss: 0.3992 - val_acc: 0.8130\n",
      "Epoch 10/30\n",
      "4140/4140 - 1s - loss: 0.3804 - acc: 0.8266 - val_loss: 0.3922 - val_acc: 0.8043\n",
      "Epoch 11/30\n",
      "4140/4140 - 1s - loss: 0.3746 - acc: 0.8302 - val_loss: 0.4055 - val_acc: 0.8174\n",
      "Epoch 12/30\n",
      "4140/4140 - 1s - loss: 0.3631 - acc: 0.8386 - val_loss: 0.4129 - val_acc: 0.8196\n",
      "Epoch 13/30\n",
      "4140/4140 - 1s - loss: 0.3624 - acc: 0.8382 - val_loss: 0.4249 - val_acc: 0.8261\n",
      "Epoch 14/30\n",
      "4140/4140 - 2s - loss: 0.3507 - acc: 0.8464 - val_loss: 0.4107 - val_acc: 0.8217\n",
      "Epoch 15/30\n",
      "4140/4140 - 2s - loss: 0.3437 - acc: 0.8536 - val_loss: 0.4019 - val_acc: 0.8326\n",
      "Epoch 16/30\n",
      "4140/4140 - 2s - loss: 0.3423 - acc: 0.8524 - val_loss: 0.3833 - val_acc: 0.8261\n",
      "Epoch 17/30\n",
      "4140/4140 - 4s - loss: 0.3242 - acc: 0.8582 - val_loss: 0.3654 - val_acc: 0.8348\n",
      "Epoch 18/30\n",
      "4140/4140 - 4s - loss: 0.3140 - acc: 0.8674 - val_loss: 0.3738 - val_acc: 0.8413\n",
      "Epoch 19/30\n",
      "4140/4140 - 5s - loss: 0.3130 - acc: 0.8720 - val_loss: 0.3603 - val_acc: 0.8326\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.3036 - acc: 0.8746 - val_loss: 0.3841 - val_acc: 0.8304\n",
      "Epoch 21/30\n",
      "4140/4140 - 8s - loss: 0.2994 - acc: 0.8758 - val_loss: 0.3630 - val_acc: 0.8261\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.2920 - acc: 0.8797 - val_loss: 0.3789 - val_acc: 0.8348\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.2922 - acc: 0.8785 - val_loss: 0.3699 - val_acc: 0.8348\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.2903 - acc: 0.8739 - val_loss: 0.3566 - val_acc: 0.8435\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.2868 - acc: 0.8802 - val_loss: 0.3620 - val_acc: 0.8413\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.2852 - acc: 0.8855 - val_loss: 0.4037 - val_acc: 0.8283\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.2827 - acc: 0.8831 - val_loss: 0.3754 - val_acc: 0.8261\n",
      "Epoch 28/30\n",
      "4140/4140 - 7s - loss: 0.2914 - acc: 0.8775 - val_loss: 0.4418 - val_acc: 0.8326\n",
      "Epoch 29/30\n",
      "4140/4140 - 7s - loss: 0.2714 - acc: 0.8940 - val_loss: 0.4002 - val_acc: 0.8348\n",
      "Epoch 30/30\n",
      "4140/4140 - 7s - loss: 0.2729 - acc: 0.8886 - val_loss: 0.4147 - val_acc: 0.8413\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.5381 - acc: 0.7200\n",
      "logs/fit/lstm_simple/kfold9\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 51s - loss: 0.6920 - acc: 0.5749 - val_loss: 0.6909 - val_acc: 0.5696\n",
      "Epoch 2/30\n",
      "4140/4140 - 7s - loss: 0.6825 - acc: 0.6529 - val_loss: 0.6545 - val_acc: 0.7370\n",
      "Epoch 3/30\n",
      "4140/4140 - 7s - loss: 0.6260 - acc: 0.7510 - val_loss: 0.5892 - val_acc: 0.7957\n",
      "Epoch 4/30\n",
      "4140/4140 - 7s - loss: 0.5045 - acc: 0.7749 - val_loss: 0.4451 - val_acc: 0.7957\n",
      "Epoch 5/30\n",
      "4140/4140 - 7s - loss: 0.4409 - acc: 0.8029 - val_loss: 0.4405 - val_acc: 0.8022\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.4165 - acc: 0.8080 - val_loss: 0.4245 - val_acc: 0.8130\n",
      "Epoch 7/30\n",
      "4140/4140 - 8s - loss: 0.4009 - acc: 0.8128 - val_loss: 0.4172 - val_acc: 0.8261\n",
      "Epoch 8/30\n",
      "4140/4140 - 7s - loss: 0.4018 - acc: 0.8184 - val_loss: 0.4019 - val_acc: 0.8152\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.3925 - acc: 0.8205 - val_loss: 0.3911 - val_acc: 0.8326\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.3738 - acc: 0.8263 - val_loss: 0.3983 - val_acc: 0.8413\n",
      "Epoch 11/30\n",
      "4140/4140 - 3s - loss: 0.3602 - acc: 0.8309 - val_loss: 0.3904 - val_acc: 0.8457\n",
      "Epoch 12/30\n",
      "4140/4140 - 1s - loss: 0.3515 - acc: 0.8324 - val_loss: 0.3764 - val_acc: 0.8478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "4140/4140 - 1s - loss: 0.3405 - acc: 0.8394 - val_loss: 0.3704 - val_acc: 0.8500\n",
      "Epoch 14/30\n",
      "4140/4140 - 1s - loss: 0.3301 - acc: 0.8452 - val_loss: 0.3767 - val_acc: 0.8457\n",
      "Epoch 15/30\n",
      "4140/4140 - 1s - loss: 0.3266 - acc: 0.8493 - val_loss: 0.3647 - val_acc: 0.8457\n",
      "Epoch 16/30\n",
      "4140/4140 - 1s - loss: 0.3223 - acc: 0.8510 - val_loss: 0.3712 - val_acc: 0.8500\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.3224 - acc: 0.8514 - val_loss: 0.3670 - val_acc: 0.8478\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.3066 - acc: 0.8548 - val_loss: 0.3752 - val_acc: 0.8587\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.3059 - acc: 0.8592 - val_loss: 0.3668 - val_acc: 0.8500\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.3066 - acc: 0.8560 - val_loss: 0.3619 - val_acc: 0.8500\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.2952 - acc: 0.8582 - val_loss: 0.3785 - val_acc: 0.8522\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.3035 - acc: 0.8638 - val_loss: 0.3693 - val_acc: 0.8478\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.3176 - acc: 0.8478 - val_loss: 0.4216 - val_acc: 0.8065\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.3227 - acc: 0.8531 - val_loss: 0.3869 - val_acc: 0.8413\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.2998 - acc: 0.8638 - val_loss: 0.3612 - val_acc: 0.8500\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.2961 - acc: 0.8601 - val_loss: 0.3879 - val_acc: 0.8478\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.2848 - acc: 0.8650 - val_loss: 0.3933 - val_acc: 0.8435\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.2888 - acc: 0.8638 - val_loss: 0.3870 - val_acc: 0.8304\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.2818 - acc: 0.8691 - val_loss: 0.4299 - val_acc: 0.8174\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.2963 - acc: 0.8621 - val_loss: 0.4153 - val_acc: 0.8261\n",
      "100/100 [==============================] - 0s 1ms/sample - loss: 0.4304 - acc: 0.7800\n",
      "logs/fit/lstm_simple/kfold10\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 51s - loss: 0.6919 - acc: 0.5708 - val_loss: 0.6897 - val_acc: 0.5870\n",
      "Epoch 2/30\n",
      "4140/4140 - 7s - loss: 0.6813 - acc: 0.5778 - val_loss: 0.6366 - val_acc: 0.5848\n",
      "Epoch 3/30\n",
      "4140/4140 - 7s - loss: 0.6185 - acc: 0.5800 - val_loss: 0.5429 - val_acc: 0.6043\n",
      "Epoch 4/30\n",
      "4140/4140 - 7s - loss: 0.5585 - acc: 0.5855 - val_loss: 0.4960 - val_acc: 0.6022\n",
      "Epoch 5/30\n",
      "4140/4140 - 7s - loss: 0.5139 - acc: 0.6350 - val_loss: 0.4581 - val_acc: 0.6717\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.4859 - acc: 0.7072 - val_loss: 0.4377 - val_acc: 0.7370\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.4609 - acc: 0.7512 - val_loss: 0.4227 - val_acc: 0.7891\n",
      "Epoch 8/30\n",
      "4140/4140 - 7s - loss: 0.4302 - acc: 0.7862 - val_loss: 0.4144 - val_acc: 0.8304\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.4259 - acc: 0.8080 - val_loss: 0.4028 - val_acc: 0.8370\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.4152 - acc: 0.8145 - val_loss: 0.4080 - val_acc: 0.8370\n",
      "Epoch 11/30\n",
      "4140/4140 - 7s - loss: 0.4043 - acc: 0.8249 - val_loss: 0.3903 - val_acc: 0.8543\n",
      "Epoch 12/30\n",
      "4140/4140 - 8s - loss: 0.3901 - acc: 0.8268 - val_loss: 0.3834 - val_acc: 0.8522\n",
      "Epoch 13/30\n",
      "4140/4140 - 7s - loss: 0.3831 - acc: 0.8287 - val_loss: 0.3841 - val_acc: 0.8609\n",
      "Epoch 14/30\n",
      "4140/4140 - 7s - loss: 0.3732 - acc: 0.8365 - val_loss: 0.3831 - val_acc: 0.8543\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.3675 - acc: 0.8415 - val_loss: 0.3832 - val_acc: 0.8717\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.3694 - acc: 0.8399 - val_loss: 0.3964 - val_acc: 0.8522\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.3634 - acc: 0.8401 - val_loss: 0.4015 - val_acc: 0.8609\n",
      "Epoch 18/30\n",
      "4140/4140 - 7s - loss: 0.3604 - acc: 0.8420 - val_loss: 0.3952 - val_acc: 0.8522\n",
      "Epoch 19/30\n",
      "4140/4140 - 7s - loss: 0.3577 - acc: 0.8386 - val_loss: 0.3917 - val_acc: 0.8630\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.3536 - acc: 0.8423 - val_loss: 0.3953 - val_acc: 0.8543\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.3625 - acc: 0.8331 - val_loss: 0.4119 - val_acc: 0.8609\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.3663 - acc: 0.8341 - val_loss: 0.4193 - val_acc: 0.8543\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.3383 - acc: 0.8437 - val_loss: 0.4050 - val_acc: 0.8565\n",
      "Epoch 24/30\n",
      "4140/4140 - 3s - loss: 0.3273 - acc: 0.8452 - val_loss: 0.4220 - val_acc: 0.8609\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.3200 - acc: 0.8507 - val_loss: 0.4201 - val_acc: 0.8587\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.3128 - acc: 0.8546 - val_loss: 0.4152 - val_acc: 0.8500\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.3130 - acc: 0.8531 - val_loss: 0.4141 - val_acc: 0.8391\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.3105 - acc: 0.8517 - val_loss: 0.4528 - val_acc: 0.8478\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.3026 - acc: 0.8565 - val_loss: 0.6428 - val_acc: 0.8478\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.2956 - acc: 0.8577 - val_loss: 0.7051 - val_acc: 0.8543\n",
      "100/100 [==============================] - 0s 714us/sample - loss: 0.3563 - acc: 0.8600\n"
     ]
    }
   ],
   "source": [
    "def create_simpler_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(10, kernel_initializer='normal', activation='relu', input_shape=(28, 300), name='lstm'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='normal', name='dense')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "simpler_hist, simpler_evas = kfold_train(create_simpler_model, 'lstm_simple', batch_size=128, epochs=30, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "4f1b36a1-cfdb-4c7b-be2c-2c0279542395",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6912510060457792,
          0.66745130457164,
          0.6522538596881184,
          0.6088982990398499,
          0.549640933672587,
          0.5247796855686944,
          0.48899228066062006,
          0.4811481872042596,
          0.44981937500589714,
          0.4235119805531801,
          0.4083104763917877,
          0.39050592794510475,
          0.3827459611754487,
          0.38186289351343533,
          0.37261866192886794,
          0.3595859201921933,
          0.35235981483390366,
          0.34779576377016336,
          0.344943987948883,
          0.33821517563096565,
          0.3371799034772864,
          0.3405535178483972,
          0.3264228700151766,
          0.3348437742622578,
          0.3246671716660117,
          0.31637690769877413,
          0.3090383423987218,
          0.3109539285374148,
          0.31584127348114327,
          0.30643941096349614
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "4d4d0c20-fb98-4c5f-918b-64375bc4a8ef",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6691275560337564,
          0.672860340450121,
          0.6207207011139911,
          0.5691162928290989,
          0.5519512036572332,
          0.5296242263006128,
          0.49607473922812423,
          0.46052895628887675,
          0.42965879673543184,
          0.42129446345826854,
          0.4290034815021183,
          0.4159188918445421,
          0.4138843847357708,
          0.41830299133839816,
          0.396927809715271,
          0.3978347405143406,
          0.4001875442007314,
          0.4097016147945238,
          0.3865450651749321,
          0.3991292603637861,
          0.4120116454103719,
          0.40073546637659485,
          0.417030610208926,
          0.4078405525373376,
          0.3870932804501575,
          0.38590367306833684,
          0.3856584551541702,
          0.3961945398994114,
          0.39341029110162157,
          0.4069114309290181
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "5b32e2ae-8d2e-4caf-b772-e0253584cbf8",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.691999586250471,
          0.6828934367728118,
          1.0454105233800584,
          0.6441996931453834,
          0.6341709872374788,
          0.6232199307225177,
          0.6152781627604351,
          0.6084011755703728,
          0.6012471711578,
          0.5942631226806825,
          0.5886446061341659,
          0.5836836304641576,
          0.5778309106250892,
          0.5719590052890317,
          0.5657456909976719,
          0.5598949985227724,
          0.5544888128405032,
          0.5496674983397775,
          0.5440173380616783,
          0.5381371443398333,
          0.5317365409095506,
          0.5245922781994953,
          0.519316441828502,
          0.5116299330324366,
          0.5088106674272657,
          0.5000453348321039,
          0.4954311804494996,
          0.4885942917515114,
          0.48064560648323834,
          0.4741088040784937
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "b674d04c-0b2b-430c-b880-9e29d4fe42de",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6911129728607509,
          0.6413222986718883,
          0.6750288128852844,
          0.6413911969765372,
          0.644953107315561,
          0.6380695674730383,
          0.6293784457704296,
          0.6214899457019308,
          0.6145230174064636,
          0.6069563575412916,
          0.6016062249308047,
          0.5966651906137881,
          0.5920963619066322,
          0.5873341378958329,
          0.583684123599011,
          0.5791476503662442,
          0.5750439161839692,
          0.5708900705627773,
          0.5691788450531338,
          0.5637283423672552,
          0.5574927920880525,
          0.5514648442683012,
          0.5464116625163866,
          0.5424561967020449,
          0.5324030098707779,
          0.5352091353872548,
          0.5302413489507593,
          0.5268794422564299,
          0.5220077468001324,
          0.5206417332524839
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "fbf48373-bd68-4520-88f2-7b52a61a9bf6",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6919701989146246,
          0.6637236459819591,
          0.6354265647809862,
          0.61212711305434,
          0.5746817775394606,
          0.537880425867827,
          0.4449865735959316,
          0.3973897624418931,
          0.37533710855216795,
          0.3716498775758605,
          0.36343148057011593,
          0.3659969573435576,
          0.3459366898893734,
          0.3274727493956469,
          0.32177490122652286,
          0.30662696761785496,
          0.30303814608405755,
          0.3252805901034443,
          0.809640059609344,
          0.6249550162882045,
          0.560455202019733,
          0.5247627992272953,
          0.49516252351267903,
          0.4692513465017512,
          0.4477997023702244,
          0.43560280284443914,
          0.42691621210264125,
          0.41615365904886364,
          0.4008559302719319,
          0.4015161895521597
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "f0fa8ee2-e051-49be-930c-eefe6d6f3a84",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6889186651810356,
          0.6435139650883882,
          0.6215879041215647,
          0.5904004983280016,
          0.55744316837062,
          0.5051907663759978,
          0.40553312508956246,
          0.3735042888185252,
          0.3700173826321312,
          0.37132751397464586,
          0.3641377195068028,
          0.4236282379730888,
          0.378020819892054,
          0.3966702598592509,
          0.39133204584536346,
          0.41137724570606066,
          0.44565456380014834,
          0.5985710823017618,
          0.6451968317446501,
          0.5835791012515192,
          0.5166085126607315,
          0.4893679556639298,
          0.47733374030693715,
          0.4719819732334303,
          0.5139859489772631,
          0.45948374297307887,
          0.43083066396091296,
          0.43563874130663666,
          0.4198410676873249,
          0.4215206169563791
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "d052a825-8715-4108-a9cb-8c0f0927d929",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6918880088317797,
          0.6674939654875492,
          0.6177664654842322,
          0.5456751538359601,
          0.46814763854091296,
          0.4305067441025794,
          0.4077598512748589,
          0.38868670477959266,
          0.38230009931297115,
          0.3744089957596599,
          0.3673415517173528,
          0.365854643508432,
          0.35244331499516673,
          0.3410333604052447,
          0.3410889296428017,
          0.33235498748827674,
          0.36197798969089123,
          0.34280295325938054,
          0.3226280898431649,
          0.3136410996245877,
          0.3041354565660735,
          0.2960117951107486,
          0.29115943763279106,
          0.28758396689154675,
          0.2801405072356192,
          0.2826685454390475,
          0.2770255230619136,
          0.2799171821218758,
          0.2930516686992369,
          0.30363656263708494
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "e4c8632c-7ea4-4e99-a5c7-f68204bddf0c",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.691885432989701,
          0.656434428691864,
          0.5966616013775701,
          0.48123004799303803,
          0.43827552769495093,
          0.41443547554638077,
          0.3951947147431581,
          0.3829040825366974,
          0.3687787361766981,
          0.3618969976902008,
          0.35928891897201537,
          0.3790254014989604,
          0.3855586831984313,
          0.4102310978848001,
          0.4103327971437703,
          0.4128926430059516,
          0.4705960328164308,
          0.40339165614998856,
          0.36973443808762924,
          0.36021760935368746,
          0.3505537349244823,
          0.3645204292691272,
          0.3594047935112663,
          0.36614515133526016,
          0.3792075934617416,
          0.3744499763716822,
          0.3794135355431101,
          0.3971242477064547,
          0.4436258652935857,
          0.4399814362111299
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "b8a75046-4272-4baa-9cf3-7adf20b510ce",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6921008413540568,
          0.6894163189302897,
          0.6748309036959772,
          0.5850759839090173,
          0.5598219136109098,
          0.4561559676548133,
          0.42699274990869607,
          0.4046834287724057,
          0.38872721330555166,
          0.37447719525023937,
          0.3747658568015997,
          0.36267304564443764,
          0.35730793058584276,
          0.3487431598458313,
          0.34344683378790886,
          0.3397458781654708,
          0.3339745258075604,
          0.32779905718305835,
          0.3262780156688414,
          0.320635361717519,
          0.3145694853602976,
          0.3098041893491422,
          0.31104667610016423,
          0.3149687112817442,
          0.3151567368403725,
          0.3544752812615915,
          0.3366184839591888,
          0.3171773421015716,
          0.3100637358167897,
          0.30513417738071386
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "a4aee490-2a3b-4ed3-a267-cf24e1e586e7",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6906664615092071,
          0.6872185437575631,
          0.6529509844987289,
          0.7249659180641175,
          0.5355100445125414,
          0.5054016310235728,
          0.49628086219663203,
          0.48230609686478326,
          0.4774617734162704,
          0.4795352754385575,
          0.4719935855139857,
          0.46516606859538867,
          0.47001589329346366,
          0.46993443810421487,
          0.4721821209658747,
          0.47163077022718347,
          0.4714890860992929,
          0.48225120461505394,
          0.4864992688531461,
          0.4856131133825883,
          0.494533021553703,
          0.4950237248254859,
          0.48906046411265497,
          0.48770068184189175,
          0.48853010690730553,
          0.49157209655512935,
          0.5192025091337121,
          0.5152841464332912,
          0.5439262903254966,
          0.543655326573745
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "7af7ccb5-05b5-4033-b1e5-84fe8f550f67",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6915616075773746,
          0.6755664049139345,
          0.658287170889297,
          0.6232885865197666,
          0.5806090459731466,
          0.5591912466546763,
          0.772564293048232,
          0.7182517561359681,
          0.6884992617339903,
          0.6706135368001633,
          0.6459083036524086,
          0.5621002919432045,
          0.5333103367095984,
          0.518340223710894,
          0.5101097148397694,
          0.5040962941980592,
          0.4958652541545278,
          0.487601091320388,
          0.47940233378594627,
          0.47149267879085266,
          0.4643930332384248,
          0.4583960495709221,
          0.45288406956023064,
          0.44821433203231886,
          0.4427299756358787,
          0.4387065059320938,
          0.43404422658653075,
          0.4306828411017063,
          0.42588096278301185,
          0.42048539853326367
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "30eeb1c7-7c98-4afa-8f00-74f76ac17228",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6888440163239189,
          0.6540412063183991,
          0.626242855320806,
          0.5799834577933601,
          0.5522957617821901,
          0.5235908611961033,
          0.6862042924632197,
          0.6997061221495918,
          0.6838033401447794,
          0.6588900991108106,
          0.6174720479094464,
          0.5383875966072083,
          0.5199745020140772,
          0.5172326891318612,
          0.5082828252211861,
          0.5003932724828305,
          0.49256692191828855,
          0.4863125806269438,
          0.4809845128785009,
          0.47745572147162063,
          0.47557178943053535,
          0.47262587650962495,
          0.46853694138319596,
          0.4662372065627057,
          0.4649087058461231,
          0.4618098927580792,
          0.45888715101324995,
          0.46002646529156227,
          0.4576952312303626,
          0.45498918217161427
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "09037e41-ad2c-4efe-9129-8b9c23bf9e8b",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6917372552093101,
          0.6850238510376013,
          0.6572190549638536,
          0.5947780468037739,
          0.521489848030938,
          0.4711831521008902,
          0.4352009300160523,
          0.4483491527861443,
          0.42052573555909495,
          0.4139175833999247,
          0.39981478452682495,
          0.45503788728644884,
          0.4417028105489298,
          0.3938033145982862,
          0.38668754814903517,
          0.38439639124317443,
          0.3770611522854238,
          0.37037516328447684,
          0.3670429357871917,
          0.36311456132050296,
          0.35955484328062637,
          0.3568240595900494,
          0.3554995046145674,
          0.3550388113600044,
          0.35048585882509387,
          0.34699204307823367,
          0.344000802754204,
          0.34111963953948826,
          0.338347623947162,
          0.3358355150130636
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "eda1d4b6-6324-4281-914a-eccfd007b745",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6906749264053677,
          0.6839584982913474,
          0.6314310229342917,
          0.5544174992519876,
          0.47174637265827346,
          0.4367662427218064,
          0.48303363530532173,
          0.42435086447259657,
          0.413223172529884,
          0.419642295267271,
          0.4076438157454781,
          0.547335512223451,
          0.42064145984856977,
          0.4110044124333755,
          0.4048530811848848,
          0.406114559588225,
          0.3861277645048888,
          0.3855237279249274,
          0.38343729869179105,
          0.38246025624482527,
          0.3810982014821923,
          0.38081559512926183,
          0.37949746873067774,
          0.38075390147126237,
          0.37838182760321576,
          0.37726151709971223,
          0.37745836947275246,
          0.3776499989240066,
          0.3775961759297744,
          0.3793996707252834
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "d29480fc-4135-4d81-bda4-fb1ea5ac5434",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6921500799736539,
          0.6896353173371098,
          0.6492528640129716,
          0.5780356996301291,
          0.490236094493221,
          0.4403795938272983,
          0.42010780958737726,
          0.40473991900250533,
          0.39323036903920383,
          0.38043852284334706,
          0.37458991186630325,
          0.36311163366704746,
          0.36239580353676987,
          0.35074752796675274,
          0.3437393152195474,
          0.3423417983135739,
          0.32422931427540985,
          0.3140165527517669,
          0.3130297405852212,
          0.30356152168506584,
          0.299428242833718,
          0.2919938615122855,
          0.2922002165645793,
          0.29025585382168995,
          0.2867989892400981,
          0.28524246518162716,
          0.28273442137068594,
          0.2914494336659206,
          0.27137178516618293,
          0.27292721966902417
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "12a1f788-0db5-49f3-a7d9-13a40eb6b9d4",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6891823136288187,
          0.6741812353548796,
          0.5943346816560496,
          0.5184534674105437,
          0.46095897866332014,
          0.42143807722174603,
          0.41916284898053047,
          0.3889074753160062,
          0.3991559220396954,
          0.3921644291152125,
          0.40548010494398035,
          0.41294102539186894,
          0.42488475882488747,
          0.4107188750868258,
          0.4019289952257405,
          0.3833007885062176,
          0.36543374528055605,
          0.37383831091549086,
          0.3603166437667349,
          0.3840989141360573,
          0.3629525293474612,
          0.3789125709430031,
          0.36993713430736375,
          0.3566146708053091,
          0.3620128851869832,
          0.4037271999794504,
          0.37543557389922766,
          0.44176572094792904,
          0.4001552685447361,
          0.4147060332090958
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "58358ea0-0fac-4671-8220-74fc0b911970",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6920475299231672,
          0.682461939226602,
          0.625965114204204,
          0.5044870523438938,
          0.440907387226676,
          0.41651308124767983,
          0.4009102758002166,
          0.40176066062300675,
          0.39246528353092175,
          0.37375666637351546,
          0.3601712637477451,
          0.35153957196479835,
          0.34046747816933526,
          0.3300548037613072,
          0.3266422907223448,
          0.3223366263695961,
          0.32241223907989003,
          0.3065628187523948,
          0.305910530715173,
          0.30659699087269643,
          0.2951542608403929,
          0.303519568020019,
          0.3176230572559983,
          0.32270500579317984,
          0.2997744900736832,
          0.29608930342151346,
          0.2847984675767917,
          0.28877851508089886,
          0.28182154086188993,
          0.2962860584690951
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "76bf4099-65ba-471e-b01b-d21ed7ab9994",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.690921632103298,
          0.6544707236082657,
          0.5892202149266782,
          0.4450798633305923,
          0.4404606606649316,
          0.42449970038040824,
          0.4172367518362792,
          0.4018864077070485,
          0.3911159422086633,
          0.39834437888601554,
          0.39040465976880945,
          0.37637922867484713,
          0.3704046285670737,
          0.3767065556153007,
          0.36472781248714614,
          0.37118389036344446,
          0.36701733936434205,
          0.37519337249838786,
          0.36678781898125357,
          0.3618570405503978,
          0.3785457175710927,
          0.36928677818049555,
          0.4215766660545183,
          0.38691028252891874,
          0.36120747379634693,
          0.38793664108151976,
          0.3933355664429457,
          0.3869520630525506,
          0.42988197725752125,
          0.4152793109416962
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "ee97f63e-706a-4ad3-ad7b-e88d72a116b2",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6919040844636263,
          0.6812566342561142,
          0.6184573840979792,
          0.5584914168297956,
          0.513875891275452,
          0.4859497484953507,
          0.46088684831840404,
          0.4301556532509661,
          0.425875055703564,
          0.4151807693179679,
          0.40425483284941044,
          0.39005838166112483,
          0.3831141283258724,
          0.3731642194416212,
          0.36752025778742803,
          0.3693969023112514,
          0.3634032872563975,
          0.3603810511637425,
          0.357703752707744,
          0.3536290679288947,
          0.3625063715061704,
          0.366304806234756,
          0.33833699908809384,
          0.32731481779024796,
          0.3200291291527126,
          0.31284931898117063,
          0.3130029508745037,
          0.31054068953518704,
          0.3026248536536083,
          0.2956255332571297
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "60712e02-26e4-402f-8a06-86d43ae024ce",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6896949752517368,
          0.6366317261820255,
          0.5428898272307022,
          0.4959640163442363,
          0.45811653733253477,
          0.4376839067624963,
          0.4226704864398293,
          0.41437451061995134,
          0.402759195410687,
          0.4080032535221266,
          0.39030894429787344,
          0.3833890598753224,
          0.3840869281602942,
          0.38312096569849097,
          0.3831920727439549,
          0.3964302127775939,
          0.4015275978523752,
          0.39524234170499056,
          0.3917331941749739,
          0.3952842603559079,
          0.41191493298696435,
          0.41932341585988586,
          0.4049834624580715,
          0.42200955929963485,
          0.42005619328954946,
          0.41520374495050183,
          0.41412003895510796,
          0.452814477422963,
          0.6428160154301187,
          0.7051060650659644
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"0d967c56-bde6-4480-b45c-91d41b77f9d2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"0d967c56-bde6-4480-b45c-91d41b77f9d2\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '0d967c56-bde6-4480-b45c-91d41b77f9d2',\n",
       "                        [{\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"4f1b36a1-cfdb-4c7b-be2c-2c0279542395\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6912510060457792, 0.66745130457164, 0.6522538596881184, 0.6088982990398499, 0.549640933672587, 0.5247796855686944, 0.48899228066062006, 0.4811481872042596, 0.44981937500589714, 0.4235119805531801, 0.4083104763917877, 0.39050592794510475, 0.3827459611754487, 0.38186289351343533, 0.37261866192886794, 0.3595859201921933, 0.35235981483390366, 0.34779576377016336, 0.344943987948883, 0.33821517563096565, 0.3371799034772864, 0.3405535178483972, 0.3264228700151766, 0.3348437742622578, 0.3246671716660117, 0.31637690769877413, 0.3090383423987218, 0.3109539285374148, 0.31584127348114327, 0.30643941096349614]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"4d4d0c20-fb98-4c5f-918b-64375bc4a8ef\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6691275560337564, 0.672860340450121, 0.6207207011139911, 0.5691162928290989, 0.5519512036572332, 0.5296242263006128, 0.49607473922812423, 0.46052895628887675, 0.42965879673543184, 0.42129446345826854, 0.4290034815021183, 0.4159188918445421, 0.4138843847357708, 0.41830299133839816, 0.396927809715271, 0.3978347405143406, 0.4001875442007314, 0.4097016147945238, 0.3865450651749321, 0.3991292603637861, 0.4120116454103719, 0.40073546637659485, 0.417030610208926, 0.4078405525373376, 0.3870932804501575, 0.38590367306833684, 0.3856584551541702, 0.3961945398994114, 0.39341029110162157, 0.4069114309290181]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"5b32e2ae-8d2e-4caf-b772-e0253584cbf8\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.691999586250471, 0.6828934367728118, 1.0454105233800584, 0.6441996931453834, 0.6341709872374788, 0.6232199307225177, 0.6152781627604351, 0.6084011755703728, 0.6012471711578, 0.5942631226806825, 0.5886446061341659, 0.5836836304641576, 0.5778309106250892, 0.5719590052890317, 0.5657456909976719, 0.5598949985227724, 0.5544888128405032, 0.5496674983397775, 0.5440173380616783, 0.5381371443398333, 0.5317365409095506, 0.5245922781994953, 0.519316441828502, 0.5116299330324366, 0.5088106674272657, 0.5000453348321039, 0.4954311804494996, 0.4885942917515114, 0.48064560648323834, 0.4741088040784937]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"b674d04c-0b2b-430c-b880-9e29d4fe42de\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6911129728607509, 0.6413222986718883, 0.6750288128852844, 0.6413911969765372, 0.644953107315561, 0.6380695674730383, 0.6293784457704296, 0.6214899457019308, 0.6145230174064636, 0.6069563575412916, 0.6016062249308047, 0.5966651906137881, 0.5920963619066322, 0.5873341378958329, 0.583684123599011, 0.5791476503662442, 0.5750439161839692, 0.5708900705627773, 0.5691788450531338, 0.5637283423672552, 0.5574927920880525, 0.5514648442683012, 0.5464116625163866, 0.5424561967020449, 0.5324030098707779, 0.5352091353872548, 0.5302413489507593, 0.5268794422564299, 0.5220077468001324, 0.5206417332524839]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"fbf48373-bd68-4520-88f2-7b52a61a9bf6\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6919701989146246, 0.6637236459819591, 0.6354265647809862, 0.61212711305434, 0.5746817775394606, 0.537880425867827, 0.4449865735959316, 0.3973897624418931, 0.37533710855216795, 0.3716498775758605, 0.36343148057011593, 0.3659969573435576, 0.3459366898893734, 0.3274727493956469, 0.32177490122652286, 0.30662696761785496, 0.30303814608405755, 0.3252805901034443, 0.809640059609344, 0.6249550162882045, 0.560455202019733, 0.5247627992272953, 0.49516252351267903, 0.4692513465017512, 0.4477997023702244, 0.43560280284443914, 0.42691621210264125, 0.41615365904886364, 0.4008559302719319, 0.4015161895521597]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"f0fa8ee2-e051-49be-930c-eefe6d6f3a84\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6889186651810356, 0.6435139650883882, 0.6215879041215647, 0.5904004983280016, 0.55744316837062, 0.5051907663759978, 0.40553312508956246, 0.3735042888185252, 0.3700173826321312, 0.37132751397464586, 0.3641377195068028, 0.4236282379730888, 0.378020819892054, 0.3966702598592509, 0.39133204584536346, 0.41137724570606066, 0.44565456380014834, 0.5985710823017618, 0.6451968317446501, 0.5835791012515192, 0.5166085126607315, 0.4893679556639298, 0.47733374030693715, 0.4719819732334303, 0.5139859489772631, 0.45948374297307887, 0.43083066396091296, 0.43563874130663666, 0.4198410676873249, 0.4215206169563791]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"d052a825-8715-4108-a9cb-8c0f0927d929\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6918880088317797, 0.6674939654875492, 0.6177664654842322, 0.5456751538359601, 0.46814763854091296, 0.4305067441025794, 0.4077598512748589, 0.38868670477959266, 0.38230009931297115, 0.3744089957596599, 0.3673415517173528, 0.365854643508432, 0.35244331499516673, 0.3410333604052447, 0.3410889296428017, 0.33235498748827674, 0.36197798969089123, 0.34280295325938054, 0.3226280898431649, 0.3136410996245877, 0.3041354565660735, 0.2960117951107486, 0.29115943763279106, 0.28758396689154675, 0.2801405072356192, 0.2826685454390475, 0.2770255230619136, 0.2799171821218758, 0.2930516686992369, 0.30363656263708494]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"e4c8632c-7ea4-4e99-a5c7-f68204bddf0c\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.691885432989701, 0.656434428691864, 0.5966616013775701, 0.48123004799303803, 0.43827552769495093, 0.41443547554638077, 0.3951947147431581, 0.3829040825366974, 0.3687787361766981, 0.3618969976902008, 0.35928891897201537, 0.3790254014989604, 0.3855586831984313, 0.4102310978848001, 0.4103327971437703, 0.4128926430059516, 0.4705960328164308, 0.40339165614998856, 0.36973443808762924, 0.36021760935368746, 0.3505537349244823, 0.3645204292691272, 0.3594047935112663, 0.36614515133526016, 0.3792075934617416, 0.3744499763716822, 0.3794135355431101, 0.3971242477064547, 0.4436258652935857, 0.4399814362111299]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"b8a75046-4272-4baa-9cf3-7adf20b510ce\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6921008413540568, 0.6894163189302897, 0.6748309036959772, 0.5850759839090173, 0.5598219136109098, 0.4561559676548133, 0.42699274990869607, 0.4046834287724057, 0.38872721330555166, 0.37447719525023937, 0.3747658568015997, 0.36267304564443764, 0.35730793058584276, 0.3487431598458313, 0.34344683378790886, 0.3397458781654708, 0.3339745258075604, 0.32779905718305835, 0.3262780156688414, 0.320635361717519, 0.3145694853602976, 0.3098041893491422, 0.31104667610016423, 0.3149687112817442, 0.3151567368403725, 0.3544752812615915, 0.3366184839591888, 0.3171773421015716, 0.3100637358167897, 0.30513417738071386]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"a4aee490-2a3b-4ed3-a267-cf24e1e586e7\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6906664615092071, 0.6872185437575631, 0.6529509844987289, 0.7249659180641175, 0.5355100445125414, 0.5054016310235728, 0.49628086219663203, 0.48230609686478326, 0.4774617734162704, 0.4795352754385575, 0.4719935855139857, 0.46516606859538867, 0.47001589329346366, 0.46993443810421487, 0.4721821209658747, 0.47163077022718347, 0.4714890860992929, 0.48225120461505394, 0.4864992688531461, 0.4856131133825883, 0.494533021553703, 0.4950237248254859, 0.48906046411265497, 0.48770068184189175, 0.48853010690730553, 0.49157209655512935, 0.5192025091337121, 0.5152841464332912, 0.5439262903254966, 0.543655326573745]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"7af7ccb5-05b5-4033-b1e5-84fe8f550f67\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6915616075773746, 0.6755664049139345, 0.658287170889297, 0.6232885865197666, 0.5806090459731466, 0.5591912466546763, 0.772564293048232, 0.7182517561359681, 0.6884992617339903, 0.6706135368001633, 0.6459083036524086, 0.5621002919432045, 0.5333103367095984, 0.518340223710894, 0.5101097148397694, 0.5040962941980592, 0.4958652541545278, 0.487601091320388, 0.47940233378594627, 0.47149267879085266, 0.4643930332384248, 0.4583960495709221, 0.45288406956023064, 0.44821433203231886, 0.4427299756358787, 0.4387065059320938, 0.43404422658653075, 0.4306828411017063, 0.42588096278301185, 0.42048539853326367]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"30eeb1c7-7c98-4afa-8f00-74f76ac17228\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6888440163239189, 0.6540412063183991, 0.626242855320806, 0.5799834577933601, 0.5522957617821901, 0.5235908611961033, 0.6862042924632197, 0.6997061221495918, 0.6838033401447794, 0.6588900991108106, 0.6174720479094464, 0.5383875966072083, 0.5199745020140772, 0.5172326891318612, 0.5082828252211861, 0.5003932724828305, 0.49256692191828855, 0.4863125806269438, 0.4809845128785009, 0.47745572147162063, 0.47557178943053535, 0.47262587650962495, 0.46853694138319596, 0.4662372065627057, 0.4649087058461231, 0.4618098927580792, 0.45888715101324995, 0.46002646529156227, 0.4576952312303626, 0.45498918217161427]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"09037e41-ad2c-4efe-9129-8b9c23bf9e8b\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6917372552093101, 0.6850238510376013, 0.6572190549638536, 0.5947780468037739, 0.521489848030938, 0.4711831521008902, 0.4352009300160523, 0.4483491527861443, 0.42052573555909495, 0.4139175833999247, 0.39981478452682495, 0.45503788728644884, 0.4417028105489298, 0.3938033145982862, 0.38668754814903517, 0.38439639124317443, 0.3770611522854238, 0.37037516328447684, 0.3670429357871917, 0.36311456132050296, 0.35955484328062637, 0.3568240595900494, 0.3554995046145674, 0.3550388113600044, 0.35048585882509387, 0.34699204307823367, 0.344000802754204, 0.34111963953948826, 0.338347623947162, 0.3358355150130636]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"eda1d4b6-6324-4281-914a-eccfd007b745\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6906749264053677, 0.6839584982913474, 0.6314310229342917, 0.5544174992519876, 0.47174637265827346, 0.4367662427218064, 0.48303363530532173, 0.42435086447259657, 0.413223172529884, 0.419642295267271, 0.4076438157454781, 0.547335512223451, 0.42064145984856977, 0.4110044124333755, 0.4048530811848848, 0.406114559588225, 0.3861277645048888, 0.3855237279249274, 0.38343729869179105, 0.38246025624482527, 0.3810982014821923, 0.38081559512926183, 0.37949746873067774, 0.38075390147126237, 0.37838182760321576, 0.37726151709971223, 0.37745836947275246, 0.3776499989240066, 0.3775961759297744, 0.3793996707252834]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"d29480fc-4135-4d81-bda4-fb1ea5ac5434\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6921500799736539, 0.6896353173371098, 0.6492528640129716, 0.5780356996301291, 0.490236094493221, 0.4403795938272983, 0.42010780958737726, 0.40473991900250533, 0.39323036903920383, 0.38043852284334706, 0.37458991186630325, 0.36311163366704746, 0.36239580353676987, 0.35074752796675274, 0.3437393152195474, 0.3423417983135739, 0.32422931427540985, 0.3140165527517669, 0.3130297405852212, 0.30356152168506584, 0.299428242833718, 0.2919938615122855, 0.2922002165645793, 0.29025585382168995, 0.2867989892400981, 0.28524246518162716, 0.28273442137068594, 0.2914494336659206, 0.27137178516618293, 0.27292721966902417]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"12a1f788-0db5-49f3-a7d9-13a40eb6b9d4\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6891823136288187, 0.6741812353548796, 0.5943346816560496, 0.5184534674105437, 0.46095897866332014, 0.42143807722174603, 0.41916284898053047, 0.3889074753160062, 0.3991559220396954, 0.3921644291152125, 0.40548010494398035, 0.41294102539186894, 0.42488475882488747, 0.4107188750868258, 0.4019289952257405, 0.3833007885062176, 0.36543374528055605, 0.37383831091549086, 0.3603166437667349, 0.3840989141360573, 0.3629525293474612, 0.3789125709430031, 0.36993713430736375, 0.3566146708053091, 0.3620128851869832, 0.4037271999794504, 0.37543557389922766, 0.44176572094792904, 0.4001552685447361, 0.4147060332090958]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"58358ea0-0fac-4671-8220-74fc0b911970\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6920475299231672, 0.682461939226602, 0.625965114204204, 0.5044870523438938, 0.440907387226676, 0.41651308124767983, 0.4009102758002166, 0.40176066062300675, 0.39246528353092175, 0.37375666637351546, 0.3601712637477451, 0.35153957196479835, 0.34046747816933526, 0.3300548037613072, 0.3266422907223448, 0.3223366263695961, 0.32241223907989003, 0.3065628187523948, 0.305910530715173, 0.30659699087269643, 0.2951542608403929, 0.303519568020019, 0.3176230572559983, 0.32270500579317984, 0.2997744900736832, 0.29608930342151346, 0.2847984675767917, 0.28877851508089886, 0.28182154086188993, 0.2962860584690951]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"76bf4099-65ba-471e-b01b-d21ed7ab9994\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.690921632103298, 0.6544707236082657, 0.5892202149266782, 0.4450798633305923, 0.4404606606649316, 0.42449970038040824, 0.4172367518362792, 0.4018864077070485, 0.3911159422086633, 0.39834437888601554, 0.39040465976880945, 0.37637922867484713, 0.3704046285670737, 0.3767065556153007, 0.36472781248714614, 0.37118389036344446, 0.36701733936434205, 0.37519337249838786, 0.36678781898125357, 0.3618570405503978, 0.3785457175710927, 0.36928677818049555, 0.4215766660545183, 0.38691028252891874, 0.36120747379634693, 0.38793664108151976, 0.3933355664429457, 0.3869520630525506, 0.42988197725752125, 0.4152793109416962]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"ee97f63e-706a-4ad3-ad7b-e88d72a116b2\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6919040844636263, 0.6812566342561142, 0.6184573840979792, 0.5584914168297956, 0.513875891275452, 0.4859497484953507, 0.46088684831840404, 0.4301556532509661, 0.425875055703564, 0.4151807693179679, 0.40425483284941044, 0.39005838166112483, 0.3831141283258724, 0.3731642194416212, 0.36752025778742803, 0.3693969023112514, 0.3634032872563975, 0.3603810511637425, 0.357703752707744, 0.3536290679288947, 0.3625063715061704, 0.366304806234756, 0.33833699908809384, 0.32731481779024796, 0.3200291291527126, 0.31284931898117063, 0.3130029508745037, 0.31054068953518704, 0.3026248536536083, 0.2956255332571297]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"60712e02-26e4-402f-8a06-86d43ae024ce\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6896949752517368, 0.6366317261820255, 0.5428898272307022, 0.4959640163442363, 0.45811653733253477, 0.4376839067624963, 0.4226704864398293, 0.41437451061995134, 0.402759195410687, 0.4080032535221266, 0.39030894429787344, 0.3833890598753224, 0.3840869281602942, 0.38312096569849097, 0.3831920727439549, 0.3964302127775939, 0.4015275978523752, 0.39524234170499056, 0.3917331941749739, 0.3952842603559079, 0.41191493298696435, 0.41932341585988586, 0.4049834624580715, 0.42200955929963485, 0.42005619328954946, 0.41520374495050183, 0.41412003895510796, 0.452814477422963, 0.6428160154301187, 0.7051060650659644]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0d967c56-bde6-4480-b45c-91d41b77f9d2');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean  acc         0.787255\n",
      "loss        0.436262\n",
      "val_acc     0.774638\n",
      "val_loss    0.472216\n",
      "dtype: float64\n",
      "std  acc         0.092440\n",
      "loss        0.131182\n",
      "val_acc     0.084163\n",
      "val_loss    0.098407\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "1",
         "text": "",
         "type": "scatter",
         "uid": "71c8dc1a-9544-4a92-9db0-fdc27648a3f3",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.8600000143051147,
          0.7900000214576721,
          0.8299999833106995,
          0.7900000214576721,
          0.7699999809265137,
          0.8299999833106995,
          0.8500000238418579,
          0.7200000286102295,
          0.7799999713897705,
          0.8600000143051147
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"2e7aada4-045f-4245-9788-5a13e4bc2da2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"2e7aada4-045f-4245-9788-5a13e4bc2da2\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '2e7aada4-045f-4245-9788-5a13e4bc2da2',\n",
       "                        [{\"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"1\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"71c8dc1a-9544-4a92-9db0-fdc27648a3f3\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.8600000143051147, 0.7900000214576721, 0.8299999833106995, 0.7900000214576721, 0.7699999809265137, 0.8299999833106995, 0.8500000238418579, 0.7200000286102295, 0.7799999713897705, 0.8600000143051147]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('2e7aada4-045f-4245-9788-5a13e4bc2da2');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media  0.8080000042915344\n",
      "std  0.0456557164254997\n"
     ]
    }
   ],
   "source": [
    "process_results(simpler_hist, simpler_evas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LA reducción de dimensionalidad de la red neuronal permite reducir la velocidad de aprendizaje sobre el conjunto de entrenamiento reduciendo así la perdida en el conjunto de validación.\n",
    "\n",
    "Si lo compramos con el resultado anterior vemos que en general se reducen los picos negativos, en un 0.30 como minimo, sin embargo la convergencia sigue estando sobre 0.4 en los mejores casos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularización por dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.077848Z",
     "start_time": "2019-06-14T06:36:08.306Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0619 08:13:41.216991 139968762341184 nn_ops.py:4230] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/dropout_lstm/kfold1\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 27s 6ms/sample - loss: 0.6919 - acc: 0.5790 - val_loss: 0.6903 - val_acc: 0.5739\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6849 - acc: 0.5763 - val_loss: 0.6808 - val_acc: 0.5739\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6635 - acc: 0.5787 - val_loss: 0.6189 - val_acc: 0.5739\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6287 - acc: 0.5795 - val_loss: 0.5961 - val_acc: 0.5739\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6070 - acc: 0.5783 - val_loss: 0.5408 - val_acc: 0.5739\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5725 - acc: 0.5790 - val_loss: 0.5254 - val_acc: 0.5739\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6633 - acc: 0.5857 - val_loss: 0.6768 - val_acc: 0.5870\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6801 - acc: 0.5894 - val_loss: 0.6792 - val_acc: 0.5739\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6790 - acc: 0.5857 - val_loss: 0.6777 - val_acc: 0.5739\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6773 - acc: 0.5816 - val_loss: 0.6763 - val_acc: 0.5739\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6754 - acc: 0.5812 - val_loss: 0.6750 - val_acc: 0.5739\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6748 - acc: 0.5795 - val_loss: 0.6740 - val_acc: 0.5739\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6739 - acc: 0.5795 - val_loss: 0.6730 - val_acc: 0.5739\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6722 - acc: 0.5792 - val_loss: 0.6722 - val_acc: 0.5739\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6710 - acc: 0.5795 - val_loss: 0.6714 - val_acc: 0.5739\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6700 - acc: 0.5797 - val_loss: 0.6707 - val_acc: 0.5739\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6690 - acc: 0.5790 - val_loss: 0.6700 - val_acc: 0.5739\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6683 - acc: 0.5792 - val_loss: 0.6693 - val_acc: 0.5739\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6671 - acc: 0.5792 - val_loss: 0.6686 - val_acc: 0.5739\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6652 - acc: 0.5797 - val_loss: 0.6679 - val_acc: 0.5739\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6649 - acc: 0.5800 - val_loss: 0.6672 - val_acc: 0.5739\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6633 - acc: 0.5797 - val_loss: 0.6663 - val_acc: 0.5739\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6626 - acc: 0.5797 - val_loss: 0.6655 - val_acc: 0.5739\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 1s 311us/sample - loss: 0.6621 - acc: 0.5790 - val_loss: 0.6645 - val_acc: 0.5739\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 1s 312us/sample - loss: 0.6604 - acc: 0.5792 - val_loss: 0.6633 - val_acc: 0.5739\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 1s 315us/sample - loss: 0.6591 - acc: 0.5787 - val_loss: 0.6621 - val_acc: 0.5739\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 1s 316us/sample - loss: 0.6578 - acc: 0.5797 - val_loss: 0.6609 - val_acc: 0.5739\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.6578 - acc: 0.5795 - val_loss: 0.6595 - val_acc: 0.5739\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.6554 - acc: 0.5797 - val_loss: 0.6581 - val_acc: 0.5739\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 1s 321us/sample - loss: 0.6526 - acc: 0.5797 - val_loss: 0.6566 - val_acc: 0.5739\n",
      "100/100 [==============================] - 0s 699us/sample - loss: 0.6698 - acc: 0.5100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0619 08:17:33.814997 139968762341184 nn_ops.py:4230] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/dropout_lstm/kfold2\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 13s 3ms/sample - loss: 0.6922 - acc: 0.5746 - val_loss: 0.6913 - val_acc: 0.5696\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.6902 - acc: 0.5800 - val_loss: 0.6896 - val_acc: 0.5696\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 6s 1ms/sample - loss: 0.6881 - acc: 0.5800 - val_loss: 0.6875 - val_acc: 0.5696\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6833 - acc: 0.5800 - val_loss: 0.6817 - val_acc: 0.5870\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6557 - acc: 0.6529 - val_loss: 0.6146 - val_acc: 0.7348\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6117 - acc: 0.6766 - val_loss: 0.5228 - val_acc: 0.7717\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5589 - acc: 0.7056 - val_loss: 0.4695 - val_acc: 0.8000\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5544 - acc: 0.7063 - val_loss: 0.4789 - val_acc: 0.7978\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5320 - acc: 0.7114 - val_loss: 0.4360 - val_acc: 0.8065\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5036 - acc: 0.7379 - val_loss: 0.4318 - val_acc: 0.8109\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5016 - acc: 0.7379 - val_loss: 0.4371 - val_acc: 0.8304\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5037 - acc: 0.7258 - val_loss: 0.4285 - val_acc: 0.8435\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4911 - acc: 0.7360 - val_loss: 0.4094 - val_acc: 0.8370\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4864 - acc: 0.7348 - val_loss: 0.4220 - val_acc: 0.8196\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4763 - acc: 0.7449 - val_loss: 0.3884 - val_acc: 0.8391\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4765 - acc: 0.7502 - val_loss: 0.3869 - val_acc: 0.8348\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4756 - acc: 0.7374 - val_loss: 0.3895 - val_acc: 0.8391\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4485 - acc: 0.7587 - val_loss: 0.3850 - val_acc: 0.8348\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4672 - acc: 0.7464 - val_loss: 0.4091 - val_acc: 0.8217\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4501 - acc: 0.7529 - val_loss: 0.4106 - val_acc: 0.8174\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4488 - acc: 0.7560 - val_loss: 0.4032 - val_acc: 0.8174\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4426 - acc: 0.7568 - val_loss: 0.3941 - val_acc: 0.8370\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4372 - acc: 0.7647 - val_loss: 0.4321 - val_acc: 0.8217\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4274 - acc: 0.7652 - val_loss: 0.3866 - val_acc: 0.8326\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4319 - acc: 0.7643 - val_loss: 0.3707 - val_acc: 0.8326\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4041 - acc: 0.7785 - val_loss: 0.4086 - val_acc: 0.8348\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4029 - acc: 0.7845 - val_loss: 0.4046 - val_acc: 0.8239\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4059 - acc: 0.7775 - val_loss: 0.4182 - val_acc: 0.8326\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 2s 383us/sample - loss: 0.3974 - acc: 0.7819 - val_loss: 0.4823 - val_acc: 0.8261\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 1s 305us/sample - loss: 0.3797 - acc: 0.7865 - val_loss: 0.4509 - val_acc: 0.8152\n",
      "100/100 [==============================] - 0s 685us/sample - loss: 0.3534 - acc: 0.8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0619 08:21:36.685403 139968762341184 nn_ops.py:4230] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/dropout_lstm/kfold3\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6922 - acc: 0.5725 - val_loss: 0.6900 - val_acc: 0.6087\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 330us/sample - loss: 0.6884 - acc: 0.5894 - val_loss: 0.6758 - val_acc: 0.6609\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 329us/sample - loss: 0.6690 - acc: 0.6290 - val_loss: 0.6203 - val_acc: 0.7304\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 2s 420us/sample - loss: 0.6207 - acc: 0.6766 - val_loss: 0.5343 - val_acc: 0.7674\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 2s 511us/sample - loss: 0.5674 - acc: 0.7080 - val_loss: 0.4890 - val_acc: 0.7609\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 4s 982us/sample - loss: 0.5371 - acc: 0.7145 - val_loss: 0.4552 - val_acc: 0.7674\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.5206 - acc: 0.7341 - val_loss: 0.4637 - val_acc: 0.7652\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 6s 1ms/sample - loss: 0.5004 - acc: 0.7483 - val_loss: 0.4379 - val_acc: 0.7870\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4885 - acc: 0.7415 - val_loss: 0.4131 - val_acc: 0.7826\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4680 - acc: 0.7534 - val_loss: 0.4038 - val_acc: 0.8000\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4650 - acc: 0.7599 - val_loss: 0.4023 - val_acc: 0.8000\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4636 - acc: 0.7650 - val_loss: 0.4190 - val_acc: 0.7848\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4601 - acc: 0.7640 - val_loss: 0.4155 - val_acc: 0.7935\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4467 - acc: 0.7732 - val_loss: 0.4085 - val_acc: 0.7978\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4325 - acc: 0.7754 - val_loss: 0.3977 - val_acc: 0.7978\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4338 - acc: 0.7686 - val_loss: 0.3962 - val_acc: 0.8109\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4190 - acc: 0.7756 - val_loss: 0.4033 - val_acc: 0.8043\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4252 - acc: 0.7775 - val_loss: 0.4072 - val_acc: 0.8000\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4175 - acc: 0.7802 - val_loss: 0.4085 - val_acc: 0.8022\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4180 - acc: 0.7850 - val_loss: 0.4155 - val_acc: 0.8043\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4148 - acc: 0.7850 - val_loss: 0.4127 - val_acc: 0.8239\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4113 - acc: 0.7872 - val_loss: 0.4277 - val_acc: 0.8174\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4170 - acc: 0.7809 - val_loss: 0.4500 - val_acc: 0.8087\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4056 - acc: 0.7954 - val_loss: 0.4689 - val_acc: 0.8000\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4057 - acc: 0.7872 - val_loss: 0.4495 - val_acc: 0.8130\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4098 - acc: 0.7819 - val_loss: 0.4269 - val_acc: 0.8087\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4007 - acc: 0.7896 - val_loss: 0.4434 - val_acc: 0.8109\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4011 - acc: 0.7918 - val_loss: 0.4118 - val_acc: 0.8196\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4167 - acc: 0.7780 - val_loss: 0.4232 - val_acc: 0.8109\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3819 - acc: 0.7998 - val_loss: 0.4281 - val_acc: 0.8239\n",
      "100/100 [==============================] - 1s 5ms/sample - loss: 0.3964 - acc: 0.8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0619 08:25:21.137230 139968762341184 nn_ops.py:4230] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/dropout_lstm/kfold4\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6921 - acc: 0.5744 - val_loss: 0.6900 - val_acc: 0.5978\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.6889 - acc: 0.5877 - val_loss: 0.6823 - val_acc: 0.6587\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 301us/sample - loss: 0.6812 - acc: 0.6353 - val_loss: 0.6818 - val_acc: 0.6130\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 301us/sample - loss: 0.6844 - acc: 0.5809 - val_loss: 0.6780 - val_acc: 0.6109\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 330us/sample - loss: 0.6752 - acc: 0.6188 - val_loss: 0.6594 - val_acc: 0.7239\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 329us/sample - loss: 0.6541 - acc: 0.6720 - val_loss: 0.6039 - val_acc: 0.7870\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 2s 473us/sample - loss: 0.6371 - acc: 0.6877 - val_loss: 0.5995 - val_acc: 0.7717\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 3s 713us/sample - loss: 0.5950 - acc: 0.7227 - val_loss: 0.5282 - val_acc: 0.8174\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.5582 - acc: 0.7399 - val_loss: 0.4782 - val_acc: 0.8217\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.5293 - acc: 0.7618 - val_loss: 0.4481 - val_acc: 0.8283\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 7s 2ms/sample - loss: 0.5078 - acc: 0.7669 - val_loss: 0.4231 - val_acc: 0.8326\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4798 - acc: 0.7739 - val_loss: 0.4076 - val_acc: 0.8348\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4804 - acc: 0.7587 - val_loss: 0.4099 - val_acc: 0.8283\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4673 - acc: 0.7664 - val_loss: 0.4459 - val_acc: 0.8022\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4605 - acc: 0.7703 - val_loss: 0.4257 - val_acc: 0.8326\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4413 - acc: 0.7850 - val_loss: 0.3774 - val_acc: 0.8348\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4305 - acc: 0.7804 - val_loss: 0.3762 - val_acc: 0.8348\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4244 - acc: 0.7899 - val_loss: 0.3935 - val_acc: 0.8391\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4017 - acc: 0.8017 - val_loss: 0.3870 - val_acc: 0.8304\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4118 - acc: 0.7915 - val_loss: 0.3861 - val_acc: 0.8348\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3965 - acc: 0.7930 - val_loss: 0.4062 - val_acc: 0.8304\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4805 - acc: 0.7493 - val_loss: 0.5167 - val_acc: 0.8217\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5248 - acc: 0.7630 - val_loss: 0.4801 - val_acc: 0.8283\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4797 - acc: 0.7853 - val_loss: 0.4271 - val_acc: 0.8239\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4474 - acc: 0.7935 - val_loss: 0.4157 - val_acc: 0.8239\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4266 - acc: 0.7973 - val_loss: 0.4060 - val_acc: 0.8174\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4278 - acc: 0.7879 - val_loss: 0.3886 - val_acc: 0.8283\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4187 - acc: 0.8065 - val_loss: 0.3926 - val_acc: 0.8196\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4052 - acc: 0.8041 - val_loss: 0.3959 - val_acc: 0.8196\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3987 - acc: 0.8031 - val_loss: 0.3830 - val_acc: 0.8239\n",
      "100/100 [==============================] - 1s 5ms/sample - loss: 0.4166 - acc: 0.8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0619 08:28:50.232286 139968762341184 nn_ops.py:4230] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/dropout_lstm/kfold5\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6921 - acc: 0.5773 - val_loss: 0.6913 - val_acc: 0.5609\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 304us/sample - loss: 0.6897 - acc: 0.5809 - val_loss: 0.6885 - val_acc: 0.5609\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.6807 - acc: 0.6278 - val_loss: 0.6618 - val_acc: 0.6935\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.6613 - acc: 0.6882 - val_loss: 0.6256 - val_acc: 0.7217\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 301us/sample - loss: 0.6315 - acc: 0.6973 - val_loss: 0.5938 - val_acc: 0.7522\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 300us/sample - loss: 0.6001 - acc: 0.6978 - val_loss: 0.5125 - val_acc: 0.7804\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.5605 - acc: 0.7256 - val_loss: 0.4785 - val_acc: 0.7935\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 335us/sample - loss: 0.5516 - acc: 0.7179 - val_loss: 0.4490 - val_acc: 0.7957\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 347us/sample - loss: 0.5182 - acc: 0.7333 - val_loss: 0.4348 - val_acc: 0.7978\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 2s 473us/sample - loss: 0.4929 - acc: 0.7514 - val_loss: 0.4143 - val_acc: 0.8130\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 3s 749us/sample - loss: 0.4838 - acc: 0.7543 - val_loss: 0.4238 - val_acc: 0.8065\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.4819 - acc: 0.7606 - val_loss: 0.4110 - val_acc: 0.8087\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.4822 - acc: 0.7486 - val_loss: 0.4031 - val_acc: 0.8130\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 7s 2ms/sample - loss: 0.4799 - acc: 0.7543 - val_loss: 0.4025 - val_acc: 0.8217\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4771 - acc: 0.7546 - val_loss: 0.4045 - val_acc: 0.8283\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4653 - acc: 0.7609 - val_loss: 0.4060 - val_acc: 0.8348\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4517 - acc: 0.7671 - val_loss: 0.3927 - val_acc: 0.8457\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4441 - acc: 0.7732 - val_loss: 0.4020 - val_acc: 0.8370\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4481 - acc: 0.7737 - val_loss: 0.4238 - val_acc: 0.8261\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4436 - acc: 0.7802 - val_loss: 0.3997 - val_acc: 0.8348\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4333 - acc: 0.7913 - val_loss: 0.3861 - val_acc: 0.8522\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5990 - acc: 0.7406 - val_loss: 0.7095 - val_acc: 0.5696\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6496 - acc: 0.6258 - val_loss: 0.6314 - val_acc: 0.6413\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6199 - acc: 0.6797 - val_loss: 0.6024 - val_acc: 0.7326\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5881 - acc: 0.7179 - val_loss: 0.5593 - val_acc: 0.7783\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5457 - acc: 0.7314 - val_loss: 0.4954 - val_acc: 0.8217\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5104 - acc: 0.7394 - val_loss: 0.4401 - val_acc: 0.8391\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4758 - acc: 0.7703 - val_loss: 0.4073 - val_acc: 0.8348\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4632 - acc: 0.7647 - val_loss: 0.4065 - val_acc: 0.8391\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4491 - acc: 0.7662 - val_loss: 0.4081 - val_acc: 0.8413\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.4317 - acc: 0.8100\n",
      "logs/fit/dropout_lstm/kfold6\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6920 - acc: 0.5739 - val_loss: 0.6909 - val_acc: 0.5717\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 315us/sample - loss: 0.6897 - acc: 0.5790 - val_loss: 0.6826 - val_acc: 0.5717\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 300us/sample - loss: 0.6667 - acc: 0.5744 - val_loss: 0.6450 - val_acc: 0.5717\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 304us/sample - loss: 0.6506 - acc: 0.5792 - val_loss: 0.6155 - val_acc: 0.5717\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 296us/sample - loss: 0.6010 - acc: 0.5800 - val_loss: 0.5613 - val_acc: 0.5717\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 300us/sample - loss: 0.5664 - acc: 0.5829 - val_loss: 0.5548 - val_acc: 0.5717\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 305us/sample - loss: 0.5554 - acc: 0.6068 - val_loss: 0.5280 - val_acc: 0.5717\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 297us/sample - loss: 0.5311 - acc: 0.6655 - val_loss: 0.5224 - val_acc: 0.7717\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 301us/sample - loss: 0.5383 - acc: 0.7053 - val_loss: 0.5219 - val_acc: 0.7717\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.5250 - acc: 0.7498 - val_loss: 0.5110 - val_acc: 0.7848\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 337us/sample - loss: 0.5066 - acc: 0.7609 - val_loss: 0.5087 - val_acc: 0.7848\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 330us/sample - loss: 0.5013 - acc: 0.7585 - val_loss: 0.4962 - val_acc: 0.7891\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 2s 479us/sample - loss: 0.5041 - acc: 0.7592 - val_loss: 0.4993 - val_acc: 0.7826\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 3s 723us/sample - loss: 0.4979 - acc: 0.7664 - val_loss: 0.5050 - val_acc: 0.7761\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.4780 - acc: 0.7773 - val_loss: 0.5012 - val_acc: 0.7696\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.4700 - acc: 0.7807 - val_loss: 0.5045 - val_acc: 0.7565\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 7s 2ms/sample - loss: 0.4636 - acc: 0.7872 - val_loss: 0.5075 - val_acc: 0.7609\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4765 - acc: 0.7908 - val_loss: 0.5025 - val_acc: 0.7370\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4702 - acc: 0.7877 - val_loss: 0.4811 - val_acc: 0.7804\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4849 - acc: 0.7732 - val_loss: 0.4618 - val_acc: 0.8109\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4779 - acc: 0.7739 - val_loss: 0.5001 - val_acc: 0.8196\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4667 - acc: 0.7908 - val_loss: 0.4826 - val_acc: 0.8043\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4529 - acc: 0.7918 - val_loss: 0.5041 - val_acc: 0.7870\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4518 - acc: 0.7911 - val_loss: 0.4913 - val_acc: 0.7913\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4296 - acc: 0.8092 - val_loss: 0.5271 - val_acc: 0.8217\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4356 - acc: 0.8048 - val_loss: 0.4689 - val_acc: 0.7891\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4316 - acc: 0.8056 - val_loss: 0.5166 - val_acc: 0.8174\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4321 - acc: 0.8053 - val_loss: 0.5181 - val_acc: 0.8043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4240 - acc: 0.8089 - val_loss: 0.4985 - val_acc: 0.8283\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4295 - acc: 0.8075 - val_loss: 0.5940 - val_acc: 0.8217\n",
      "100/100 [==============================] - 1s 5ms/sample - loss: 0.6181 - acc: 0.8100\n",
      "logs/fit/dropout_lstm/kfold7\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 35s 8ms/sample - loss: 0.6921 - acc: 0.5758 - val_loss: 0.6911 - val_acc: 0.5717\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 305us/sample - loss: 0.6892 - acc: 0.5829 - val_loss: 0.6771 - val_acc: 0.6217\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 298us/sample - loss: 1.0435 - acc: 0.7012 - val_loss: 0.6174 - val_acc: 0.7413\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.6487 - acc: 0.6990 - val_loss: 0.6412 - val_acc: 0.7152\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 304us/sample - loss: 0.6327 - acc: 0.7072 - val_loss: 0.6322 - val_acc: 0.7196\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 304us/sample - loss: 0.6225 - acc: 0.7167 - val_loss: 0.6270 - val_acc: 0.7239\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 298us/sample - loss: 0.6155 - acc: 0.7309 - val_loss: 0.6192 - val_acc: 0.7196\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.6105 - acc: 0.7278 - val_loss: 0.6080 - val_acc: 0.7391\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 301us/sample - loss: 0.6030 - acc: 0.7309 - val_loss: 0.6033 - val_acc: 0.7304\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 304us/sample - loss: 0.5901 - acc: 0.7425 - val_loss: 0.5911 - val_acc: 0.7435\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.5782 - acc: 0.7493 - val_loss: 0.5886 - val_acc: 0.7391\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 304us/sample - loss: 0.5768 - acc: 0.7430 - val_loss: 0.5718 - val_acc: 0.7543\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 1s 297us/sample - loss: 0.5658 - acc: 0.7551 - val_loss: 0.5722 - val_acc: 0.7609\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.5725 - acc: 0.7493 - val_loss: 0.5821 - val_acc: 0.7391\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 1s 339us/sample - loss: 0.5645 - acc: 0.7512 - val_loss: 0.5527 - val_acc: 0.7652\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 1s 355us/sample - loss: 0.5622 - acc: 0.7483 - val_loss: 0.5584 - val_acc: 0.7565\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 2s 480us/sample - loss: 0.5532 - acc: 0.7618 - val_loss: 0.5591 - val_acc: 0.7500\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 3s 801us/sample - loss: 0.5490 - acc: 0.7626 - val_loss: 0.6086 - val_acc: 0.7261\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.5578 - acc: 0.7681 - val_loss: 0.5442 - val_acc: 0.7696\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.5496 - acc: 0.7679 - val_loss: 0.5514 - val_acc: 0.7587\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5286 - acc: 0.7807 - val_loss: 0.5269 - val_acc: 0.7717\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5297 - acc: 0.7787 - val_loss: 0.5319 - val_acc: 0.7609\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5304 - acc: 0.7812 - val_loss: 0.5354 - val_acc: 0.7630\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5217 - acc: 0.7816 - val_loss: 0.5321 - val_acc: 0.7652\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5192 - acc: 0.7795 - val_loss: 0.5368 - val_acc: 0.7696\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5023 - acc: 0.7969 - val_loss: 0.5124 - val_acc: 0.7739\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4933 - acc: 0.7949 - val_loss: 0.4864 - val_acc: 0.8065\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5026 - acc: 0.7966 - val_loss: 0.5036 - val_acc: 0.7848\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4870 - acc: 0.7949 - val_loss: 0.4797 - val_acc: 0.7891\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4936 - acc: 0.7949 - val_loss: 0.4766 - val_acc: 0.8022\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.4555 - acc: 0.8300\n",
      "logs/fit/dropout_lstm/kfold8\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 52s 12ms/sample - loss: 0.6920 - acc: 0.5780 - val_loss: 0.6909 - val_acc: 0.5652\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.6832 - acc: 0.5816 - val_loss: 0.6426 - val_acc: 0.5696\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 301us/sample - loss: 0.6569 - acc: 0.6553 - val_loss: 0.5854 - val_acc: 0.7065\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.5953 - acc: 0.7019 - val_loss: 0.5073 - val_acc: 0.7413\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 305us/sample - loss: 0.5332 - acc: 0.7162 - val_loss: 0.4488 - val_acc: 0.7500\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 301us/sample - loss: 0.5085 - acc: 0.7258 - val_loss: 0.4411 - val_acc: 0.7674\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 300us/sample - loss: 0.4888 - acc: 0.7437 - val_loss: 0.4361 - val_acc: 0.7848\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 301us/sample - loss: 0.4858 - acc: 0.7481 - val_loss: 0.4248 - val_acc: 0.7891\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 300us/sample - loss: 0.4614 - acc: 0.7531 - val_loss: 0.4151 - val_acc: 0.7978\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 305us/sample - loss: 0.4559 - acc: 0.7628 - val_loss: 0.4151 - val_acc: 0.8087\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.4409 - acc: 0.7775 - val_loss: 0.4063 - val_acc: 0.8130\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 305us/sample - loss: 0.4541 - acc: 0.7725 - val_loss: 0.3989 - val_acc: 0.8174\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 1s 300us/sample - loss: 0.4396 - acc: 0.7621 - val_loss: 0.4104 - val_acc: 0.8196\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.4410 - acc: 0.7768 - val_loss: 0.3972 - val_acc: 0.8217\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.4258 - acc: 0.7732 - val_loss: 0.3942 - val_acc: 0.8217\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 1s 331us/sample - loss: 0.4191 - acc: 0.7809 - val_loss: 0.3848 - val_acc: 0.8239\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 1s 327us/sample - loss: 0.4163 - acc: 0.7746 - val_loss: 0.3907 - val_acc: 0.8174\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 1s 346us/sample - loss: 0.4113 - acc: 0.7867 - val_loss: 0.3839 - val_acc: 0.8217\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 2s 423us/sample - loss: 0.3866 - acc: 0.7865 - val_loss: 0.3958 - val_acc: 0.8217\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 2s 483us/sample - loss: 0.3933 - acc: 0.7836 - val_loss: 0.3872 - val_acc: 0.8087\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 4s 977us/sample - loss: 0.3996 - acc: 0.7749 - val_loss: 0.3872 - val_acc: 0.8174\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.3861 - acc: 0.7947 - val_loss: 0.3980 - val_acc: 0.8087\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 6s 1ms/sample - loss: 0.3688 - acc: 0.8072 - val_loss: 0.3933 - val_acc: 0.8217\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3728 - acc: 0.8106 - val_loss: 0.3810 - val_acc: 0.8174\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3751 - acc: 0.8082 - val_loss: 0.3960 - val_acc: 0.8130\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3732 - acc: 0.8063 - val_loss: 0.3844 - val_acc: 0.8217\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3692 - acc: 0.8147 - val_loss: 0.3951 - val_acc: 0.8217\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3493 - acc: 0.8234 - val_loss: 0.3944 - val_acc: 0.8370\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3508 - acc: 0.8227 - val_loss: 0.4037 - val_acc: 0.8217\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3472 - acc: 0.8275 - val_loss: 0.3970 - val_acc: 0.8304\n",
      "100/100 [==============================] - 1s 6ms/sample - loss: 0.3673 - acc: 0.8500\n",
      "logs/fit/dropout_lstm/kfold9\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 53s 13ms/sample - loss: 0.6921 - acc: 0.5778 - val_loss: 0.6915 - val_acc: 0.5587\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6894 - acc: 0.5812 - val_loss: 0.6893 - val_acc: 0.5587\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6641 - acc: 0.6254 - val_loss: 0.6164 - val_acc: 0.7217\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6092 - acc: 0.7101 - val_loss: 0.4927 - val_acc: 0.7826\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5690 - acc: 0.7188 - val_loss: 0.4972 - val_acc: 0.7587\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5038 - acc: 0.7618 - val_loss: 0.4492 - val_acc: 0.8043\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4856 - acc: 0.7816 - val_loss: 0.4475 - val_acc: 0.7935\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 4s 900us/sample - loss: 0.4812 - acc: 0.7732 - val_loss: 0.4207 - val_acc: 0.8043\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 305us/sample - loss: 0.4763 - acc: 0.7688 - val_loss: 0.4543 - val_acc: 0.7848\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 304us/sample - loss: 0.4518 - acc: 0.7913 - val_loss: 0.4154 - val_acc: 0.8043\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.4538 - acc: 0.7886 - val_loss: 0.4431 - val_acc: 0.7957\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 305us/sample - loss: 0.4523 - acc: 0.7988 - val_loss: 0.4483 - val_acc: 0.7978\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.4484 - acc: 0.7947 - val_loss: 0.4640 - val_acc: 0.7913\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 1s 305us/sample - loss: 0.4272 - acc: 0.8152 - val_loss: 0.4439 - val_acc: 0.8109\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.4137 - acc: 0.8116 - val_loss: 0.4257 - val_acc: 0.8174\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.4165 - acc: 0.8179 - val_loss: 0.4117 - val_acc: 0.8174\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.4074 - acc: 0.8237 - val_loss: 0.4285 - val_acc: 0.8065\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.3926 - acc: 0.8348 - val_loss: 0.4288 - val_acc: 0.8130\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.3876 - acc: 0.8379 - val_loss: 0.4803 - val_acc: 0.8065\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.3943 - acc: 0.8249 - val_loss: 0.4225 - val_acc: 0.8130\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.3766 - acc: 0.8386 - val_loss: 0.3796 - val_acc: 0.8196\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.3759 - acc: 0.8324 - val_loss: 0.4220 - val_acc: 0.8196\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 1s 326us/sample - loss: 0.3757 - acc: 0.8382 - val_loss: 0.4174 - val_acc: 0.8174\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 1s 335us/sample - loss: 0.3712 - acc: 0.8401 - val_loss: 0.4163 - val_acc: 0.8130\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 1s 343us/sample - loss: 0.3581 - acc: 0.8432 - val_loss: 0.4436 - val_acc: 0.8217\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 2s 481us/sample - loss: 0.3624 - acc: 0.8372 - val_loss: 0.4069 - val_acc: 0.8196\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 3s 725us/sample - loss: 0.3612 - acc: 0.8355 - val_loss: 0.4898 - val_acc: 0.8022\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.3423 - acc: 0.8548 - val_loss: 0.5457 - val_acc: 0.8109\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.3635 - acc: 0.8435 - val_loss: 0.4813 - val_acc: 0.8130\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3649 - acc: 0.8457 - val_loss: 0.5485 - val_acc: 0.8043\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.5410 - acc: 0.7600\n",
      "logs/fit/dropout_lstm/kfold10\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 54s 13ms/sample - loss: 0.6921 - acc: 0.5734 - val_loss: 0.6897 - val_acc: 0.6087\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6836 - acc: 0.6034 - val_loss: 0.6531 - val_acc: 0.7130\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6450 - acc: 0.6850 - val_loss: 0.6147 - val_acc: 0.7391\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6254 - acc: 0.7162 - val_loss: 0.5391 - val_acc: 0.7457\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5842 - acc: 0.7362 - val_loss: 0.5248 - val_acc: 0.7587\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5602 - acc: 0.7437 - val_loss: 0.4773 - val_acc: 0.7674\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5216 - acc: 0.7556 - val_loss: 0.4494 - val_acc: 0.7630\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5071 - acc: 0.7418 - val_loss: 0.4360 - val_acc: 0.7652\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4882 - acc: 0.7623 - val_loss: 0.4247 - val_acc: 0.7652\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4819 - acc: 0.7640 - val_loss: 0.3992 - val_acc: 0.7935\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4639 - acc: 0.7773 - val_loss: 0.3964 - val_acc: 0.7978\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4766 - acc: 0.7739 - val_loss: 0.4134 - val_acc: 0.7848\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 1s 351us/sample - loss: 0.4680 - acc: 0.7737 - val_loss: 0.4014 - val_acc: 0.7870\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.4565 - acc: 0.7901 - val_loss: 0.4181 - val_acc: 0.7870\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 1s 304us/sample - loss: 0.4496 - acc: 0.7804 - val_loss: 0.3995 - val_acc: 0.7935\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.4430 - acc: 0.7894 - val_loss: 0.4021 - val_acc: 0.8022\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.4371 - acc: 0.7935 - val_loss: 0.4035 - val_acc: 0.8043\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.4237 - acc: 0.8060 - val_loss: 0.4167 - val_acc: 0.8087\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 1s 300us/sample - loss: 0.4255 - acc: 0.8085 - val_loss: 0.4042 - val_acc: 0.8065\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 1s 304us/sample - loss: 0.4186 - acc: 0.8116 - val_loss: 0.4040 - val_acc: 0.8152\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 1s 305us/sample - loss: 0.4068 - acc: 0.8263 - val_loss: 0.3953 - val_acc: 0.8152\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 1s 301us/sample - loss: 0.3934 - acc: 0.8266 - val_loss: 0.4059 - val_acc: 0.8130\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.4001 - acc: 0.8220 - val_loss: 0.3954 - val_acc: 0.8304\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.3963 - acc: 0.8249 - val_loss: 0.3881 - val_acc: 0.8196\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.3914 - acc: 0.8295 - val_loss: 0.3994 - val_acc: 0.8239\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.3918 - acc: 0.8331 - val_loss: 0.3799 - val_acc: 0.8261\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.3781 - acc: 0.8266 - val_loss: 0.3870 - val_acc: 0.8348\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 1s 324us/sample - loss: 0.3637 - acc: 0.8357 - val_loss: 0.4184 - val_acc: 0.8348\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 1s 362us/sample - loss: 0.3762 - acc: 0.8406 - val_loss: 0.3952 - val_acc: 0.8348\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 2s 470us/sample - loss: 0.3559 - acc: 0.8435 - val_loss: 0.4084 - val_acc: 0.8196\n",
      "100/100 [==============================] - 0s 1ms/sample - loss: 0.3209 - acc: 0.8900\n"
     ]
    }
   ],
   "source": [
    "def create_drop_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(10, kernel_initializer='normal', activation='relu', input_shape=(28, 300), name='lstm'),\n",
    "        tf.keras.layers.Dropout(0.7),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='normal', name='dense')\n",
    "    ])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "drop_hist, drop_evas = kfold_train(create_drop_model, 'dropout_lstm', batch_size=128, epochs=30, shuffle=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "0473ec9f-93ee-41b7-b151-7aa6e651e29b",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6919408813766811,
          0.6848700804986816,
          0.6634534994761149,
          0.6286877508324702,
          0.6070433817623894,
          0.572498349291115,
          0.6632607742784103,
          0.680138635808143,
          0.6789648155083403,
          0.6773067057996557,
          0.6754053446405752,
          0.6748155013950551,
          0.6738972796910051,
          0.6721502564379559,
          0.6709986542158081,
          0.6700104473869581,
          0.6689791302174186,
          0.6682894755676748,
          0.6670763421173833,
          0.6651589405709418,
          0.6648735592330711,
          0.6633188065123443,
          0.6626048162363578,
          0.6620636899690121,
          0.6603974132146236,
          0.6590892084554774,
          0.6577657863137802,
          0.6578096159414393,
          0.6553936389333384,
          0.6526367755903714
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "3091a216-6416-4b54-923e-322296c25fcb",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6903384125750998,
          0.6807697290959566,
          0.6189072583032691,
          0.5961147634879402,
          0.5407883024733999,
          0.5254353826460632,
          0.676846268384353,
          0.6792169462079587,
          0.6776980348255324,
          0.6762685832769975,
          0.6750302998915962,
          0.6739615041276683,
          0.6730323584183403,
          0.6721905558005623,
          0.6714141550271407,
          0.6706774664961773,
          0.6699525299279586,
          0.6692768169486004,
          0.6686199380003888,
          0.6678947443547456,
          0.667155615143154,
          0.6663451853005783,
          0.6654675784318344,
          0.664521238596543,
          0.6633352746134219,
          0.6620813431947128,
          0.6608779616977858,
          0.6595482701840608,
          0.6581364372502203,
          0.6565858079039533
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "cb4bd21a-ad2d-4f22-ae7a-52c764d70ab7",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6921794198561406,
          0.6901813160970015,
          0.68812649221236,
          0.6832854619348683,
          0.6557013308368443,
          0.6117402691772018,
          0.5588838578422288,
          0.5544007292692212,
          0.5320271664771481,
          0.5036110389923704,
          0.5016448732735455,
          0.5037070316105073,
          0.49107622322828876,
          0.4864275662795357,
          0.47629300678409814,
          0.4764809985091721,
          0.47558104703967696,
          0.4485239969935394,
          0.4672409251404269,
          0.4501300760801288,
          0.44883531058468107,
          0.4425865411758423,
          0.43718137415710856,
          0.4274190202427371,
          0.431884671582116,
          0.4041241600893546,
          0.4029115433854181,
          0.4058500299131237,
          0.3974323711245532,
          0.3796666518789559
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "c756c3e1-b878-4491-8952-7e6ad13e3b69",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.691296953222026,
          0.689585616795913,
          0.6874525961668595,
          0.6817348843035491,
          0.6145949617676113,
          0.5228053999983746,
          0.469546683974888,
          0.4789046909498132,
          0.435959492818169,
          0.4317699282065682,
          0.43710048043209576,
          0.4284627844458041,
          0.40935223672700966,
          0.42197848480680716,
          0.38842171378757645,
          0.3869065261405447,
          0.3894736769406692,
          0.3849912301353786,
          0.4091173716213392,
          0.4105668298576189,
          0.4032406892465509,
          0.39411435619644497,
          0.43209618381831955,
          0.38659658535667085,
          0.3706940724797871,
          0.4086312586846559,
          0.4045673122872477,
          0.41816369243290114,
          0.4823374825975169,
          0.4509139890256135
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "00e89d88-f6b8-4754-b0c3-fbe621d5556b",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6921939021723282,
          0.688365882606322,
          0.6690337221979519,
          0.6207002518833548,
          0.5674420562919211,
          0.5370837863516692,
          0.5205667793462818,
          0.5003515874993973,
          0.48845173981454637,
          0.46799133463182313,
          0.4650100340589809,
          0.4635563486152225,
          0.4600884589884016,
          0.4466856712880342,
          0.4324880314334003,
          0.43380271253954383,
          0.4189880038805054,
          0.4252092595837542,
          0.417515500386556,
          0.41802669383477475,
          0.41482275888539744,
          0.4112988413531999,
          0.41700202569293515,
          0.4056459841232945,
          0.405699742761787,
          0.4098172550328112,
          0.4007404069105784,
          0.40113532393450896,
          0.41671980723090796,
          0.3818786572143076
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "4a57a458-54e8-44bf-bad8-2f2b512049aa",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6900103662324988,
          0.6757918974627619,
          0.6202521795811861,
          0.534280718927798,
          0.4889635340027187,
          0.4551567629627559,
          0.4636527382809183,
          0.43792895571045254,
          0.41307326840317765,
          0.40377899874811585,
          0.40234934998595195,
          0.4189547017864559,
          0.4155163054880889,
          0.40852693889452063,
          0.39772436022758484,
          0.39622555038203366,
          0.40333775411481443,
          0.4072302380333776,
          0.4085119833116946,
          0.4155345709427543,
          0.4126801182394442,
          0.4276713078436644,
          0.4500349674535834,
          0.4689295224521471,
          0.4494568469731704,
          0.4269306771133257,
          0.44337042103643004,
          0.411809671184291,
          0.4231569961361263,
          0.42807374518850577
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "5b58bde5-bab8-4503-a930-66d1048f184e",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6921000197889724,
          0.6889288997880503,
          0.6811708567223111,
          0.6843806016272392,
          0.6751575450966324,
          0.6541466200409304,
          0.6371254389988628,
          0.5949992291593321,
          0.5582482949547146,
          0.5293199744777403,
          0.5077544428300167,
          0.479794837973544,
          0.48036560848139337,
          0.46730688064570586,
          0.46054010258780587,
          0.44126114957574486,
          0.4304834487357577,
          0.4243724575077278,
          0.4016923590846684,
          0.41175564711796486,
          0.39648865818401463,
          0.48052855516977355,
          0.5247850155484849,
          0.4796634034258156,
          0.44744288371380975,
          0.426550082826384,
          0.42779331495220535,
          0.4187406262337873,
          0.4052318159220875,
          0.398727368991732
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "612e452a-d7b8-449a-9572-cc6e5cef711d",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6900136662566143,
          0.6822746313136557,
          0.6818177057349164,
          0.6779537206110747,
          0.6593815855357958,
          0.6039029162863027,
          0.5994843057964159,
          0.5282449675642926,
          0.4781864723433619,
          0.4481270836747211,
          0.4231387091719586,
          0.40757525148599044,
          0.40991357098455017,
          0.4459168301976245,
          0.4256551268308059,
          0.37742473249850067,
          0.37619516745857573,
          0.3934737252152484,
          0.38695353606472843,
          0.38608249788698945,
          0.4061713817326919,
          0.5166821168816608,
          0.4800611508929211,
          0.4270898894123409,
          0.41570702609808546,
          0.40600909538891006,
          0.3885546165963878,
          0.3925745691942132,
          0.3958885835564655,
          0.38298873331235805
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "336eead0-f915-4c05-8bd8-96fbfc416917",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6920645124094498,
          0.6897347404761015,
          0.680691595411531,
          0.6612682625867319,
          0.6314983005684931,
          0.600126528509573,
          0.5605272426697367,
          0.5516323788154528,
          0.518191415100282,
          0.4928736885676637,
          0.48378862862425726,
          0.4818648440538397,
          0.48223876947366096,
          0.4799012612893386,
          0.4770622089865127,
          0.4653130887211233,
          0.45166295507679816,
          0.4440694819325986,
          0.448123979712454,
          0.44363932540451273,
          0.43325464449067047,
          0.5990428613003901,
          0.6496375962731918,
          0.6198969653263184,
          0.5880809925028667,
          0.5457424307790931,
          0.5103922367671837,
          0.475816564945783,
          0.46324215816414877,
          0.44908688408165165
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "3aa2bd60-194c-4b8d-9454-535cbcdf8fbc",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6913180035093557,
          0.688514026351597,
          0.6617972467256629,
          0.6256255574848341,
          0.5937827442003333,
          0.5124897863553918,
          0.4784925191298775,
          0.44899660815363346,
          0.43476443990417146,
          0.41430027329403424,
          0.42381147120309914,
          0.4109865333722985,
          0.4030984875948533,
          0.4024784689364226,
          0.4045342067013616,
          0.40596853546474293,
          0.3927378719267638,
          0.4019771762516188,
          0.42376231110614276,
          0.39968156374019126,
          0.38613215736720874,
          0.7094820872597073,
          0.6314300236494644,
          0.6023924848307733,
          0.5593271680500196,
          0.4954493242761363,
          0.4401124565497689,
          0.40728745823321133,
          0.40653624560521995,
          0.4081240218618642
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "f667a29d-5371-4bbc-9065-b8ac23b3772a",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6920311323686499,
          0.6897305583608323,
          0.6666949723653747,
          0.650616579067304,
          0.6010318947299091,
          0.5663533297713828,
          0.5554101218347964,
          0.5310624019823212,
          0.538325031713587,
          0.525026295899193,
          0.506624692592068,
          0.501328953049609,
          0.5041036066225761,
          0.4979048383120753,
          0.4779944948240179,
          0.47003203267636506,
          0.4635547009931094,
          0.4764658430060327,
          0.4702465812077269,
          0.48488234079978315,
          0.47788129564068743,
          0.46665767031015404,
          0.45285415157027864,
          0.4517707580241604,
          0.42958310902982516,
          0.4356194275588805,
          0.4315708865578048,
          0.4320519144408369,
          0.42397565308976287,
          0.42950832731481914
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "9a7f9b3e-014b-4a6f-a49f-3b4d4225e80a",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.690933995143227,
          0.6826382528180661,
          0.6449728768804799,
          0.6154798761658047,
          0.5613220245941826,
          0.5547961820726809,
          0.5280325988064641,
          0.5223897275717362,
          0.5219468671342601,
          0.5110334142394688,
          0.5087059186852496,
          0.49623770143674767,
          0.4993357580641042,
          0.5050379027491031,
          0.5012286056642947,
          0.5044731109038644,
          0.5075212548608365,
          0.5024530364119488,
          0.4810706364071887,
          0.4617850407310154,
          0.500102165211802,
          0.48259431408799214,
          0.5041150010150411,
          0.49126165483308876,
          0.5271015369373819,
          0.4689091555450274,
          0.51658441502115,
          0.5180970756903939,
          0.49845886023148245,
          0.5939595808153567
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "0368ee6d-79fa-4642-9b84-62bdb325fb38",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6920883859413257,
          0.6892298350011669,
          1.0435496235815223,
          0.6487498389925934,
          0.6327074485700488,
          0.6225190111980347,
          0.6154580021825965,
          0.6105367115730249,
          0.6029515614256191,
          0.5901299764568679,
          0.5781662058139193,
          0.5768247403960297,
          0.5658455188147687,
          0.5725446559956684,
          0.5644764224112322,
          0.5622267961502075,
          0.5532067001153882,
          0.5489725738907781,
          0.5577997347582941,
          0.5496415646179863,
          0.5286028743366112,
          0.5297006692863316,
          0.5303729993133729,
          0.5216658156851064,
          0.5191553694614466,
          0.5022556360792999,
          0.4932576383945447,
          0.5026248717653579,
          0.4869606451999738,
          0.4936298843743145
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "cf52675e-9230-4458-b202-b2966a77fcb3",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6910778745360996,
          0.6770987775014794,
          0.6173985076987225,
          0.6412210537039715,
          0.6321979056233945,
          0.6270474273225536,
          0.619181678087815,
          0.6079900902250539,
          0.6033219446306644,
          0.5910588129707005,
          0.5886192648307137,
          0.5718042933422586,
          0.5721994519233704,
          0.5821200629939204,
          0.5527416208515996,
          0.5584219875543014,
          0.5591474807780722,
          0.608590711199719,
          0.5442468912705131,
          0.5514054495355357,
          0.5269043176070504,
          0.5319174522938935,
          0.5353570860365163,
          0.5320961050365283,
          0.5368076640626659,
          0.5124081572760706,
          0.48644212173378987,
          0.5035972061364548,
          0.4797300255816916,
          0.47660861792771714
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "39959ea7-f0fb-4710-894e-be50e5fa0be8",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6920156218003536,
          0.6832150600382672,
          0.6569383352850946,
          0.5952682405278302,
          0.5331592095646881,
          0.5084883957669355,
          0.48880007399453057,
          0.4857543228329092,
          0.4614078559161384,
          0.4559379270111305,
          0.4409324144395653,
          0.4540531179179316,
          0.4396376956200254,
          0.44104142442417604,
          0.42577949226766393,
          0.419072568502979,
          0.4162798864254053,
          0.41126617311279556,
          0.3865741977945042,
          0.3933188529406193,
          0.3995829089252269,
          0.3860843235167904,
          0.3687611841637155,
          0.3728299772393876,
          0.37506169083613705,
          0.3732125721979832,
          0.36920278754787167,
          0.34926906343243547,
          0.3508490018222643,
          0.34719578620892216
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "4a3fb87f-abb2-4f67-b091-664937d26d9c",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6908642939899279,
          0.6425678595252658,
          0.5854112272677214,
          0.5072715751502825,
          0.44884933077770733,
          0.4410853458487469,
          0.4360916161018869,
          0.42477862368459285,
          0.4150631456271462,
          0.4150997674983481,
          0.4062804823336394,
          0.39892581338467803,
          0.4103843862595766,
          0.3972443964170373,
          0.3942125545895618,
          0.3848381288673567,
          0.3906614881494771,
          0.383905335612919,
          0.3957929924778316,
          0.38720128199328546,
          0.3871971454309381,
          0.3979624159958052,
          0.3932605979235276,
          0.38099123084026837,
          0.39599734441093776,
          0.3844304779301519,
          0.39511411501013716,
          0.39443127694337266,
          0.40368139044098234,
          0.39699794986973636
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "c6908fe7-142b-4c1b-9a29-c2b1c2d3e0d1",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6920659411932535,
          0.6894333123008985,
          0.6640797801639723,
          0.6092459044594696,
          0.5690206899159197,
          0.5037931907004204,
          0.4855888582946022,
          0.4812316506093251,
          0.4762715023496877,
          0.4518383105883852,
          0.4538449721059937,
          0.45229373721108923,
          0.4484419017310304,
          0.42721364452067206,
          0.4137301163972864,
          0.41646224312160324,
          0.40742659257805863,
          0.3926126608526073,
          0.38763541890227277,
          0.39434658648887116,
          0.3766142738902051,
          0.37585776220773154,
          0.37572287079216776,
          0.37117559031587866,
          0.358061002533217,
          0.3624485991427288,
          0.3612200099776908,
          0.3423158235308053,
          0.36348304279184573,
          0.36488182616694537
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "aaee009e-a01e-4de5-bced-4db48a607ea1",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6914683585581572,
          0.6893357515335083,
          0.6163892968841221,
          0.49267299408498016,
          0.4971761283667191,
          0.44917864358943443,
          0.4474765886431155,
          0.42066830370737157,
          0.4543131473271743,
          0.4154355422310207,
          0.44308588116065317,
          0.44825437613155533,
          0.46403864233390146,
          0.44392458666925844,
          0.425703510771627,
          0.41171094723369767,
          0.42848695697991745,
          0.42883355176967125,
          0.4802859866100809,
          0.4225038839423138,
          0.3796325673227725,
          0.421951269844304,
          0.41738524462865745,
          0.4163476428259974,
          0.44364510048990663,
          0.4068598228952159,
          0.48983220691266266,
          0.5456774842479954,
          0.48125304501989613,
          0.5485038404879363
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "363df24d-57ae-4818-974f-d3526c744170",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6920887950537862,
          0.6836311486032274,
          0.6449653346181492,
          0.6254378325697304,
          0.5842334004415982,
          0.5602037970282605,
          0.5215761883247302,
          0.5071279186557457,
          0.488209364005333,
          0.4818741619586945,
          0.4638677471501816,
          0.4766056436271483,
          0.4680048165401975,
          0.45650430065422243,
          0.4496034773651528,
          0.442966532016146,
          0.4371157769707666,
          0.4237428747225499,
          0.42545390990045334,
          0.41857870820063897,
          0.40676577376282735,
          0.3934051809967428,
          0.40012079771014225,
          0.3963179091324553,
          0.3914482105181413,
          0.3917740135953046,
          0.37811286518539206,
          0.363712727850762,
          0.37624360092596154,
          0.3558513495369234
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "ac6c8c5d-400a-4e79-adf9-cc0d8c55ddc3",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6896753570307856,
          0.6531119227409363,
          0.6147355458010798,
          0.5391182951305223,
          0.5247666395228842,
          0.47728789008182027,
          0.4494393480860669,
          0.4359631185946257,
          0.42474469853484115,
          0.39916998847671176,
          0.39644509398418926,
          0.4134456701900648,
          0.40137376163316807,
          0.41808296649352367,
          0.39945172745248547,
          0.4021242144315139,
          0.40348836883254674,
          0.41671623898589094,
          0.4041850706805354,
          0.4040178490721661,
          0.395264667790869,
          0.40589072263759113,
          0.3954102881576704,
          0.3881196986074033,
          0.3994042930395707,
          0.37990233846332716,
          0.3870326682277348,
          0.4184415135694587,
          0.3951694931672967,
          0.40835472526757616
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"4f7907be-9335-4291-a6c6-dab9fde215fb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"4f7907be-9335-4291-a6c6-dab9fde215fb\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '4f7907be-9335-4291-a6c6-dab9fde215fb',\n",
       "                        [{\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"0473ec9f-93ee-41b7-b151-7aa6e651e29b\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6919408813766811, 0.6848700804986816, 0.6634534994761149, 0.6286877508324702, 0.6070433817623894, 0.572498349291115, 0.6632607742784103, 0.680138635808143, 0.6789648155083403, 0.6773067057996557, 0.6754053446405752, 0.6748155013950551, 0.6738972796910051, 0.6721502564379559, 0.6709986542158081, 0.6700104473869581, 0.6689791302174186, 0.6682894755676748, 0.6670763421173833, 0.6651589405709418, 0.6648735592330711, 0.6633188065123443, 0.6626048162363578, 0.6620636899690121, 0.6603974132146236, 0.6590892084554774, 0.6577657863137802, 0.6578096159414393, 0.6553936389333384, 0.6526367755903714]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"3091a216-6416-4b54-923e-322296c25fcb\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6903384125750998, 0.6807697290959566, 0.6189072583032691, 0.5961147634879402, 0.5407883024733999, 0.5254353826460632, 0.676846268384353, 0.6792169462079587, 0.6776980348255324, 0.6762685832769975, 0.6750302998915962, 0.6739615041276683, 0.6730323584183403, 0.6721905558005623, 0.6714141550271407, 0.6706774664961773, 0.6699525299279586, 0.6692768169486004, 0.6686199380003888, 0.6678947443547456, 0.667155615143154, 0.6663451853005783, 0.6654675784318344, 0.664521238596543, 0.6633352746134219, 0.6620813431947128, 0.6608779616977858, 0.6595482701840608, 0.6581364372502203, 0.6565858079039533]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"cb4bd21a-ad2d-4f22-ae7a-52c764d70ab7\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6921794198561406, 0.6901813160970015, 0.68812649221236, 0.6832854619348683, 0.6557013308368443, 0.6117402691772018, 0.5588838578422288, 0.5544007292692212, 0.5320271664771481, 0.5036110389923704, 0.5016448732735455, 0.5037070316105073, 0.49107622322828876, 0.4864275662795357, 0.47629300678409814, 0.4764809985091721, 0.47558104703967696, 0.4485239969935394, 0.4672409251404269, 0.4501300760801288, 0.44883531058468107, 0.4425865411758423, 0.43718137415710856, 0.4274190202427371, 0.431884671582116, 0.4041241600893546, 0.4029115433854181, 0.4058500299131237, 0.3974323711245532, 0.3796666518789559]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"c756c3e1-b878-4491-8952-7e6ad13e3b69\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.691296953222026, 0.689585616795913, 0.6874525961668595, 0.6817348843035491, 0.6145949617676113, 0.5228053999983746, 0.469546683974888, 0.4789046909498132, 0.435959492818169, 0.4317699282065682, 0.43710048043209576, 0.4284627844458041, 0.40935223672700966, 0.42197848480680716, 0.38842171378757645, 0.3869065261405447, 0.3894736769406692, 0.3849912301353786, 0.4091173716213392, 0.4105668298576189, 0.4032406892465509, 0.39411435619644497, 0.43209618381831955, 0.38659658535667085, 0.3706940724797871, 0.4086312586846559, 0.4045673122872477, 0.41816369243290114, 0.4823374825975169, 0.4509139890256135]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"00e89d88-f6b8-4754-b0c3-fbe621d5556b\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6921939021723282, 0.688365882606322, 0.6690337221979519, 0.6207002518833548, 0.5674420562919211, 0.5370837863516692, 0.5205667793462818, 0.5003515874993973, 0.48845173981454637, 0.46799133463182313, 0.4650100340589809, 0.4635563486152225, 0.4600884589884016, 0.4466856712880342, 0.4324880314334003, 0.43380271253954383, 0.4189880038805054, 0.4252092595837542, 0.417515500386556, 0.41802669383477475, 0.41482275888539744, 0.4112988413531999, 0.41700202569293515, 0.4056459841232945, 0.405699742761787, 0.4098172550328112, 0.4007404069105784, 0.40113532393450896, 0.41671980723090796, 0.3818786572143076]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"4a57a458-54e8-44bf-bad8-2f2b512049aa\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6900103662324988, 0.6757918974627619, 0.6202521795811861, 0.534280718927798, 0.4889635340027187, 0.4551567629627559, 0.4636527382809183, 0.43792895571045254, 0.41307326840317765, 0.40377899874811585, 0.40234934998595195, 0.4189547017864559, 0.4155163054880889, 0.40852693889452063, 0.39772436022758484, 0.39622555038203366, 0.40333775411481443, 0.4072302380333776, 0.4085119833116946, 0.4155345709427543, 0.4126801182394442, 0.4276713078436644, 0.4500349674535834, 0.4689295224521471, 0.4494568469731704, 0.4269306771133257, 0.44337042103643004, 0.411809671184291, 0.4231569961361263, 0.42807374518850577]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"5b58bde5-bab8-4503-a930-66d1048f184e\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6921000197889724, 0.6889288997880503, 0.6811708567223111, 0.6843806016272392, 0.6751575450966324, 0.6541466200409304, 0.6371254389988628, 0.5949992291593321, 0.5582482949547146, 0.5293199744777403, 0.5077544428300167, 0.479794837973544, 0.48036560848139337, 0.46730688064570586, 0.46054010258780587, 0.44126114957574486, 0.4304834487357577, 0.4243724575077278, 0.4016923590846684, 0.41175564711796486, 0.39648865818401463, 0.48052855516977355, 0.5247850155484849, 0.4796634034258156, 0.44744288371380975, 0.426550082826384, 0.42779331495220535, 0.4187406262337873, 0.4052318159220875, 0.398727368991732]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"612e452a-d7b8-449a-9572-cc6e5cef711d\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6900136662566143, 0.6822746313136557, 0.6818177057349164, 0.6779537206110747, 0.6593815855357958, 0.6039029162863027, 0.5994843057964159, 0.5282449675642926, 0.4781864723433619, 0.4481270836747211, 0.4231387091719586, 0.40757525148599044, 0.40991357098455017, 0.4459168301976245, 0.4256551268308059, 0.37742473249850067, 0.37619516745857573, 0.3934737252152484, 0.38695353606472843, 0.38608249788698945, 0.4061713817326919, 0.5166821168816608, 0.4800611508929211, 0.4270898894123409, 0.41570702609808546, 0.40600909538891006, 0.3885546165963878, 0.3925745691942132, 0.3958885835564655, 0.38298873331235805]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"336eead0-f915-4c05-8bd8-96fbfc416917\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6920645124094498, 0.6897347404761015, 0.680691595411531, 0.6612682625867319, 0.6314983005684931, 0.600126528509573, 0.5605272426697367, 0.5516323788154528, 0.518191415100282, 0.4928736885676637, 0.48378862862425726, 0.4818648440538397, 0.48223876947366096, 0.4799012612893386, 0.4770622089865127, 0.4653130887211233, 0.45166295507679816, 0.4440694819325986, 0.448123979712454, 0.44363932540451273, 0.43325464449067047, 0.5990428613003901, 0.6496375962731918, 0.6198969653263184, 0.5880809925028667, 0.5457424307790931, 0.5103922367671837, 0.475816564945783, 0.46324215816414877, 0.44908688408165165]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"3aa2bd60-194c-4b8d-9454-535cbcdf8fbc\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6913180035093557, 0.688514026351597, 0.6617972467256629, 0.6256255574848341, 0.5937827442003333, 0.5124897863553918, 0.4784925191298775, 0.44899660815363346, 0.43476443990417146, 0.41430027329403424, 0.42381147120309914, 0.4109865333722985, 0.4030984875948533, 0.4024784689364226, 0.4045342067013616, 0.40596853546474293, 0.3927378719267638, 0.4019771762516188, 0.42376231110614276, 0.39968156374019126, 0.38613215736720874, 0.7094820872597073, 0.6314300236494644, 0.6023924848307733, 0.5593271680500196, 0.4954493242761363, 0.4401124565497689, 0.40728745823321133, 0.40653624560521995, 0.4081240218618642]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"f667a29d-5371-4bbc-9065-b8ac23b3772a\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6920311323686499, 0.6897305583608323, 0.6666949723653747, 0.650616579067304, 0.6010318947299091, 0.5663533297713828, 0.5554101218347964, 0.5310624019823212, 0.538325031713587, 0.525026295899193, 0.506624692592068, 0.501328953049609, 0.5041036066225761, 0.4979048383120753, 0.4779944948240179, 0.47003203267636506, 0.4635547009931094, 0.4764658430060327, 0.4702465812077269, 0.48488234079978315, 0.47788129564068743, 0.46665767031015404, 0.45285415157027864, 0.4517707580241604, 0.42958310902982516, 0.4356194275588805, 0.4315708865578048, 0.4320519144408369, 0.42397565308976287, 0.42950832731481914]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"9a7f9b3e-014b-4a6f-a49f-3b4d4225e80a\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.690933995143227, 0.6826382528180661, 0.6449728768804799, 0.6154798761658047, 0.5613220245941826, 0.5547961820726809, 0.5280325988064641, 0.5223897275717362, 0.5219468671342601, 0.5110334142394688, 0.5087059186852496, 0.49623770143674767, 0.4993357580641042, 0.5050379027491031, 0.5012286056642947, 0.5044731109038644, 0.5075212548608365, 0.5024530364119488, 0.4810706364071887, 0.4617850407310154, 0.500102165211802, 0.48259431408799214, 0.5041150010150411, 0.49126165483308876, 0.5271015369373819, 0.4689091555450274, 0.51658441502115, 0.5180970756903939, 0.49845886023148245, 0.5939595808153567]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"0368ee6d-79fa-4642-9b84-62bdb325fb38\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6920883859413257, 0.6892298350011669, 1.0435496235815223, 0.6487498389925934, 0.6327074485700488, 0.6225190111980347, 0.6154580021825965, 0.6105367115730249, 0.6029515614256191, 0.5901299764568679, 0.5781662058139193, 0.5768247403960297, 0.5658455188147687, 0.5725446559956684, 0.5644764224112322, 0.5622267961502075, 0.5532067001153882, 0.5489725738907781, 0.5577997347582941, 0.5496415646179863, 0.5286028743366112, 0.5297006692863316, 0.5303729993133729, 0.5216658156851064, 0.5191553694614466, 0.5022556360792999, 0.4932576383945447, 0.5026248717653579, 0.4869606451999738, 0.4936298843743145]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"cf52675e-9230-4458-b202-b2966a77fcb3\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6910778745360996, 0.6770987775014794, 0.6173985076987225, 0.6412210537039715, 0.6321979056233945, 0.6270474273225536, 0.619181678087815, 0.6079900902250539, 0.6033219446306644, 0.5910588129707005, 0.5886192648307137, 0.5718042933422586, 0.5721994519233704, 0.5821200629939204, 0.5527416208515996, 0.5584219875543014, 0.5591474807780722, 0.608590711199719, 0.5442468912705131, 0.5514054495355357, 0.5269043176070504, 0.5319174522938935, 0.5353570860365163, 0.5320961050365283, 0.5368076640626659, 0.5124081572760706, 0.48644212173378987, 0.5035972061364548, 0.4797300255816916, 0.47660861792771714]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"39959ea7-f0fb-4710-894e-be50e5fa0be8\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6920156218003536, 0.6832150600382672, 0.6569383352850946, 0.5952682405278302, 0.5331592095646881, 0.5084883957669355, 0.48880007399453057, 0.4857543228329092, 0.4614078559161384, 0.4559379270111305, 0.4409324144395653, 0.4540531179179316, 0.4396376956200254, 0.44104142442417604, 0.42577949226766393, 0.419072568502979, 0.4162798864254053, 0.41126617311279556, 0.3865741977945042, 0.3933188529406193, 0.3995829089252269, 0.3860843235167904, 0.3687611841637155, 0.3728299772393876, 0.37506169083613705, 0.3732125721979832, 0.36920278754787167, 0.34926906343243547, 0.3508490018222643, 0.34719578620892216]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"4a3fb87f-abb2-4f67-b091-664937d26d9c\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6908642939899279, 0.6425678595252658, 0.5854112272677214, 0.5072715751502825, 0.44884933077770733, 0.4410853458487469, 0.4360916161018869, 0.42477862368459285, 0.4150631456271462, 0.4150997674983481, 0.4062804823336394, 0.39892581338467803, 0.4103843862595766, 0.3972443964170373, 0.3942125545895618, 0.3848381288673567, 0.3906614881494771, 0.383905335612919, 0.3957929924778316, 0.38720128199328546, 0.3871971454309381, 0.3979624159958052, 0.3932605979235276, 0.38099123084026837, 0.39599734441093776, 0.3844304779301519, 0.39511411501013716, 0.39443127694337266, 0.40368139044098234, 0.39699794986973636]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"c6908fe7-142b-4c1b-9a29-c2b1c2d3e0d1\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6920659411932535, 0.6894333123008985, 0.6640797801639723, 0.6092459044594696, 0.5690206899159197, 0.5037931907004204, 0.4855888582946022, 0.4812316506093251, 0.4762715023496877, 0.4518383105883852, 0.4538449721059937, 0.45229373721108923, 0.4484419017310304, 0.42721364452067206, 0.4137301163972864, 0.41646224312160324, 0.40742659257805863, 0.3926126608526073, 0.38763541890227277, 0.39434658648887116, 0.3766142738902051, 0.37585776220773154, 0.37572287079216776, 0.37117559031587866, 0.358061002533217, 0.3624485991427288, 0.3612200099776908, 0.3423158235308053, 0.36348304279184573, 0.36488182616694537]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"aaee009e-a01e-4de5-bced-4db48a607ea1\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6914683585581572, 0.6893357515335083, 0.6163892968841221, 0.49267299408498016, 0.4971761283667191, 0.44917864358943443, 0.4474765886431155, 0.42066830370737157, 0.4543131473271743, 0.4154355422310207, 0.44308588116065317, 0.44825437613155533, 0.46403864233390146, 0.44392458666925844, 0.425703510771627, 0.41171094723369767, 0.42848695697991745, 0.42883355176967125, 0.4802859866100809, 0.4225038839423138, 0.3796325673227725, 0.421951269844304, 0.41738524462865745, 0.4163476428259974, 0.44364510048990663, 0.4068598228952159, 0.48983220691266266, 0.5456774842479954, 0.48125304501989613, 0.5485038404879363]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"363df24d-57ae-4818-974f-d3526c744170\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6920887950537862, 0.6836311486032274, 0.6449653346181492, 0.6254378325697304, 0.5842334004415982, 0.5602037970282605, 0.5215761883247302, 0.5071279186557457, 0.488209364005333, 0.4818741619586945, 0.4638677471501816, 0.4766056436271483, 0.4680048165401975, 0.45650430065422243, 0.4496034773651528, 0.442966532016146, 0.4371157769707666, 0.4237428747225499, 0.42545390990045334, 0.41857870820063897, 0.40676577376282735, 0.3934051809967428, 0.40012079771014225, 0.3963179091324553, 0.3914482105181413, 0.3917740135953046, 0.37811286518539206, 0.363712727850762, 0.37624360092596154, 0.3558513495369234]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"ac6c8c5d-400a-4e79-adf9-cc0d8c55ddc3\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6896753570307856, 0.6531119227409363, 0.6147355458010798, 0.5391182951305223, 0.5247666395228842, 0.47728789008182027, 0.4494393480860669, 0.4359631185946257, 0.42474469853484115, 0.39916998847671176, 0.39644509398418926, 0.4134456701900648, 0.40137376163316807, 0.41808296649352367, 0.39945172745248547, 0.4021242144315139, 0.40348836883254674, 0.41671623898589094, 0.4041850706805354, 0.4040178490721661, 0.395264667790869, 0.40589072263759113, 0.3954102881576704, 0.3881196986074033, 0.3994042930395707, 0.37990233846332716, 0.3870326682277348, 0.4184415135694587, 0.3951694931672967, 0.40835472526757616]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4f7907be-9335-4291-a6c6-dab9fde215fb');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean  acc         0.731907\n",
      "loss        0.514644\n",
      "val_acc     0.756217\n",
      "val_loss    0.498160\n",
      "dtype: float64\n",
      "std  acc         0.083188\n",
      "loss        0.108404\n",
      "val_acc     0.091526\n",
      "val_loss    0.103988\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "1",
         "text": "",
         "type": "scatter",
         "uid": "29c24f85-b21a-41ec-8280-b49daada400a",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.5099999904632568,
          0.8600000143051147,
          0.8600000143051147,
          0.8299999833106995,
          0.8100000023841858,
          0.8100000023841858,
          0.8299999833106995,
          0.8500000238418579,
          0.7599999904632568,
          0.8899999856948853
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"3e0fb3ae-e45b-40b6-9191-d760ba355824\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"3e0fb3ae-e45b-40b6-9191-d760ba355824\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '3e0fb3ae-e45b-40b6-9191-d760ba355824',\n",
       "                        [{\"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"1\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"29c24f85-b21a-41ec-8280-b49daada400a\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.5099999904632568, 0.8600000143051147, 0.8600000143051147, 0.8299999833106995, 0.8100000023841858, 0.8100000023841858, 0.8299999833106995, 0.8500000238418579, 0.7599999904632568, 0.8899999856948853]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3e0fb3ae-e45b-40b6-9191-d760ba355824');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media  0.8009999990463257\n",
      "std  0.10826408435368169\n"
     ]
    }
   ],
   "source": [
    "process_results(drop_hist, drop_evas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un valor tan alto de dropout (0.7) provoca peores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.080753Z",
     "start_time": "2019-06-14T06:36:08.309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/dropout2_lstm/kfold1\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 55s 13ms/sample - loss: 0.6921 - acc: 0.5727 - val_loss: 0.6906 - val_acc: 0.5739\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6845 - acc: 0.6329 - val_loss: 0.6676 - val_acc: 0.6957\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6607 - acc: 0.6778 - val_loss: 0.6157 - val_acc: 0.7196\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6282 - acc: 0.7012 - val_loss: 0.5673 - val_acc: 0.7413\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6007 - acc: 0.7343 - val_loss: 0.5576 - val_acc: 0.7370\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5136 - acc: 0.7512 - val_loss: 0.4621 - val_acc: 0.7717\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4643 - acc: 0.7729 - val_loss: 0.4402 - val_acc: 0.7717\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4311 - acc: 0.7783 - val_loss: 0.4307 - val_acc: 0.7891\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4050 - acc: 0.7891 - val_loss: 0.4216 - val_acc: 0.7978\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3911 - acc: 0.8010 - val_loss: 0.4168 - val_acc: 0.8000\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3834 - acc: 0.8130 - val_loss: 0.4119 - val_acc: 0.8130\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3741 - acc: 0.8203 - val_loss: 0.4109 - val_acc: 0.8043\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3681 - acc: 0.8205 - val_loss: 0.4103 - val_acc: 0.8065\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3527 - acc: 0.8283 - val_loss: 0.4208 - val_acc: 0.8065\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3617 - acc: 0.8249 - val_loss: 0.4250 - val_acc: 0.8065\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3459 - acc: 0.8324 - val_loss: 0.4556 - val_acc: 0.8087\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3539 - acc: 0.8316 - val_loss: 0.4792 - val_acc: 0.8043\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3415 - acc: 0.8355 - val_loss: 0.4391 - val_acc: 0.8196\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3229 - acc: 0.8435 - val_loss: 0.4234 - val_acc: 0.8000\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3246 - acc: 0.8459 - val_loss: 0.4320 - val_acc: 0.8130\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3130 - acc: 0.8481 - val_loss: 0.4356 - val_acc: 0.8022\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3038 - acc: 0.8519 - val_loss: 0.4449 - val_acc: 0.8109\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3039 - acc: 0.8498 - val_loss: 0.4700 - val_acc: 0.8087\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 4s 985us/sample - loss: 0.2944 - acc: 0.8553 - val_loss: 0.4531 - val_acc: 0.8130\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.2965 - acc: 0.8510 - val_loss: 0.4502 - val_acc: 0.8065\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.2944 - acc: 0.8524 - val_loss: 0.4301 - val_acc: 0.8174\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.3001 - acc: 0.8505 - val_loss: 0.4465 - val_acc: 0.8239\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 1s 315us/sample - loss: 0.3203 - acc: 0.8510 - val_loss: 0.5744 - val_acc: 0.7935\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 1s 313us/sample - loss: 0.3250 - acc: 0.8461 - val_loss: 0.5056 - val_acc: 0.8196\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.2914 - acc: 0.8601 - val_loss: 0.6066 - val_acc: 0.8130\n",
      "100/100 [==============================] - 0s 782us/sample - loss: 0.5719 - acc: 0.8300\n",
      "logs/fit/dropout2_lstm/kfold2\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 17s 4ms/sample - loss: 0.6921 - acc: 0.5746 - val_loss: 0.6912 - val_acc: 0.5696\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 6s 1ms/sample - loss: 0.6899 - acc: 0.5800 - val_loss: 0.6889 - val_acc: 0.5696\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6674 - acc: 0.5797 - val_loss: 0.6541 - val_acc: 0.5696\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6396 - acc: 0.5792 - val_loss: 0.6246 - val_acc: 0.5696\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6050 - acc: 0.5792 - val_loss: 0.5786 - val_acc: 0.5696\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5763 - acc: 0.5848 - val_loss: 0.5634 - val_acc: 0.5891\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5201 - acc: 0.6473 - val_loss: 0.4811 - val_acc: 0.7348\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4825 - acc: 0.7022 - val_loss: 0.4520 - val_acc: 0.7630\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4962 - acc: 0.7623 - val_loss: 0.4828 - val_acc: 0.7739\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5806 - acc: 0.7072 - val_loss: 0.5825 - val_acc: 0.6935\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5802 - acc: 0.6882 - val_loss: 0.5309 - val_acc: 0.7391\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5302 - acc: 0.7135 - val_loss: 0.4891 - val_acc: 0.7587\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5153 - acc: 0.7104 - val_loss: 0.4831 - val_acc: 0.7587\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4912 - acc: 0.7217 - val_loss: 0.4602 - val_acc: 0.7587\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4680 - acc: 0.7237 - val_loss: 0.4484 - val_acc: 0.7565\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4616 - acc: 0.7234 - val_loss: 0.4434 - val_acc: 0.7609\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4631 - acc: 0.7143 - val_loss: 0.4383 - val_acc: 0.7630\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4485 - acc: 0.7283 - val_loss: 0.4343 - val_acc: 0.7674\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4428 - acc: 0.7302 - val_loss: 0.4330 - val_acc: 0.7696\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4424 - acc: 0.7302 - val_loss: 0.4320 - val_acc: 0.7696\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4724 - acc: 0.7345 - val_loss: 0.4656 - val_acc: 0.7478\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4725 - acc: 0.7263 - val_loss: 0.4474 - val_acc: 0.7630\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4469 - acc: 0.7384 - val_loss: 0.4390 - val_acc: 0.7739\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4395 - acc: 0.7476 - val_loss: 0.4326 - val_acc: 0.7739\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4359 - acc: 0.7481 - val_loss: 0.4283 - val_acc: 0.7761\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4325 - acc: 0.7553 - val_loss: 0.4246 - val_acc: 0.7783\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4220 - acc: 0.7655 - val_loss: 0.4229 - val_acc: 0.7804\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4173 - acc: 0.7720 - val_loss: 0.4204 - val_acc: 0.7804\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4177 - acc: 0.7826 - val_loss: 0.4174 - val_acc: 0.7870\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4108 - acc: 0.7867 - val_loss: 0.4154 - val_acc: 0.7957\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 0.3634 - acc: 0.8100\n",
      "logs/fit/dropout2_lstm/kfold3\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 10s 2ms/sample - loss: 0.6920 - acc: 0.5754 - val_loss: 0.6892 - val_acc: 0.6087\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.6788 - acc: 0.5756 - val_loss: 0.6466 - val_acc: 0.6087\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 336us/sample - loss: 0.6328 - acc: 0.5754 - val_loss: 0.5975 - val_acc: 0.6087\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 337us/sample - loss: 0.6136 - acc: 0.5754 - val_loss: 0.5744 - val_acc: 0.6087\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 2s 447us/sample - loss: 0.5673 - acc: 0.5749 - val_loss: 0.5212 - val_acc: 0.6087\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 3s 623us/sample - loss: 0.5605 - acc: 0.5775 - val_loss: 0.4961 - val_acc: 0.6087\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.5179 - acc: 0.6063 - val_loss: 0.4886 - val_acc: 0.6435\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.4961 - acc: 0.7430 - val_loss: 0.4599 - val_acc: 0.7674\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 6s 2ms/sample - loss: 0.4859 - acc: 0.8082 - val_loss: 0.4603 - val_acc: 0.8239\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4814 - acc: 0.8254 - val_loss: 0.4614 - val_acc: 0.8326\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4693 - acc: 0.8246 - val_loss: 0.4472 - val_acc: 0.8326\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4550 - acc: 0.8338 - val_loss: 0.4277 - val_acc: 0.8391\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4468 - acc: 0.8300 - val_loss: 0.4403 - val_acc: 0.8348\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4407 - acc: 0.8336 - val_loss: 0.4553 - val_acc: 0.8413\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4314 - acc: 0.8384 - val_loss: 0.4244 - val_acc: 0.8391\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4222 - acc: 0.8420 - val_loss: 0.4135 - val_acc: 0.8304\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4137 - acc: 0.8425 - val_loss: 0.4108 - val_acc: 0.8348\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4070 - acc: 0.8440 - val_loss: 0.4106 - val_acc: 0.8283\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4070 - acc: 0.8440 - val_loss: 0.4087 - val_acc: 0.8391\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4115 - acc: 0.8435 - val_loss: 0.4078 - val_acc: 0.8261\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.5021 - acc: 0.7391 - val_loss: 0.4331 - val_acc: 0.8326\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4198 - acc: 0.8263 - val_loss: 0.4110 - val_acc: 0.8413\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4045 - acc: 0.8374 - val_loss: 0.4114 - val_acc: 0.8500\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3920 - acc: 0.8391 - val_loss: 0.4162 - val_acc: 0.8457\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3924 - acc: 0.8430 - val_loss: 0.4147 - val_acc: 0.8478\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3870 - acc: 0.8418 - val_loss: 0.4081 - val_acc: 0.8457\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3748 - acc: 0.8454 - val_loss: 0.4023 - val_acc: 0.8370\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3602 - acc: 0.8505 - val_loss: 0.4059 - val_acc: 0.8391\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3510 - acc: 0.8514 - val_loss: 0.4181 - val_acc: 0.8391\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3476 - acc: 0.8529 - val_loss: 0.4183 - val_acc: 0.8413\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.5467 - acc: 0.8200\n",
      "logs/fit/dropout2_lstm/kfold4\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6921 - acc: 0.5758 - val_loss: 0.6899 - val_acc: 0.5978\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 292us/sample - loss: 0.6976 - acc: 0.5768 - val_loss: 0.6871 - val_acc: 0.5978\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.6879 - acc: 0.5768 - val_loss: 0.6853 - val_acc: 0.5978\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 325us/sample - loss: 0.6920 - acc: 0.5814 - val_loss: 0.6817 - val_acc: 0.6043\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 336us/sample - loss: 0.6852 - acc: 0.5768 - val_loss: 0.6820 - val_acc: 0.5978\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 2s 379us/sample - loss: 0.6845 - acc: 0.5768 - val_loss: 0.6807 - val_acc: 0.5978\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 2s 480us/sample - loss: 0.6838 - acc: 0.5768 - val_loss: 0.6796 - val_acc: 0.5978\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 3s 689us/sample - loss: 0.6830 - acc: 0.5768 - val_loss: 0.6786 - val_acc: 0.5978\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.6825 - acc: 0.5768 - val_loss: 0.6777 - val_acc: 0.5978\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.6818 - acc: 0.5768 - val_loss: 0.6769 - val_acc: 0.5978\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 7s 2ms/sample - loss: 0.6817 - acc: 0.5768 - val_loss: 0.6763 - val_acc: 0.5978\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6813 - acc: 0.5768 - val_loss: 0.6757 - val_acc: 0.5978\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6809 - acc: 0.5768 - val_loss: 0.6751 - val_acc: 0.5978\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6807 - acc: 0.5768 - val_loss: 0.6744 - val_acc: 0.5978\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6799 - acc: 0.5768 - val_loss: 0.6733 - val_acc: 0.5978\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6788 - acc: 0.5768 - val_loss: 0.6710 - val_acc: 0.5978\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6740 - acc: 0.5768 - val_loss: 0.6584 - val_acc: 0.5978\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6433 - acc: 0.5809 - val_loss: 0.6468 - val_acc: 0.7217\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6371 - acc: 0.6688 - val_loss: 0.5650 - val_acc: 0.7500\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5588 - acc: 0.7377 - val_loss: 0.4831 - val_acc: 0.7478\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4599 - acc: 0.7797 - val_loss: 0.4072 - val_acc: 0.8478\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4440 - acc: 0.8017 - val_loss: 0.3608 - val_acc: 0.8413\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4097 - acc: 0.8297 - val_loss: 0.3348 - val_acc: 0.8435\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3875 - acc: 0.8384 - val_loss: 0.3299 - val_acc: 0.8478\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3685 - acc: 0.8420 - val_loss: 0.3343 - val_acc: 0.8478\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3595 - acc: 0.8430 - val_loss: 0.3302 - val_acc: 0.8500\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3509 - acc: 0.8517 - val_loss: 0.3289 - val_acc: 0.8500\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3426 - acc: 0.8527 - val_loss: 0.3339 - val_acc: 0.8500\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3330 - acc: 0.8558 - val_loss: 0.3306 - val_acc: 0.8478\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3206 - acc: 0.8628 - val_loss: 0.3339 - val_acc: 0.8457\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.3204 - acc: 0.8700\n",
      "logs/fit/dropout2_lstm/kfold5\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 18s 4ms/sample - loss: 0.6920 - acc: 0.5792 - val_loss: 0.6913 - val_acc: 0.5609\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 304us/sample - loss: 0.6868 - acc: 0.5966 - val_loss: 0.6437 - val_acc: 0.7130\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 298us/sample - loss: 0.6394 - acc: 0.7138 - val_loss: 0.5691 - val_acc: 0.7609\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.5661 - acc: 0.7686 - val_loss: 0.5268 - val_acc: 0.8065\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 300us/sample - loss: 0.4900 - acc: 0.7923 - val_loss: 0.4350 - val_acc: 0.8217\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 294us/sample - loss: 0.4546 - acc: 0.7932 - val_loss: 0.4340 - val_acc: 0.8152\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 300us/sample - loss: 0.4479 - acc: 0.8041 - val_loss: 0.4082 - val_acc: 0.8217\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 298us/sample - loss: 0.4195 - acc: 0.8150 - val_loss: 0.4051 - val_acc: 0.8239\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 299us/sample - loss: 0.4091 - acc: 0.8196 - val_loss: 0.4080 - val_acc: 0.8196\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 298us/sample - loss: 0.4017 - acc: 0.8254 - val_loss: 0.4271 - val_acc: 0.8152\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 327us/sample - loss: 0.3964 - acc: 0.8244 - val_loss: 0.4361 - val_acc: 0.8152\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 332us/sample - loss: 0.3841 - acc: 0.8271 - val_loss: 0.4562 - val_acc: 0.8087\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 2s 415us/sample - loss: 0.3707 - acc: 0.8324 - val_loss: 0.4754 - val_acc: 0.8152\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 2s 518us/sample - loss: 0.3648 - acc: 0.8379 - val_loss: 0.4954 - val_acc: 0.8130\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.3505 - acc: 0.8442 - val_loss: 0.4764 - val_acc: 0.8261\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.3428 - acc: 0.8452 - val_loss: 0.5102 - val_acc: 0.8217\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 6s 1ms/sample - loss: 0.3375 - acc: 0.8512 - val_loss: 0.4442 - val_acc: 0.8304\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3282 - acc: 0.8527 - val_loss: 0.4824 - val_acc: 0.8261\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3148 - acc: 0.8609 - val_loss: 0.4999 - val_acc: 0.8239\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3036 - acc: 0.8647 - val_loss: 0.5095 - val_acc: 0.8261\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2947 - acc: 0.8650 - val_loss: 0.4978 - val_acc: 0.8174\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3000 - acc: 0.8684 - val_loss: 0.4489 - val_acc: 0.8152\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2769 - acc: 0.8727 - val_loss: 0.4914 - val_acc: 0.8087\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2793 - acc: 0.8739 - val_loss: 0.4584 - val_acc: 0.8152\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2603 - acc: 0.8804 - val_loss: 0.4653 - val_acc: 0.8130\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2655 - acc: 0.8831 - val_loss: 0.4578 - val_acc: 0.8217\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2670 - acc: 0.8795 - val_loss: 0.4347 - val_acc: 0.8283\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2774 - acc: 0.8720 - val_loss: 0.4695 - val_acc: 0.8174\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2525 - acc: 0.8821 - val_loss: 0.4973 - val_acc: 0.8326\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2346 - acc: 0.8928 - val_loss: 0.4747 - val_acc: 0.8348\n",
      "100/100 [==============================] - 1s 5ms/sample - loss: 0.4915 - acc: 0.8500\n",
      "logs/fit/dropout2_lstm/kfold6\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 24s 6ms/sample - loss: 0.6920 - acc: 0.5761 - val_loss: 0.6908 - val_acc: 0.5717\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.6876 - acc: 0.5795 - val_loss: 0.6697 - val_acc: 0.5804\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.6141 - acc: 0.6874 - val_loss: 0.5695 - val_acc: 0.7478\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 305us/sample - loss: 0.5298 - acc: 0.7652 - val_loss: 0.4760 - val_acc: 0.8043\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 301us/sample - loss: 0.4724 - acc: 0.7920 - val_loss: 0.4535 - val_acc: 0.7870\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.4275 - acc: 0.8097 - val_loss: 0.4600 - val_acc: 0.7913\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.4188 - acc: 0.8099 - val_loss: 0.4535 - val_acc: 0.7935\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.4047 - acc: 0.8254 - val_loss: 0.4689 - val_acc: 0.7978\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.3817 - acc: 0.8350 - val_loss: 0.4632 - val_acc: 0.7978\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.3621 - acc: 0.8350 - val_loss: 0.4840 - val_acc: 0.8000\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 314us/sample - loss: 0.3633 - acc: 0.8415 - val_loss: 0.4841 - val_acc: 0.7978\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 336us/sample - loss: 0.3372 - acc: 0.8512 - val_loss: 0.4903 - val_acc: 0.8000\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 1s 354us/sample - loss: 0.3326 - acc: 0.8527 - val_loss: 0.4886 - val_acc: 0.8000\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 2s 484us/sample - loss: 0.3660 - acc: 0.8399 - val_loss: 0.4806 - val_acc: 0.7674\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 3s 804us/sample - loss: 0.3581 - acc: 0.8425 - val_loss: 0.4668 - val_acc: 0.8087\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.3303 - acc: 0.8601 - val_loss: 0.4642 - val_acc: 0.8065\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.3189 - acc: 0.8664 - val_loss: 0.4673 - val_acc: 0.8022\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3126 - acc: 0.8684 - val_loss: 0.4744 - val_acc: 0.8043\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3059 - acc: 0.8720 - val_loss: 0.4821 - val_acc: 0.8043\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2972 - acc: 0.8797 - val_loss: 0.4942 - val_acc: 0.7913\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2904 - acc: 0.8783 - val_loss: 0.5028 - val_acc: 0.7913\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2830 - acc: 0.8814 - val_loss: 0.5079 - val_acc: 0.7957\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2770 - acc: 0.8862 - val_loss: 0.4954 - val_acc: 0.8109\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2755 - acc: 0.8915 - val_loss: 0.4978 - val_acc: 0.8087\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2733 - acc: 0.8889 - val_loss: 0.5030 - val_acc: 0.8109\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2538 - acc: 0.8973 - val_loss: 0.5613 - val_acc: 0.8065\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2458 - acc: 0.9039 - val_loss: 0.6001 - val_acc: 0.8130\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2559 - acc: 0.9002 - val_loss: 0.5447 - val_acc: 0.8065\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2606 - acc: 0.8976 - val_loss: 0.5027 - val_acc: 0.8022\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.2680 - acc: 0.8925 - val_loss: 0.4828 - val_acc: 0.8043\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.3550 - acc: 0.8300\n",
      "logs/fit/dropout2_lstm/kfold7\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 33s 8ms/sample - loss: 0.6921 - acc: 0.5746 - val_loss: 0.6911 - val_acc: 0.5717\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 278us/sample - loss: 0.6850 - acc: 0.6138 - val_loss: 0.6828 - val_acc: 0.6196\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 273us/sample - loss: 0.6695 - acc: 0.6688 - val_loss: 0.6596 - val_acc: 0.6587\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 273us/sample - loss: 0.6271 - acc: 0.7208 - val_loss: 0.6524 - val_acc: 0.7500\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 269us/sample - loss: 0.5853 - acc: 0.7444 - val_loss: 0.5869 - val_acc: 0.7326\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 278us/sample - loss: 0.5313 - acc: 0.7821 - val_loss: 0.5483 - val_acc: 0.7761\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 284us/sample - loss: 0.5164 - acc: 0.7925 - val_loss: 0.5874 - val_acc: 0.7565\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.4633 - acc: 0.8126 - val_loss: 0.4990 - val_acc: 0.7978\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 316us/sample - loss: 0.4360 - acc: 0.8244 - val_loss: 0.4988 - val_acc: 0.7913\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 331us/sample - loss: 0.3951 - acc: 0.8399 - val_loss: 0.4384 - val_acc: 0.8217\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 2s 379us/sample - loss: 0.4205 - acc: 0.8191 - val_loss: 0.4496 - val_acc: 0.8152\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 2s 439us/sample - loss: 0.3861 - acc: 0.8464 - val_loss: 0.4634 - val_acc: 0.8087\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 2s 431us/sample - loss: 0.3726 - acc: 0.8514 - val_loss: 0.4756 - val_acc: 0.8065\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 2s 541us/sample - loss: 0.3592 - acc: 0.8551 - val_loss: 0.4671 - val_acc: 0.8065\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 2s 559us/sample - loss: 0.3494 - acc: 0.8621 - val_loss: 0.4417 - val_acc: 0.8283\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.3544 - acc: 0.8582 - val_loss: 0.4611 - val_acc: 0.8217\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.3384 - acc: 0.8671 - val_loss: 0.4615 - val_acc: 0.8152\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 6s 1ms/sample - loss: 0.3358 - acc: 0.8688 - val_loss: 0.4552 - val_acc: 0.8196\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3273 - acc: 0.8659 - val_loss: 0.4513 - val_acc: 0.8217\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3242 - acc: 0.8734 - val_loss: 0.4213 - val_acc: 0.8304\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3177 - acc: 0.8763 - val_loss: 0.4151 - val_acc: 0.8413\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3187 - acc: 0.8720 - val_loss: 0.4156 - val_acc: 0.8413\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3036 - acc: 0.8773 - val_loss: 0.4150 - val_acc: 0.8304\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3042 - acc: 0.8819 - val_loss: 0.4272 - val_acc: 0.8217\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2950 - acc: 0.8896 - val_loss: 0.4095 - val_acc: 0.8283\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2849 - acc: 0.8935 - val_loss: 0.4134 - val_acc: 0.8326\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2831 - acc: 0.8940 - val_loss: 0.4926 - val_acc: 0.8239\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2771 - acc: 0.8959 - val_loss: 0.4464 - val_acc: 0.8348\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2730 - acc: 0.8959 - val_loss: 0.4907 - val_acc: 0.8217\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2700 - acc: 0.8988 - val_loss: 0.5183 - val_acc: 0.8283\n",
      "100/100 [==============================] - 1s 5ms/sample - loss: 0.5104 - acc: 0.8300\n",
      "logs/fit/dropout2_lstm/kfold8\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 52s 12ms/sample - loss: 0.6922 - acc: 0.5754 - val_loss: 0.6914 - val_acc: 0.5652\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 314us/sample - loss: 0.6876 - acc: 0.5942 - val_loss: 0.7151 - val_acc: 0.6391\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.6755 - acc: 0.6655 - val_loss: 0.6822 - val_acc: 0.6565\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.6510 - acc: 0.7029 - val_loss: 0.6389 - val_acc: 0.6978\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.6139 - acc: 0.7290 - val_loss: 0.6288 - val_acc: 0.7109\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 305us/sample - loss: 0.6105 - acc: 0.7348 - val_loss: 0.6073 - val_acc: 0.7261\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.5871 - acc: 0.7623 - val_loss: 0.5722 - val_acc: 0.7522\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.5600 - acc: 0.7775 - val_loss: 0.5323 - val_acc: 0.7565\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.5403 - acc: 0.7952 - val_loss: 0.5207 - val_acc: 0.7804\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.5045 - acc: 0.8072 - val_loss: 0.4933 - val_acc: 0.7848\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 301us/sample - loss: 0.4893 - acc: 0.8176 - val_loss: 0.4867 - val_acc: 0.8022\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 304us/sample - loss: 0.4601 - acc: 0.8239 - val_loss: 0.4564 - val_acc: 0.8152\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.4423 - acc: 0.8345 - val_loss: 0.4200 - val_acc: 0.8239\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.4133 - acc: 0.8401 - val_loss: 0.5240 - val_acc: 0.8239\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.3947 - acc: 0.8444 - val_loss: 0.4680 - val_acc: 0.8283\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 1s 332us/sample - loss: 0.3861 - acc: 0.8396 - val_loss: 0.4443 - val_acc: 0.8043\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 1s 353us/sample - loss: 0.3829 - acc: 0.8382 - val_loss: 0.3996 - val_acc: 0.8239\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 2s 447us/sample - loss: 0.3614 - acc: 0.8483 - val_loss: 0.3951 - val_acc: 0.8239\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 3s 605us/sample - loss: 0.3617 - acc: 0.8536 - val_loss: 0.4006 - val_acc: 0.8196\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 4s 999us/sample - loss: 0.3688 - acc: 0.8517 - val_loss: 0.4095 - val_acc: 0.8239\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.3404 - acc: 0.8597 - val_loss: 0.4345 - val_acc: 0.8196\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 6s 2ms/sample - loss: 0.3350 - acc: 0.8676 - val_loss: 0.4525 - val_acc: 0.8283\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3302 - acc: 0.8667 - val_loss: 0.4911 - val_acc: 0.8283\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3256 - acc: 0.8684 - val_loss: 0.5249 - val_acc: 0.8261\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3164 - acc: 0.8727 - val_loss: 0.5471 - val_acc: 0.8261\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3108 - acc: 0.8727 - val_loss: 0.5627 - val_acc: 0.8348\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3089 - acc: 0.8705 - val_loss: 0.5629 - val_acc: 0.8348\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3033 - acc: 0.8771 - val_loss: 0.6784 - val_acc: 0.8326\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3006 - acc: 0.8725 - val_loss: 0.8054 - val_acc: 0.8326\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3075 - acc: 0.8746 - val_loss: 0.5787 - val_acc: 0.8326\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.6749 - acc: 0.8400\n",
      "logs/fit/dropout2_lstm/kfold9\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 60s 14ms/sample - loss: 0.6920 - acc: 0.5751 - val_loss: 0.6913 - val_acc: 0.5587\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 2s 480us/sample - loss: 0.6850 - acc: 0.6169 - val_loss: 0.6396 - val_acc: 0.6978\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.6578 - acc: 0.6804 - val_loss: 0.6373 - val_acc: 0.6913\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.6310 - acc: 0.7048 - val_loss: 0.6109 - val_acc: 0.7152\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 298us/sample - loss: 0.5973 - acc: 0.7295 - val_loss: 0.5568 - val_acc: 0.7457\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 298us/sample - loss: 0.5796 - acc: 0.7348 - val_loss: 0.5536 - val_acc: 0.7370\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 299us/sample - loss: 0.5362 - acc: 0.7592 - val_loss: 0.5330 - val_acc: 0.7522\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 299us/sample - loss: 0.5124 - acc: 0.7775 - val_loss: 0.5144 - val_acc: 0.7435\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 298us/sample - loss: 0.4818 - acc: 0.7954 - val_loss: 0.4911 - val_acc: 0.7783\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 300us/sample - loss: 0.4755 - acc: 0.8063 - val_loss: 0.4790 - val_acc: 0.7804\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.4424 - acc: 0.8118 - val_loss: 0.4563 - val_acc: 0.7652\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 300us/sample - loss: 0.4049 - acc: 0.8283 - val_loss: 0.4278 - val_acc: 0.8043\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 1s 304us/sample - loss: 0.3921 - acc: 0.8343 - val_loss: 0.4223 - val_acc: 0.7848\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 1s 302us/sample - loss: 0.3652 - acc: 0.8406 - val_loss: 0.4163 - val_acc: 0.8065\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.3695 - acc: 0.8483 - val_loss: 0.4279 - val_acc: 0.8065\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.3851 - acc: 0.8435 - val_loss: 0.4736 - val_acc: 0.8000\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 1s 329us/sample - loss: 0.3549 - acc: 0.8481 - val_loss: 0.4637 - val_acc: 0.7978\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 1s 333us/sample - loss: 0.3485 - acc: 0.8502 - val_loss: 0.4588 - val_acc: 0.8022\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 1s 355us/sample - loss: 0.3371 - acc: 0.8565 - val_loss: 0.4238 - val_acc: 0.8130\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 2s 487us/sample - loss: 0.3377 - acc: 0.8589 - val_loss: 0.4627 - val_acc: 0.8022\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 3s 763us/sample - loss: 0.3311 - acc: 0.8599 - val_loss: 0.4058 - val_acc: 0.8217\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.3270 - acc: 0.8582 - val_loss: 0.4329 - val_acc: 0.8043\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.3160 - acc: 0.8618 - val_loss: 0.4487 - val_acc: 0.8130\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 7s 2ms/sample - loss: 0.3083 - acc: 0.8684 - val_loss: 0.4483 - val_acc: 0.8043\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3055 - acc: 0.8693 - val_loss: 0.4372 - val_acc: 0.7913\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3059 - acc: 0.8688 - val_loss: 0.4778 - val_acc: 0.7935\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3190 - acc: 0.8684 - val_loss: 0.5743 - val_acc: 0.7717\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3288 - acc: 0.8572 - val_loss: 0.6003 - val_acc: 0.7674\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3397 - acc: 0.8621 - val_loss: 0.4995 - val_acc: 0.8043\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2954 - acc: 0.8763 - val_loss: 0.5503 - val_acc: 0.7761\n",
      "100/100 [==============================] - 1s 5ms/sample - loss: 0.7962 - acc: 0.7700\n",
      "logs/fit/dropout2_lstm/kfold10\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 60s 14ms/sample - loss: 0.6920 - acc: 0.5734 - val_loss: 0.6893 - val_acc: 0.6087\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.6958 - acc: 0.6200 - val_loss: 0.6844 - val_acc: 0.6152\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.6853 - acc: 0.5778 - val_loss: 0.6802 - val_acc: 0.6109\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.6807 - acc: 0.5763 - val_loss: 0.6690 - val_acc: 0.6109\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.6894 - acc: 0.5814 - val_loss: 0.6882 - val_acc: 0.6174\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.6740 - acc: 0.6094 - val_loss: 0.6707 - val_acc: 0.6326\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.6639 - acc: 0.6435 - val_loss: 0.6675 - val_acc: 0.6435\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.6559 - acc: 0.6543 - val_loss: 0.6641 - val_acc: 0.6478\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 311us/sample - loss: 0.6506 - acc: 0.6662 - val_loss: 0.6575 - val_acc: 0.6543\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.6379 - acc: 0.6771 - val_loss: 0.6538 - val_acc: 0.6652\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.6316 - acc: 0.6879 - val_loss: 0.6438 - val_acc: 0.6848\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.6176 - acc: 0.6983 - val_loss: 0.6281 - val_acc: 0.6891\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.6041 - acc: 0.7077 - val_loss: 0.6142 - val_acc: 0.7087\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 1s 305us/sample - loss: 0.5943 - acc: 0.7150 - val_loss: 0.6034 - val_acc: 0.7109\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.5846 - acc: 0.7227 - val_loss: 0.5914 - val_acc: 0.7239\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 1s 322us/sample - loss: 0.5731 - acc: 0.7316 - val_loss: 0.5781 - val_acc: 0.7283\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4140/4140 [==============================] - 2s 362us/sample - loss: 0.5578 - acc: 0.7486 - val_loss: 0.5572 - val_acc: 0.7500\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 1s 337us/sample - loss: 0.5359 - acc: 0.7722 - val_loss: 0.5268 - val_acc: 0.7630\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 2s 413us/sample - loss: 0.5174 - acc: 0.7826 - val_loss: 0.4982 - val_acc: 0.7957\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 2s 484us/sample - loss: 0.4894 - acc: 0.8104 - val_loss: 0.4644 - val_acc: 0.8065\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 4s 997us/sample - loss: 0.4793 - acc: 0.8150 - val_loss: 0.4961 - val_acc: 0.7783\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.4644 - acc: 0.8239 - val_loss: 0.4494 - val_acc: 0.8043\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 6s 1ms/sample - loss: 0.4682 - acc: 0.8239 - val_loss: 0.4962 - val_acc: 0.8109\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4882 - acc: 0.8116 - val_loss: 0.4859 - val_acc: 0.8000\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4515 - acc: 0.8343 - val_loss: 0.4680 - val_acc: 0.8022\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4333 - acc: 0.8399 - val_loss: 0.4582 - val_acc: 0.8043\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4214 - acc: 0.8435 - val_loss: 0.4460 - val_acc: 0.8130\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4064 - acc: 0.8420 - val_loss: 0.4287 - val_acc: 0.8130\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3916 - acc: 0.8452 - val_loss: 0.4116 - val_acc: 0.8130\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3731 - acc: 0.8486 - val_loss: 0.4202 - val_acc: 0.8087\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.5778 - acc: 0.8100\n"
     ]
    }
   ],
   "source": [
    "def create_drop_model_2():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(10, kernel_initializer='normal', activation='relu', input_shape=(28, 300), name='lstm'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='normal', name='dense')\n",
    "    ])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "drop2_hist, drop2_evas = kfold_train(create_drop_model_2, 'dropout2_lstm', batch_size=128, epochs=30, shuffle=False, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "a842dd2b-4c86-4f38-80c7-29ec4d10e48e",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6920507642382009,
          0.6844541937256781,
          0.6607118183288021,
          0.628182287895737,
          0.6007001773170803,
          0.5135698678412876,
          0.4643017819538209,
          0.4311143328314242,
          0.4049964859577769,
          0.3911200647768767,
          0.3834253051718652,
          0.37406985808685783,
          0.36806316606088535,
          0.3526529066804526,
          0.36167369741172606,
          0.34591887446417324,
          0.3539069406940165,
          0.3415349300932769,
          0.3228991393305829,
          0.3246404743712881,
          0.3130151938701021,
          0.30384562208456695,
          0.3039030423774811,
          0.29438503623584616,
          0.2965185551251766,
          0.2944427318043179,
          0.30006635168900236,
          0.3202875548514767,
          0.3249576785570181,
          0.2914315792961397
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "04e652f5-a521-46e5-b9ef-5e348b735f19",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6905596385831418,
          0.6676048283991607,
          0.61574641984442,
          0.5673147004583607,
          0.5575943952021392,
          0.4621325241482776,
          0.44023268300554025,
          0.4306958250377489,
          0.42162777366845505,
          0.41682947278022764,
          0.4119150156560151,
          0.41093311387559645,
          0.41033892579700637,
          0.42083261686822643,
          0.42504087479218194,
          0.45557226201762324,
          0.47920802779819655,
          0.43914218648620273,
          0.42337461088014683,
          0.4319677114486694,
          0.43559611724770586,
          0.4448838029218757,
          0.4699603821920312,
          0.45312506893406745,
          0.45019702030264813,
          0.43005309623220694,
          0.4465264618396759,
          0.57436617301858,
          0.5056162380653879,
          0.606553916827492
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "bd7e1da5-d949-4472-a1b7-8e3d32c2f496",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6921151351813533,
          0.6899128177315716,
          0.6674356378794868,
          0.6396013505792848,
          0.6049753550170125,
          0.5762684899251818,
          0.5201116247165606,
          0.48253297929602545,
          0.49618074709666526,
          0.5806187526039456,
          0.5802243783278166,
          0.530239941302129,
          0.5153337805743379,
          0.49119931914380205,
          0.4679575096005979,
          0.4616080253020577,
          0.46306755174185343,
          0.44853064412080146,
          0.4427869396797125,
          0.4424105527608291,
          0.4724368110946987,
          0.4725238393470285,
          0.4469325368531084,
          0.439507060724756,
          0.43593016186198175,
          0.43246372051285087,
          0.42195472437978365,
          0.41731820590254187,
          0.41772888305682493,
          0.41080221568328745
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "0586fb4b-154e-4e04-b126-755d92b30341",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6911740007607833,
          0.6888543595438418,
          0.6540578805881998,
          0.6246086172435594,
          0.5785676567450814,
          0.5633792576582536,
          0.4810994539571845,
          0.4520147116287895,
          0.48281200839125593,
          0.582466955806898,
          0.5309173177117886,
          0.4891125298064688,
          0.48310899086620496,
          0.46016335513280787,
          0.44841782709826594,
          0.443434448864149,
          0.43830766418705813,
          0.4343036555725595,
          0.43295151876366655,
          0.43197168008140896,
          0.4656330546607142,
          0.4473681400651517,
          0.4390419646449711,
          0.4325705139533333,
          0.4282744384330252,
          0.42457465348036394,
          0.42287059296732366,
          0.4204331685667453,
          0.4174225415872491,
          0.4154420642749123
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "80f36955-6dde-4bb2-adaa-2e9c30d2679f",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6920219022294749,
          0.6787892318002268,
          0.6328451338597542,
          0.6135534103941802,
          0.5673020782102133,
          0.5605412231551277,
          0.5178746320775166,
          0.4960985875072111,
          0.4858819695774484,
          0.4813934722960283,
          0.4693391099932113,
          0.4549566030214374,
          0.4468335318680547,
          0.4407055554470578,
          0.43135585376030006,
          0.4221842529693087,
          0.41368812420517925,
          0.4070315093809856,
          0.40700203796515716,
          0.4114964295412607,
          0.5020815792579005,
          0.4197847843458111,
          0.4045496398124142,
          0.39195536766651173,
          0.3924068526081417,
          0.38696983347192476,
          0.3748183143887543,
          0.3601572451096226,
          0.35096896454907844,
          0.3476329825926518
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "12c324a1-f587-44e8-8d2e-3243dae428d8",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6891942532166191,
          0.6465787390004034,
          0.5975330150645712,
          0.5743883236594822,
          0.5212040800115336,
          0.4960612817950871,
          0.48859237251074417,
          0.4599419990311498,
          0.46032548261725387,
          0.46139934944069905,
          0.447155216206675,
          0.4276893937069437,
          0.4402896938116654,
          0.4553168086901955,
          0.42439962314522783,
          0.4134649357070094,
          0.41084194494330367,
          0.410557651778926,
          0.4087277723395306,
          0.40777849762336066,
          0.43309361312700356,
          0.4110191676927649,
          0.41143537578375444,
          0.4161551978277124,
          0.41471603823744735,
          0.408119479469631,
          0.40227920672167905,
          0.4059473312419394,
          0.41805875975152723,
          0.41828872846520465
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "544d4a12-0b78-498b-a5a0-119d82050f3e",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6920733905068918,
          0.6975699509399524,
          0.6879397081292193,
          0.6919796360287689,
          0.6852333401712243,
          0.6845444162110775,
          0.6837977318948018,
          0.6830111198955112,
          0.6825344914399484,
          0.6817912380476505,
          0.681694387525752,
          0.6813359229461007,
          0.6809382671319344,
          0.6807162799121101,
          0.6799062746158545,
          0.6788453938304514,
          0.6740476839208372,
          0.6432888829765688,
          0.637068554111149,
          0.5588239863874832,
          0.4599263294883396,
          0.4439912496557558,
          0.4097191978767874,
          0.38753597117276584,
          0.3685470025032615,
          0.35954505012231175,
          0.35086464202346435,
          0.3425908068815867,
          0.33303074125506454,
          0.3205870275048242
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "70a42fbb-0667-43dd-a6b9-b70294545cfe",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6898878527724225,
          0.6871261949124543,
          0.6853072337482287,
          0.681704394713692,
          0.6820248909618544,
          0.6807084829910942,
          0.6795815244964931,
          0.6785913866499196,
          0.6777234554290772,
          0.6769259618676227,
          0.6762577751408453,
          0.6756676181502964,
          0.6750967144966126,
          0.6743756828100785,
          0.6732745497123055,
          0.6710010186485622,
          0.6583701372146606,
          0.6467902022859324,
          0.5649624751961749,
          0.48307953036349754,
          0.4071591107741646,
          0.3607762634754181,
          0.33480364524799844,
          0.3299368974955186,
          0.33429340875667074,
          0.3302190029102823,
          0.3288743143496306,
          0.3338992888512819,
          0.3306143073931984,
          0.33392403695894324
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "1f7964fe-076c-4503-83f7-8e71477a7e05",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6920131314779825,
          0.6868182204195843,
          0.639406839085086,
          0.5661324432506654,
          0.489971397406813,
          0.4546068763675321,
          0.44793265628929874,
          0.4195301241344876,
          0.40907807776317506,
          0.40168560426592254,
          0.3964444901632226,
          0.3841183662990441,
          0.3707480727474471,
          0.364755661447267,
          0.3504549748079788,
          0.34281479837237927,
          0.33749667763134134,
          0.3282356576067238,
          0.3147868954041154,
          0.3035896808196957,
          0.29465057681436124,
          0.29995279032827,
          0.2769225876400436,
          0.27932761671462497,
          0.2602915667249385,
          0.2654521382085367,
          0.26697577942108763,
          0.27741572871300335,
          0.25245042162528936,
          0.23462904369197607
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "1e64b089-4c73-4e96-be92-91dd5e50bc6b",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6912624442059061,
          0.6437169748803844,
          0.5691195130348206,
          0.5267635407655136,
          0.43496358887009,
          0.43402497042780336,
          0.40822046736012335,
          0.4051197158253711,
          0.407994261254435,
          0.4271014477895654,
          0.43612029967100724,
          0.45622229809346404,
          0.47544732249301414,
          0.49542430172795837,
          0.47640427506488303,
          0.5102157266243644,
          0.44417650129484093,
          0.4823931144631427,
          0.49991034010182256,
          0.5095424683197685,
          0.4977510623309923,
          0.4488773654336515,
          0.49136019064032516,
          0.45835332144861635,
          0.4653073202008786,
          0.45782920588617737,
          0.4347219944000244,
          0.4694691424784453,
          0.49730881452560427,
          0.4747219881285792
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "6d24e104-68d3-426b-9f9c-09cf0600527a",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6920440393369555,
          0.6876310301287739,
          0.6140818330400808,
          0.5298493528135733,
          0.47239321182315475,
          0.42754380127082126,
          0.4187745563937846,
          0.40471705800093316,
          0.38171700267976033,
          0.36211094332202043,
          0.36328283009897683,
          0.3372178654451877,
          0.3326398632664611,
          0.3660250196998246,
          0.35812802144870665,
          0.33029096866575414,
          0.31887370287508204,
          0.3126300265247695,
          0.30588785841845084,
          0.29715759759939814,
          0.2904279585621783,
          0.2830314442443387,
          0.2770393017409504,
          0.2755087879832816,
          0.273258294114744,
          0.2538009731233984,
          0.2457524093740804,
          0.2558533467244411,
          0.2605910401701351,
          0.2680309700505169
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "56102efd-5551-442b-9303-d373df336c19",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6907847881317138,
          0.6697075724601745,
          0.5695156548334205,
          0.47602173400961834,
          0.45346428311389425,
          0.46001980615698773,
          0.453508372410484,
          0.46888694789098656,
          0.46324537629666535,
          0.4840459644794464,
          0.4840872629829075,
          0.4902609353480132,
          0.48859804454057115,
          0.48064290699751483,
          0.46680135208627455,
          0.464153114868247,
          0.4672607256018597,
          0.4743785173996635,
          0.4821211198101873,
          0.4941525982773822,
          0.502773730651192,
          0.5078511486882749,
          0.4954007783661718,
          0.4978371682374374,
          0.502995549077573,
          0.5613024193307627,
          0.6001210692136184,
          0.5446575185526972,
          0.5027212464291116,
          0.4827680079833321
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "6d706a97-85f4-4ff9-bda7-b35379d5f552",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6921215221501779,
          0.6850287678736995,
          0.669482446004803,
          0.6271297740475567,
          0.5853454333572572,
          0.5312817334264949,
          0.5163658899385573,
          0.46329238161372677,
          0.43601543946542604,
          0.395116182629037,
          0.4204554378122523,
          0.3860590460219821,
          0.3725636072780775,
          0.3591619673270534,
          0.34935290257711915,
          0.35436779822128406,
          0.33843706250190736,
          0.33575262839091574,
          0.3273431542702919,
          0.32422499950381295,
          0.31768998993191744,
          0.3187306206871346,
          0.30363572763935953,
          0.30418594744470384,
          0.2949561479874855,
          0.28487601215424746,
          0.28309960633084397,
          0.27710745442604673,
          0.27298888696564566,
          0.27002169662627623
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "ea986f05-3bea-4f61-9ac9-2217e9aa1c09",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6911354261895885,
          0.6828225374221801,
          0.6595853935117307,
          0.6524456153745236,
          0.5869434139002925,
          0.5483270183853481,
          0.5874143470888552,
          0.49897655222726905,
          0.49883288093235184,
          0.4383849335753399,
          0.44956803166348003,
          0.46344136958536897,
          0.4755901082702305,
          0.4671244927074598,
          0.44172705282335695,
          0.46105919946794927,
          0.4614835060161093,
          0.45519078114758366,
          0.4513061365355616,
          0.4212807471337526,
          0.4150754329950913,
          0.41562097228091693,
          0.41499235500460085,
          0.42717677147492117,
          0.4094777804353963,
          0.4134417419848235,
          0.4925691192564757,
          0.4464014426521633,
          0.490712564147037,
          0.5182909353919651
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "5c15edfa-35cd-46aa-b224-6c3ff4a7e90c",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6921594730897802,
          0.6876278413666619,
          0.6755238294025551,
          0.6509671815351588,
          0.6138952533979922,
          0.610525355534853,
          0.5871205165766288,
          0.5599985831601608,
          0.5402742193516902,
          0.5044872373774432,
          0.48927069326529754,
          0.4601231260864055,
          0.44231488687404685,
          0.41327228096948154,
          0.39470779043464843,
          0.38614942347945796,
          0.3828723142688401,
          0.36142681292865586,
          0.36172240615466944,
          0.36875919227438847,
          0.34041828625444054,
          0.33504073850198646,
          0.3302485229600455,
          0.3255602935374071,
          0.3163612416976892,
          0.3107561317618918,
          0.308947608810692,
          0.303340938154626,
          0.3006454327256207,
          0.3074978968659461
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "2a637fee-7877-4f70-85c3-9af0b11353a7",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6913687534954237,
          0.7151161515194436,
          0.6821948471276656,
          0.6389110435610232,
          0.6287798902262812,
          0.6072506971981214,
          0.5721732533496359,
          0.5323311805725097,
          0.5206532203632852,
          0.49332665049511454,
          0.4867283440154532,
          0.4564226238623909,
          0.4199726223945618,
          0.5239688621914905,
          0.467957554951958,
          0.4443053170390751,
          0.3995714413083118,
          0.39505476381467736,
          0.4006403806416885,
          0.40953691653583363,
          0.4344933626444443,
          0.4524703746256621,
          0.49112965542337167,
          0.5248878898827926,
          0.5471185386180878,
          0.5626765935317329,
          0.5629211703072423,
          0.6783974538678709,
          0.8054113470989724,
          0.5786775127701137
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "8863e64f-0df4-41eb-a36b-a413cbf07f29",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6920355203071078,
          0.6849622238085465,
          0.6577846542648648,
          0.630962698183198,
          0.5972756224553942,
          0.5796470052954079,
          0.536214222021149,
          0.5123763731712304,
          0.48180291295627464,
          0.4755442912451887,
          0.44239344124632757,
          0.40487949338512147,
          0.3920565295046654,
          0.365198513591923,
          0.36954852172717956,
          0.3850984960362531,
          0.3549241706081059,
          0.3484644042984875,
          0.33712532189157274,
          0.3376528515619932,
          0.3310943715238341,
          0.326991150431011,
          0.3159603542463791,
          0.3083233640389742,
          0.30547846351268787,
          0.30593332841200527,
          0.3189679693196707,
          0.3288351380594687,
          0.3397150661346417,
          0.2953929338766181
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "bd878ea1-6ee1-44b7-aff6-f709def2573c",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6913143204606098,
          0.639602722292361,
          0.6372777861097585,
          0.6108757392219876,
          0.5567582778308703,
          0.5536133164944856,
          0.5329529132532037,
          0.5143636449523594,
          0.49109677646471106,
          0.4789629024008046,
          0.4563354803168255,
          0.42781609193138453,
          0.4222738911276278,
          0.41633232935615205,
          0.4279302656650543,
          0.47358456435410873,
          0.4636842139389204,
          0.45881327364755714,
          0.423753065129985,
          0.4626660826413528,
          0.4057802438735962,
          0.4328839156938636,
          0.44873145792795266,
          0.448310939643694,
          0.4372420336889184,
          0.47782583573590154,
          0.5742748747701231,
          0.600342903966489,
          0.49950626233349676,
          0.5502679047377214
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "74137840-55e4-4e7b-b7a9-7bc24848844d",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6919515628745591,
          0.6957706426076843,
          0.6853014186960488,
          0.6806742928454266,
          0.6894279794416566,
          0.6739759161852408,
          0.6638757804741606,
          0.6559444030701826,
          0.6505532893005777,
          0.6379088822194343,
          0.6316146419244112,
          0.6175588857724471,
          0.6041188656419948,
          0.5942820955589774,
          0.584568803033967,
          0.573084022515062,
          0.5577714854968343,
          0.5358813143006845,
          0.5173787923826687,
          0.489388580656282,
          0.47933250435308555,
          0.4644051179793722,
          0.46815272535102953,
          0.488187597396869,
          0.45152015403848916,
          0.4333268023919368,
          0.4214265823652203,
          0.4064087282056394,
          0.3915590138539024,
          0.3731116058745822
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "bad39904-40dc-4187-9962-14f66912a826",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6892773773359215,
          0.6844168424606323,
          0.6801509292229362,
          0.6689922799234805,
          0.6882385616717132,
          0.6707027393838634,
          0.6675152674965237,
          0.6640834372976552,
          0.6574749034384023,
          0.6538459663805755,
          0.6438449895900229,
          0.6281096095624177,
          0.6142107642215231,
          0.6034100465152574,
          0.591412805992624,
          0.5780631790990415,
          0.5572340389956598,
          0.5267523350922958,
          0.49824957847595214,
          0.4643642695053764,
          0.4960949117722719,
          0.4494079084500023,
          0.4961904121481854,
          0.4859439201976942,
          0.4680428774460502,
          0.45818308850993283,
          0.44595875092174697,
          0.42871396360190017,
          0.41164209246635436,
          0.4202044360015703
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"3d354303-e6d9-473f-91cc-a5576108b0aa\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"3d354303-e6d9-473f-91cc-a5576108b0aa\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '3d354303-e6d9-473f-91cc-a5576108b0aa',\n",
       "                        [{\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"a842dd2b-4c86-4f38-80c7-29ec4d10e48e\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6920507642382009, 0.6844541937256781, 0.6607118183288021, 0.628182287895737, 0.6007001773170803, 0.5135698678412876, 0.4643017819538209, 0.4311143328314242, 0.4049964859577769, 0.3911200647768767, 0.3834253051718652, 0.37406985808685783, 0.36806316606088535, 0.3526529066804526, 0.36167369741172606, 0.34591887446417324, 0.3539069406940165, 0.3415349300932769, 0.3228991393305829, 0.3246404743712881, 0.3130151938701021, 0.30384562208456695, 0.3039030423774811, 0.29438503623584616, 0.2965185551251766, 0.2944427318043179, 0.30006635168900236, 0.3202875548514767, 0.3249576785570181, 0.2914315792961397]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"04e652f5-a521-46e5-b9ef-5e348b735f19\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6905596385831418, 0.6676048283991607, 0.61574641984442, 0.5673147004583607, 0.5575943952021392, 0.4621325241482776, 0.44023268300554025, 0.4306958250377489, 0.42162777366845505, 0.41682947278022764, 0.4119150156560151, 0.41093311387559645, 0.41033892579700637, 0.42083261686822643, 0.42504087479218194, 0.45557226201762324, 0.47920802779819655, 0.43914218648620273, 0.42337461088014683, 0.4319677114486694, 0.43559611724770586, 0.4448838029218757, 0.4699603821920312, 0.45312506893406745, 0.45019702030264813, 0.43005309623220694, 0.4465264618396759, 0.57436617301858, 0.5056162380653879, 0.606553916827492]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"bd7e1da5-d949-4472-a1b7-8e3d32c2f496\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6921151351813533, 0.6899128177315716, 0.6674356378794868, 0.6396013505792848, 0.6049753550170125, 0.5762684899251818, 0.5201116247165606, 0.48253297929602545, 0.49618074709666526, 0.5806187526039456, 0.5802243783278166, 0.530239941302129, 0.5153337805743379, 0.49119931914380205, 0.4679575096005979, 0.4616080253020577, 0.46306755174185343, 0.44853064412080146, 0.4427869396797125, 0.4424105527608291, 0.4724368110946987, 0.4725238393470285, 0.4469325368531084, 0.439507060724756, 0.43593016186198175, 0.43246372051285087, 0.42195472437978365, 0.41731820590254187, 0.41772888305682493, 0.41080221568328745]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"0586fb4b-154e-4e04-b126-755d92b30341\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6911740007607833, 0.6888543595438418, 0.6540578805881998, 0.6246086172435594, 0.5785676567450814, 0.5633792576582536, 0.4810994539571845, 0.4520147116287895, 0.48281200839125593, 0.582466955806898, 0.5309173177117886, 0.4891125298064688, 0.48310899086620496, 0.46016335513280787, 0.44841782709826594, 0.443434448864149, 0.43830766418705813, 0.4343036555725595, 0.43295151876366655, 0.43197168008140896, 0.4656330546607142, 0.4473681400651517, 0.4390419646449711, 0.4325705139533333, 0.4282744384330252, 0.42457465348036394, 0.42287059296732366, 0.4204331685667453, 0.4174225415872491, 0.4154420642749123]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"80f36955-6dde-4bb2-adaa-2e9c30d2679f\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6920219022294749, 0.6787892318002268, 0.6328451338597542, 0.6135534103941802, 0.5673020782102133, 0.5605412231551277, 0.5178746320775166, 0.4960985875072111, 0.4858819695774484, 0.4813934722960283, 0.4693391099932113, 0.4549566030214374, 0.4468335318680547, 0.4407055554470578, 0.43135585376030006, 0.4221842529693087, 0.41368812420517925, 0.4070315093809856, 0.40700203796515716, 0.4114964295412607, 0.5020815792579005, 0.4197847843458111, 0.4045496398124142, 0.39195536766651173, 0.3924068526081417, 0.38696983347192476, 0.3748183143887543, 0.3601572451096226, 0.35096896454907844, 0.3476329825926518]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"12c324a1-f587-44e8-8d2e-3243dae428d8\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6891942532166191, 0.6465787390004034, 0.5975330150645712, 0.5743883236594822, 0.5212040800115336, 0.4960612817950871, 0.48859237251074417, 0.4599419990311498, 0.46032548261725387, 0.46139934944069905, 0.447155216206675, 0.4276893937069437, 0.4402896938116654, 0.4553168086901955, 0.42439962314522783, 0.4134649357070094, 0.41084194494330367, 0.410557651778926, 0.4087277723395306, 0.40777849762336066, 0.43309361312700356, 0.4110191676927649, 0.41143537578375444, 0.4161551978277124, 0.41471603823744735, 0.408119479469631, 0.40227920672167905, 0.4059473312419394, 0.41805875975152723, 0.41828872846520465]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"544d4a12-0b78-498b-a5a0-119d82050f3e\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6920733905068918, 0.6975699509399524, 0.6879397081292193, 0.6919796360287689, 0.6852333401712243, 0.6845444162110775, 0.6837977318948018, 0.6830111198955112, 0.6825344914399484, 0.6817912380476505, 0.681694387525752, 0.6813359229461007, 0.6809382671319344, 0.6807162799121101, 0.6799062746158545, 0.6788453938304514, 0.6740476839208372, 0.6432888829765688, 0.637068554111149, 0.5588239863874832, 0.4599263294883396, 0.4439912496557558, 0.4097191978767874, 0.38753597117276584, 0.3685470025032615, 0.35954505012231175, 0.35086464202346435, 0.3425908068815867, 0.33303074125506454, 0.3205870275048242]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"70a42fbb-0667-43dd-a6b9-b70294545cfe\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6898878527724225, 0.6871261949124543, 0.6853072337482287, 0.681704394713692, 0.6820248909618544, 0.6807084829910942, 0.6795815244964931, 0.6785913866499196, 0.6777234554290772, 0.6769259618676227, 0.6762577751408453, 0.6756676181502964, 0.6750967144966126, 0.6743756828100785, 0.6732745497123055, 0.6710010186485622, 0.6583701372146606, 0.6467902022859324, 0.5649624751961749, 0.48307953036349754, 0.4071591107741646, 0.3607762634754181, 0.33480364524799844, 0.3299368974955186, 0.33429340875667074, 0.3302190029102823, 0.3288743143496306, 0.3338992888512819, 0.3306143073931984, 0.33392403695894324]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"1f7964fe-076c-4503-83f7-8e71477a7e05\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6920131314779825, 0.6868182204195843, 0.639406839085086, 0.5661324432506654, 0.489971397406813, 0.4546068763675321, 0.44793265628929874, 0.4195301241344876, 0.40907807776317506, 0.40168560426592254, 0.3964444901632226, 0.3841183662990441, 0.3707480727474471, 0.364755661447267, 0.3504549748079788, 0.34281479837237927, 0.33749667763134134, 0.3282356576067238, 0.3147868954041154, 0.3035896808196957, 0.29465057681436124, 0.29995279032827, 0.2769225876400436, 0.27932761671462497, 0.2602915667249385, 0.2654521382085367, 0.26697577942108763, 0.27741572871300335, 0.25245042162528936, 0.23462904369197607]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"1e64b089-4c73-4e96-be92-91dd5e50bc6b\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6912624442059061, 0.6437169748803844, 0.5691195130348206, 0.5267635407655136, 0.43496358887009, 0.43402497042780336, 0.40822046736012335, 0.4051197158253711, 0.407994261254435, 0.4271014477895654, 0.43612029967100724, 0.45622229809346404, 0.47544732249301414, 0.49542430172795837, 0.47640427506488303, 0.5102157266243644, 0.44417650129484093, 0.4823931144631427, 0.49991034010182256, 0.5095424683197685, 0.4977510623309923, 0.4488773654336515, 0.49136019064032516, 0.45835332144861635, 0.4653073202008786, 0.45782920588617737, 0.4347219944000244, 0.4694691424784453, 0.49730881452560427, 0.4747219881285792]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"6d24e104-68d3-426b-9f9c-09cf0600527a\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6920440393369555, 0.6876310301287739, 0.6140818330400808, 0.5298493528135733, 0.47239321182315475, 0.42754380127082126, 0.4187745563937846, 0.40471705800093316, 0.38171700267976033, 0.36211094332202043, 0.36328283009897683, 0.3372178654451877, 0.3326398632664611, 0.3660250196998246, 0.35812802144870665, 0.33029096866575414, 0.31887370287508204, 0.3126300265247695, 0.30588785841845084, 0.29715759759939814, 0.2904279585621783, 0.2830314442443387, 0.2770393017409504, 0.2755087879832816, 0.273258294114744, 0.2538009731233984, 0.2457524093740804, 0.2558533467244411, 0.2605910401701351, 0.2680309700505169]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"56102efd-5551-442b-9303-d373df336c19\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6907847881317138, 0.6697075724601745, 0.5695156548334205, 0.47602173400961834, 0.45346428311389425, 0.46001980615698773, 0.453508372410484, 0.46888694789098656, 0.46324537629666535, 0.4840459644794464, 0.4840872629829075, 0.4902609353480132, 0.48859804454057115, 0.48064290699751483, 0.46680135208627455, 0.464153114868247, 0.4672607256018597, 0.4743785173996635, 0.4821211198101873, 0.4941525982773822, 0.502773730651192, 0.5078511486882749, 0.4954007783661718, 0.4978371682374374, 0.502995549077573, 0.5613024193307627, 0.6001210692136184, 0.5446575185526972, 0.5027212464291116, 0.4827680079833321]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"6d706a97-85f4-4ff9-bda7-b35379d5f552\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6921215221501779, 0.6850287678736995, 0.669482446004803, 0.6271297740475567, 0.5853454333572572, 0.5312817334264949, 0.5163658899385573, 0.46329238161372677, 0.43601543946542604, 0.395116182629037, 0.4204554378122523, 0.3860590460219821, 0.3725636072780775, 0.3591619673270534, 0.34935290257711915, 0.35436779822128406, 0.33843706250190736, 0.33575262839091574, 0.3273431542702919, 0.32422499950381295, 0.31768998993191744, 0.3187306206871346, 0.30363572763935953, 0.30418594744470384, 0.2949561479874855, 0.28487601215424746, 0.28309960633084397, 0.27710745442604673, 0.27298888696564566, 0.27002169662627623]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"ea986f05-3bea-4f61-9ac9-2217e9aa1c09\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6911354261895885, 0.6828225374221801, 0.6595853935117307, 0.6524456153745236, 0.5869434139002925, 0.5483270183853481, 0.5874143470888552, 0.49897655222726905, 0.49883288093235184, 0.4383849335753399, 0.44956803166348003, 0.46344136958536897, 0.4755901082702305, 0.4671244927074598, 0.44172705282335695, 0.46105919946794927, 0.4614835060161093, 0.45519078114758366, 0.4513061365355616, 0.4212807471337526, 0.4150754329950913, 0.41562097228091693, 0.41499235500460085, 0.42717677147492117, 0.4094777804353963, 0.4134417419848235, 0.4925691192564757, 0.4464014426521633, 0.490712564147037, 0.5182909353919651]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"5c15edfa-35cd-46aa-b224-6c3ff4a7e90c\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6921594730897802, 0.6876278413666619, 0.6755238294025551, 0.6509671815351588, 0.6138952533979922, 0.610525355534853, 0.5871205165766288, 0.5599985831601608, 0.5402742193516902, 0.5044872373774432, 0.48927069326529754, 0.4601231260864055, 0.44231488687404685, 0.41327228096948154, 0.39470779043464843, 0.38614942347945796, 0.3828723142688401, 0.36142681292865586, 0.36172240615466944, 0.36875919227438847, 0.34041828625444054, 0.33504073850198646, 0.3302485229600455, 0.3255602935374071, 0.3163612416976892, 0.3107561317618918, 0.308947608810692, 0.303340938154626, 0.3006454327256207, 0.3074978968659461]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"2a637fee-7877-4f70-85c3-9af0b11353a7\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6913687534954237, 0.7151161515194436, 0.6821948471276656, 0.6389110435610232, 0.6287798902262812, 0.6072506971981214, 0.5721732533496359, 0.5323311805725097, 0.5206532203632852, 0.49332665049511454, 0.4867283440154532, 0.4564226238623909, 0.4199726223945618, 0.5239688621914905, 0.467957554951958, 0.4443053170390751, 0.3995714413083118, 0.39505476381467736, 0.4006403806416885, 0.40953691653583363, 0.4344933626444443, 0.4524703746256621, 0.49112965542337167, 0.5248878898827926, 0.5471185386180878, 0.5626765935317329, 0.5629211703072423, 0.6783974538678709, 0.8054113470989724, 0.5786775127701137]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"8863e64f-0df4-41eb-a36b-a413cbf07f29\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6920355203071078, 0.6849622238085465, 0.6577846542648648, 0.630962698183198, 0.5972756224553942, 0.5796470052954079, 0.536214222021149, 0.5123763731712304, 0.48180291295627464, 0.4755442912451887, 0.44239344124632757, 0.40487949338512147, 0.3920565295046654, 0.365198513591923, 0.36954852172717956, 0.3850984960362531, 0.3549241706081059, 0.3484644042984875, 0.33712532189157274, 0.3376528515619932, 0.3310943715238341, 0.326991150431011, 0.3159603542463791, 0.3083233640389742, 0.30547846351268787, 0.30593332841200527, 0.3189679693196707, 0.3288351380594687, 0.3397150661346417, 0.2953929338766181]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"bd878ea1-6ee1-44b7-aff6-f709def2573c\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6913143204606098, 0.639602722292361, 0.6372777861097585, 0.6108757392219876, 0.5567582778308703, 0.5536133164944856, 0.5329529132532037, 0.5143636449523594, 0.49109677646471106, 0.4789629024008046, 0.4563354803168255, 0.42781609193138453, 0.4222738911276278, 0.41633232935615205, 0.4279302656650543, 0.47358456435410873, 0.4636842139389204, 0.45881327364755714, 0.423753065129985, 0.4626660826413528, 0.4057802438735962, 0.4328839156938636, 0.44873145792795266, 0.448310939643694, 0.4372420336889184, 0.47782583573590154, 0.5742748747701231, 0.600342903966489, 0.49950626233349676, 0.5502679047377214]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"74137840-55e4-4e7b-b7a9-7bc24848844d\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6919515628745591, 0.6957706426076843, 0.6853014186960488, 0.6806742928454266, 0.6894279794416566, 0.6739759161852408, 0.6638757804741606, 0.6559444030701826, 0.6505532893005777, 0.6379088822194343, 0.6316146419244112, 0.6175588857724471, 0.6041188656419948, 0.5942820955589774, 0.584568803033967, 0.573084022515062, 0.5577714854968343, 0.5358813143006845, 0.5173787923826687, 0.489388580656282, 0.47933250435308555, 0.4644051179793722, 0.46815272535102953, 0.488187597396869, 0.45152015403848916, 0.4333268023919368, 0.4214265823652203, 0.4064087282056394, 0.3915590138539024, 0.3731116058745822]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"bad39904-40dc-4187-9962-14f66912a826\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6892773773359215, 0.6844168424606323, 0.6801509292229362, 0.6689922799234805, 0.6882385616717132, 0.6707027393838634, 0.6675152674965237, 0.6640834372976552, 0.6574749034384023, 0.6538459663805755, 0.6438449895900229, 0.6281096095624177, 0.6142107642215231, 0.6034100465152574, 0.591412805992624, 0.5780631790990415, 0.5572340389956598, 0.5267523350922958, 0.49824957847595214, 0.4643642695053764, 0.4960949117722719, 0.4494079084500023, 0.4961904121481854, 0.4859439201976942, 0.4680428774460502, 0.45818308850993283, 0.44595875092174697, 0.42871396360190017, 0.41164209246635436, 0.4202044360015703]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3d354303-e6d9-473f-91cc-a5576108b0aa');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean  acc         0.777572\n",
      "loss        0.452812\n",
      "val_acc     0.765080\n",
      "val_loss    0.507004\n",
      "dtype: float64\n",
      "std  acc         0.102955\n",
      "loss        0.137817\n",
      "val_acc     0.081349\n",
      "val_loss    0.096892\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "1",
         "text": "",
         "type": "scatter",
         "uid": "8ff4d6a3-bdf7-4968-b0c0-1e82f8c282ff",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.8299999833106995,
          0.8100000023841858,
          0.8199999928474426,
          0.8700000047683716,
          0.8500000238418579,
          0.8299999833106995,
          0.8299999833106995,
          0.8399999737739563,
          0.7699999809265137,
          0.8100000023841858
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"db638967-8dc4-4804-b443-df9dffc60d94\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"db638967-8dc4-4804-b443-df9dffc60d94\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'db638967-8dc4-4804-b443-df9dffc60d94',\n",
       "                        [{\"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"1\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"8ff4d6a3-bdf7-4968-b0c0-1e82f8c282ff\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.8299999833106995, 0.8100000023841858, 0.8199999928474426, 0.8700000047683716, 0.8500000238418579, 0.8299999833106995, 0.8299999833106995, 0.8399999737739563, 0.7699999809265137, 0.8100000023841858]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('db638967-8dc4-4804-b443-df9dffc60d94');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media  0.8259999930858613\n",
      "std  0.026749875386270022\n"
     ]
    }
   ],
   "source": [
    "process_results(drop2_hist, drop2_evas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando reducimos el valor de dropout a 0.2 vemos que el val_loss es menos estable, y presenta picos más altos que el dropout mayor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.084768Z",
     "start_time": "2019-06-14T06:36:08.313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/bn_lstm/kfold1\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 62s 15ms/sample - loss: 0.6913 - acc: 0.5442 - val_loss: 0.6905 - val_acc: 0.5739\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.6814 - acc: 0.6116 - val_loss: 0.6855 - val_acc: 0.5783\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 311us/sample - loss: 0.6528 - acc: 0.6614 - val_loss: 0.6640 - val_acc: 0.7022\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.6072 - acc: 0.7046 - val_loss: 0.6153 - val_acc: 0.7543\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 312us/sample - loss: 0.5548 - acc: 0.7534 - val_loss: 0.5415 - val_acc: 0.8087\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 316us/sample - loss: 0.5103 - acc: 0.7722 - val_loss: 0.5039 - val_acc: 0.8022\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.4814 - acc: 0.7879 - val_loss: 0.4753 - val_acc: 0.7891\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.4602 - acc: 0.7983 - val_loss: 0.4340 - val_acc: 0.8152\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.4383 - acc: 0.8099 - val_loss: 0.4254 - val_acc: 0.8130\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 314us/sample - loss: 0.4198 - acc: 0.8138 - val_loss: 0.4035 - val_acc: 0.8326\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.4222 - acc: 0.8152 - val_loss: 0.4314 - val_acc: 0.8283\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 303us/sample - loss: 0.4107 - acc: 0.8215 - val_loss: 0.4113 - val_acc: 0.8283\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.3995 - acc: 0.8181 - val_loss: 0.3977 - val_acc: 0.8326\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.3987 - acc: 0.8237 - val_loss: 0.4203 - val_acc: 0.8174\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 1s 312us/sample - loss: 0.3808 - acc: 0.8287 - val_loss: 0.4124 - val_acc: 0.8065\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 1s 316us/sample - loss: 0.3744 - acc: 0.8374 - val_loss: 0.4229 - val_acc: 0.8239\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 1s 334us/sample - loss: 0.3643 - acc: 0.8292 - val_loss: 0.4099 - val_acc: 0.8065\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 1s 348us/sample - loss: 0.3538 - acc: 0.8367 - val_loss: 0.4271 - val_acc: 0.8022\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 1s 349us/sample - loss: 0.3466 - acc: 0.8452 - val_loss: 0.4297 - val_acc: 0.8109\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 2s 494us/sample - loss: 0.3655 - acc: 0.8408 - val_loss: 0.5064 - val_acc: 0.7217\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 3s 836us/sample - loss: 0.3565 - acc: 0.8401 - val_loss: 0.4538 - val_acc: 0.7848\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.3460 - acc: 0.8471 - val_loss: 0.4356 - val_acc: 0.7891\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.3394 - acc: 0.8481 - val_loss: 0.4230 - val_acc: 0.8130\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3228 - acc: 0.8517 - val_loss: 0.4166 - val_acc: 0.8261\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3194 - acc: 0.8536 - val_loss: 0.4321 - val_acc: 0.8152\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2977 - acc: 0.8744 - val_loss: 0.4483 - val_acc: 0.8043\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2988 - acc: 0.8614 - val_loss: 0.4473 - val_acc: 0.8283\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2964 - acc: 0.8688 - val_loss: 0.4424 - val_acc: 0.8087\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3013 - acc: 0.8700 - val_loss: 0.4609 - val_acc: 0.8043\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.2754 - acc: 0.8824 - val_loss: 0.4504 - val_acc: 0.8261\n",
      "100/100 [==============================] - 1s 6ms/sample - loss: 0.4493 - acc: 0.8200\n",
      "logs/fit/bn_lstm/kfold2\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 62s 15ms/sample - loss: 0.6878 - acc: 0.5751 - val_loss: 0.6882 - val_acc: 0.6043\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6645 - acc: 0.6432 - val_loss: 0.6744 - val_acc: 0.6543\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6143 - acc: 0.7097 - val_loss: 0.6371 - val_acc: 0.7391\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 320us/sample - loss: 0.5714 - acc: 0.7413 - val_loss: 0.6247 - val_acc: 0.6826\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 312us/sample - loss: 0.5291 - acc: 0.7739 - val_loss: 0.5615 - val_acc: 0.8348\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.5054 - acc: 0.7826 - val_loss: 0.5278 - val_acc: 0.8304\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 315us/sample - loss: 0.4872 - acc: 0.7874 - val_loss: 0.4752 - val_acc: 0.8413\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.4837 - acc: 0.7884 - val_loss: 0.4272 - val_acc: 0.8457\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 312us/sample - loss: 0.4685 - acc: 0.7932 - val_loss: 0.4055 - val_acc: 0.8217\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 313us/sample - loss: 0.4540 - acc: 0.8041 - val_loss: 0.3896 - val_acc: 0.8391\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.4493 - acc: 0.8087 - val_loss: 0.3913 - val_acc: 0.8565\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 316us/sample - loss: 0.4296 - acc: 0.8210 - val_loss: 0.3830 - val_acc: 0.8435\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.4400 - acc: 0.8167 - val_loss: 0.3743 - val_acc: 0.8500\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.4243 - acc: 0.8143 - val_loss: 0.3931 - val_acc: 0.8543\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 1s 312us/sample - loss: 0.4138 - acc: 0.8295 - val_loss: 0.4092 - val_acc: 0.8326\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.3995 - acc: 0.8413 - val_loss: 0.4044 - val_acc: 0.8500\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 1s 311us/sample - loss: 0.3904 - acc: 0.8461 - val_loss: 0.4142 - val_acc: 0.8457\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 1s 314us/sample - loss: 0.3807 - acc: 0.8539 - val_loss: 0.4095 - val_acc: 0.8522\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 1s 338us/sample - loss: 0.3657 - acc: 0.8599 - val_loss: 0.4397 - val_acc: 0.8304\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 1s 353us/sample - loss: 0.3642 - acc: 0.8616 - val_loss: 0.4032 - val_acc: 0.8348\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 2s 434us/sample - loss: 0.3565 - acc: 0.8662 - val_loss: 0.4052 - val_acc: 0.8304\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 2s 573us/sample - loss: 0.3595 - acc: 0.8671 - val_loss: 0.4447 - val_acc: 0.8217\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.3540 - acc: 0.8681 - val_loss: 0.4213 - val_acc: 0.8348\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.3462 - acc: 0.8722 - val_loss: 0.4188 - val_acc: 0.8261\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 7s 2ms/sample - loss: 0.3481 - acc: 0.8737 - val_loss: 0.4081 - val_acc: 0.8239\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3393 - acc: 0.8713 - val_loss: 0.4100 - val_acc: 0.8435\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3285 - acc: 0.8836 - val_loss: 0.4189 - val_acc: 0.8413\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3253 - acc: 0.8923 - val_loss: 0.4523 - val_acc: 0.8326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3185 - acc: 0.8906 - val_loss: 0.4243 - val_acc: 0.8435\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3167 - acc: 0.8877 - val_loss: 0.4358 - val_acc: 0.8283\n",
      "100/100 [==============================] - 1s 6ms/sample - loss: 0.4094 - acc: 0.8300\n",
      "logs/fit/bn_lstm/kfold3\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 61s 15ms/sample - loss: 0.6915 - acc: 0.5623 - val_loss: 0.6886 - val_acc: 0.6087\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 318us/sample - loss: 0.6757 - acc: 0.6254 - val_loss: 0.6788 - val_acc: 0.6196\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.6214 - acc: 0.7036 - val_loss: 0.6570 - val_acc: 0.6217\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 314us/sample - loss: 0.5691 - acc: 0.7374 - val_loss: 0.6198 - val_acc: 0.6870\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.5292 - acc: 0.7527 - val_loss: 0.5663 - val_acc: 0.7587\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 316us/sample - loss: 0.4978 - acc: 0.7700 - val_loss: 0.5305 - val_acc: 0.7696\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 312us/sample - loss: 0.4786 - acc: 0.7790 - val_loss: 0.4949 - val_acc: 0.7870\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 312us/sample - loss: 0.4590 - acc: 0.7949 - val_loss: 0.4523 - val_acc: 0.8217\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.4461 - acc: 0.7971 - val_loss: 0.4387 - val_acc: 0.8217\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 311us/sample - loss: 0.4369 - acc: 0.7908 - val_loss: 0.4326 - val_acc: 0.8239\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.4290 - acc: 0.7983 - val_loss: 0.4105 - val_acc: 0.8196\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 312us/sample - loss: 0.4255 - acc: 0.7877 - val_loss: 0.4151 - val_acc: 0.8304\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.4081 - acc: 0.8014 - val_loss: 0.4151 - val_acc: 0.8370\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.4065 - acc: 0.8143 - val_loss: 0.4140 - val_acc: 0.8435\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 1s 314us/sample - loss: 0.3930 - acc: 0.8171 - val_loss: 0.4028 - val_acc: 0.8391\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 1s 325us/sample - loss: 0.3849 - acc: 0.8174 - val_loss: 0.4001 - val_acc: 0.8348\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 1s 343us/sample - loss: 0.4002 - acc: 0.8041 - val_loss: 0.4430 - val_acc: 0.8348\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 1s 355us/sample - loss: 0.3971 - acc: 0.8043 - val_loss: 0.4404 - val_acc: 0.8304\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 2s 487us/sample - loss: 0.3792 - acc: 0.8070 - val_loss: 0.4648 - val_acc: 0.8196\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 3s 761us/sample - loss: 0.3988 - acc: 0.8070 - val_loss: 0.4168 - val_acc: 0.8391\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.3742 - acc: 0.8111 - val_loss: 0.4440 - val_acc: 0.8391\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.3627 - acc: 0.8256 - val_loss: 0.4579 - val_acc: 0.8391\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3782 - acc: 0.8101 - val_loss: 0.4249 - val_acc: 0.8413\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3769 - acc: 0.8174 - val_loss: 0.4233 - val_acc: 0.8304\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3635 - acc: 0.8261 - val_loss: 0.4162 - val_acc: 0.8370\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3558 - acc: 0.8174 - val_loss: 0.4243 - val_acc: 0.8413\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3423 - acc: 0.8302 - val_loss: 0.4087 - val_acc: 0.8283\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3364 - acc: 0.8341 - val_loss: 0.4269 - val_acc: 0.8413\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3380 - acc: 0.8336 - val_loss: 0.4367 - val_acc: 0.8326\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3298 - acc: 0.8372 - val_loss: 0.4203 - val_acc: 0.8370\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.4317 - acc: 0.8500\n",
      "logs/fit/bn_lstm/kfold4\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 58s 14ms/sample - loss: 0.6898 - acc: 0.5964 - val_loss: 0.6885 - val_acc: 0.6000\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 311us/sample - loss: 0.6532 - acc: 0.6582 - val_loss: 0.6435 - val_acc: 0.7370\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 316us/sample - loss: 0.6129 - acc: 0.7065 - val_loss: 0.5736 - val_acc: 0.7848\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.5760 - acc: 0.7304 - val_loss: 0.5329 - val_acc: 0.8022\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.5450 - acc: 0.7536 - val_loss: 0.5151 - val_acc: 0.7935\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.5259 - acc: 0.7597 - val_loss: 0.4876 - val_acc: 0.8087\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 314us/sample - loss: 0.5065 - acc: 0.7722 - val_loss: 0.4764 - val_acc: 0.8196\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.4897 - acc: 0.7838 - val_loss: 0.4523 - val_acc: 0.8326\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 314us/sample - loss: 0.4775 - acc: 0.7928 - val_loss: 0.4493 - val_acc: 0.8261\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.4716 - acc: 0.7964 - val_loss: 0.4305 - val_acc: 0.8283\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 315us/sample - loss: 0.4695 - acc: 0.7940 - val_loss: 0.4258 - val_acc: 0.8391\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 314us/sample - loss: 0.4581 - acc: 0.8027 - val_loss: 0.4208 - val_acc: 0.8304\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 1s 312us/sample - loss: 0.4530 - acc: 0.8005 - val_loss: 0.4226 - val_acc: 0.8239\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 1s 311us/sample - loss: 0.4461 - acc: 0.8130 - val_loss: 0.4387 - val_acc: 0.8065\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.4380 - acc: 0.8126 - val_loss: 0.4273 - val_acc: 0.8130\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 1s 345us/sample - loss: 0.4369 - acc: 0.8196 - val_loss: 0.4492 - val_acc: 0.7870\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 1s 344us/sample - loss: 0.4301 - acc: 0.8188 - val_loss: 0.4291 - val_acc: 0.8152\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 2s 461us/sample - loss: 0.4275 - acc: 0.8191 - val_loss: 0.4095 - val_acc: 0.8239\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 3s 639us/sample - loss: 0.4195 - acc: 0.8312 - val_loss: 0.4207 - val_acc: 0.8217\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.4312 - acc: 0.8104 - val_loss: 0.4059 - val_acc: 0.8152\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.4356 - acc: 0.8089 - val_loss: 0.4031 - val_acc: 0.8283\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 7s 2ms/sample - loss: 0.4125 - acc: 0.8220 - val_loss: 0.4266 - val_acc: 0.7957\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4005 - acc: 0.8357 - val_loss: 0.4030 - val_acc: 0.8413\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3952 - acc: 0.8372 - val_loss: 0.3994 - val_acc: 0.8326\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3969 - acc: 0.8425 - val_loss: 0.4174 - val_acc: 0.8217\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3782 - acc: 0.8399 - val_loss: 0.4271 - val_acc: 0.8283\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3775 - acc: 0.8514 - val_loss: 0.4495 - val_acc: 0.8283\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3802 - acc: 0.8483 - val_loss: 0.4182 - val_acc: 0.8196\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3604 - acc: 0.8589 - val_loss: 0.4154 - val_acc: 0.8152\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3507 - acc: 0.8585 - val_loss: 0.4221 - val_acc: 0.8239\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.3709 - acc: 0.8600\n",
      "logs/fit/bn_lstm/kfold5\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 49s 12ms/sample - loss: 0.6874 - acc: 0.5722 - val_loss: 0.6896 - val_acc: 0.5609\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 311us/sample - loss: 0.6540 - acc: 0.6746 - val_loss: 0.6474 - val_acc: 0.7435\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.5992 - acc: 0.7403 - val_loss: 0.5660 - val_acc: 0.8239\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.5503 - acc: 0.7669 - val_loss: 0.5480 - val_acc: 0.8065\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.5061 - acc: 0.7889 - val_loss: 0.5112 - val_acc: 0.8174\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.4743 - acc: 0.7993 - val_loss: 0.4675 - val_acc: 0.8283\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.4591 - acc: 0.8082 - val_loss: 0.4639 - val_acc: 0.8217\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 314us/sample - loss: 0.4507 - acc: 0.8143 - val_loss: 0.4407 - val_acc: 0.8261\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 312us/sample - loss: 0.4357 - acc: 0.8145 - val_loss: 0.4051 - val_acc: 0.8370\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.4254 - acc: 0.8205 - val_loss: 0.4001 - val_acc: 0.8348\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.4192 - acc: 0.8336 - val_loss: 0.4118 - val_acc: 0.8326\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.4079 - acc: 0.8382 - val_loss: 0.3742 - val_acc: 0.8457\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.4089 - acc: 0.8386 - val_loss: 0.3998 - val_acc: 0.8391\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 1s 325us/sample - loss: 0.4017 - acc: 0.8483 - val_loss: 0.4010 - val_acc: 0.8370\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 1s 344us/sample - loss: 0.3994 - acc: 0.8457 - val_loss: 0.3881 - val_acc: 0.8478\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 2s 383us/sample - loss: 0.4014 - acc: 0.8457 - val_loss: 0.3803 - val_acc: 0.8370\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 2s 504us/sample - loss: 0.3894 - acc: 0.8473 - val_loss: 0.3991 - val_acc: 0.8391\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 4s 920us/sample - loss: 0.3739 - acc: 0.8626 - val_loss: 0.3920 - val_acc: 0.8457\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.3539 - acc: 0.8749 - val_loss: 0.3855 - val_acc: 0.8522\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 6s 1ms/sample - loss: 0.3690 - acc: 0.8696 - val_loss: 0.3944 - val_acc: 0.8500\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3516 - acc: 0.8751 - val_loss: 0.3904 - val_acc: 0.8478\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3486 - acc: 0.8751 - val_loss: 0.4039 - val_acc: 0.8391\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3628 - acc: 0.8674 - val_loss: 0.4030 - val_acc: 0.8391\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3435 - acc: 0.8804 - val_loss: 0.4188 - val_acc: 0.8391\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3400 - acc: 0.8870 - val_loss: 0.4566 - val_acc: 0.8217\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3481 - acc: 0.8761 - val_loss: 0.3922 - val_acc: 0.8522\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3237 - acc: 0.8882 - val_loss: 0.4153 - val_acc: 0.8326\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3235 - acc: 0.8877 - val_loss: 0.4010 - val_acc: 0.8500\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3386 - acc: 0.8737 - val_loss: 0.4108 - val_acc: 0.8457\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3057 - acc: 0.8988 - val_loss: 0.4540 - val_acc: 0.8283\n",
      "100/100 [==============================] - 1s 5ms/sample - loss: 0.5038 - acc: 0.8100\n",
      "logs/fit/bn_lstm/kfold6\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 39s 9ms/sample - loss: 0.6914 - acc: 0.5469 - val_loss: 0.6903 - val_acc: 0.5717\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 317us/sample - loss: 0.6827 - acc: 0.6135 - val_loss: 0.6861 - val_acc: 0.5717\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.6514 - acc: 0.6430 - val_loss: 0.6661 - val_acc: 0.6413\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 313us/sample - loss: 0.6062 - acc: 0.7043 - val_loss: 0.5483 - val_acc: 0.7870\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.5489 - acc: 0.7490 - val_loss: 0.5025 - val_acc: 0.8326\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.5177 - acc: 0.7688 - val_loss: 0.4757 - val_acc: 0.8217\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.4949 - acc: 0.7826 - val_loss: 0.4817 - val_acc: 0.8109\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 306us/sample - loss: 0.4822 - acc: 0.7923 - val_loss: 0.4768 - val_acc: 0.8022\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.4618 - acc: 0.7988 - val_loss: 0.4401 - val_acc: 0.8130\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 313us/sample - loss: 0.4488 - acc: 0.8027 - val_loss: 0.4250 - val_acc: 0.8239\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.4381 - acc: 0.8041 - val_loss: 0.4121 - val_acc: 0.8174\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 1s 315us/sample - loss: 0.4279 - acc: 0.8174 - val_loss: 0.3918 - val_acc: 0.8370\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 1s 347us/sample - loss: 0.4148 - acc: 0.8254 - val_loss: 0.3999 - val_acc: 0.8152\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 2s 373us/sample - loss: 0.4129 - acc: 0.8215 - val_loss: 0.4009 - val_acc: 0.8152\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 2s 509us/sample - loss: 0.3918 - acc: 0.8285 - val_loss: 0.3822 - val_acc: 0.8391\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 4s 900us/sample - loss: 0.3968 - acc: 0.8273 - val_loss: 0.3948 - val_acc: 0.8217\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.3843 - acc: 0.8336 - val_loss: 0.4275 - val_acc: 0.8065\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 6s 1ms/sample - loss: 0.3968 - acc: 0.8280 - val_loss: 0.4160 - val_acc: 0.8065\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3792 - acc: 0.8367 - val_loss: 0.3996 - val_acc: 0.8283\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3709 - acc: 0.8372 - val_loss: 0.4319 - val_acc: 0.7804\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3812 - acc: 0.8280 - val_loss: 0.4043 - val_acc: 0.7978\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3730 - acc: 0.8411 - val_loss: 0.3778 - val_acc: 0.8391\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3644 - acc: 0.8447 - val_loss: 0.3960 - val_acc: 0.8261\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3507 - acc: 0.8461 - val_loss: 0.4058 - val_acc: 0.8239\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3453 - acc: 0.8490 - val_loss: 0.4091 - val_acc: 0.8065\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3417 - acc: 0.8514 - val_loss: 0.4057 - val_acc: 0.8217\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3247 - acc: 0.8553 - val_loss: 0.4098 - val_acc: 0.8174\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3202 - acc: 0.8556 - val_loss: 0.4126 - val_acc: 0.8217\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3194 - acc: 0.8589 - val_loss: 0.4120 - val_acc: 0.8152\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3261 - acc: 0.8478 - val_loss: 0.4253 - val_acc: 0.8130\n",
      "100/100 [==============================] - 1s 5ms/sample - loss: 0.3404 - acc: 0.8700\n",
      "logs/fit/bn_lstm/kfold7\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 24s 6ms/sample - loss: 0.6900 - acc: 0.5816 - val_loss: 0.6902 - val_acc: 0.5674\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 315us/sample - loss: 0.6719 - acc: 0.6481 - val_loss: 0.6857 - val_acc: 0.5739\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 317us/sample - loss: 0.6395 - acc: 0.6862 - val_loss: 0.6714 - val_acc: 0.6196\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.5866 - acc: 0.7413 - val_loss: 0.6146 - val_acc: 0.7913\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 315us/sample - loss: 0.5429 - acc: 0.7708 - val_loss: 0.5794 - val_acc: 0.7913\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 319us/sample - loss: 0.5076 - acc: 0.7843 - val_loss: 0.4984 - val_acc: 0.8348\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.4882 - acc: 0.7944 - val_loss: 0.4808 - val_acc: 0.8109\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 313us/sample - loss: 0.4741 - acc: 0.7944 - val_loss: 0.4702 - val_acc: 0.8065\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 1s 311us/sample - loss: 0.4633 - acc: 0.7944 - val_loss: 0.4557 - val_acc: 0.7957\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 1s 341us/sample - loss: 0.4453 - acc: 0.8056 - val_loss: 0.4589 - val_acc: 0.7935\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 1s 343us/sample - loss: 0.4442 - acc: 0.8133 - val_loss: 0.4698 - val_acc: 0.7848\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 2s 466us/sample - loss: 0.4360 - acc: 0.8114 - val_loss: 0.4468 - val_acc: 0.7870\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 3s 664us/sample - loss: 0.4285 - acc: 0.8213 - val_loss: 0.4132 - val_acc: 0.8174\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.4052 - acc: 0.8326 - val_loss: 0.3987 - val_acc: 0.8391\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.4241 - acc: 0.8225 - val_loss: 0.3907 - val_acc: 0.8326\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 7s 2ms/sample - loss: 0.4136 - acc: 0.8237 - val_loss: 0.3897 - val_acc: 0.8370\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4163 - acc: 0.8268 - val_loss: 0.3925 - val_acc: 0.8457\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4077 - acc: 0.8246 - val_loss: 0.3910 - val_acc: 0.8304\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3967 - acc: 0.8258 - val_loss: 0.3868 - val_acc: 0.8478\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3942 - acc: 0.8353 - val_loss: 0.4052 - val_acc: 0.8326\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3761 - acc: 0.8374 - val_loss: 0.4080 - val_acc: 0.8391\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3594 - acc: 0.8490 - val_loss: 0.4253 - val_acc: 0.8239\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3785 - acc: 0.8336 - val_loss: 0.4664 - val_acc: 0.8022\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3561 - acc: 0.8442 - val_loss: 0.4271 - val_acc: 0.8478\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3522 - acc: 0.8553 - val_loss: 0.4253 - val_acc: 0.8478\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3483 - acc: 0.8570 - val_loss: 0.4223 - val_acc: 0.8478\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3255 - acc: 0.8662 - val_loss: 0.4541 - val_acc: 0.8304\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3316 - acc: 0.8635 - val_loss: 0.4546 - val_acc: 0.8152\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3269 - acc: 0.8645 - val_loss: 0.4865 - val_acc: 0.8043\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3212 - acc: 0.8713 - val_loss: 0.4744 - val_acc: 0.8283\n",
      "100/100 [==============================] - 1s 5ms/sample - loss: 0.5619 - acc: 0.8000\n",
      "logs/fit/bn_lstm/kfold8\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 12s 3ms/sample - loss: 0.6844 - acc: 0.6104 - val_loss: 0.6890 - val_acc: 0.5848\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 312us/sample - loss: 0.6625 - acc: 0.6413 - val_loss: 0.6495 - val_acc: 0.6717\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 310us/sample - loss: 0.6413 - acc: 0.6708 - val_loss: 0.6397 - val_acc: 0.6826\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 309us/sample - loss: 0.6408 - acc: 0.6490 - val_loss: 0.6358 - val_acc: 0.6391\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 308us/sample - loss: 0.6282 - acc: 0.6710 - val_loss: 0.6884 - val_acc: 0.5826\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 1s 314us/sample - loss: 0.6542 - acc: 0.6155 - val_loss: 0.6483 - val_acc: 0.6022\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 1s 338us/sample - loss: 0.6616 - acc: 0.6089 - val_loss: 0.6395 - val_acc: 0.6913\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 1s 347us/sample - loss: 0.6562 - acc: 0.6225 - val_loss: 0.6382 - val_acc: 0.7022\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 2s 446us/sample - loss: 0.6505 - acc: 0.6365 - val_loss: 0.6378 - val_acc: 0.6978\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 4s 889us/sample - loss: 0.6494 - acc: 0.6357 - val_loss: 0.6370 - val_acc: 0.6739\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.6545 - acc: 0.6273 - val_loss: 0.6373 - val_acc: 0.6609\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.6506 - acc: 0.6297 - val_loss: 0.6370 - val_acc: 0.6435\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6436 - acc: 0.6345 - val_loss: 0.6358 - val_acc: 0.6413\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6461 - acc: 0.6348 - val_loss: 0.6370 - val_acc: 0.6283\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6466 - acc: 0.6287 - val_loss: 0.6355 - val_acc: 0.6304\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6437 - acc: 0.6312 - val_loss: 0.6321 - val_acc: 0.6500\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6405 - acc: 0.6432 - val_loss: 0.6285 - val_acc: 0.6565\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6395 - acc: 0.6360 - val_loss: 0.6330 - val_acc: 0.6283\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6402 - acc: 0.6415 - val_loss: 0.6308 - val_acc: 0.6348\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6465 - acc: 0.6302 - val_loss: 0.6274 - val_acc: 0.6522\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6321 - acc: 0.6522 - val_loss: 0.6236 - val_acc: 0.6652\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6380 - acc: 0.6459 - val_loss: 0.6187 - val_acc: 0.6891\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.6258 - acc: 0.6524 - val_loss: 0.6125 - val_acc: 0.6978\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6275 - acc: 0.6512 - val_loss: 0.6074 - val_acc: 0.6978\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6231 - acc: 0.6505 - val_loss: 0.6120 - val_acc: 0.6870\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6296 - acc: 0.6457 - val_loss: 0.6077 - val_acc: 0.6957\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6231 - acc: 0.6609 - val_loss: 0.6038 - val_acc: 0.6957\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6152 - acc: 0.6681 - val_loss: 0.5957 - val_acc: 0.7022\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6131 - acc: 0.6763 - val_loss: 0.5850 - val_acc: 0.6957\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.6130 - acc: 0.6848 - val_loss: 0.5800 - val_acc: 0.7283\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.5474 - acc: 0.7900\n",
      "logs/fit/bn_lstm/kfold9\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 12s 3ms/sample - loss: 0.6855 - acc: 0.6010 - val_loss: 0.6889 - val_acc: 0.5696\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 1s 311us/sample - loss: 0.6538 - acc: 0.6831 - val_loss: 0.6731 - val_acc: 0.6783\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.6079 - acc: 0.7302 - val_loss: 0.6409 - val_acc: 0.7457\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 1s 338us/sample - loss: 0.5547 - acc: 0.7671 - val_loss: 0.5767 - val_acc: 0.8109\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 1s 348us/sample - loss: 0.5110 - acc: 0.7911 - val_loss: 0.5205 - val_acc: 0.8109\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 2s 486us/sample - loss: 0.4790 - acc: 0.8080 - val_loss: 0.4783 - val_acc: 0.8261\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 3s 748us/sample - loss: 0.4730 - acc: 0.8014 - val_loss: 0.4591 - val_acc: 0.8217\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.4501 - acc: 0.8133 - val_loss: 0.4415 - val_acc: 0.8261\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.4523 - acc: 0.8060 - val_loss: 0.4266 - val_acc: 0.8196\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4264 - acc: 0.8184 - val_loss: 0.4352 - val_acc: 0.8217\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4208 - acc: 0.8251 - val_loss: 0.4394 - val_acc: 0.8152\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4228 - acc: 0.8179 - val_loss: 0.4818 - val_acc: 0.7891\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4206 - acc: 0.8222 - val_loss: 0.5002 - val_acc: 0.7674\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4272 - acc: 0.8254 - val_loss: 0.4247 - val_acc: 0.8109\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4071 - acc: 0.8290 - val_loss: 0.4659 - val_acc: 0.7935\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3993 - acc: 0.8384 - val_loss: 0.4023 - val_acc: 0.8304\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3925 - acc: 0.8435 - val_loss: 0.4018 - val_acc: 0.8370\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3757 - acc: 0.8454 - val_loss: 0.4214 - val_acc: 0.8304\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3746 - acc: 0.8575 - val_loss: 0.3903 - val_acc: 0.8304\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3724 - acc: 0.8471 - val_loss: 0.3843 - val_acc: 0.8391\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3633 - acc: 0.8543 - val_loss: 0.3997 - val_acc: 0.8370\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3610 - acc: 0.8469 - val_loss: 0.3960 - val_acc: 0.8283\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3495 - acc: 0.8589 - val_loss: 0.3785 - val_acc: 0.8261\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3411 - acc: 0.8565 - val_loss: 0.3843 - val_acc: 0.8304\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3374 - acc: 0.8585 - val_loss: 0.3935 - val_acc: 0.8304\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3368 - acc: 0.8560 - val_loss: 0.3979 - val_acc: 0.8326\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3271 - acc: 0.8570 - val_loss: 0.3964 - val_acc: 0.8370\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3352 - acc: 0.8667 - val_loss: 0.3906 - val_acc: 0.8348\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3330 - acc: 0.8616 - val_loss: 0.4755 - val_acc: 0.8174\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3513 - acc: 0.8609 - val_loss: 0.3897 - val_acc: 0.8457\n",
      "100/100 [==============================] - 1s 5ms/sample - loss: 0.3799 - acc: 0.8400\n",
      "logs/fit/bn_lstm/kfold10\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 [==============================] - 13s 3ms/sample - loss: 0.6911 - acc: 0.5773 - val_loss: 0.6890 - val_acc: 0.6109\n",
      "Epoch 2/30\n",
      "4140/4140 [==============================] - 2s 432us/sample - loss: 0.6791 - acc: 0.6140 - val_loss: 0.6812 - val_acc: 0.6196\n",
      "Epoch 3/30\n",
      "4140/4140 [==============================] - 2s 569us/sample - loss: 0.6613 - acc: 0.6452 - val_loss: 0.6669 - val_acc: 0.6478\n",
      "Epoch 4/30\n",
      "4140/4140 [==============================] - 4s 1ms/sample - loss: 0.6211 - acc: 0.6860 - val_loss: 0.6199 - val_acc: 0.7326\n",
      "Epoch 5/30\n",
      "4140/4140 [==============================] - 5s 1ms/sample - loss: 0.5715 - acc: 0.7329 - val_loss: 0.5569 - val_acc: 0.7870\n",
      "Epoch 6/30\n",
      "4140/4140 [==============================] - 7s 2ms/sample - loss: 0.5338 - acc: 0.7630 - val_loss: 0.5208 - val_acc: 0.8043\n",
      "Epoch 7/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.5141 - acc: 0.7766 - val_loss: 0.5008 - val_acc: 0.8043\n",
      "Epoch 8/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4960 - acc: 0.7874 - val_loss: 0.4870 - val_acc: 0.8022\n",
      "Epoch 9/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4797 - acc: 0.7969 - val_loss: 0.4693 - val_acc: 0.7957\n",
      "Epoch 10/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4689 - acc: 0.7971 - val_loss: 0.4263 - val_acc: 0.8217\n",
      "Epoch 11/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4575 - acc: 0.8017 - val_loss: 0.4061 - val_acc: 0.8348\n",
      "Epoch 12/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4709 - acc: 0.7935 - val_loss: 0.5144 - val_acc: 0.7413\n",
      "Epoch 13/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4423 - acc: 0.8121 - val_loss: 0.4309 - val_acc: 0.8130\n",
      "Epoch 14/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4302 - acc: 0.8065 - val_loss: 0.4499 - val_acc: 0.8022\n",
      "Epoch 15/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4295 - acc: 0.8193 - val_loss: 0.4535 - val_acc: 0.8065\n",
      "Epoch 16/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4099 - acc: 0.8193 - val_loss: 0.4226 - val_acc: 0.8239\n",
      "Epoch 17/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.4314 - acc: 0.8072 - val_loss: 0.4494 - val_acc: 0.7870\n",
      "Epoch 18/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4172 - acc: 0.8169 - val_loss: 0.4248 - val_acc: 0.8217\n",
      "Epoch 19/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4110 - acc: 0.8249 - val_loss: 0.4408 - val_acc: 0.7848\n",
      "Epoch 20/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.4001 - acc: 0.8263 - val_loss: 0.4290 - val_acc: 0.8152\n",
      "Epoch 21/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3866 - acc: 0.8229 - val_loss: 0.4224 - val_acc: 0.8239\n",
      "Epoch 22/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3929 - acc: 0.8273 - val_loss: 0.4526 - val_acc: 0.7913\n",
      "Epoch 23/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3923 - acc: 0.8234 - val_loss: 0.4511 - val_acc: 0.7870\n",
      "Epoch 24/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3852 - acc: 0.8302 - val_loss: 0.4386 - val_acc: 0.7891\n",
      "Epoch 25/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3784 - acc: 0.8302 - val_loss: 0.4505 - val_acc: 0.7891\n",
      "Epoch 26/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3708 - acc: 0.8287 - val_loss: 0.4702 - val_acc: 0.7696\n",
      "Epoch 27/30\n",
      "4140/4140 [==============================] - 9s 2ms/sample - loss: 0.3818 - acc: 0.8232 - val_loss: 0.4620 - val_acc: 0.7804\n",
      "Epoch 28/30\n",
      "4140/4140 [==============================] - 8s 2ms/sample - loss: 0.3683 - acc: 0.8331 - val_loss: 0.4567 - val_acc: 0.7848\n",
      "Epoch 29/30\n",
      "4140/4140 [==============================] - 3s 817us/sample - loss: 0.3691 - acc: 0.8208 - val_loss: 0.4505 - val_acc: 0.7891\n",
      "Epoch 30/30\n",
      "4140/4140 [==============================] - 1s 307us/sample - loss: 0.3659 - acc: 0.8316 - val_loss: 0.4567 - val_acc: 0.7957\n",
      "100/100 [==============================] - 0s 631us/sample - loss: 0.4429 - acc: 0.8100\n"
     ]
    }
   ],
   "source": [
    "def create_bn_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(10, kernel_initializer='normal', activation='relu', input_shape=(28, 300), name='lstm'),\n",
    "        tf.keras.layers.Dropout(0.7),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='normal', name='dense')\n",
    "    ])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "bn_hist, bn_evas = kfold_train(create_bn_model, 'bn_lstm', batch_size=128, epochs=30, shuffle=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.449343</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.409371</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.431744</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.370904</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.503804</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.340413</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.561920</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.547365</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.379911</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.442909</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1\n",
       "0  0.449343  0.82\n",
       "1  0.409371  0.83\n",
       "2  0.431744  0.85\n",
       "3  0.370904  0.86\n",
       "4  0.503804  0.81\n",
       "5  0.340413  0.87\n",
       "6  0.561920  0.80\n",
       "7  0.547365  0.79\n",
       "8  0.379911  0.84\n",
       "9  0.442909  0.81"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_evas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "a76af720-f35f-4d9c-a123-65862bff385c",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6913186464332728,
          0.6813600243001744,
          0.6528397858430798,
          0.6072300019471542,
          0.5547859274822733,
          0.5102923538949754,
          0.4813753148783808,
          0.4601614468915451,
          0.4383012043969067,
          0.41977641677510913,
          0.422211089687071,
          0.4107410800053877,
          0.3995487392236645,
          0.3986584643810844,
          0.3807625667772431,
          0.3743529767229937,
          0.36428693815129964,
          0.35382346787314484,
          0.34658000459129684,
          0.3654783548076372,
          0.35654349674061303,
          0.3460450606645593,
          0.339403957646826,
          0.32277128103274655,
          0.31944060532943064,
          0.29769499175214537,
          0.2987655406124926,
          0.2963710412311093,
          0.30131764249237264,
          0.2754309624289545
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "e6ffe258-db47-4d2a-9519-d7d312ef7df4",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.690480373216712,
          0.685477328300476,
          0.6639526615972104,
          0.6153452287549558,
          0.5414844844652259,
          0.5039323721242988,
          0.4752821484337682,
          0.43396228214968807,
          0.4254293353661247,
          0.4034723100454911,
          0.43137045943218727,
          0.41126609703768857,
          0.3976961807064388,
          0.4202854830285777,
          0.41241805320200714,
          0.4229475555212601,
          0.40992697632831077,
          0.4270821203356204,
          0.42970999660699266,
          0.5063756186029186,
          0.4537631649038066,
          0.4355973990067192,
          0.42295080967571425,
          0.4165850121042003,
          0.4320613498273103,
          0.4483449129954628,
          0.4473477806734002,
          0.442378292394721,
          0.4608945659969164,
          0.4503888987976572
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "c92d5663-4e00-4b00-93a7-afeefe21a7a3",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6877623057595773,
          0.66454267386653,
          0.6143461090930994,
          0.5714071680382254,
          0.5290671439274498,
          0.5053933936328704,
          0.4872137046954482,
          0.4836588364292458,
          0.4685295399548351,
          0.4540047243309482,
          0.4492605338925901,
          0.42960539546565735,
          0.4399900976586457,
          0.42428113043596205,
          0.41384426004068864,
          0.399546239974994,
          0.39041268131583207,
          0.3807364123454992,
          0.3656646926909829,
          0.364221454559317,
          0.35650660700844106,
          0.3594837854161931,
          0.35398800974882744,
          0.3461760748555695,
          0.3480561011367374,
          0.33934166379596875,
          0.328528543745262,
          0.32531339935058556,
          0.3184924368121198,
          0.31668271834147727
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "ea453119-5a45-48dc-a29b-24ba0a68a0c2",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.688226856874383,
          0.674420212144437,
          0.6371147782906242,
          0.6246602716653243,
          0.56150338338769,
          0.5278297584989796,
          0.4752235816872638,
          0.427192937809488,
          0.40549016646716907,
          0.38964793474777887,
          0.39129218122233517,
          0.3829990679803102,
          0.37429721018542417,
          0.39309305108111836,
          0.40924417920734574,
          0.40440428153328273,
          0.41417639100033304,
          0.40952417876409447,
          0.4396995147933131,
          0.4031967987184939,
          0.405227713222089,
          0.44471240536026335,
          0.4212570371835128,
          0.4188359172447868,
          0.40809110739956733,
          0.40995656640633293,
          0.4189102084740349,
          0.4523061091485231,
          0.42426331691119984,
          0.4358163755872975
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "ffec5fcf-723f-4d61-beeb-59e4d0dd35f8",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6914981264998947,
          0.6757189478275281,
          0.6213797041759399,
          0.5691263298481559,
          0.5292417278036403,
          0.49781222144762677,
          0.4786038116556435,
          0.4590311579370268,
          0.4461400450427751,
          0.4369285795711665,
          0.42897642747215603,
          0.42548895901527956,
          0.40807732216977843,
          0.406452505024159,
          0.3929611523082291,
          0.384924822844169,
          0.4001756816670515,
          0.3970916240111641,
          0.37920116825380185,
          0.3987651373741131,
          0.3742465805316317,
          0.3627118513923912,
          0.378184030280597,
          0.3768626861094277,
          0.36351114613710395,
          0.35576526223173466,
          0.34227019364131245,
          0.3363729855576575,
          0.33801506700147177,
          0.3297634793940374
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "52b0488b-3aa8-4464-b153-db6701b9e99c",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6886422789615133,
          0.6788025265154631,
          0.657047102244004,
          0.6197538951168889,
          0.5663136005401611,
          0.5305003389068271,
          0.4948881683142289,
          0.452300263746925,
          0.4386952358743419,
          0.43264515425847927,
          0.4105222484339838,
          0.41511591232341266,
          0.41508761748023654,
          0.41396210919255794,
          0.40278302068295685,
          0.4000653562338456,
          0.4429917936739714,
          0.4403609216213226,
          0.4648330253103505,
          0.41684891115064204,
          0.4439632192901943,
          0.4578585780185202,
          0.42488470984541854,
          0.42327760639397993,
          0.4161703876827074,
          0.42427524094996244,
          0.4086559127206388,
          0.42694945335388185,
          0.43665022331735365,
          0.420335520868716
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "6a896dd7-41a1-4998-98fe-2266afbcf18f",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.689797320112514,
          0.6532184849038792,
          0.6129032400495188,
          0.5760324931950961,
          0.54495952901057,
          0.5258734203767086,
          0.5064853197710526,
          0.48965456485748293,
          0.4775381694669309,
          0.47156267972384097,
          0.46948473922872314,
          0.4580593856924398,
          0.45296818919227894,
          0.4460918735478811,
          0.4379989722500677,
          0.4369411748388539,
          0.4301156737666199,
          0.4274914262663339,
          0.41951189686134815,
          0.4311819893438459,
          0.4355765678168495,
          0.4125499246776968,
          0.4005097568323071,
          0.3952489429913857,
          0.39690424598357527,
          0.37822846398837323,
          0.37749297454737235,
          0.3802204394973994,
          0.3603578907568098,
          0.35066496361280985
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "8955c227-e83f-4694-a58e-5f4b4462cab2",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6884519950203274,
          0.6434775435406229,
          0.573636691984923,
          0.5328901068024013,
          0.5150607712890791,
          0.48755307612211807,
          0.47637453519779704,
          0.4523494274719902,
          0.4493017922277036,
          0.4305104771386022,
          0.42576380916263745,
          0.4207640593466551,
          0.4225618574930274,
          0.4386586482110231,
          0.4272984483967657,
          0.44917562267054684,
          0.4290649266346641,
          0.4094557383786077,
          0.4207423368225927,
          0.4059335029643515,
          0.40308589209680973,
          0.4266146076762158,
          0.40303597502086475,
          0.399407870873161,
          0.41741511251615443,
          0.4271190783251887,
          0.4495023911413939,
          0.4182131570318471,
          0.41540339355883393,
          0.42212382295857304
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "062b7fa3-c2d7-43c7-bc86-e0984d5d3972",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6873592296084344,
          0.6539897980321433,
          0.5991937827948787,
          0.5502908639285875,
          0.506102366666287,
          0.4743441720515634,
          0.45912849606523193,
          0.4506726416988649,
          0.43573598262768437,
          0.4254409112792084,
          0.4192447901347985,
          0.4079362228296805,
          0.40890191897102024,
          0.40167834364273697,
          0.39943933944771254,
          0.4013646308062733,
          0.3893535968474144,
          0.3738944091082771,
          0.35391691629437433,
          0.36900800647942916,
          0.3515839275242626,
          0.34858248717543006,
          0.3627744457859924,
          0.3434744798618814,
          0.3399721141886596,
          0.3480709559963521,
          0.32367129094070857,
          0.3234556786679991,
          0.3385848216676482,
          0.3056749534779701
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "a4f48513-49c2-4da2-9679-04711f2f81c1",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6895642881808074,
          0.6474005372627921,
          0.5660395378651826,
          0.5479833359303682,
          0.5112324071967084,
          0.46751083809396493,
          0.4639431419579879,
          0.4406553911126178,
          0.4051457767901213,
          0.4001142478507498,
          0.41178295508674956,
          0.3742067305938057,
          0.39984365546185036,
          0.4010279743567757,
          0.3880764287451039,
          0.3803394307260928,
          0.3991072387798973,
          0.3919616691444231,
          0.38552548056063446,
          0.39442805181378904,
          0.3904366583927818,
          0.4039082796677299,
          0.40302517025367074,
          0.41880238263503367,
          0.4566027309583581,
          0.39224056342373725,
          0.4152909133745276,
          0.4009859103223552,
          0.41083531794340716,
          0.453971150647039
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "f88f3835-104c-4a83-ab85-c983dc63a81e",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6913550409717836,
          0.6827488995404635,
          0.6514254849314114,
          0.6061922541563062,
          0.5489472217605885,
          0.5177432679035814,
          0.4948738610110997,
          0.48224916455250433,
          0.46183438839543844,
          0.44879254235161675,
          0.43807155780746165,
          0.42791481055499275,
          0.41481482950961535,
          0.4128917038440704,
          0.39180278510287186,
          0.39678975384016546,
          0.3843432972108684,
          0.396814454264111,
          0.37917229633976296,
          0.37089574958967125,
          0.3812375673061408,
          0.37301923521762886,
          0.36438307885962407,
          0.3507445149951511,
          0.34529110440885386,
          0.34174429925455563,
          0.3247342505172831,
          0.3201529986904439,
          0.3194398202038042,
          0.3261292227512396
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "725f1079-a5e5-459c-9477-8758c307caff",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.690262074055879,
          0.6861305718836577,
          0.6660963514576788,
          0.5482542758402618,
          0.502511507531871,
          0.4756772963897042,
          0.481709825474283,
          0.4768332460652227,
          0.4400569920954497,
          0.4250052001165307,
          0.4120935795099839,
          0.3918423108432604,
          0.39993448127870973,
          0.4009174201799476,
          0.3821832662043364,
          0.3948467415312062,
          0.4274927380292312,
          0.4159670834955962,
          0.3996226279631905,
          0.43194104925445886,
          0.40428466045338174,
          0.37782961000566895,
          0.39599868318308956,
          0.40576182059619736,
          0.4091309744378795,
          0.40565576346024224,
          0.4097767420437025,
          0.41261936581653097,
          0.411977948313174,
          0.4253141851528831
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "67f18583-e58c-4653-9244-107877428dab",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6899796742747947,
          0.671862424686911,
          0.639492402387702,
          0.5865837573429237,
          0.5429347268049268,
          0.5075651531058233,
          0.48818107434516944,
          0.47413580348526224,
          0.46328959701141875,
          0.44529978817211835,
          0.44419996608858525,
          0.43597891517883336,
          0.4284655756708505,
          0.40522514979044594,
          0.4241437019645304,
          0.4136397892438271,
          0.41633915932858045,
          0.4077330479875279,
          0.3967261769345417,
          0.3941870546283353,
          0.3761473336369519,
          0.35936980587272827,
          0.3784551179351438,
          0.35605312015699303,
          0.3522413098005857,
          0.3483208560425302,
          0.3255052570271607,
          0.3315507295051059,
          0.3269429947155109,
          0.32117026661329223
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "02412592-7ae9-4010-a1a7-f7aeb0ff6b0e",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6901635688284169,
          0.6856682533803193,
          0.6713951012362604,
          0.614558391985686,
          0.57937759782957,
          0.4983836111815079,
          0.48078155439832937,
          0.4701748739118161,
          0.4556961450887763,
          0.4589429114175879,
          0.46978807682576385,
          0.44680699965228204,
          0.41324346221011615,
          0.3987090481364209,
          0.39070261950078217,
          0.3896879292052725,
          0.39253389161566027,
          0.3910183261270108,
          0.3867906101371931,
          0.4051620654437853,
          0.407967295853988,
          0.42529773712158203,
          0.46644909900167714,
          0.4270766159762507,
          0.4253265121708745,
          0.4222788955854333,
          0.4540863936362059,
          0.45463500541189444,
          0.4864930764488552,
          0.4744331963684248
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "eb4724e4-abb3-402f-bb07-7724722c6b52",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6844277871979607,
          0.66245509541553,
          0.6412876281761317,
          0.6407934116280597,
          0.6281596096241532,
          0.6542235884113589,
          0.6615723201618102,
          0.6561688724923249,
          0.6504505454054201,
          0.6494112757668979,
          0.654482738925639,
          0.6506236192108928,
          0.6435742545818937,
          0.6461101663285408,
          0.646554690628236,
          0.6437104623674771,
          0.6405462634160323,
          0.6394535743671915,
          0.6401597190594328,
          0.6464734008922669,
          0.6320590206390417,
          0.6379578529924587,
          0.6257689993738552,
          0.6274969556481366,
          0.6230844072097741,
          0.6296395419300467,
          0.623060987709801,
          0.6152251999159366,
          0.6131279661459623,
          0.6130047528064193
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "8c7395ef-48ac-40ea-920a-706db4de898a",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6889592243277508,
          0.6495276834653771,
          0.6397390728411467,
          0.6358206220295118,
          0.6884261535561603,
          0.6483277730319811,
          0.6395054506218951,
          0.6382372768028922,
          0.6378266956495202,
          0.6370313354160475,
          0.6373312944951265,
          0.6370467927144922,
          0.6358481319054313,
          0.6370108013567717,
          0.6354891901430877,
          0.6320919534434443,
          0.6284516790638799,
          0.6329752377841784,
          0.6308036353277123,
          0.6273668921512107,
          0.6236005176668582,
          0.6186732245528179,
          0.6124881184619406,
          0.6073678286179253,
          0.6120085602221281,
          0.6076772332191467,
          0.603763501022173,
          0.5956578503484311,
          0.584987527391185,
          0.5800049113190693
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "f6dec66d-9148-422e-b347-5773b8ed1f63",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6855338125413166,
          0.6537517772204634,
          0.6079012817806668,
          0.5547302060657078,
          0.5109746901309432,
          0.4789832710931842,
          0.47295596855850036,
          0.450131334659558,
          0.4522893315927994,
          0.42636044494771724,
          0.42076286929817014,
          0.4228044536090703,
          0.42061252196629845,
          0.4272352535367588,
          0.4071035242886935,
          0.39926229850681505,
          0.39248259899696863,
          0.37570632353497013,
          0.37456276416778567,
          0.372365954676688,
          0.3633092985061056,
          0.3610475128975467,
          0.3494607430437337,
          0.34105138522415346,
          0.33742735342703006,
          0.3367877669380483,
          0.327147862991849,
          0.3352167087764556,
          0.33303943909884653,
          0.3512789569039276
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "f23ab833-27ae-4c0e-9ba5-7069bc9f1ca0",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6889319311017575,
          0.6730553678844287,
          0.6408950515415357,
          0.5766822934150696,
          0.5204589745272761,
          0.4782597946084064,
          0.4591163516044617,
          0.4415248930454254,
          0.4265573245027791,
          0.43515633240990015,
          0.43943328676016435,
          0.4818105117134426,
          0.5002194523811341,
          0.4246719692064368,
          0.4658649524916773,
          0.4023017061793286,
          0.40184836206228836,
          0.42144472521284354,
          0.39031505481056544,
          0.3842861515024434,
          0.39965235539104627,
          0.395953717439071,
          0.3785311740377675,
          0.3842694837114085,
          0.3935193981813348,
          0.3978627083094224,
          0.3963971594105596,
          0.39056257164996605,
          0.4755320056625035,
          0.38971339619677997
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "e151f096-aee4-4891-9944-49ec08ba23e7",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6910593209059342,
          0.6791186515835749,
          0.661299100878158,
          0.6211396047458556,
          0.5715280451636383,
          0.533828862508138,
          0.514137475617266,
          0.4960113333043269,
          0.47970275231029674,
          0.4688834196703445,
          0.4574728206447933,
          0.47089112593931853,
          0.44233962893486023,
          0.4302178322980945,
          0.4295311245365419,
          0.4099410209678797,
          0.43143074138153004,
          0.41720588515346174,
          0.4109857518603836,
          0.40011958877245585,
          0.38658982797521324,
          0.392886683791156,
          0.3923268025336058,
          0.38515005105935435,
          0.3783888387795232,
          0.3708047292370727,
          0.38176245902471495,
          0.3683071422116192,
          0.3691181821811602,
          0.3658791677099495
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "1e0593d5-9fba-432e-9841-25800e3e1dc0",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6890040869298188,
          0.6811693761659705,
          0.6669003688770792,
          0.6198690061983855,
          0.5569463227106177,
          0.5207855602969294,
          0.5008233324341153,
          0.4869796755521194,
          0.46927586223768153,
          0.42631143098292146,
          0.4061243720676588,
          0.5144496150638747,
          0.430895039309626,
          0.4498983372812686,
          0.45350471190784286,
          0.4226366768712583,
          0.4493733095086139,
          0.4247682402963224,
          0.4408307116964589,
          0.4289747971555461,
          0.42242464941480884,
          0.45258829515913257,
          0.45105396535085596,
          0.4385812492474266,
          0.4504818926686826,
          0.47021816839342534,
          0.46197039614553037,
          0.45674871595009514,
          0.45045417158500006,
          0.4566674258397973
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"2cd79df4-2ffc-4984-9737-9eeb58bfb3fb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"2cd79df4-2ffc-4984-9737-9eeb58bfb3fb\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '2cd79df4-2ffc-4984-9737-9eeb58bfb3fb',\n",
       "                        [{\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"a76af720-f35f-4d9c-a123-65862bff385c\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6913186464332728, 0.6813600243001744, 0.6528397858430798, 0.6072300019471542, 0.5547859274822733, 0.5102923538949754, 0.4813753148783808, 0.4601614468915451, 0.4383012043969067, 0.41977641677510913, 0.422211089687071, 0.4107410800053877, 0.3995487392236645, 0.3986584643810844, 0.3807625667772431, 0.3743529767229937, 0.36428693815129964, 0.35382346787314484, 0.34658000459129684, 0.3654783548076372, 0.35654349674061303, 0.3460450606645593, 0.339403957646826, 0.32277128103274655, 0.31944060532943064, 0.29769499175214537, 0.2987655406124926, 0.2963710412311093, 0.30131764249237264, 0.2754309624289545]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"e6ffe258-db47-4d2a-9519-d7d312ef7df4\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.690480373216712, 0.685477328300476, 0.6639526615972104, 0.6153452287549558, 0.5414844844652259, 0.5039323721242988, 0.4752821484337682, 0.43396228214968807, 0.4254293353661247, 0.4034723100454911, 0.43137045943218727, 0.41126609703768857, 0.3976961807064388, 0.4202854830285777, 0.41241805320200714, 0.4229475555212601, 0.40992697632831077, 0.4270821203356204, 0.42970999660699266, 0.5063756186029186, 0.4537631649038066, 0.4355973990067192, 0.42295080967571425, 0.4165850121042003, 0.4320613498273103, 0.4483449129954628, 0.4473477806734002, 0.442378292394721, 0.4608945659969164, 0.4503888987976572]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"c92d5663-4e00-4b00-93a7-afeefe21a7a3\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6877623057595773, 0.66454267386653, 0.6143461090930994, 0.5714071680382254, 0.5290671439274498, 0.5053933936328704, 0.4872137046954482, 0.4836588364292458, 0.4685295399548351, 0.4540047243309482, 0.4492605338925901, 0.42960539546565735, 0.4399900976586457, 0.42428113043596205, 0.41384426004068864, 0.399546239974994, 0.39041268131583207, 0.3807364123454992, 0.3656646926909829, 0.364221454559317, 0.35650660700844106, 0.3594837854161931, 0.35398800974882744, 0.3461760748555695, 0.3480561011367374, 0.33934166379596875, 0.328528543745262, 0.32531339935058556, 0.3184924368121198, 0.31668271834147727]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"ea453119-5a45-48dc-a29b-24ba0a68a0c2\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.688226856874383, 0.674420212144437, 0.6371147782906242, 0.6246602716653243, 0.56150338338769, 0.5278297584989796, 0.4752235816872638, 0.427192937809488, 0.40549016646716907, 0.38964793474777887, 0.39129218122233517, 0.3829990679803102, 0.37429721018542417, 0.39309305108111836, 0.40924417920734574, 0.40440428153328273, 0.41417639100033304, 0.40952417876409447, 0.4396995147933131, 0.4031967987184939, 0.405227713222089, 0.44471240536026335, 0.4212570371835128, 0.4188359172447868, 0.40809110739956733, 0.40995656640633293, 0.4189102084740349, 0.4523061091485231, 0.42426331691119984, 0.4358163755872975]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"ffec5fcf-723f-4d61-beeb-59e4d0dd35f8\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6914981264998947, 0.6757189478275281, 0.6213797041759399, 0.5691263298481559, 0.5292417278036403, 0.49781222144762677, 0.4786038116556435, 0.4590311579370268, 0.4461400450427751, 0.4369285795711665, 0.42897642747215603, 0.42548895901527956, 0.40807732216977843, 0.406452505024159, 0.3929611523082291, 0.384924822844169, 0.4001756816670515, 0.3970916240111641, 0.37920116825380185, 0.3987651373741131, 0.3742465805316317, 0.3627118513923912, 0.378184030280597, 0.3768626861094277, 0.36351114613710395, 0.35576526223173466, 0.34227019364131245, 0.3363729855576575, 0.33801506700147177, 0.3297634793940374]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"52b0488b-3aa8-4464-b153-db6701b9e99c\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6886422789615133, 0.6788025265154631, 0.657047102244004, 0.6197538951168889, 0.5663136005401611, 0.5305003389068271, 0.4948881683142289, 0.452300263746925, 0.4386952358743419, 0.43264515425847927, 0.4105222484339838, 0.41511591232341266, 0.41508761748023654, 0.41396210919255794, 0.40278302068295685, 0.4000653562338456, 0.4429917936739714, 0.4403609216213226, 0.4648330253103505, 0.41684891115064204, 0.4439632192901943, 0.4578585780185202, 0.42488470984541854, 0.42327760639397993, 0.4161703876827074, 0.42427524094996244, 0.4086559127206388, 0.42694945335388185, 0.43665022331735365, 0.420335520868716]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"6a896dd7-41a1-4998-98fe-2266afbcf18f\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.689797320112514, 0.6532184849038792, 0.6129032400495188, 0.5760324931950961, 0.54495952901057, 0.5258734203767086, 0.5064853197710526, 0.48965456485748293, 0.4775381694669309, 0.47156267972384097, 0.46948473922872314, 0.4580593856924398, 0.45296818919227894, 0.4460918735478811, 0.4379989722500677, 0.4369411748388539, 0.4301156737666199, 0.4274914262663339, 0.41951189686134815, 0.4311819893438459, 0.4355765678168495, 0.4125499246776968, 0.4005097568323071, 0.3952489429913857, 0.39690424598357527, 0.37822846398837323, 0.37749297454737235, 0.3802204394973994, 0.3603578907568098, 0.35066496361280985]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"8955c227-e83f-4694-a58e-5f4b4462cab2\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6884519950203274, 0.6434775435406229, 0.573636691984923, 0.5328901068024013, 0.5150607712890791, 0.48755307612211807, 0.47637453519779704, 0.4523494274719902, 0.4493017922277036, 0.4305104771386022, 0.42576380916263745, 0.4207640593466551, 0.4225618574930274, 0.4386586482110231, 0.4272984483967657, 0.44917562267054684, 0.4290649266346641, 0.4094557383786077, 0.4207423368225927, 0.4059335029643515, 0.40308589209680973, 0.4266146076762158, 0.40303597502086475, 0.399407870873161, 0.41741511251615443, 0.4271190783251887, 0.4495023911413939, 0.4182131570318471, 0.41540339355883393, 0.42212382295857304]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"062b7fa3-c2d7-43c7-bc86-e0984d5d3972\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6873592296084344, 0.6539897980321433, 0.5991937827948787, 0.5502908639285875, 0.506102366666287, 0.4743441720515634, 0.45912849606523193, 0.4506726416988649, 0.43573598262768437, 0.4254409112792084, 0.4192447901347985, 0.4079362228296805, 0.40890191897102024, 0.40167834364273697, 0.39943933944771254, 0.4013646308062733, 0.3893535968474144, 0.3738944091082771, 0.35391691629437433, 0.36900800647942916, 0.3515839275242626, 0.34858248717543006, 0.3627744457859924, 0.3434744798618814, 0.3399721141886596, 0.3480709559963521, 0.32367129094070857, 0.3234556786679991, 0.3385848216676482, 0.3056749534779701]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"a4f48513-49c2-4da2-9679-04711f2f81c1\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6895642881808074, 0.6474005372627921, 0.5660395378651826, 0.5479833359303682, 0.5112324071967084, 0.46751083809396493, 0.4639431419579879, 0.4406553911126178, 0.4051457767901213, 0.4001142478507498, 0.41178295508674956, 0.3742067305938057, 0.39984365546185036, 0.4010279743567757, 0.3880764287451039, 0.3803394307260928, 0.3991072387798973, 0.3919616691444231, 0.38552548056063446, 0.39442805181378904, 0.3904366583927818, 0.4039082796677299, 0.40302517025367074, 0.41880238263503367, 0.4566027309583581, 0.39224056342373725, 0.4152909133745276, 0.4009859103223552, 0.41083531794340716, 0.453971150647039]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"f88f3835-104c-4a83-ab85-c983dc63a81e\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6913550409717836, 0.6827488995404635, 0.6514254849314114, 0.6061922541563062, 0.5489472217605885, 0.5177432679035814, 0.4948738610110997, 0.48224916455250433, 0.46183438839543844, 0.44879254235161675, 0.43807155780746165, 0.42791481055499275, 0.41481482950961535, 0.4128917038440704, 0.39180278510287186, 0.39678975384016546, 0.3843432972108684, 0.396814454264111, 0.37917229633976296, 0.37089574958967125, 0.3812375673061408, 0.37301923521762886, 0.36438307885962407, 0.3507445149951511, 0.34529110440885386, 0.34174429925455563, 0.3247342505172831, 0.3201529986904439, 0.3194398202038042, 0.3261292227512396]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"725f1079-a5e5-459c-9477-8758c307caff\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.690262074055879, 0.6861305718836577, 0.6660963514576788, 0.5482542758402618, 0.502511507531871, 0.4756772963897042, 0.481709825474283, 0.4768332460652227, 0.4400569920954497, 0.4250052001165307, 0.4120935795099839, 0.3918423108432604, 0.39993448127870973, 0.4009174201799476, 0.3821832662043364, 0.3948467415312062, 0.4274927380292312, 0.4159670834955962, 0.3996226279631905, 0.43194104925445886, 0.40428466045338174, 0.37782961000566895, 0.39599868318308956, 0.40576182059619736, 0.4091309744378795, 0.40565576346024224, 0.4097767420437025, 0.41261936581653097, 0.411977948313174, 0.4253141851528831]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"67f18583-e58c-4653-9244-107877428dab\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6899796742747947, 0.671862424686911, 0.639492402387702, 0.5865837573429237, 0.5429347268049268, 0.5075651531058233, 0.48818107434516944, 0.47413580348526224, 0.46328959701141875, 0.44529978817211835, 0.44419996608858525, 0.43597891517883336, 0.4284655756708505, 0.40522514979044594, 0.4241437019645304, 0.4136397892438271, 0.41633915932858045, 0.4077330479875279, 0.3967261769345417, 0.3941870546283353, 0.3761473336369519, 0.35936980587272827, 0.3784551179351438, 0.35605312015699303, 0.3522413098005857, 0.3483208560425302, 0.3255052570271607, 0.3315507295051059, 0.3269429947155109, 0.32117026661329223]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"02412592-7ae9-4010-a1a7-f7aeb0ff6b0e\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6901635688284169, 0.6856682533803193, 0.6713951012362604, 0.614558391985686, 0.57937759782957, 0.4983836111815079, 0.48078155439832937, 0.4701748739118161, 0.4556961450887763, 0.4589429114175879, 0.46978807682576385, 0.44680699965228204, 0.41324346221011615, 0.3987090481364209, 0.39070261950078217, 0.3896879292052725, 0.39253389161566027, 0.3910183261270108, 0.3867906101371931, 0.4051620654437853, 0.407967295853988, 0.42529773712158203, 0.46644909900167714, 0.4270766159762507, 0.4253265121708745, 0.4222788955854333, 0.4540863936362059, 0.45463500541189444, 0.4864930764488552, 0.4744331963684248]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"eb4724e4-abb3-402f-bb07-7724722c6b52\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6844277871979607, 0.66245509541553, 0.6412876281761317, 0.6407934116280597, 0.6281596096241532, 0.6542235884113589, 0.6615723201618102, 0.6561688724923249, 0.6504505454054201, 0.6494112757668979, 0.654482738925639, 0.6506236192108928, 0.6435742545818937, 0.6461101663285408, 0.646554690628236, 0.6437104623674771, 0.6405462634160323, 0.6394535743671915, 0.6401597190594328, 0.6464734008922669, 0.6320590206390417, 0.6379578529924587, 0.6257689993738552, 0.6274969556481366, 0.6230844072097741, 0.6296395419300467, 0.623060987709801, 0.6152251999159366, 0.6131279661459623, 0.6130047528064193]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"8c7395ef-48ac-40ea-920a-706db4de898a\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6889592243277508, 0.6495276834653771, 0.6397390728411467, 0.6358206220295118, 0.6884261535561603, 0.6483277730319811, 0.6395054506218951, 0.6382372768028922, 0.6378266956495202, 0.6370313354160475, 0.6373312944951265, 0.6370467927144922, 0.6358481319054313, 0.6370108013567717, 0.6354891901430877, 0.6320919534434443, 0.6284516790638799, 0.6329752377841784, 0.6308036353277123, 0.6273668921512107, 0.6236005176668582, 0.6186732245528179, 0.6124881184619406, 0.6073678286179253, 0.6120085602221281, 0.6076772332191467, 0.603763501022173, 0.5956578503484311, 0.584987527391185, 0.5800049113190693]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"f6dec66d-9148-422e-b347-5773b8ed1f63\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6855338125413166, 0.6537517772204634, 0.6079012817806668, 0.5547302060657078, 0.5109746901309432, 0.4789832710931842, 0.47295596855850036, 0.450131334659558, 0.4522893315927994, 0.42636044494771724, 0.42076286929817014, 0.4228044536090703, 0.42061252196629845, 0.4272352535367588, 0.4071035242886935, 0.39926229850681505, 0.39248259899696863, 0.37570632353497013, 0.37456276416778567, 0.372365954676688, 0.3633092985061056, 0.3610475128975467, 0.3494607430437337, 0.34105138522415346, 0.33742735342703006, 0.3367877669380483, 0.327147862991849, 0.3352167087764556, 0.33303943909884653, 0.3512789569039276]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"f23ab833-27ae-4c0e-9ba5-7069bc9f1ca0\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6889319311017575, 0.6730553678844287, 0.6408950515415357, 0.5766822934150696, 0.5204589745272761, 0.4782597946084064, 0.4591163516044617, 0.4415248930454254, 0.4265573245027791, 0.43515633240990015, 0.43943328676016435, 0.4818105117134426, 0.5002194523811341, 0.4246719692064368, 0.4658649524916773, 0.4023017061793286, 0.40184836206228836, 0.42144472521284354, 0.39031505481056544, 0.3842861515024434, 0.39965235539104627, 0.395953717439071, 0.3785311740377675, 0.3842694837114085, 0.3935193981813348, 0.3978627083094224, 0.3963971594105596, 0.39056257164996605, 0.4755320056625035, 0.38971339619677997]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"e151f096-aee4-4891-9944-49ec08ba23e7\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6910593209059342, 0.6791186515835749, 0.661299100878158, 0.6211396047458556, 0.5715280451636383, 0.533828862508138, 0.514137475617266, 0.4960113333043269, 0.47970275231029674, 0.4688834196703445, 0.4574728206447933, 0.47089112593931853, 0.44233962893486023, 0.4302178322980945, 0.4295311245365419, 0.4099410209678797, 0.43143074138153004, 0.41720588515346174, 0.4109857518603836, 0.40011958877245585, 0.38658982797521324, 0.392886683791156, 0.3923268025336058, 0.38515005105935435, 0.3783888387795232, 0.3708047292370727, 0.38176245902471495, 0.3683071422116192, 0.3691181821811602, 0.3658791677099495]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"1e0593d5-9fba-432e-9841-25800e3e1dc0\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6890040869298188, 0.6811693761659705, 0.6669003688770792, 0.6198690061983855, 0.5569463227106177, 0.5207855602969294, 0.5008233324341153, 0.4869796755521194, 0.46927586223768153, 0.42631143098292146, 0.4061243720676588, 0.5144496150638747, 0.430895039309626, 0.4498983372812686, 0.45350471190784286, 0.4226366768712583, 0.4493733095086139, 0.4247682402963224, 0.4408307116964589, 0.4289747971555461, 0.42242464941480884, 0.45258829515913257, 0.45105396535085596, 0.4385812492474266, 0.4504818926686826, 0.47021816839342534, 0.46197039614553037, 0.45674871595009514, 0.45045417158500006, 0.4566674258397973]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('2cd79df4-2ffc-4984-9737-9eeb58bfb3fb');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean  acc         0.788700\n",
      "loss        0.455791\n",
      "val_acc     0.787696\n",
      "val_loss    0.478266\n",
      "dtype: float64\n",
      "std  acc         0.081273\n",
      "loss        0.112855\n",
      "val_acc     0.073134\n",
      "val_loss    0.093776\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "1",
         "text": "",
         "type": "scatter",
         "uid": "18cbd5e4-4d66-40d0-87aa-e10eb6eb3937",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.8199999928474426,
          0.8299999833106995,
          0.8500000238418579,
          0.8600000143051147,
          0.8100000023841858,
          0.8700000047683716,
          0.800000011920929,
          0.7900000214576721,
          0.8399999737739563,
          0.8100000023841858
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"df2b1d2c-d099-4b7f-ba1a-c4e8a19062e1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"df2b1d2c-d099-4b7f-ba1a-c4e8a19062e1\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'df2b1d2c-d099-4b7f-ba1a-c4e8a19062e1',\n",
       "                        [{\"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"1\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"18cbd5e4-4d66-40d0-87aa-e10eb6eb3937\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.8199999928474426, 0.8299999833106995, 0.8500000238418579, 0.8600000143051147, 0.8100000023841858, 0.8700000047683716, 0.800000011920929, 0.7900000214576721, 0.8399999737739563, 0.8100000023841858]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('df2b1d2c-d099-4b7f-ba1a-c4e8a19062e1');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media  0.8280000030994416\n",
      "std  0.02658320128150446\n"
     ]
    }
   ],
   "source": [
    "process_results(bn_hist, bn_evas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos la inicialización de pesos por el algoritmo Xavier (glorot_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.087931Z",
     "start_time": "2019-06-14T06:36:08.318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/glorot_lstm/kfold1\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 62s - loss: 0.6781 - acc: 0.6056 - val_loss: 0.6842 - val_acc: 0.5761\n",
      "Epoch 2/30\n",
      "4140/4140 - 7s - loss: 0.6554 - acc: 0.6353 - val_loss: 0.6738 - val_acc: 0.5848\n",
      "Epoch 3/30\n",
      "4140/4140 - 7s - loss: 0.6219 - acc: 0.6749 - val_loss: 0.6635 - val_acc: 0.6109\n",
      "Epoch 4/30\n",
      "4140/4140 - 8s - loss: 0.5743 - acc: 0.7191 - val_loss: 0.6545 - val_acc: 0.6522\n",
      "Epoch 5/30\n",
      "4140/4140 - 8s - loss: 0.5452 - acc: 0.7449 - val_loss: 0.6271 - val_acc: 0.7391\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.5162 - acc: 0.7599 - val_loss: 0.6074 - val_acc: 0.7565\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.5007 - acc: 0.7783 - val_loss: 0.5744 - val_acc: 0.8022\n",
      "Epoch 8/30\n",
      "4140/4140 - 7s - loss: 0.4704 - acc: 0.7942 - val_loss: 0.5473 - val_acc: 0.8217\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.4627 - acc: 0.8080 - val_loss: 0.5279 - val_acc: 0.8239\n",
      "Epoch 10/30\n",
      "4140/4140 - 6s - loss: 0.4443 - acc: 0.8094 - val_loss: 0.4928 - val_acc: 0.8196\n",
      "Epoch 11/30\n",
      "4140/4140 - 6s - loss: 0.4346 - acc: 0.8222 - val_loss: 0.4860 - val_acc: 0.8217\n",
      "Epoch 12/30\n",
      "4140/4140 - 7s - loss: 0.4309 - acc: 0.8220 - val_loss: 0.4843 - val_acc: 0.8043\n",
      "Epoch 13/30\n",
      "4140/4140 - 7s - loss: 0.4306 - acc: 0.8169 - val_loss: 0.4523 - val_acc: 0.8130\n",
      "Epoch 14/30\n",
      "4140/4140 - 7s - loss: 0.4102 - acc: 0.8275 - val_loss: 0.4497 - val_acc: 0.8174\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.4131 - acc: 0.8287 - val_loss: 0.4570 - val_acc: 0.8000\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.3941 - acc: 0.8406 - val_loss: 0.4409 - val_acc: 0.8196\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.3934 - acc: 0.8457 - val_loss: 0.4312 - val_acc: 0.8261\n",
      "Epoch 18/30\n",
      "4140/4140 - 6s - loss: 0.3610 - acc: 0.8604 - val_loss: 0.4387 - val_acc: 0.8174\n",
      "Epoch 19/30\n",
      "4140/4140 - 7s - loss: 0.3581 - acc: 0.8645 - val_loss: 0.4391 - val_acc: 0.8109\n",
      "Epoch 20/30\n",
      "4140/4140 - 6s - loss: 0.3729 - acc: 0.8536 - val_loss: 0.4576 - val_acc: 0.8217\n",
      "Epoch 21/30\n",
      "4140/4140 - 6s - loss: 0.3556 - acc: 0.8543 - val_loss: 0.4460 - val_acc: 0.8217\n",
      "Epoch 22/30\n",
      "4140/4140 - 6s - loss: 0.3600 - acc: 0.8618 - val_loss: 0.4637 - val_acc: 0.8196\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.3319 - acc: 0.8693 - val_loss: 0.4720 - val_acc: 0.8152\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.3290 - acc: 0.8761 - val_loss: 0.4600 - val_acc: 0.8109\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.3492 - acc: 0.8674 - val_loss: 0.4697 - val_acc: 0.8087\n",
      "Epoch 26/30\n",
      "4140/4140 - 6s - loss: 0.3293 - acc: 0.8722 - val_loss: 0.4628 - val_acc: 0.8065\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.3190 - acc: 0.8766 - val_loss: 0.4942 - val_acc: 0.7935\n",
      "Epoch 28/30\n",
      "4140/4140 - 6s - loss: 0.3406 - acc: 0.8643 - val_loss: 0.4989 - val_acc: 0.8152\n",
      "Epoch 29/30\n",
      "4140/4140 - 6s - loss: 0.3127 - acc: 0.8877 - val_loss: 0.4545 - val_acc: 0.8217\n",
      "Epoch 30/30\n",
      "4140/4140 - 6s - loss: 0.2833 - acc: 0.8964 - val_loss: 0.4801 - val_acc: 0.8065\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.5118 - acc: 0.7500\n",
      "logs/fit/glorot_lstm/kfold2\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 45s - loss: 0.6841 - acc: 0.5923 - val_loss: 0.6855 - val_acc: 0.5696\n",
      "Epoch 2/30\n",
      "4140/4140 - 2s - loss: 0.6692 - acc: 0.6150 - val_loss: 0.6804 - val_acc: 0.5696\n",
      "Epoch 3/30\n",
      "4140/4140 - 2s - loss: 0.6448 - acc: 0.6519 - val_loss: 0.6677 - val_acc: 0.5957\n",
      "Epoch 4/30\n",
      "4140/4140 - 2s - loss: 0.6156 - acc: 0.6696 - val_loss: 0.6590 - val_acc: 0.6109\n",
      "Epoch 5/30\n",
      "4140/4140 - 2s - loss: 0.5743 - acc: 0.6966 - val_loss: 0.6098 - val_acc: 0.7413\n",
      "Epoch 6/30\n",
      "4140/4140 - 2s - loss: 0.5645 - acc: 0.7126 - val_loss: 0.5801 - val_acc: 0.7565\n",
      "Epoch 7/30\n",
      "4140/4140 - 2s - loss: 0.5301 - acc: 0.7167 - val_loss: 0.5600 - val_acc: 0.7413\n",
      "Epoch 8/30\n",
      "4140/4140 - 2s - loss: 0.5040 - acc: 0.7418 - val_loss: 0.5163 - val_acc: 0.7978\n",
      "Epoch 9/30\n",
      "4140/4140 - 2s - loss: 0.4953 - acc: 0.7478 - val_loss: 0.4361 - val_acc: 0.8152\n",
      "Epoch 10/30\n",
      "4140/4140 - 2s - loss: 0.4894 - acc: 0.7647 - val_loss: 0.4352 - val_acc: 0.8391\n",
      "Epoch 11/30\n",
      "4140/4140 - 2s - loss: 0.4667 - acc: 0.7713 - val_loss: 0.3881 - val_acc: 0.8413\n",
      "Epoch 12/30\n",
      "4140/4140 - 2s - loss: 0.4586 - acc: 0.7754 - val_loss: 0.3707 - val_acc: 0.8391\n",
      "Epoch 13/30\n",
      "4140/4140 - 3s - loss: 0.4378 - acc: 0.7882 - val_loss: 0.3696 - val_acc: 0.8435\n",
      "Epoch 14/30\n",
      "4140/4140 - 5s - loss: 0.4355 - acc: 0.7952 - val_loss: 0.3704 - val_acc: 0.8478\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.4243 - acc: 0.7988 - val_loss: 0.3679 - val_acc: 0.8435\n",
      "Epoch 16/30\n",
      "4140/4140 - 8s - loss: 0.4096 - acc: 0.8068 - val_loss: 0.3616 - val_acc: 0.8370\n",
      "Epoch 17/30\n",
      "4140/4140 - 8s - loss: 0.3983 - acc: 0.8159 - val_loss: 0.3582 - val_acc: 0.8370\n",
      "Epoch 18/30\n",
      "4140/4140 - 8s - loss: 0.3959 - acc: 0.8203 - val_loss: 0.3557 - val_acc: 0.8239\n",
      "Epoch 19/30\n",
      "4140/4140 - 8s - loss: 0.3944 - acc: 0.8205 - val_loss: 0.3533 - val_acc: 0.8391\n",
      "Epoch 20/30\n",
      "4140/4140 - 8s - loss: 0.3977 - acc: 0.8196 - val_loss: 0.3761 - val_acc: 0.8304\n",
      "Epoch 21/30\n",
      "4140/4140 - 8s - loss: 0.3702 - acc: 0.8275 - val_loss: 0.3802 - val_acc: 0.8370\n",
      "Epoch 22/30\n",
      "4140/4140 - 8s - loss: 0.3820 - acc: 0.8208 - val_loss: 0.3944 - val_acc: 0.8109\n",
      "Epoch 23/30\n",
      "4140/4140 - 8s - loss: 0.3682 - acc: 0.8278 - val_loss: 0.3784 - val_acc: 0.8348\n",
      "Epoch 24/30\n",
      "4140/4140 - 8s - loss: 0.3642 - acc: 0.8324 - val_loss: 0.3590 - val_acc: 0.8435\n",
      "Epoch 25/30\n",
      "4140/4140 - 8s - loss: 0.3532 - acc: 0.8401 - val_loss: 0.3628 - val_acc: 0.8413\n",
      "Epoch 26/30\n",
      "4140/4140 - 8s - loss: 0.3352 - acc: 0.8464 - val_loss: 0.3569 - val_acc: 0.8413\n",
      "Epoch 27/30\n",
      "4140/4140 - 8s - loss: 0.3472 - acc: 0.8420 - val_loss: 0.3843 - val_acc: 0.8413\n",
      "Epoch 28/30\n",
      "4140/4140 - 8s - loss: 0.3310 - acc: 0.8558 - val_loss: 0.3854 - val_acc: 0.8478\n",
      "Epoch 29/30\n",
      "4140/4140 - 8s - loss: 0.3293 - acc: 0.8553 - val_loss: 0.4241 - val_acc: 0.8435\n",
      "Epoch 30/30\n",
      "4140/4140 - 8s - loss: 0.3305 - acc: 0.8527 - val_loss: 0.4150 - val_acc: 0.8500\n",
      "100/100 [==============================] - 1s 7ms/sample - loss: 0.4505 - acc: 0.8200\n",
      "logs/fit/glorot_lstm/kfold3\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 15s - loss: 0.6908 - acc: 0.5469 - val_loss: 0.6803 - val_acc: 0.6087\n",
      "Epoch 2/30\n",
      "4140/4140 - 1s - loss: 0.6816 - acc: 0.5886 - val_loss: 0.6745 - val_acc: 0.6087\n",
      "Epoch 3/30\n",
      "4140/4140 - 1s - loss: 0.6722 - acc: 0.6024 - val_loss: 0.6710 - val_acc: 0.6087\n",
      "Epoch 4/30\n",
      "4140/4140 - 2s - loss: 0.6423 - acc: 0.6486 - val_loss: 0.6621 - val_acc: 0.6130\n",
      "Epoch 5/30\n",
      "4140/4140 - 3s - loss: 0.6107 - acc: 0.6797 - val_loss: 0.6494 - val_acc: 0.6522\n",
      "Epoch 6/30\n",
      "4140/4140 - 4s - loss: 0.5723 - acc: 0.7234 - val_loss: 0.6024 - val_acc: 0.7739\n",
      "Epoch 7/30\n",
      "4140/4140 - 5s - loss: 0.5375 - acc: 0.7519 - val_loss: 0.5612 - val_acc: 0.7935\n",
      "Epoch 8/30\n",
      "4140/4140 - 7s - loss: 0.5135 - acc: 0.7676 - val_loss: 0.5197 - val_acc: 0.8239\n",
      "Epoch 9/30\n",
      "4140/4140 - 8s - loss: 0.4875 - acc: 0.7773 - val_loss: 0.5060 - val_acc: 0.8022\n",
      "Epoch 10/30\n",
      "4140/4140 - 8s - loss: 0.4773 - acc: 0.7855 - val_loss: 0.4859 - val_acc: 0.8239\n",
      "Epoch 11/30\n",
      "4140/4140 - 8s - loss: 0.4747 - acc: 0.7814 - val_loss: 0.4768 - val_acc: 0.8304\n",
      "Epoch 12/30\n",
      "4140/4140 - 8s - loss: 0.4750 - acc: 0.7845 - val_loss: 0.4807 - val_acc: 0.8217\n",
      "Epoch 13/30\n",
      "4140/4140 - 8s - loss: 0.4541 - acc: 0.7877 - val_loss: 0.4789 - val_acc: 0.7957\n",
      "Epoch 14/30\n",
      "4140/4140 - 8s - loss: 0.4495 - acc: 0.7884 - val_loss: 0.4554 - val_acc: 0.7935\n",
      "Epoch 15/30\n",
      "4140/4140 - 8s - loss: 0.4342 - acc: 0.8031 - val_loss: 0.4515 - val_acc: 0.8022\n",
      "Epoch 16/30\n",
      "4140/4140 - 8s - loss: 0.4427 - acc: 0.7961 - val_loss: 0.4732 - val_acc: 0.7761\n",
      "Epoch 17/30\n",
      "4140/4140 - 8s - loss: 0.4302 - acc: 0.8056 - val_loss: 0.4595 - val_acc: 0.7848\n",
      "Epoch 18/30\n",
      "4140/4140 - 8s - loss: 0.4215 - acc: 0.8097 - val_loss: 0.4906 - val_acc: 0.7587\n",
      "Epoch 19/30\n",
      "4140/4140 - 8s - loss: 0.4161 - acc: 0.8130 - val_loss: 0.4429 - val_acc: 0.8022\n",
      "Epoch 20/30\n",
      "4140/4140 - 8s - loss: 0.4271 - acc: 0.8150 - val_loss: 0.4499 - val_acc: 0.8065\n",
      "Epoch 21/30\n",
      "4140/4140 - 8s - loss: 0.4030 - acc: 0.8232 - val_loss: 0.4890 - val_acc: 0.7543\n",
      "Epoch 22/30\n",
      "4140/4140 - 8s - loss: 0.3979 - acc: 0.8254 - val_loss: 0.4636 - val_acc: 0.7935\n",
      "Epoch 23/30\n",
      "4140/4140 - 8s - loss: 0.3810 - acc: 0.8343 - val_loss: 0.4369 - val_acc: 0.8022\n",
      "Epoch 24/30\n",
      "4140/4140 - 8s - loss: 0.3834 - acc: 0.8297 - val_loss: 0.4784 - val_acc: 0.7783\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4140/4140 - 8s - loss: 0.3817 - acc: 0.8273 - val_loss: 0.4575 - val_acc: 0.7978\n",
      "Epoch 26/30\n",
      "4140/4140 - 8s - loss: 0.3712 - acc: 0.8382 - val_loss: 0.4851 - val_acc: 0.7978\n",
      "Epoch 27/30\n",
      "4140/4140 - 8s - loss: 0.3700 - acc: 0.8432 - val_loss: 0.4486 - val_acc: 0.7935\n",
      "Epoch 28/30\n",
      "4140/4140 - 8s - loss: 0.3647 - acc: 0.8382 - val_loss: 0.4583 - val_acc: 0.8043\n",
      "Epoch 29/30\n",
      "4140/4140 - 6s - loss: 0.3512 - acc: 0.8466 - val_loss: 0.4573 - val_acc: 0.8087\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.3351 - acc: 0.8560 - val_loss: 0.4379 - val_acc: 0.8326\n",
      "100/100 [==============================] - 0s 661us/sample - loss: 0.4745 - acc: 0.8200\n",
      "logs/fit/glorot_lstm/kfold4\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 33s - loss: 0.6887 - acc: 0.5638 - val_loss: 0.6846 - val_acc: 0.5978\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.6699 - acc: 0.6179 - val_loss: 0.6761 - val_acc: 0.5978\n",
      "Epoch 3/30\n",
      "4140/4140 - 8s - loss: 0.6376 - acc: 0.6519 - val_loss: 0.6596 - val_acc: 0.6348\n",
      "Epoch 4/30\n",
      "4140/4140 - 8s - loss: 0.6201 - acc: 0.6679 - val_loss: 0.6182 - val_acc: 0.7500\n",
      "Epoch 5/30\n",
      "4140/4140 - 8s - loss: 0.5780 - acc: 0.7101 - val_loss: 0.5873 - val_acc: 0.7935\n",
      "Epoch 6/30\n",
      "4140/4140 - 9s - loss: 0.5549 - acc: 0.7287 - val_loss: 0.5652 - val_acc: 0.8109\n",
      "Epoch 7/30\n",
      "4140/4140 - 8s - loss: 0.5176 - acc: 0.7580 - val_loss: 0.5352 - val_acc: 0.8152\n",
      "Epoch 8/30\n",
      "4140/4140 - 8s - loss: 0.4942 - acc: 0.7746 - val_loss: 0.4894 - val_acc: 0.8217\n",
      "Epoch 9/30\n",
      "4140/4140 - 8s - loss: 0.4616 - acc: 0.7925 - val_loss: 0.5488 - val_acc: 0.8370\n",
      "Epoch 10/30\n",
      "4140/4140 - 8s - loss: 0.4475 - acc: 0.7983 - val_loss: 0.4324 - val_acc: 0.8239\n",
      "Epoch 11/30\n",
      "4140/4140 - 8s - loss: 0.4500 - acc: 0.8019 - val_loss: 0.4754 - val_acc: 0.8326\n",
      "Epoch 12/30\n",
      "4140/4140 - 8s - loss: 0.4460 - acc: 0.8070 - val_loss: 0.4629 - val_acc: 0.7761\n",
      "Epoch 13/30\n",
      "4140/4140 - 8s - loss: 0.4304 - acc: 0.8082 - val_loss: 0.3914 - val_acc: 0.8304\n",
      "Epoch 14/30\n",
      "4140/4140 - 8s - loss: 0.4089 - acc: 0.8263 - val_loss: 0.3924 - val_acc: 0.8283\n",
      "Epoch 15/30\n",
      "4140/4140 - 8s - loss: 0.4076 - acc: 0.8263 - val_loss: 0.3835 - val_acc: 0.8304\n",
      "Epoch 16/30\n",
      "4140/4140 - 8s - loss: 0.3868 - acc: 0.8312 - val_loss: 0.3850 - val_acc: 0.8326\n",
      "Epoch 17/30\n",
      "4140/4140 - 8s - loss: 0.3948 - acc: 0.8309 - val_loss: 0.3758 - val_acc: 0.8326\n",
      "Epoch 18/30\n",
      "4140/4140 - 8s - loss: 0.3850 - acc: 0.8355 - val_loss: 0.4232 - val_acc: 0.8304\n",
      "Epoch 19/30\n",
      "4140/4140 - 8s - loss: 0.3726 - acc: 0.8379 - val_loss: 0.4122 - val_acc: 0.8304\n",
      "Epoch 20/30\n",
      "4140/4140 - 8s - loss: 0.3728 - acc: 0.8384 - val_loss: 0.4451 - val_acc: 0.8304\n",
      "Epoch 21/30\n",
      "4140/4140 - 8s - loss: 0.3642 - acc: 0.8452 - val_loss: 0.4162 - val_acc: 0.8000\n",
      "Epoch 22/30\n",
      "4140/4140 - 8s - loss: 0.3646 - acc: 0.8355 - val_loss: 0.4060 - val_acc: 0.8109\n",
      "Epoch 23/30\n",
      "4140/4140 - 8s - loss: 0.3547 - acc: 0.8435 - val_loss: 0.4427 - val_acc: 0.8217\n",
      "Epoch 24/30\n",
      "4140/4140 - 8s - loss: 0.3390 - acc: 0.8560 - val_loss: 0.4529 - val_acc: 0.8065\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.3423 - acc: 0.8486 - val_loss: 0.4333 - val_acc: 0.8022\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.3601 - acc: 0.8490 - val_loss: 0.4423 - val_acc: 0.7848\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.3534 - acc: 0.8394 - val_loss: 0.4206 - val_acc: 0.8304\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.3287 - acc: 0.8568 - val_loss: 0.4086 - val_acc: 0.8304\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.3183 - acc: 0.8626 - val_loss: 0.4249 - val_acc: 0.8239\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.3191 - acc: 0.8599 - val_loss: 0.4398 - val_acc: 0.7826\n",
      "100/100 [==============================] - 0s 676us/sample - loss: 0.5188 - acc: 0.6800\n",
      "logs/fit/glorot_lstm/kfold5\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 61s - loss: 0.6687 - acc: 0.6300 - val_loss: 0.6842 - val_acc: 0.5717\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.6374 - acc: 0.6681 - val_loss: 0.6745 - val_acc: 0.5826\n",
      "Epoch 3/30\n",
      "4140/4140 - 8s - loss: 0.6110 - acc: 0.6850 - val_loss: 0.6631 - val_acc: 0.5957\n",
      "Epoch 4/30\n",
      "4140/4140 - 8s - loss: 0.5873 - acc: 0.7048 - val_loss: 0.6577 - val_acc: 0.6000\n",
      "Epoch 5/30\n",
      "4140/4140 - 8s - loss: 0.5740 - acc: 0.7186 - val_loss: 0.6289 - val_acc: 0.7043\n",
      "Epoch 6/30\n",
      "4140/4140 - 8s - loss: 0.5502 - acc: 0.7382 - val_loss: 0.6040 - val_acc: 0.7522\n",
      "Epoch 7/30\n",
      "4140/4140 - 8s - loss: 0.5494 - acc: 0.7384 - val_loss: 0.5464 - val_acc: 0.8152\n",
      "Epoch 8/30\n",
      "4140/4140 - 8s - loss: 0.5281 - acc: 0.7510 - val_loss: 0.4943 - val_acc: 0.8370\n",
      "Epoch 9/30\n",
      "4140/4140 - 8s - loss: 0.5105 - acc: 0.7739 - val_loss: 0.4950 - val_acc: 0.8130\n",
      "Epoch 10/30\n",
      "4140/4140 - 8s - loss: 0.4915 - acc: 0.7855 - val_loss: 0.4912 - val_acc: 0.8043\n",
      "Epoch 11/30\n",
      "4140/4140 - 8s - loss: 0.4832 - acc: 0.7932 - val_loss: 0.4469 - val_acc: 0.8413\n",
      "Epoch 12/30\n",
      "4140/4140 - 8s - loss: 0.4720 - acc: 0.7988 - val_loss: 0.4394 - val_acc: 0.8326\n",
      "Epoch 13/30\n",
      "4140/4140 - 8s - loss: 0.4756 - acc: 0.7964 - val_loss: 0.4502 - val_acc: 0.8130\n",
      "Epoch 14/30\n",
      "4140/4140 - 8s - loss: 0.4702 - acc: 0.8051 - val_loss: 0.4540 - val_acc: 0.8043\n",
      "Epoch 15/30\n",
      "4140/4140 - 8s - loss: 0.4429 - acc: 0.8143 - val_loss: 0.4550 - val_acc: 0.8087\n",
      "Epoch 16/30\n",
      "4140/4140 - 8s - loss: 0.4400 - acc: 0.8167 - val_loss: 0.4562 - val_acc: 0.8087\n",
      "Epoch 17/30\n",
      "4140/4140 - 2s - loss: 0.4169 - acc: 0.8319 - val_loss: 0.4494 - val_acc: 0.8087\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.4252 - acc: 0.8278 - val_loss: 0.4487 - val_acc: 0.8152\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.4237 - acc: 0.8237 - val_loss: 0.4559 - val_acc: 0.8065\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.4170 - acc: 0.8307 - val_loss: 0.4537 - val_acc: 0.8087\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.3942 - acc: 0.8415 - val_loss: 0.4613 - val_acc: 0.8130\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.3905 - acc: 0.8466 - val_loss: 0.5021 - val_acc: 0.8326\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.3892 - acc: 0.8454 - val_loss: 0.4659 - val_acc: 0.8239\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.3857 - acc: 0.8473 - val_loss: 0.5250 - val_acc: 0.8261\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.3554 - acc: 0.8688 - val_loss: 0.4781 - val_acc: 0.8217\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.3536 - acc: 0.8674 - val_loss: 0.4926 - val_acc: 0.8000\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.3536 - acc: 0.8713 - val_loss: 0.5161 - val_acc: 0.8283\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.3563 - acc: 0.8650 - val_loss: 0.4908 - val_acc: 0.8239\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.3372 - acc: 0.8780 - val_loss: 0.5052 - val_acc: 0.8152\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.3171 - acc: 0.8906 - val_loss: 0.5217 - val_acc: 0.8239\n",
      "100/100 [==============================] - 0s 725us/sample - loss: 0.3571 - acc: 0.8700\n",
      "logs/fit/glorot_lstm/kfold6\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 82s - loss: 0.6762 - acc: 0.6089 - val_loss: 0.6825 - val_acc: 0.5804\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.6304 - acc: 0.6691 - val_loss: 0.6739 - val_acc: 0.5978\n",
      "Epoch 3/30\n",
      "4140/4140 - 8s - loss: 0.6001 - acc: 0.6949 - val_loss: 0.6585 - val_acc: 0.6391\n",
      "Epoch 4/30\n",
      "4140/4140 - 8s - loss: 0.5754 - acc: 0.7118 - val_loss: 0.6457 - val_acc: 0.6891\n",
      "Epoch 5/30\n",
      "4140/4140 - 8s - loss: 0.5334 - acc: 0.7408 - val_loss: 0.6112 - val_acc: 0.7826\n",
      "Epoch 6/30\n",
      "4140/4140 - 8s - loss: 0.4973 - acc: 0.7592 - val_loss: 0.5774 - val_acc: 0.8000\n",
      "Epoch 7/30\n",
      "4140/4140 - 8s - loss: 0.4916 - acc: 0.7749 - val_loss: 0.5574 - val_acc: 0.7913\n",
      "Epoch 8/30\n",
      "4140/4140 - 8s - loss: 0.4643 - acc: 0.7899 - val_loss: 0.5114 - val_acc: 0.8130\n",
      "Epoch 9/30\n",
      "4140/4140 - 8s - loss: 0.4562 - acc: 0.7947 - val_loss: 0.4782 - val_acc: 0.8130\n",
      "Epoch 10/30\n",
      "4140/4140 - 8s - loss: 0.4354 - acc: 0.8138 - val_loss: 0.4510 - val_acc: 0.8196\n",
      "Epoch 11/30\n",
      "4140/4140 - 8s - loss: 0.4524 - acc: 0.8114 - val_loss: 0.4382 - val_acc: 0.8239\n",
      "Epoch 12/30\n",
      "4140/4140 - 8s - loss: 0.4106 - acc: 0.8242 - val_loss: 0.4299 - val_acc: 0.8196\n",
      "Epoch 13/30\n",
      "4140/4140 - 8s - loss: 0.4129 - acc: 0.8343 - val_loss: 0.4275 - val_acc: 0.8174\n",
      "Epoch 14/30\n",
      "4140/4140 - 8s - loss: 0.3943 - acc: 0.8326 - val_loss: 0.4219 - val_acc: 0.8196\n",
      "Epoch 15/30\n",
      "4140/4140 - 6s - loss: 0.3875 - acc: 0.8382 - val_loss: 0.4096 - val_acc: 0.8391\n",
      "Epoch 16/30\n",
      "4140/4140 - 1s - loss: 0.3869 - acc: 0.8408 - val_loss: 0.3935 - val_acc: 0.8522\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.3842 - acc: 0.8382 - val_loss: 0.4454 - val_acc: 0.8174\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.3902 - acc: 0.8350 - val_loss: 0.3957 - val_acc: 0.8478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.3802 - acc: 0.8406 - val_loss: 0.4395 - val_acc: 0.7826\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.3602 - acc: 0.8517 - val_loss: 0.3983 - val_acc: 0.8326\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.3471 - acc: 0.8601 - val_loss: 0.4221 - val_acc: 0.8478\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.3629 - acc: 0.8488 - val_loss: 0.3960 - val_acc: 0.8326\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.3434 - acc: 0.8606 - val_loss: 0.3880 - val_acc: 0.8565\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.3438 - acc: 0.8592 - val_loss: 0.3963 - val_acc: 0.8478\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.3419 - acc: 0.8645 - val_loss: 0.3981 - val_acc: 0.8565\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.3578 - acc: 0.8546 - val_loss: 0.4740 - val_acc: 0.7652\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.3360 - acc: 0.8664 - val_loss: 0.4444 - val_acc: 0.8174\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.3291 - acc: 0.8676 - val_loss: 0.4342 - val_acc: 0.8152\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.3166 - acc: 0.8732 - val_loss: 0.4298 - val_acc: 0.8261\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.3224 - acc: 0.8732 - val_loss: 0.4342 - val_acc: 0.8174\n",
      "100/100 [==============================] - 0s 671us/sample - loss: 0.4126 - acc: 0.8100\n",
      "logs/fit/glorot_lstm/kfold7\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 83s - loss: 0.6859 - acc: 0.5483 - val_loss: 0.6867 - val_acc: 0.5717\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.6646 - acc: 0.6198 - val_loss: 0.6814 - val_acc: 0.5717\n",
      "Epoch 3/30\n",
      "4140/4140 - 8s - loss: 0.6397 - acc: 0.6500 - val_loss: 0.6766 - val_acc: 0.5717\n",
      "Epoch 4/30\n",
      "4140/4140 - 8s - loss: 0.6063 - acc: 0.6775 - val_loss: 0.6596 - val_acc: 0.6152\n",
      "Epoch 5/30\n",
      "4140/4140 - 8s - loss: 0.5752 - acc: 0.7043 - val_loss: 0.6434 - val_acc: 0.6261\n",
      "Epoch 6/30\n",
      "4140/4140 - 8s - loss: 0.5423 - acc: 0.7283 - val_loss: 0.5906 - val_acc: 0.6978\n",
      "Epoch 7/30\n",
      "4140/4140 - 8s - loss: 0.5126 - acc: 0.7379 - val_loss: 0.5487 - val_acc: 0.7522\n",
      "Epoch 8/30\n",
      "4140/4140 - 8s - loss: 0.4940 - acc: 0.7377 - val_loss: 0.5332 - val_acc: 0.7478\n",
      "Epoch 9/30\n",
      "4140/4140 - 8s - loss: 0.4702 - acc: 0.7401 - val_loss: 0.4814 - val_acc: 0.7761\n",
      "Epoch 10/30\n",
      "4140/4140 - 8s - loss: 0.4602 - acc: 0.7621 - val_loss: 0.4962 - val_acc: 0.7587\n",
      "Epoch 11/30\n",
      "4140/4140 - 8s - loss: 0.4535 - acc: 0.7662 - val_loss: 0.4558 - val_acc: 0.7826\n",
      "Epoch 12/30\n",
      "4140/4140 - 8s - loss: 0.4382 - acc: 0.7848 - val_loss: 0.4712 - val_acc: 0.7761\n",
      "Epoch 13/30\n",
      "4140/4140 - 8s - loss: 0.4411 - acc: 0.7761 - val_loss: 0.4336 - val_acc: 0.7957\n",
      "Epoch 14/30\n",
      "4140/4140 - 8s - loss: 0.4291 - acc: 0.7879 - val_loss: 0.4349 - val_acc: 0.8065\n",
      "Epoch 15/30\n",
      "4140/4140 - 8s - loss: 0.4232 - acc: 0.7877 - val_loss: 0.4797 - val_acc: 0.7978\n",
      "Epoch 16/30\n",
      "4140/4140 - 3s - loss: 0.4291 - acc: 0.7829 - val_loss: 0.4140 - val_acc: 0.8283\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.4162 - acc: 0.7947 - val_loss: 0.4172 - val_acc: 0.8283\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.3917 - acc: 0.8068 - val_loss: 0.4447 - val_acc: 0.8196\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.4025 - acc: 0.8019 - val_loss: 0.4711 - val_acc: 0.8261\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.3949 - acc: 0.8099 - val_loss: 0.4152 - val_acc: 0.8348\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.3892 - acc: 0.8135 - val_loss: 0.4882 - val_acc: 0.8174\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.3764 - acc: 0.8176 - val_loss: 0.4803 - val_acc: 0.8196\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.3795 - acc: 0.8152 - val_loss: 0.5209 - val_acc: 0.8152\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.3667 - acc: 0.8171 - val_loss: 0.5201 - val_acc: 0.8022\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.3698 - acc: 0.8261 - val_loss: 0.4358 - val_acc: 0.8217\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.3590 - acc: 0.8191 - val_loss: 0.4658 - val_acc: 0.8152\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.3657 - acc: 0.8215 - val_loss: 0.4041 - val_acc: 0.8413\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.3554 - acc: 0.8287 - val_loss: 0.5052 - val_acc: 0.8261\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.3588 - acc: 0.8285 - val_loss: 0.5722 - val_acc: 0.8087\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.3506 - acc: 0.8266 - val_loss: 0.4910 - val_acc: 0.8196\n",
      "100/100 [==============================] - 0s 753us/sample - loss: 0.5146 - acc: 0.8000\n",
      "logs/fit/glorot_lstm/kfold8\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 84s - loss: 0.6890 - acc: 0.5662 - val_loss: 0.6884 - val_acc: 0.5652\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.6675 - acc: 0.6227 - val_loss: 0.6813 - val_acc: 0.5783\n",
      "Epoch 3/30\n",
      "4140/4140 - 8s - loss: 0.6238 - acc: 0.6662 - val_loss: 0.6661 - val_acc: 0.6065\n",
      "Epoch 4/30\n",
      "4140/4140 - 8s - loss: 0.5802 - acc: 0.7118 - val_loss: 0.5820 - val_acc: 0.7826\n",
      "Epoch 5/30\n",
      "4140/4140 - 8s - loss: 0.5476 - acc: 0.7428 - val_loss: 0.5150 - val_acc: 0.8261\n",
      "Epoch 6/30\n",
      "4140/4140 - 8s - loss: 0.5228 - acc: 0.7534 - val_loss: 0.4923 - val_acc: 0.8196\n",
      "Epoch 7/30\n",
      "4140/4140 - 8s - loss: 0.4996 - acc: 0.7761 - val_loss: 0.4751 - val_acc: 0.8130\n",
      "Epoch 8/30\n",
      "4140/4140 - 8s - loss: 0.4774 - acc: 0.7896 - val_loss: 0.4662 - val_acc: 0.8000\n",
      "Epoch 9/30\n",
      "4140/4140 - 8s - loss: 0.4683 - acc: 0.7971 - val_loss: 0.4661 - val_acc: 0.7978\n",
      "Epoch 10/30\n",
      "4140/4140 - 8s - loss: 0.4608 - acc: 0.7964 - val_loss: 0.4499 - val_acc: 0.8000\n",
      "Epoch 11/30\n",
      "4140/4140 - 8s - loss: 0.4482 - acc: 0.8101 - val_loss: 0.4410 - val_acc: 0.8022\n",
      "Epoch 12/30\n",
      "4140/4140 - 8s - loss: 0.4482 - acc: 0.8014 - val_loss: 0.4415 - val_acc: 0.7978\n",
      "Epoch 13/30\n",
      "4140/4140 - 8s - loss: 0.4432 - acc: 0.8130 - val_loss: 0.5310 - val_acc: 0.6848\n",
      "Epoch 14/30\n",
      "4140/4140 - 4s - loss: 0.4293 - acc: 0.8193 - val_loss: 0.4241 - val_acc: 0.8174\n",
      "Epoch 15/30\n",
      "4140/4140 - 1s - loss: 0.4220 - acc: 0.8239 - val_loss: 0.4085 - val_acc: 0.8217\n",
      "Epoch 16/30\n",
      "4140/4140 - 1s - loss: 0.4175 - acc: 0.8184 - val_loss: 0.4002 - val_acc: 0.8261\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.4062 - acc: 0.8188 - val_loss: 0.4052 - val_acc: 0.8174\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.3942 - acc: 0.8319 - val_loss: 0.3995 - val_acc: 0.8196\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.3909 - acc: 0.8357 - val_loss: 0.4104 - val_acc: 0.8196\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.3885 - acc: 0.8254 - val_loss: 0.4265 - val_acc: 0.8261\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.3775 - acc: 0.8372 - val_loss: 0.4213 - val_acc: 0.8283\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.3706 - acc: 0.8401 - val_loss: 0.3912 - val_acc: 0.8196\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.3680 - acc: 0.8408 - val_loss: 0.4217 - val_acc: 0.8261\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.3761 - acc: 0.8227 - val_loss: 0.4326 - val_acc: 0.7913\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.3645 - acc: 0.8348 - val_loss: 0.4438 - val_acc: 0.7913\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.3553 - acc: 0.8386 - val_loss: 0.4299 - val_acc: 0.8217\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.3531 - acc: 0.8437 - val_loss: 0.4646 - val_acc: 0.7804\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.3653 - acc: 0.8428 - val_loss: 0.4491 - val_acc: 0.7848\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.3551 - acc: 0.8382 - val_loss: 0.4837 - val_acc: 0.8000\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.3509 - acc: 0.8420 - val_loss: 0.5378 - val_acc: 0.7891\n",
      "100/100 [==============================] - 0s 841us/sample - loss: 0.6130 - acc: 0.7900\n",
      "logs/fit/glorot_lstm/kfold9\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 85s - loss: 0.6878 - acc: 0.5829 - val_loss: 0.6877 - val_acc: 0.5587\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.6730 - acc: 0.6121 - val_loss: 0.6850 - val_acc: 0.5609\n",
      "Epoch 3/30\n",
      "4140/4140 - 8s - loss: 0.6530 - acc: 0.6341 - val_loss: 0.6721 - val_acc: 0.5761\n",
      "Epoch 4/30\n",
      "4140/4140 - 8s - loss: 0.6329 - acc: 0.6483 - val_loss: 0.6638 - val_acc: 0.5891\n",
      "Epoch 5/30\n",
      "4140/4140 - 8s - loss: 0.6111 - acc: 0.6838 - val_loss: 0.6637 - val_acc: 0.5891\n",
      "Epoch 6/30\n",
      "4140/4140 - 9s - loss: 0.5732 - acc: 0.7176 - val_loss: 0.6462 - val_acc: 0.6587\n",
      "Epoch 7/30\n",
      "4140/4140 - 8s - loss: 0.5579 - acc: 0.7319 - val_loss: 0.6303 - val_acc: 0.7022\n",
      "Epoch 8/30\n",
      "4140/4140 - 8s - loss: 0.5266 - acc: 0.7507 - val_loss: 0.5908 - val_acc: 0.7848\n",
      "Epoch 9/30\n",
      "4140/4140 - 8s - loss: 0.5193 - acc: 0.7592 - val_loss: 0.5866 - val_acc: 0.7739\n",
      "Epoch 10/30\n",
      "4140/4140 - 3s - loss: 0.5112 - acc: 0.7691 - val_loss: 0.5365 - val_acc: 0.8261\n",
      "Epoch 11/30\n",
      "4140/4140 - 1s - loss: 0.4859 - acc: 0.7884 - val_loss: 0.4924 - val_acc: 0.8304\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4140/4140 - 1s - loss: 0.4829 - acc: 0.7841 - val_loss: 0.4670 - val_acc: 0.8174\n",
      "Epoch 13/30\n",
      "4140/4140 - 1s - loss: 0.4559 - acc: 0.7978 - val_loss: 0.4508 - val_acc: 0.8196\n",
      "Epoch 14/30\n",
      "4140/4140 - 1s - loss: 0.4500 - acc: 0.8060 - val_loss: 0.4327 - val_acc: 0.8065\n",
      "Epoch 15/30\n",
      "4140/4140 - 1s - loss: 0.4344 - acc: 0.8130 - val_loss: 0.4234 - val_acc: 0.8087\n",
      "Epoch 16/30\n",
      "4140/4140 - 1s - loss: 0.4207 - acc: 0.8234 - val_loss: 0.4085 - val_acc: 0.8283\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.4260 - acc: 0.8159 - val_loss: 0.4442 - val_acc: 0.8043\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.4116 - acc: 0.8213 - val_loss: 0.4264 - val_acc: 0.8109\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.3934 - acc: 0.8391 - val_loss: 0.4340 - val_acc: 0.8130\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.3889 - acc: 0.8357 - val_loss: 0.4242 - val_acc: 0.8217\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.3702 - acc: 0.8502 - val_loss: 0.4151 - val_acc: 0.8217\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.3762 - acc: 0.8440 - val_loss: 0.4538 - val_acc: 0.8000\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.3654 - acc: 0.8502 - val_loss: 0.4291 - val_acc: 0.8174\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.3529 - acc: 0.8621 - val_loss: 0.4176 - val_acc: 0.8196\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.3386 - acc: 0.8618 - val_loss: 0.4353 - val_acc: 0.8152\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.3521 - acc: 0.8553 - val_loss: 0.4550 - val_acc: 0.8196\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.3368 - acc: 0.8643 - val_loss: 0.4555 - val_acc: 0.8130\n",
      "Epoch 28/30\n",
      "4140/4140 - 2s - loss: 0.3347 - acc: 0.8621 - val_loss: 0.4288 - val_acc: 0.8239\n",
      "Epoch 29/30\n",
      "4140/4140 - 3s - loss: 0.3314 - acc: 0.8647 - val_loss: 0.4399 - val_acc: 0.8239\n",
      "Epoch 30/30\n",
      "4140/4140 - 4s - loss: 0.3195 - acc: 0.8659 - val_loss: 0.4394 - val_acc: 0.8109\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.3112 - acc: 0.8600\n",
      "logs/fit/glorot_lstm/kfold10\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 85s - loss: 0.6768 - acc: 0.6085 - val_loss: 0.6812 - val_acc: 0.6087\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.6161 - acc: 0.6836 - val_loss: 0.6575 - val_acc: 0.6348\n",
      "Epoch 3/30\n",
      "4140/4140 - 4s - loss: 0.5554 - acc: 0.7256 - val_loss: 0.6391 - val_acc: 0.6435\n",
      "Epoch 4/30\n",
      "4140/4140 - 1s - loss: 0.5199 - acc: 0.7531 - val_loss: 0.6196 - val_acc: 0.6587\n",
      "Epoch 5/30\n",
      "4140/4140 - 1s - loss: 0.5127 - acc: 0.7594 - val_loss: 0.5991 - val_acc: 0.6696\n",
      "Epoch 6/30\n",
      "4140/4140 - 1s - loss: 0.4912 - acc: 0.7713 - val_loss: 0.5675 - val_acc: 0.7391\n",
      "Epoch 7/30\n",
      "4140/4140 - 1s - loss: 0.4831 - acc: 0.7795 - val_loss: 0.5416 - val_acc: 0.7500\n",
      "Epoch 8/30\n",
      "4140/4140 - 1s - loss: 0.4627 - acc: 0.7930 - val_loss: 0.5215 - val_acc: 0.7500\n",
      "Epoch 9/30\n",
      "4140/4140 - 1s - loss: 0.4589 - acc: 0.7906 - val_loss: 0.4942 - val_acc: 0.8109\n",
      "Epoch 10/30\n",
      "4140/4140 - 1s - loss: 0.4501 - acc: 0.8094 - val_loss: 0.4683 - val_acc: 0.8087\n",
      "Epoch 11/30\n",
      "4140/4140 - 1s - loss: 0.4496 - acc: 0.8010 - val_loss: 0.4536 - val_acc: 0.8109\n",
      "Epoch 12/30\n",
      "4140/4140 - 1s - loss: 0.4483 - acc: 0.7990 - val_loss: 0.4485 - val_acc: 0.8239\n",
      "Epoch 13/30\n",
      "4140/4140 - 1s - loss: 0.4302 - acc: 0.8126 - val_loss: 0.4353 - val_acc: 0.8217\n",
      "Epoch 14/30\n",
      "4140/4140 - 1s - loss: 0.4390 - acc: 0.8048 - val_loss: 0.4312 - val_acc: 0.8000\n",
      "Epoch 15/30\n",
      "4140/4140 - 1s - loss: 0.4312 - acc: 0.8164 - val_loss: 0.4318 - val_acc: 0.8326\n",
      "Epoch 16/30\n",
      "4140/4140 - 1s - loss: 0.4223 - acc: 0.8217 - val_loss: 0.4344 - val_acc: 0.7978\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.4138 - acc: 0.8258 - val_loss: 0.4121 - val_acc: 0.8087\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.4323 - acc: 0.8157 - val_loss: 0.4364 - val_acc: 0.8370\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.4188 - acc: 0.8266 - val_loss: 0.4381 - val_acc: 0.8370\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.4020 - acc: 0.8329 - val_loss: 0.4345 - val_acc: 0.8413\n",
      "Epoch 21/30\n",
      "4140/4140 - 2s - loss: 0.4051 - acc: 0.8268 - val_loss: 0.4331 - val_acc: 0.8261\n",
      "Epoch 22/30\n",
      "4140/4140 - 3s - loss: 0.3954 - acc: 0.8302 - val_loss: 0.4295 - val_acc: 0.8326\n",
      "Epoch 23/30\n",
      "4140/4140 - 4s - loss: 0.3775 - acc: 0.8428 - val_loss: 0.4459 - val_acc: 0.8261\n",
      "Epoch 24/30\n",
      "4140/4140 - 5s - loss: 0.3776 - acc: 0.8454 - val_loss: 0.4492 - val_acc: 0.8261\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.3674 - acc: 0.8432 - val_loss: 0.4086 - val_acc: 0.8370\n",
      "Epoch 26/30\n",
      "4140/4140 - 8s - loss: 0.3775 - acc: 0.8423 - val_loss: 0.4448 - val_acc: 0.8239\n",
      "Epoch 27/30\n",
      "4140/4140 - 8s - loss: 0.3631 - acc: 0.8543 - val_loss: 0.4158 - val_acc: 0.8304\n",
      "Epoch 28/30\n",
      "4140/4140 - 8s - loss: 0.3604 - acc: 0.8541 - val_loss: 0.4836 - val_acc: 0.8109\n",
      "Epoch 29/30\n",
      "4140/4140 - 8s - loss: 0.3628 - acc: 0.8514 - val_loss: 0.4543 - val_acc: 0.8130\n",
      "Epoch 30/30\n",
      "4140/4140 - 8s - loss: 0.3539 - acc: 0.8568 - val_loss: 0.4642 - val_acc: 0.8130\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.5195 - acc: 0.8100\n"
     ]
    }
   ],
   "source": [
    "def glorot_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(10, kernel_initializer='glorot_normal', activation='relu', input_shape=(28, 300), name='lstm'),\n",
    "        tf.keras.layers.Dropout(0.7),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='glorot_normal', name='dense')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "gl_hist, gl_evas = kfold_train(glorot_model, 'glorot_lstm', batch_size=128, epochs=30, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "99f679d4-76e7-4f9f-bbd1-555e78fa3ea4",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6780548441813188,
          0.6553785091437003,
          0.6219432119010151,
          0.5742637628518441,
          0.5451517521471217,
          0.5162097198663702,
          0.5007325283571142,
          0.4704017445085129,
          0.4626525338433215,
          0.4443148097266322,
          0.4346340032879281,
          0.43093129690142645,
          0.43058447284974916,
          0.4101549734815883,
          0.41312943056297763,
          0.3941123033923227,
          0.3933503596103134,
          0.361002100435432,
          0.3580716672870848,
          0.3729392845849484,
          0.35556058877908087,
          0.3600199680685421,
          0.33193760114015586,
          0.3290123304451145,
          0.3492292205924573,
          0.3293317657449971,
          0.3189847915932752,
          0.34060598172715323,
          0.31266800484795504,
          0.2833140635404034
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "89cf4597-5bc1-439a-a60d-58248761b78f",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.684204361749732,
          0.6737770676612854,
          0.6634528362232706,
          0.6544931961142498,
          0.6270864103151405,
          0.6074170947074891,
          0.5743604307589324,
          0.5473149543223174,
          0.5279045944628509,
          0.49278677442799446,
          0.48599600584610647,
          0.48427699493325277,
          0.4523281004117883,
          0.4497304022312164,
          0.45702350295108296,
          0.44089669559312905,
          0.431158978783566,
          0.43874595709469005,
          0.43906833037086157,
          0.4575766770736031,
          0.4459936579932337,
          0.4637103495390519,
          0.47199372441872306,
          0.4599961915741796,
          0.46968068610066954,
          0.4627873964931654,
          0.4941813059475111,
          0.49893002976541934,
          0.45451603531837464,
          0.4800651182299075
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "ddc5774a-8ba7-4d40-a43e-ccbba8c05620",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6840628790970585,
          0.6691667268241661,
          0.6448489522588425,
          0.6155849137168,
          0.5742605687915415,
          0.5644566144056367,
          0.5301005848939868,
          0.5040440591925008,
          0.49531337365436096,
          0.4894125965482371,
          0.46666154455447545,
          0.45856905663071046,
          0.43784999337749203,
          0.4355132689510567,
          0.42425974077648587,
          0.4095668687912577,
          0.3982548151615161,
          0.39594716611115827,
          0.3943622988779188,
          0.39770372486920746,
          0.37015475152771254,
          0.3819641895628206,
          0.3681936460992564,
          0.36423123536478497,
          0.35320471931194913,
          0.3351901813837641,
          0.3471981970728307,
          0.33100938920813483,
          0.3292732968710471,
          0.3304823974048458
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "c722afe3-9015-45b0-a852-21418a6d2e74",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.685517944978631,
          0.6803771884545036,
          0.6676947433015574,
          0.6589863113735033,
          0.6098404464514359,
          0.5801480018574259,
          0.5600286281627157,
          0.5162663148797076,
          0.43614847685979763,
          0.4351988312990769,
          0.38808068788569905,
          0.37070523785508197,
          0.36956518655237947,
          0.37040053606033324,
          0.3678945533607317,
          0.3616098326185475,
          0.358190509547358,
          0.35574188258336936,
          0.3532881013725115,
          0.37606710221456446,
          0.3802095952241317,
          0.3944414740023406,
          0.3784010348112687,
          0.35900615375974904,
          0.3627664980681046,
          0.3569385518198428,
          0.3843065583187601,
          0.38535331980041837,
          0.4241171225257542,
          0.4149809293124987
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "2eef39ec-2948-49d8-89bf-8017fcc21c67",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6908488293776766,
          0.6815562822968487,
          0.6721608019681369,
          0.6423448119762439,
          0.6106547505383331,
          0.5722546137473433,
          0.5375067293931897,
          0.513466439385345,
          0.4874883306487171,
          0.47727467342851243,
          0.47468184057065255,
          0.47499746801196663,
          0.45406520732359035,
          0.4495279550264423,
          0.43423574661863024,
          0.4426912366768012,
          0.4302351482824427,
          0.42154666741113156,
          0.4160750128220821,
          0.42713721452127906,
          0.4029849032273039,
          0.39794368182403456,
          0.38101441085626536,
          0.3834051663460939,
          0.38168300300980534,
          0.3712402146507576,
          0.37001746089562126,
          0.3646526482946055,
          0.35117477797655666,
          0.3351301475135601
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "67da3708-dea6-4fc2-882c-16735636acc1",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6803015968073969,
          0.6744948547819386,
          0.6710220295449961,
          0.6620698659316353,
          0.6493567834729733,
          0.6023688622142958,
          0.5612378581710483,
          0.5196757487628771,
          0.5060200092585191,
          0.4859442296235458,
          0.47678791621456973,
          0.48066660632257874,
          0.47886513575263645,
          0.45535824583924334,
          0.45145799647206847,
          0.47322421877280524,
          0.4594953080882197,
          0.49055538643961366,
          0.4429254925769308,
          0.4498768511025802,
          0.488962329470593,
          0.4635592597982158,
          0.43687688941540925,
          0.47839923475099644,
          0.45752736926078796,
          0.48511506370876145,
          0.44861718105233234,
          0.45829596104829207,
          0.45728879000829614,
          0.43791951822197955
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "3e874065-36a7-4f5f-a790-227df6dc78a8",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.688653208149804,
          0.6698550131009973,
          0.6375521196835283,
          0.6201025693888825,
          0.5779832683899553,
          0.5549043905907783,
          0.5175946086501154,
          0.4942022896619235,
          0.4616437109772134,
          0.4474668520948161,
          0.45004559588317133,
          0.445959072297322,
          0.4303997218608856,
          0.40886207536798747,
          0.4076063463653343,
          0.38678640786576385,
          0.39477335784746254,
          0.3849763740088053,
          0.37262422733260814,
          0.37278245442731367,
          0.3642185691762086,
          0.36464235347826124,
          0.3546807630050585,
          0.3389910836438626,
          0.34228904405653765,
          0.3600515762676939,
          0.3533593824232258,
          0.3287244268661536,
          0.31827989433698606,
          0.3191286185225427
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "b28e3c1c-6f9d-481d-aed0-5e031abc6885",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6845555144807567,
          0.6760806208071501,
          0.6595813362494759,
          0.6182211378346318,
          0.5872960785160894,
          0.5651838831279589,
          0.5352103508037069,
          0.4894402527290842,
          0.5488068103790283,
          0.4323890849300053,
          0.475373855881069,
          0.46288994732110395,
          0.3914041845694832,
          0.39237379924110743,
          0.383466679116954,
          0.38502727695133376,
          0.3758289567802263,
          0.4231949010620946,
          0.41218390050141707,
          0.44512541605078654,
          0.4161548088426175,
          0.40600001656490825,
          0.44274698547694996,
          0.4529354593028193,
          0.43333632686863777,
          0.44227150600889453,
          0.4206065509630286,
          0.40855804785438204,
          0.42490017725073775,
          0.43984424238619596
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "34c23ff3-4158-4367-b26d-d58e9b29da6f",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6687390860152129,
          0.637418728634931,
          0.6109920233920001,
          0.587338634332021,
          0.5739547185851755,
          0.5501763798188473,
          0.5494157311996976,
          0.5280684979641496,
          0.5105016960038079,
          0.49150072635659847,
          0.483194959566789,
          0.47202684098971637,
          0.4756347417831421,
          0.47015305481095243,
          0.44290877730374173,
          0.4399693326673646,
          0.4169161081026142,
          0.42521084927130437,
          0.4237234691778819,
          0.4169521056799497,
          0.3941852791297839,
          0.390464145693802,
          0.3892108728920204,
          0.38567518505497256,
          0.35539162832757704,
          0.3535707185665766,
          0.3535757195690404,
          0.35631607779558155,
          0.33717361907452204,
          0.31714990126050036
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "43ecbdb1-18d9-4530-b969-7433c45d8b9a",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.684245474960493,
          0.6745424674904865,
          0.663131782801255,
          0.6577222932939945,
          0.6288885976957238,
          0.604045017387556,
          0.546367931884268,
          0.49429815463397814,
          0.494991235629372,
          0.49123712648516116,
          0.4468561651914016,
          0.4394282480944758,
          0.45022506921187694,
          0.45400780491206955,
          0.4549995033637337,
          0.4562366651452106,
          0.44937872005545576,
          0.4486732164154882,
          0.455902782212133,
          0.45372189283370973,
          0.46128780530846636,
          0.502059997682986,
          0.4658888386643451,
          0.5250499808269998,
          0.4780651543451392,
          0.4926214679427769,
          0.5161490181218022,
          0.49076038262118465,
          0.5051565582337587,
          0.5217371883599654
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "d8df1ff6-0135-431f-ab5a-c7f1bf88d54c",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6761750850124636,
          0.6304141660819307,
          0.6000529267361775,
          0.5754293071475006,
          0.5334273664847664,
          0.49730545685487093,
          0.4916001340041414,
          0.4643399113330288,
          0.45617576324997317,
          0.4353641997788839,
          0.4523949740589529,
          0.4106393123594459,
          0.4128548128593371,
          0.3942899115131673,
          0.3874697877589055,
          0.38688890062956416,
          0.38423043869543766,
          0.39023378715998885,
          0.3801779430557564,
          0.36019442458659556,
          0.3471294038825565,
          0.36288972615043896,
          0.3433576215724438,
          0.343842874892092,
          0.3419108012592159,
          0.35779400041713805,
          0.3360357998073965,
          0.32906989125525893,
          0.3165690408236739,
          0.3224430963612985
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "0586372d-2628-4388-9d34-19354f2fa14b",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6825458179349485,
          0.6739210522693136,
          0.6585339276686959,
          0.6456814926603566,
          0.6112189619437508,
          0.5773622803066087,
          0.5573529658110246,
          0.511428876026817,
          0.4782190245130788,
          0.45099926746409874,
          0.4382017985634182,
          0.4299151062965393,
          0.4274911046028137,
          0.4218586012073185,
          0.4096098684746286,
          0.3935209118801615,
          0.44535715761392014,
          0.39567627984544507,
          0.43952665847280753,
          0.3982902195142663,
          0.4221443544263425,
          0.3959605079630147,
          0.3879664475503175,
          0.3963185271491175,
          0.39812271439510843,
          0.47403285192406697,
          0.4443762447523034,
          0.4341632920762767,
          0.4298169120498326,
          0.43419119145559226
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "20c15527-c8d3-4d58-8295-32c5d3c825c2",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6859428794487663,
          0.6646020304177694,
          0.6397008616567234,
          0.6063094886604714,
          0.5752161577127982,
          0.5422828981265929,
          0.5125543580538985,
          0.4940455483065711,
          0.47018742906874506,
          0.4601521419442218,
          0.4535265715513828,
          0.438177652347491,
          0.4410777461701545,
          0.42909972440217425,
          0.42318416180242086,
          0.4291041781073031,
          0.4161583010989111,
          0.39167389095117505,
          0.40247083156581087,
          0.39489471483345767,
          0.38917730528375377,
          0.376418198623519,
          0.3795239215311797,
          0.36670924626686724,
          0.369820064968533,
          0.3589943563592607,
          0.3657058102497156,
          0.35535480190014496,
          0.358841283597808,
          0.35057007431408055
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "f7dce77b-b39c-408e-adec-c1f99c95168d",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6866990649181863,
          0.6814491427463034,
          0.6766098291977592,
          0.6595985625101173,
          0.6433985051901444,
          0.5906348052232162,
          0.5486959037573441,
          0.5332332543704821,
          0.48137817512387815,
          0.49617916967557824,
          0.4557914303696674,
          0.4711929606354755,
          0.433597497318102,
          0.43494791699492413,
          0.47965599609457926,
          0.4140112633290498,
          0.41719396736310876,
          0.4447085528270058,
          0.47113605271215026,
          0.4152068037053813,
          0.4882103803365127,
          0.4802614284598309,
          0.5208609218182771,
          0.5200719719347746,
          0.43576317248137103,
          0.46579986059147377,
          0.4041161617507105,
          0.5052389458469723,
          0.5722408885541169,
          0.4909918629604837
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "0b03f913-9939-4942-b0cf-e0be127fe0df",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6890221130444808,
          0.6674948459086211,
          0.6237627669233055,
          0.5801515959887112,
          0.547591955765434,
          0.522786605761247,
          0.4996164930327503,
          0.47739635144454845,
          0.46832170002702356,
          0.46076832618114455,
          0.44816958984891,
          0.44819685799488124,
          0.44317074904695225,
          0.429278206076599,
          0.421978921878741,
          0.4175269319239446,
          0.406234684197799,
          0.39421365448242224,
          0.39087036848068235,
          0.38850782104736364,
          0.37747853882070903,
          0.37064932149965407,
          0.36801660510076994,
          0.37611952380857605,
          0.364543159313248,
          0.35530457971752555,
          0.35310493500336354,
          0.36526710863274653,
          0.355117225330233,
          0.35086294596897805
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "777049cc-76c0-4582-bf26-8f3b51148cb3",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6883843675903653,
          0.6813321652619735,
          0.6660984650902126,
          0.5819897501364998,
          0.514954237834267,
          0.492320748515751,
          0.475054998760638,
          0.4662173475908197,
          0.4661070437534996,
          0.4498760985291522,
          0.44104059053503947,
          0.44149437754050547,
          0.5309782717538917,
          0.424067478335422,
          0.408480894047281,
          0.4001907086890677,
          0.40520262381304867,
          0.3995272439459096,
          0.4104383681131446,
          0.426533588896627,
          0.4212814344012219,
          0.39118142516716664,
          0.421715988283572,
          0.4325633341851442,
          0.4438256439955338,
          0.42989662911580956,
          0.46455912849177483,
          0.4491042103456414,
          0.48369759891344155,
          0.537813582368519
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "b112dbfe-2424-4738-99f8-781ca8ef7466",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6878116634732859,
          0.6729862218893669,
          0.6529525497109417,
          0.6328667598646044,
          0.6111172701425599,
          0.5731618783900128,
          0.5579244487527488,
          0.5265587789424951,
          0.5192557478008639,
          0.5112463011257891,
          0.48592833461968793,
          0.4828789051604156,
          0.4559391757428358,
          0.45000584612146094,
          0.4343548724040893,
          0.42071442359311567,
          0.42603779147212634,
          0.4115716843213436,
          0.39337120142535886,
          0.38888459058775415,
          0.3702473367757843,
          0.37624069184496783,
          0.3654454911964527,
          0.35285527536258604,
          0.33861295166222943,
          0.35206386112936455,
          0.33677370268941503,
          0.33471409507131805,
          0.33139985894811325,
          0.319480612701264
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "6dffc7df-3b77-4ec9-a4f2-bfc3924e22fd",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6876918968947038,
          0.6850453045057214,
          0.6720998997273653,
          0.6637615950211234,
          0.6637062544408052,
          0.6462436339129572,
          0.6302568637806436,
          0.5907697859017745,
          0.5865785588388858,
          0.5364690689936928,
          0.4924317048943561,
          0.4669832763464554,
          0.4508134219957435,
          0.43269919157028197,
          0.4234208583831787,
          0.4085049256034519,
          0.44423268152319867,
          0.4264428035072658,
          0.43399016675741775,
          0.42422497635302336,
          0.41510684127392977,
          0.4538117136644281,
          0.42911537652430326,
          0.4175835601661516,
          0.43531496395235475,
          0.45495117980500926,
          0.45554354968278304,
          0.4287676541701607,
          0.43993936828944996,
          0.43944503924121026
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "db928086-c3fc-4bb3-bb87-bd0187ca79b5",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6767947305803713,
          0.6161072067592455,
          0.5554470202197199,
          0.519903082029831,
          0.5127181114781881,
          0.49119913969638845,
          0.4830600048320881,
          0.46265892072576253,
          0.458894546797886,
          0.4501345598467306,
          0.4495813680155842,
          0.4482829385333591,
          0.43017156800786077,
          0.4390060876878563,
          0.4311779777496909,
          0.4223466842934705,
          0.4137559946320483,
          0.4322644732712548,
          0.41882361326240686,
          0.4020060013169828,
          0.40512055080869924,
          0.39539441290684946,
          0.37753830249758735,
          0.37763847999526684,
          0.3673603625689152,
          0.37753948863001835,
          0.3630969016880229,
          0.36039151293068117,
          0.3627979925001301,
          0.3538733818968713
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "05e6d6d5-2f45-4e94-b209-832852d839ed",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6811535130376402,
          0.6575180224750353,
          0.6390527409055958,
          0.6196363900018775,
          0.5990707941677259,
          0.5674509779266689,
          0.541600455408511,
          0.521527315741,
          0.49423577630001564,
          0.4683456851088482,
          0.4535912158696548,
          0.448472850996515,
          0.4353028911611308,
          0.43116785987563755,
          0.4318482577800751,
          0.4344091394673223,
          0.4120545483153799,
          0.43635877604069917,
          0.438130115426105,
          0.4344757253709047,
          0.43306242797685707,
          0.4295066177845001,
          0.44591081919877423,
          0.4492435211720674,
          0.4085939573205036,
          0.4447534890278526,
          0.41583398813786715,
          0.48358459394911063,
          0.4542994789455248,
          0.46422790185264917
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"6b9d72c9-3938-4f3d-8a2c-9d83d029df93\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"6b9d72c9-3938-4f3d-8a2c-9d83d029df93\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '6b9d72c9-3938-4f3d-8a2c-9d83d029df93',\n",
       "                        [{\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"99f679d4-76e7-4f9f-bbd1-555e78fa3ea4\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6780548441813188, 0.6553785091437003, 0.6219432119010151, 0.5742637628518441, 0.5451517521471217, 0.5162097198663702, 0.5007325283571142, 0.4704017445085129, 0.4626525338433215, 0.4443148097266322, 0.4346340032879281, 0.43093129690142645, 0.43058447284974916, 0.4101549734815883, 0.41312943056297763, 0.3941123033923227, 0.3933503596103134, 0.361002100435432, 0.3580716672870848, 0.3729392845849484, 0.35556058877908087, 0.3600199680685421, 0.33193760114015586, 0.3290123304451145, 0.3492292205924573, 0.3293317657449971, 0.3189847915932752, 0.34060598172715323, 0.31266800484795504, 0.2833140635404034]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"89cf4597-5bc1-439a-a60d-58248761b78f\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.684204361749732, 0.6737770676612854, 0.6634528362232706, 0.6544931961142498, 0.6270864103151405, 0.6074170947074891, 0.5743604307589324, 0.5473149543223174, 0.5279045944628509, 0.49278677442799446, 0.48599600584610647, 0.48427699493325277, 0.4523281004117883, 0.4497304022312164, 0.45702350295108296, 0.44089669559312905, 0.431158978783566, 0.43874595709469005, 0.43906833037086157, 0.4575766770736031, 0.4459936579932337, 0.4637103495390519, 0.47199372441872306, 0.4599961915741796, 0.46968068610066954, 0.4627873964931654, 0.4941813059475111, 0.49893002976541934, 0.45451603531837464, 0.4800651182299075]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"ddc5774a-8ba7-4d40-a43e-ccbba8c05620\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6840628790970585, 0.6691667268241661, 0.6448489522588425, 0.6155849137168, 0.5742605687915415, 0.5644566144056367, 0.5301005848939868, 0.5040440591925008, 0.49531337365436096, 0.4894125965482371, 0.46666154455447545, 0.45856905663071046, 0.43784999337749203, 0.4355132689510567, 0.42425974077648587, 0.4095668687912577, 0.3982548151615161, 0.39594716611115827, 0.3943622988779188, 0.39770372486920746, 0.37015475152771254, 0.3819641895628206, 0.3681936460992564, 0.36423123536478497, 0.35320471931194913, 0.3351901813837641, 0.3471981970728307, 0.33100938920813483, 0.3292732968710471, 0.3304823974048458]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"c722afe3-9015-45b0-a852-21418a6d2e74\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.685517944978631, 0.6803771884545036, 0.6676947433015574, 0.6589863113735033, 0.6098404464514359, 0.5801480018574259, 0.5600286281627157, 0.5162663148797076, 0.43614847685979763, 0.4351988312990769, 0.38808068788569905, 0.37070523785508197, 0.36956518655237947, 0.37040053606033324, 0.3678945533607317, 0.3616098326185475, 0.358190509547358, 0.35574188258336936, 0.3532881013725115, 0.37606710221456446, 0.3802095952241317, 0.3944414740023406, 0.3784010348112687, 0.35900615375974904, 0.3627664980681046, 0.3569385518198428, 0.3843065583187601, 0.38535331980041837, 0.4241171225257542, 0.4149809293124987]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"2eef39ec-2948-49d8-89bf-8017fcc21c67\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6908488293776766, 0.6815562822968487, 0.6721608019681369, 0.6423448119762439, 0.6106547505383331, 0.5722546137473433, 0.5375067293931897, 0.513466439385345, 0.4874883306487171, 0.47727467342851243, 0.47468184057065255, 0.47499746801196663, 0.45406520732359035, 0.4495279550264423, 0.43423574661863024, 0.4426912366768012, 0.4302351482824427, 0.42154666741113156, 0.4160750128220821, 0.42713721452127906, 0.4029849032273039, 0.39794368182403456, 0.38101441085626536, 0.3834051663460939, 0.38168300300980534, 0.3712402146507576, 0.37001746089562126, 0.3646526482946055, 0.35117477797655666, 0.3351301475135601]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"67da3708-dea6-4fc2-882c-16735636acc1\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6803015968073969, 0.6744948547819386, 0.6710220295449961, 0.6620698659316353, 0.6493567834729733, 0.6023688622142958, 0.5612378581710483, 0.5196757487628771, 0.5060200092585191, 0.4859442296235458, 0.47678791621456973, 0.48066660632257874, 0.47886513575263645, 0.45535824583924334, 0.45145799647206847, 0.47322421877280524, 0.4594953080882197, 0.49055538643961366, 0.4429254925769308, 0.4498768511025802, 0.488962329470593, 0.4635592597982158, 0.43687688941540925, 0.47839923475099644, 0.45752736926078796, 0.48511506370876145, 0.44861718105233234, 0.45829596104829207, 0.45728879000829614, 0.43791951822197955]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"3e874065-36a7-4f5f-a790-227df6dc78a8\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.688653208149804, 0.6698550131009973, 0.6375521196835283, 0.6201025693888825, 0.5779832683899553, 0.5549043905907783, 0.5175946086501154, 0.4942022896619235, 0.4616437109772134, 0.4474668520948161, 0.45004559588317133, 0.445959072297322, 0.4303997218608856, 0.40886207536798747, 0.4076063463653343, 0.38678640786576385, 0.39477335784746254, 0.3849763740088053, 0.37262422733260814, 0.37278245442731367, 0.3642185691762086, 0.36464235347826124, 0.3546807630050585, 0.3389910836438626, 0.34228904405653765, 0.3600515762676939, 0.3533593824232258, 0.3287244268661536, 0.31827989433698606, 0.3191286185225427]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"b28e3c1c-6f9d-481d-aed0-5e031abc6885\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6845555144807567, 0.6760806208071501, 0.6595813362494759, 0.6182211378346318, 0.5872960785160894, 0.5651838831279589, 0.5352103508037069, 0.4894402527290842, 0.5488068103790283, 0.4323890849300053, 0.475373855881069, 0.46288994732110395, 0.3914041845694832, 0.39237379924110743, 0.383466679116954, 0.38502727695133376, 0.3758289567802263, 0.4231949010620946, 0.41218390050141707, 0.44512541605078654, 0.4161548088426175, 0.40600001656490825, 0.44274698547694996, 0.4529354593028193, 0.43333632686863777, 0.44227150600889453, 0.4206065509630286, 0.40855804785438204, 0.42490017725073775, 0.43984424238619596]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"34c23ff3-4158-4367-b26d-d58e9b29da6f\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6687390860152129, 0.637418728634931, 0.6109920233920001, 0.587338634332021, 0.5739547185851755, 0.5501763798188473, 0.5494157311996976, 0.5280684979641496, 0.5105016960038079, 0.49150072635659847, 0.483194959566789, 0.47202684098971637, 0.4756347417831421, 0.47015305481095243, 0.44290877730374173, 0.4399693326673646, 0.4169161081026142, 0.42521084927130437, 0.4237234691778819, 0.4169521056799497, 0.3941852791297839, 0.390464145693802, 0.3892108728920204, 0.38567518505497256, 0.35539162832757704, 0.3535707185665766, 0.3535757195690404, 0.35631607779558155, 0.33717361907452204, 0.31714990126050036]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"43ecbdb1-18d9-4530-b969-7433c45d8b9a\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.684245474960493, 0.6745424674904865, 0.663131782801255, 0.6577222932939945, 0.6288885976957238, 0.604045017387556, 0.546367931884268, 0.49429815463397814, 0.494991235629372, 0.49123712648516116, 0.4468561651914016, 0.4394282480944758, 0.45022506921187694, 0.45400780491206955, 0.4549995033637337, 0.4562366651452106, 0.44937872005545576, 0.4486732164154882, 0.455902782212133, 0.45372189283370973, 0.46128780530846636, 0.502059997682986, 0.4658888386643451, 0.5250499808269998, 0.4780651543451392, 0.4926214679427769, 0.5161490181218022, 0.49076038262118465, 0.5051565582337587, 0.5217371883599654]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"d8df1ff6-0135-431f-ab5a-c7f1bf88d54c\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6761750850124636, 0.6304141660819307, 0.6000529267361775, 0.5754293071475006, 0.5334273664847664, 0.49730545685487093, 0.4916001340041414, 0.4643399113330288, 0.45617576324997317, 0.4353641997788839, 0.4523949740589529, 0.4106393123594459, 0.4128548128593371, 0.3942899115131673, 0.3874697877589055, 0.38688890062956416, 0.38423043869543766, 0.39023378715998885, 0.3801779430557564, 0.36019442458659556, 0.3471294038825565, 0.36288972615043896, 0.3433576215724438, 0.343842874892092, 0.3419108012592159, 0.35779400041713805, 0.3360357998073965, 0.32906989125525893, 0.3165690408236739, 0.3224430963612985]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"0586372d-2628-4388-9d34-19354f2fa14b\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6825458179349485, 0.6739210522693136, 0.6585339276686959, 0.6456814926603566, 0.6112189619437508, 0.5773622803066087, 0.5573529658110246, 0.511428876026817, 0.4782190245130788, 0.45099926746409874, 0.4382017985634182, 0.4299151062965393, 0.4274911046028137, 0.4218586012073185, 0.4096098684746286, 0.3935209118801615, 0.44535715761392014, 0.39567627984544507, 0.43952665847280753, 0.3982902195142663, 0.4221443544263425, 0.3959605079630147, 0.3879664475503175, 0.3963185271491175, 0.39812271439510843, 0.47403285192406697, 0.4443762447523034, 0.4341632920762767, 0.4298169120498326, 0.43419119145559226]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"20c15527-c8d3-4d58-8295-32c5d3c825c2\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6859428794487663, 0.6646020304177694, 0.6397008616567234, 0.6063094886604714, 0.5752161577127982, 0.5422828981265929, 0.5125543580538985, 0.4940455483065711, 0.47018742906874506, 0.4601521419442218, 0.4535265715513828, 0.438177652347491, 0.4410777461701545, 0.42909972440217425, 0.42318416180242086, 0.4291041781073031, 0.4161583010989111, 0.39167389095117505, 0.40247083156581087, 0.39489471483345767, 0.38917730528375377, 0.376418198623519, 0.3795239215311797, 0.36670924626686724, 0.369820064968533, 0.3589943563592607, 0.3657058102497156, 0.35535480190014496, 0.358841283597808, 0.35057007431408055]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"f7dce77b-b39c-408e-adec-c1f99c95168d\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6866990649181863, 0.6814491427463034, 0.6766098291977592, 0.6595985625101173, 0.6433985051901444, 0.5906348052232162, 0.5486959037573441, 0.5332332543704821, 0.48137817512387815, 0.49617916967557824, 0.4557914303696674, 0.4711929606354755, 0.433597497318102, 0.43494791699492413, 0.47965599609457926, 0.4140112633290498, 0.41719396736310876, 0.4447085528270058, 0.47113605271215026, 0.4152068037053813, 0.4882103803365127, 0.4802614284598309, 0.5208609218182771, 0.5200719719347746, 0.43576317248137103, 0.46579986059147377, 0.4041161617507105, 0.5052389458469723, 0.5722408885541169, 0.4909918629604837]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"0b03f913-9939-4942-b0cf-e0be127fe0df\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6890221130444808, 0.6674948459086211, 0.6237627669233055, 0.5801515959887112, 0.547591955765434, 0.522786605761247, 0.4996164930327503, 0.47739635144454845, 0.46832170002702356, 0.46076832618114455, 0.44816958984891, 0.44819685799488124, 0.44317074904695225, 0.429278206076599, 0.421978921878741, 0.4175269319239446, 0.406234684197799, 0.39421365448242224, 0.39087036848068235, 0.38850782104736364, 0.37747853882070903, 0.37064932149965407, 0.36801660510076994, 0.37611952380857605, 0.364543159313248, 0.35530457971752555, 0.35310493500336354, 0.36526710863274653, 0.355117225330233, 0.35086294596897805]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"777049cc-76c0-4582-bf26-8f3b51148cb3\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6883843675903653, 0.6813321652619735, 0.6660984650902126, 0.5819897501364998, 0.514954237834267, 0.492320748515751, 0.475054998760638, 0.4662173475908197, 0.4661070437534996, 0.4498760985291522, 0.44104059053503947, 0.44149437754050547, 0.5309782717538917, 0.424067478335422, 0.408480894047281, 0.4001907086890677, 0.40520262381304867, 0.3995272439459096, 0.4104383681131446, 0.426533588896627, 0.4212814344012219, 0.39118142516716664, 0.421715988283572, 0.4325633341851442, 0.4438256439955338, 0.42989662911580956, 0.46455912849177483, 0.4491042103456414, 0.48369759891344155, 0.537813582368519]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"b112dbfe-2424-4738-99f8-781ca8ef7466\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6878116634732859, 0.6729862218893669, 0.6529525497109417, 0.6328667598646044, 0.6111172701425599, 0.5731618783900128, 0.5579244487527488, 0.5265587789424951, 0.5192557478008639, 0.5112463011257891, 0.48592833461968793, 0.4828789051604156, 0.4559391757428358, 0.45000584612146094, 0.4343548724040893, 0.42071442359311567, 0.42603779147212634, 0.4115716843213436, 0.39337120142535886, 0.38888459058775415, 0.3702473367757843, 0.37624069184496783, 0.3654454911964527, 0.35285527536258604, 0.33861295166222943, 0.35206386112936455, 0.33677370268941503, 0.33471409507131805, 0.33139985894811325, 0.319480612701264]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"6dffc7df-3b77-4ec9-a4f2-bfc3924e22fd\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6876918968947038, 0.6850453045057214, 0.6720998997273653, 0.6637615950211234, 0.6637062544408052, 0.6462436339129572, 0.6302568637806436, 0.5907697859017745, 0.5865785588388858, 0.5364690689936928, 0.4924317048943561, 0.4669832763464554, 0.4508134219957435, 0.43269919157028197, 0.4234208583831787, 0.4085049256034519, 0.44423268152319867, 0.4264428035072658, 0.43399016675741775, 0.42422497635302336, 0.41510684127392977, 0.4538117136644281, 0.42911537652430326, 0.4175835601661516, 0.43531496395235475, 0.45495117980500926, 0.45554354968278304, 0.4287676541701607, 0.43993936828944996, 0.43944503924121026]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"db928086-c3fc-4bb3-bb87-bd0187ca79b5\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6767947305803713, 0.6161072067592455, 0.5554470202197199, 0.519903082029831, 0.5127181114781881, 0.49119913969638845, 0.4830600048320881, 0.46265892072576253, 0.458894546797886, 0.4501345598467306, 0.4495813680155842, 0.4482829385333591, 0.43017156800786077, 0.4390060876878563, 0.4311779777496909, 0.4223466842934705, 0.4137559946320483, 0.4322644732712548, 0.41882361326240686, 0.4020060013169828, 0.40512055080869924, 0.39539441290684946, 0.37753830249758735, 0.37763847999526684, 0.3673603625689152, 0.37753948863001835, 0.3630969016880229, 0.36039151293068117, 0.3627979925001301, 0.3538733818968713]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"05e6d6d5-2f45-4e94-b209-832852d839ed\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6811535130376402, 0.6575180224750353, 0.6390527409055958, 0.6196363900018775, 0.5990707941677259, 0.5674509779266689, 0.541600455408511, 0.521527315741, 0.49423577630001564, 0.4683456851088482, 0.4535912158696548, 0.448472850996515, 0.4353028911611308, 0.43116785987563755, 0.4318482577800751, 0.4344091394673223, 0.4120545483153799, 0.43635877604069917, 0.438130115426105, 0.4344757253709047, 0.43306242797685707, 0.4295066177845001, 0.44591081919877423, 0.4492435211720674, 0.4085939573205036, 0.4447534890278526, 0.41583398813786715, 0.48358459394911063, 0.4542994789455248, 0.46422790185264917]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6b9d72c9-3938-4f3d-8a2c-9d83d029df93');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean  acc         0.791872\n",
      "loss        0.446528\n",
      "val_acc     0.781109\n",
      "val_loss    0.490319\n",
      "dtype: float64\n",
      "std  acc         0.072161\n",
      "loss        0.099221\n",
      "val_acc     0.077469\n",
      "val_loss    0.090155\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "1",
         "text": "",
         "type": "scatter",
         "uid": "7028412f-c79b-4b7f-9bd9-c0a9cfb039bf",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.75,
          0.8199999928474426,
          0.8199999928474426,
          0.6800000071525574,
          0.8700000047683716,
          0.8100000023841858,
          0.800000011920929,
          0.7900000214576721,
          0.8600000143051147,
          0.8100000023841858
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"ce66762d-9a0e-41b6-b745-7482391a40b5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"ce66762d-9a0e-41b6-b745-7482391a40b5\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'ce66762d-9a0e-41b6-b745-7482391a40b5',\n",
       "                        [{\"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"1\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"7028412f-c79b-4b7f-9bd9-c0a9cfb039bf\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.75, 0.8199999928474426, 0.8199999928474426, 0.6800000071525574, 0.8700000047683716, 0.8100000023841858, 0.800000011920929, 0.7900000214576721, 0.8600000143051147, 0.8100000023841858]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ce66762d-9a0e-41b6-b745-7482391a40b5');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media  0.8010000050067901\n",
      "std  0.05425249575564484\n"
     ]
    }
   ],
   "source": [
    "process_results(gl_hist, gl_evas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/glorot__wobn_lstm/kfold1\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 16s - loss: 0.6911 - acc: 0.5746 - val_loss: 0.6864 - val_acc: 0.5957\n",
      "Epoch 2/30\n",
      "4140/4140 - 7s - loss: 0.6850 - acc: 0.5768 - val_loss: 0.6736 - val_acc: 0.5957\n",
      "Epoch 3/30\n",
      "4140/4140 - 7s - loss: 0.6670 - acc: 0.5906 - val_loss: 0.6234 - val_acc: 0.6739\n",
      "Epoch 4/30\n",
      "4140/4140 - 7s - loss: 0.6324 - acc: 0.6543 - val_loss: 0.5719 - val_acc: 0.7348\n",
      "Epoch 5/30\n",
      "4140/4140 - 5s - loss: 0.6061 - acc: 0.6964 - val_loss: 0.5504 - val_acc: 0.7674\n",
      "Epoch 6/30\n",
      "4140/4140 - 1s - loss: 0.5819 - acc: 0.6923 - val_loss: 0.4730 - val_acc: 0.7826\n",
      "Epoch 7/30\n",
      "4140/4140 - 1s - loss: 0.5457 - acc: 0.7155 - val_loss: 0.4479 - val_acc: 0.7848\n",
      "Epoch 8/30\n",
      "4140/4140 - 1s - loss: 0.5192 - acc: 0.7469 - val_loss: 0.4264 - val_acc: 0.8065\n",
      "Epoch 9/30\n",
      "4140/4140 - 1s - loss: 0.5023 - acc: 0.7464 - val_loss: 0.4133 - val_acc: 0.8087\n",
      "Epoch 10/30\n",
      "4140/4140 - 1s - loss: 0.4856 - acc: 0.7640 - val_loss: 0.4002 - val_acc: 0.8196\n",
      "Epoch 11/30\n",
      "4140/4140 - 1s - loss: 0.4714 - acc: 0.7717 - val_loss: 0.3924 - val_acc: 0.8304\n",
      "Epoch 12/30\n",
      "4140/4140 - 1s - loss: 0.4638 - acc: 0.7664 - val_loss: 0.3892 - val_acc: 0.8304\n",
      "Epoch 13/30\n",
      "4140/4140 - 1s - loss: 0.4363 - acc: 0.7848 - val_loss: 0.3983 - val_acc: 0.8261\n",
      "Epoch 14/30\n",
      "4140/4140 - 1s - loss: 0.4381 - acc: 0.7778 - val_loss: 0.4069 - val_acc: 0.8283\n",
      "Epoch 15/30\n",
      "4140/4140 - 1s - loss: 0.4228 - acc: 0.7814 - val_loss: 0.4689 - val_acc: 0.8283\n",
      "Epoch 16/30\n",
      "4140/4140 - 1s - loss: 0.4359 - acc: 0.7845 - val_loss: 0.3882 - val_acc: 0.8217\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.4412 - acc: 0.7814 - val_loss: 0.4042 - val_acc: 0.8304\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.4173 - acc: 0.7879 - val_loss: 0.4424 - val_acc: 0.8087\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.4283 - acc: 0.7809 - val_loss: 0.4267 - val_acc: 0.8130\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.4126 - acc: 0.7899 - val_loss: 0.4099 - val_acc: 0.8196\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.4002 - acc: 0.7981 - val_loss: 0.5153 - val_acc: 0.8109\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.3822 - acc: 0.7990 - val_loss: 0.5863 - val_acc: 0.8174\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.3880 - acc: 0.7954 - val_loss: 0.5009 - val_acc: 0.8304\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.3866 - acc: 0.7978 - val_loss: 0.5214 - val_acc: 0.8196\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.3790 - acc: 0.7964 - val_loss: 0.8101 - val_acc: 0.8348\n",
      "Epoch 26/30\n",
      "4140/4140 - 2s - loss: 0.3791 - acc: 0.8031 - val_loss: 0.8036 - val_acc: 0.8326\n",
      "Epoch 27/30\n",
      "4140/4140 - 3s - loss: 0.3900 - acc: 0.7925 - val_loss: 0.6141 - val_acc: 0.8283\n",
      "Epoch 28/30\n",
      "4140/4140 - 4s - loss: 0.3915 - acc: 0.7915 - val_loss: 0.4119 - val_acc: 0.8152\n",
      "Epoch 29/30\n",
      "4140/4140 - 4s - loss: 0.3791 - acc: 0.8048 - val_loss: 0.6071 - val_acc: 0.8304\n",
      "Epoch 30/30\n",
      "4140/4140 - 6s - loss: 0.3626 - acc: 0.8041 - val_loss: 0.5502 - val_acc: 0.8174\n",
      "100/100 [==============================] - 1s 5ms/sample - loss: 0.5571 - acc: 0.8700\n",
      "logs/fit/glorot__wobn_lstm/kfold2\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 17s - loss: 0.6913 - acc: 0.5831 - val_loss: 0.6895 - val_acc: 0.5609\n",
      "Epoch 2/30\n",
      "4140/4140 - 7s - loss: 0.6846 - acc: 0.6162 - val_loss: 0.6826 - val_acc: 0.5761\n",
      "Epoch 3/30\n",
      "4140/4140 - 7s - loss: 0.6766 - acc: 0.6128 - val_loss: 0.6608 - val_acc: 0.6196\n",
      "Epoch 4/30\n",
      "4140/4140 - 7s - loss: 0.6644 - acc: 0.6527 - val_loss: 0.6572 - val_acc: 0.5826\n",
      "Epoch 5/30\n",
      "4140/4140 - 7s - loss: 0.6563 - acc: 0.6232 - val_loss: 0.6356 - val_acc: 0.6543\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.6240 - acc: 0.6920 - val_loss: 0.5812 - val_acc: 0.7435\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.5940 - acc: 0.7099 - val_loss: 0.5699 - val_acc: 0.7391\n",
      "Epoch 8/30\n",
      "4140/4140 - 7s - loss: 0.5641 - acc: 0.7374 - val_loss: 0.6269 - val_acc: 0.7761\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.5692 - acc: 0.7290 - val_loss: 0.5153 - val_acc: 0.7696\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.5361 - acc: 0.7486 - val_loss: 0.5305 - val_acc: 0.7913\n",
      "Epoch 11/30\n",
      "4140/4140 - 7s - loss: 0.5145 - acc: 0.7514 - val_loss: 0.5205 - val_acc: 0.8109\n",
      "Epoch 12/30\n",
      "4140/4140 - 7s - loss: 0.5072 - acc: 0.7563 - val_loss: 0.5755 - val_acc: 0.8043\n",
      "Epoch 13/30\n",
      "4140/4140 - 7s - loss: 0.5374 - acc: 0.7423 - val_loss: 0.4702 - val_acc: 0.8000\n",
      "Epoch 14/30\n",
      "4140/4140 - 7s - loss: 0.4962 - acc: 0.7676 - val_loss: 0.4690 - val_acc: 0.8196\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.4797 - acc: 0.7775 - val_loss: 0.4463 - val_acc: 0.8152\n",
      "Epoch 16/30\n",
      "4140/4140 - 8s - loss: 0.4717 - acc: 0.7787 - val_loss: 0.4574 - val_acc: 0.8174\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.4620 - acc: 0.7913 - val_loss: 0.4387 - val_acc: 0.8130\n",
      "Epoch 18/30\n",
      "4140/4140 - 7s - loss: 0.4623 - acc: 0.7906 - val_loss: 0.4449 - val_acc: 0.8196\n",
      "Epoch 19/30\n",
      "4140/4140 - 7s - loss: 0.4532 - acc: 0.8036 - val_loss: 0.4366 - val_acc: 0.8239\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.4445 - acc: 0.8104 - val_loss: 0.4253 - val_acc: 0.8239\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.4504 - acc: 0.7983 - val_loss: 0.4433 - val_acc: 0.8348\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.4370 - acc: 0.8123 - val_loss: 0.4317 - val_acc: 0.8087\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.4344 - acc: 0.8143 - val_loss: 0.4738 - val_acc: 0.8261\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.4373 - acc: 0.8174 - val_loss: 0.4338 - val_acc: 0.8239\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.4258 - acc: 0.8227 - val_loss: 0.4678 - val_acc: 0.8239\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.4173 - acc: 0.8220 - val_loss: 0.4626 - val_acc: 0.8261\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.4019 - acc: 0.8372 - val_loss: 0.4772 - val_acc: 0.8261\n",
      "Epoch 28/30\n",
      "4140/4140 - 7s - loss: 0.3948 - acc: 0.8321 - val_loss: 0.5129 - val_acc: 0.8152\n",
      "Epoch 29/30\n",
      "4140/4140 - 7s - loss: 0.3985 - acc: 0.8321 - val_loss: 0.4896 - val_acc: 0.8239\n",
      "Epoch 30/30\n",
      "4140/4140 - 7s - loss: 0.3977 - acc: 0.8394 - val_loss: 0.4564 - val_acc: 0.8239\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.3604 - acc: 0.8600\n",
      "logs/fit/glorot__wobn_lstm/kfold3\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 3s - loss: 0.6909 - acc: 0.5715 - val_loss: 0.6857 - val_acc: 0.6109\n",
      "Epoch 2/30\n",
      "4140/4140 - 1s - loss: 0.7012 - acc: 0.5872 - val_loss: 0.6773 - val_acc: 0.6609\n",
      "Epoch 3/30\n",
      "4140/4140 - 1s - loss: 0.6800 - acc: 0.6249 - val_loss: 0.6635 - val_acc: 0.6891\n",
      "Epoch 4/30\n",
      "4140/4140 - 1s - loss: 0.6676 - acc: 0.6314 - val_loss: 0.6305 - val_acc: 0.7130\n",
      "Epoch 5/30\n",
      "4140/4140 - 1s - loss: 0.6591 - acc: 0.6362 - val_loss: 0.6190 - val_acc: 0.7130\n",
      "Epoch 6/30\n",
      "4140/4140 - 1s - loss: 0.6559 - acc: 0.6442 - val_loss: 0.6140 - val_acc: 0.7348\n",
      "Epoch 7/30\n",
      "4140/4140 - 1s - loss: 0.6474 - acc: 0.6447 - val_loss: 0.6131 - val_acc: 0.7283\n",
      "Epoch 8/30\n",
      "4140/4140 - 1s - loss: 0.6377 - acc: 0.6710 - val_loss: 0.5934 - val_acc: 0.7478\n",
      "Epoch 9/30\n",
      "4140/4140 - 1s - loss: 0.6131 - acc: 0.6896 - val_loss: 0.5771 - val_acc: 0.7478\n",
      "Epoch 10/30\n",
      "4140/4140 - 1s - loss: 0.6057 - acc: 0.6937 - val_loss: 0.5590 - val_acc: 0.7609\n",
      "Epoch 11/30\n",
      "4140/4140 - 1s - loss: 0.5971 - acc: 0.6954 - val_loss: 0.5678 - val_acc: 0.7326\n",
      "Epoch 12/30\n",
      "4140/4140 - 1s - loss: 0.5706 - acc: 0.7070 - val_loss: 0.5125 - val_acc: 0.7739\n",
      "Epoch 13/30\n",
      "4140/4140 - 1s - loss: 0.5690 - acc: 0.7143 - val_loss: 0.5055 - val_acc: 0.7696\n",
      "Epoch 14/30\n",
      "4140/4140 - 1s - loss: 0.5555 - acc: 0.7227 - val_loss: 0.4905 - val_acc: 0.7717\n",
      "Epoch 15/30\n",
      "4140/4140 - 1s - loss: 0.5404 - acc: 0.7280 - val_loss: 0.5160 - val_acc: 0.7783\n",
      "Epoch 16/30\n",
      "4140/4140 - 1s - loss: 0.5612 - acc: 0.7278 - val_loss: 0.5031 - val_acc: 0.7826\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.5491 - acc: 0.7258 - val_loss: 0.4917 - val_acc: 0.7935\n",
      "Epoch 18/30\n",
      "4140/4140 - 2s - loss: 0.5462 - acc: 0.7273 - val_loss: 0.5017 - val_acc: 0.7565\n",
      "Epoch 19/30\n",
      "4140/4140 - 2s - loss: 0.5246 - acc: 0.7454 - val_loss: 0.4683 - val_acc: 0.7870\n",
      "Epoch 20/30\n",
      "4140/4140 - 4s - loss: 0.5199 - acc: 0.7505 - val_loss: 0.4665 - val_acc: 0.7674\n",
      "Epoch 21/30\n",
      "4140/4140 - 4s - loss: 0.5004 - acc: 0.7705 - val_loss: 0.4362 - val_acc: 0.8174\n",
      "Epoch 22/30\n",
      "4140/4140 - 5s - loss: 0.4890 - acc: 0.7657 - val_loss: 0.4230 - val_acc: 0.8087\n",
      "Epoch 23/30\n",
      "4140/4140 - 6s - loss: 0.4615 - acc: 0.7870 - val_loss: 0.4097 - val_acc: 0.8217\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.4658 - acc: 0.7838 - val_loss: 0.4024 - val_acc: 0.8152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.4602 - acc: 0.7795 - val_loss: 0.3882 - val_acc: 0.8326\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.4658 - acc: 0.7819 - val_loss: 0.3996 - val_acc: 0.8152\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.4439 - acc: 0.7930 - val_loss: 0.3968 - val_acc: 0.8152\n",
      "Epoch 28/30\n",
      "4140/4140 - 7s - loss: 0.4496 - acc: 0.7884 - val_loss: 0.3849 - val_acc: 0.8283\n",
      "Epoch 29/30\n",
      "4140/4140 - 7s - loss: 0.4380 - acc: 0.7903 - val_loss: 0.3698 - val_acc: 0.8348\n",
      "Epoch 30/30\n",
      "4140/4140 - 7s - loss: 0.4455 - acc: 0.7853 - val_loss: 0.3731 - val_acc: 0.8391\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 0.3614 - acc: 0.8400\n",
      "logs/fit/glorot__wobn_lstm/kfold4\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 18s - loss: 0.6910 - acc: 0.5800 - val_loss: 0.6914 - val_acc: 0.5326\n",
      "Epoch 2/30\n",
      "4140/4140 - 7s - loss: 0.6875 - acc: 0.5814 - val_loss: 0.6861 - val_acc: 0.5370\n",
      "Epoch 3/30\n",
      "4140/4140 - 7s - loss: 0.6895 - acc: 0.5937 - val_loss: 0.6723 - val_acc: 0.5348\n",
      "Epoch 4/30\n",
      "4140/4140 - 7s - loss: 0.6699 - acc: 0.5826 - val_loss: 0.6730 - val_acc: 0.5348\n",
      "Epoch 5/30\n",
      "4140/4140 - 7s - loss: 0.6628 - acc: 0.5857 - val_loss: 0.6718 - val_acc: 0.5391\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.6728 - acc: 0.6048 - val_loss: 0.6770 - val_acc: 0.5652\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.6652 - acc: 0.6155 - val_loss: 0.6453 - val_acc: 0.6304\n",
      "Epoch 8/30\n",
      "4140/4140 - 7s - loss: 0.6450 - acc: 0.6324 - val_loss: 0.6068 - val_acc: 0.6478\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.6209 - acc: 0.6512 - val_loss: 0.5671 - val_acc: 0.6348\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.5740 - acc: 0.6681 - val_loss: 0.5019 - val_acc: 0.7500\n",
      "Epoch 11/30\n",
      "4140/4140 - 7s - loss: 0.5738 - acc: 0.6703 - val_loss: 0.4825 - val_acc: 0.7239\n",
      "Epoch 12/30\n",
      "4140/4140 - 7s - loss: 0.5455 - acc: 0.6894 - val_loss: 0.4819 - val_acc: 0.7304\n",
      "Epoch 13/30\n",
      "4140/4140 - 7s - loss: 0.5298 - acc: 0.6952 - val_loss: 0.4853 - val_acc: 0.7043\n",
      "Epoch 14/30\n",
      "4140/4140 - 7s - loss: 0.5048 - acc: 0.7155 - val_loss: 0.4431 - val_acc: 0.7674\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.4882 - acc: 0.7403 - val_loss: 0.4536 - val_acc: 0.7609\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.4779 - acc: 0.7365 - val_loss: 0.4255 - val_acc: 0.7761\n",
      "Epoch 17/30\n",
      "4140/4140 - 8s - loss: 0.4833 - acc: 0.7502 - val_loss: 0.4618 - val_acc: 0.7587\n",
      "Epoch 18/30\n",
      "4140/4140 - 7s - loss: 0.4545 - acc: 0.7577 - val_loss: 0.4226 - val_acc: 0.7804\n",
      "Epoch 19/30\n",
      "4140/4140 - 7s - loss: 0.4499 - acc: 0.7606 - val_loss: 0.4126 - val_acc: 0.7935\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.4479 - acc: 0.7635 - val_loss: 0.4604 - val_acc: 0.7935\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.4376 - acc: 0.7640 - val_loss: 0.4350 - val_acc: 0.8130\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.4413 - acc: 0.7587 - val_loss: 0.4153 - val_acc: 0.8022\n",
      "Epoch 23/30\n",
      "4140/4140 - 6s - loss: 0.4250 - acc: 0.7722 - val_loss: 0.3985 - val_acc: 0.8261\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.4292 - acc: 0.7742 - val_loss: 0.4308 - val_acc: 0.8348\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.4338 - acc: 0.7749 - val_loss: 0.3903 - val_acc: 0.8370\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.4126 - acc: 0.7742 - val_loss: 0.4104 - val_acc: 0.8391\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.4043 - acc: 0.7857 - val_loss: 0.4237 - val_acc: 0.8413\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.4103 - acc: 0.7870 - val_loss: 0.3850 - val_acc: 0.8391\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.4106 - acc: 0.7780 - val_loss: 0.4623 - val_acc: 0.8196\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.4027 - acc: 0.7771 - val_loss: 0.4353 - val_acc: 0.8370\n",
      "100/100 [==============================] - 0s 587us/sample - loss: 0.4362 - acc: 0.8600\n",
      "logs/fit/glorot__wobn_lstm/kfold5\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 3s - loss: 0.6907 - acc: 0.5780 - val_loss: 0.6865 - val_acc: 0.5804\n",
      "Epoch 2/30\n",
      "4140/4140 - 1s - loss: 0.6799 - acc: 0.5785 - val_loss: 0.6758 - val_acc: 0.5804\n",
      "Epoch 3/30\n",
      "4140/4140 - 1s - loss: 0.6641 - acc: 0.5787 - val_loss: 0.6548 - val_acc: 0.5804\n",
      "Epoch 4/30\n",
      "4140/4140 - 1s - loss: 0.6338 - acc: 0.5903 - val_loss: 0.6249 - val_acc: 0.5804\n",
      "Epoch 5/30\n",
      "4140/4140 - 1s - loss: 0.6210 - acc: 0.5920 - val_loss: 0.6104 - val_acc: 0.5804\n",
      "Epoch 6/30\n",
      "4140/4140 - 1s - loss: 0.5786 - acc: 0.6130 - val_loss: 0.5691 - val_acc: 0.6348\n",
      "Epoch 7/30\n",
      "4140/4140 - 1s - loss: 0.5438 - acc: 0.6425 - val_loss: 0.5656 - val_acc: 0.7391\n",
      "Epoch 8/30\n",
      "4140/4140 - 1s - loss: 0.5228 - acc: 0.6959 - val_loss: 0.5545 - val_acc: 0.7826\n",
      "Epoch 9/30\n",
      "4140/4140 - 2s - loss: 0.5059 - acc: 0.7732 - val_loss: 0.5861 - val_acc: 0.7761\n",
      "Epoch 10/30\n",
      "4140/4140 - 2s - loss: 0.4853 - acc: 0.7940 - val_loss: 0.5337 - val_acc: 0.7848\n",
      "Epoch 11/30\n",
      "4140/4140 - 4s - loss: 0.4794 - acc: 0.7978 - val_loss: 0.5344 - val_acc: 0.7761\n",
      "Epoch 12/30\n",
      "4140/4140 - 4s - loss: 0.4604 - acc: 0.8082 - val_loss: 0.5368 - val_acc: 0.7761\n",
      "Epoch 13/30\n",
      "4140/4140 - 5s - loss: 0.4470 - acc: 0.8167 - val_loss: 0.5346 - val_acc: 0.7652\n",
      "Epoch 14/30\n",
      "4140/4140 - 7s - loss: 0.4471 - acc: 0.8097 - val_loss: 0.5396 - val_acc: 0.7826\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.4401 - acc: 0.8164 - val_loss: 0.5301 - val_acc: 0.7761\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.4402 - acc: 0.8116 - val_loss: 0.5902 - val_acc: 0.8022\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.4271 - acc: 0.8213 - val_loss: 0.6386 - val_acc: 0.7891\n",
      "Epoch 18/30\n",
      "4140/4140 - 8s - loss: 0.4505 - acc: 0.8024 - val_loss: 0.6623 - val_acc: 0.7957\n",
      "Epoch 19/30\n",
      "4140/4140 - 7s - loss: 0.4218 - acc: 0.8324 - val_loss: 0.5838 - val_acc: 0.7870\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.4117 - acc: 0.8336 - val_loss: 0.6627 - val_acc: 0.8043\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.4022 - acc: 0.8336 - val_loss: 0.6036 - val_acc: 0.8000\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.3970 - acc: 0.8336 - val_loss: 0.5861 - val_acc: 0.7957\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.3971 - acc: 0.8362 - val_loss: 0.5709 - val_acc: 0.7978\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.3867 - acc: 0.8415 - val_loss: 0.5494 - val_acc: 0.7891\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.3822 - acc: 0.8406 - val_loss: 0.5406 - val_acc: 0.7891\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.3744 - acc: 0.8452 - val_loss: 0.5358 - val_acc: 0.7783\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.3738 - acc: 0.8442 - val_loss: 0.5459 - val_acc: 0.7739\n",
      "Epoch 28/30\n",
      "4140/4140 - 7s - loss: 0.3760 - acc: 0.8399 - val_loss: 0.5643 - val_acc: 0.7804\n",
      "Epoch 29/30\n",
      "4140/4140 - 7s - loss: 0.3813 - acc: 0.8377 - val_loss: 0.6913 - val_acc: 0.8087\n",
      "Epoch 30/30\n",
      "4140/4140 - 7s - loss: 0.3465 - acc: 0.8577 - val_loss: 0.7574 - val_acc: 0.8087\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 0.6985 - acc: 0.8300\n",
      "logs/fit/glorot__wobn_lstm/kfold6\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 18s - loss: 0.6908 - acc: 0.5807 - val_loss: 0.6885 - val_acc: 0.5717\n",
      "Epoch 2/30\n",
      "4140/4140 - 7s - loss: 0.6863 - acc: 0.5787 - val_loss: 0.6824 - val_acc: 0.5717\n",
      "Epoch 3/30\n",
      "4140/4140 - 7s - loss: 0.6783 - acc: 0.5995 - val_loss: 0.6686 - val_acc: 0.6261\n",
      "Epoch 4/30\n",
      "4140/4140 - 7s - loss: 0.6718 - acc: 0.6085 - val_loss: 0.6443 - val_acc: 0.5717\n",
      "Epoch 5/30\n",
      "4140/4140 - 7s - loss: 0.6407 - acc: 0.6162 - val_loss: 0.5880 - val_acc: 0.6348\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.5976 - acc: 0.6476 - val_loss: 0.5468 - val_acc: 0.7087\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.5679 - acc: 0.6802 - val_loss: 0.5068 - val_acc: 0.7543\n",
      "Epoch 8/30\n",
      "4140/4140 - 7s - loss: 0.5429 - acc: 0.6954 - val_loss: 0.5001 - val_acc: 0.7739\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.5182 - acc: 0.7150 - val_loss: 0.4826 - val_acc: 0.7913\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.5047 - acc: 0.7251 - val_loss: 0.4496 - val_acc: 0.8109\n",
      "Epoch 11/30\n",
      "4140/4140 - 7s - loss: 0.4782 - acc: 0.7362 - val_loss: 0.4300 - val_acc: 0.8000\n",
      "Epoch 12/30\n",
      "4140/4140 - 7s - loss: 0.4833 - acc: 0.7522 - val_loss: 0.4348 - val_acc: 0.8239\n",
      "Epoch 13/30\n",
      "4140/4140 - 7s - loss: 0.4763 - acc: 0.7652 - val_loss: 0.4261 - val_acc: 0.8065\n",
      "Epoch 14/30\n",
      "4140/4140 - 7s - loss: 0.4586 - acc: 0.7635 - val_loss: 0.4192 - val_acc: 0.8065\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.4528 - acc: 0.7556 - val_loss: 0.5076 - val_acc: 0.8152\n",
      "Epoch 16/30\n",
      "4140/4140 - 6s - loss: 0.4494 - acc: 0.7500 - val_loss: 0.4823 - val_acc: 0.8239\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.4429 - acc: 0.7587 - val_loss: 0.4412 - val_acc: 0.8261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.4290 - acc: 0.7742 - val_loss: 0.4428 - val_acc: 0.8261\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.4189 - acc: 0.7693 - val_loss: 0.4795 - val_acc: 0.8217\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.4177 - acc: 0.7696 - val_loss: 0.4633 - val_acc: 0.8283\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.4175 - acc: 0.7650 - val_loss: 0.4052 - val_acc: 0.8152\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.4015 - acc: 0.7800 - val_loss: 0.4331 - val_acc: 0.8239\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.3983 - acc: 0.7802 - val_loss: 0.4276 - val_acc: 0.8348\n",
      "Epoch 24/30\n",
      "4140/4140 - 1s - loss: 0.3868 - acc: 0.7923 - val_loss: 0.5409 - val_acc: 0.8261\n",
      "Epoch 25/30\n",
      "4140/4140 - 1s - loss: 0.4035 - acc: 0.7816 - val_loss: 0.4822 - val_acc: 0.8304\n",
      "Epoch 26/30\n",
      "4140/4140 - 1s - loss: 0.3822 - acc: 0.7983 - val_loss: 0.5901 - val_acc: 0.8283\n",
      "Epoch 27/30\n",
      "4140/4140 - 1s - loss: 0.3845 - acc: 0.8048 - val_loss: 0.5029 - val_acc: 0.8239\n",
      "Epoch 28/30\n",
      "4140/4140 - 1s - loss: 0.3851 - acc: 0.8138 - val_loss: 0.5599 - val_acc: 0.8239\n",
      "Epoch 29/30\n",
      "4140/4140 - 1s - loss: 0.3570 - acc: 0.8147 - val_loss: 0.7622 - val_acc: 0.8348\n",
      "Epoch 30/30\n",
      "4140/4140 - 1s - loss: 0.3710 - acc: 0.8213 - val_loss: 0.6769 - val_acc: 0.8283\n",
      "100/100 [==============================] - 0s 610us/sample - loss: 0.6189 - acc: 0.8000\n",
      "logs/fit/glorot__wobn_lstm/kfold7\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 4s - loss: 0.6905 - acc: 0.5804 - val_loss: 0.6890 - val_acc: 0.5565\n",
      "Epoch 2/30\n",
      "4140/4140 - 2s - loss: 0.6806 - acc: 0.5807 - val_loss: 0.6698 - val_acc: 0.5565\n",
      "Epoch 3/30\n",
      "4140/4140 - 4s - loss: 0.6688 - acc: 0.5819 - val_loss: 0.6517 - val_acc: 0.5587\n",
      "Epoch 4/30\n",
      "4140/4140 - 4s - loss: 0.6407 - acc: 0.6268 - val_loss: 0.5776 - val_acc: 0.6870\n",
      "Epoch 5/30\n",
      "4140/4140 - 4s - loss: 0.6007 - acc: 0.6539 - val_loss: 0.5214 - val_acc: 0.7717\n",
      "Epoch 6/30\n",
      "4140/4140 - 6s - loss: 0.5819 - acc: 0.6713 - val_loss: 0.4842 - val_acc: 0.7630\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.5532 - acc: 0.6732 - val_loss: 0.4702 - val_acc: 0.7783\n",
      "Epoch 8/30\n",
      "4140/4140 - 7s - loss: 0.5408 - acc: 0.6853 - val_loss: 0.4442 - val_acc: 0.8174\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.5230 - acc: 0.6932 - val_loss: 0.4553 - val_acc: 0.8022\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.5126 - acc: 0.7007 - val_loss: 0.4356 - val_acc: 0.8261\n",
      "Epoch 11/30\n",
      "4140/4140 - 7s - loss: 0.4960 - acc: 0.7072 - val_loss: 0.4227 - val_acc: 0.8109\n",
      "Epoch 12/30\n",
      "4140/4140 - 7s - loss: 0.4944 - acc: 0.7126 - val_loss: 0.4398 - val_acc: 0.8239\n",
      "Epoch 13/30\n",
      "4140/4140 - 7s - loss: 0.4845 - acc: 0.7060 - val_loss: 0.4374 - val_acc: 0.8283\n",
      "Epoch 14/30\n",
      "4140/4140 - 7s - loss: 0.4677 - acc: 0.7126 - val_loss: 0.4097 - val_acc: 0.8326\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.4736 - acc: 0.7157 - val_loss: 0.4127 - val_acc: 0.8174\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.4684 - acc: 0.7116 - val_loss: 0.4269 - val_acc: 0.8239\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.4619 - acc: 0.7082 - val_loss: 0.4114 - val_acc: 0.8326\n",
      "Epoch 18/30\n",
      "4140/4140 - 7s - loss: 0.4723 - acc: 0.7171 - val_loss: 0.4164 - val_acc: 0.8239\n",
      "Epoch 19/30\n",
      "4140/4140 - 7s - loss: 0.4467 - acc: 0.7693 - val_loss: 0.4235 - val_acc: 0.8283\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.4533 - acc: 0.7742 - val_loss: 0.3992 - val_acc: 0.8174\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.4317 - acc: 0.7814 - val_loss: 0.4013 - val_acc: 0.8348\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.4305 - acc: 0.7785 - val_loss: 0.3939 - val_acc: 0.8196\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.4467 - acc: 0.7790 - val_loss: 0.4577 - val_acc: 0.8261\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.4104 - acc: 0.7920 - val_loss: 0.4157 - val_acc: 0.8370\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.4346 - acc: 0.7891 - val_loss: 0.4216 - val_acc: 0.8261\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.4299 - acc: 0.7886 - val_loss: 0.4422 - val_acc: 0.8261\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.4294 - acc: 0.7800 - val_loss: 0.4032 - val_acc: 0.8261\n",
      "Epoch 28/30\n",
      "4140/4140 - 7s - loss: 0.4221 - acc: 0.7920 - val_loss: 0.3904 - val_acc: 0.8304\n",
      "Epoch 29/30\n",
      "4140/4140 - 7s - loss: 0.4108 - acc: 0.8014 - val_loss: 0.4320 - val_acc: 0.8283\n",
      "Epoch 30/30\n",
      "4140/4140 - 7s - loss: 0.4046 - acc: 0.8014 - val_loss: 0.4693 - val_acc: 0.8326\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 0.4811 - acc: 0.8500\n",
      "logs/fit/glorot__wobn_lstm/kfold8\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 19s - loss: 0.6911 - acc: 0.5710 - val_loss: 0.6855 - val_acc: 0.6217\n",
      "Epoch 2/30\n",
      "4140/4140 - 7s - loss: 0.7330 - acc: 0.6029 - val_loss: 0.6592 - val_acc: 0.6652\n",
      "Epoch 3/30\n",
      "4140/4140 - 7s - loss: 0.6676 - acc: 0.6348 - val_loss: 0.6599 - val_acc: 0.6826\n",
      "Epoch 4/30\n",
      "4140/4140 - 3s - loss: 0.6662 - acc: 0.6304 - val_loss: 0.6576 - val_acc: 0.6674\n",
      "Epoch 5/30\n",
      "4140/4140 - 1s - loss: 0.6576 - acc: 0.6379 - val_loss: 0.6324 - val_acc: 0.7022\n",
      "Epoch 6/30\n",
      "4140/4140 - 1s - loss: 0.6457 - acc: 0.6466 - val_loss: 0.6145 - val_acc: 0.7217\n",
      "Epoch 7/30\n",
      "4140/4140 - 1s - loss: 0.6471 - acc: 0.6370 - val_loss: 0.6159 - val_acc: 0.6848\n",
      "Epoch 8/30\n",
      "4140/4140 - 1s - loss: 0.6231 - acc: 0.6616 - val_loss: 0.6029 - val_acc: 0.6848\n",
      "Epoch 9/30\n",
      "4140/4140 - 1s - loss: 0.6018 - acc: 0.6874 - val_loss: 0.5668 - val_acc: 0.7304\n",
      "Epoch 10/30\n",
      "4140/4140 - 1s - loss: 0.5891 - acc: 0.6877 - val_loss: 0.5488 - val_acc: 0.7457\n",
      "Epoch 11/30\n",
      "4140/4140 - 1s - loss: 0.5983 - acc: 0.6872 - val_loss: 0.6090 - val_acc: 0.6500\n",
      "Epoch 12/30\n",
      "4140/4140 - 1s - loss: 0.5860 - acc: 0.6843 - val_loss: 0.5089 - val_acc: 0.7565\n",
      "Epoch 13/30\n",
      "4140/4140 - 1s - loss: 0.5563 - acc: 0.7140 - val_loss: 0.5213 - val_acc: 0.7522\n",
      "Epoch 14/30\n",
      "4140/4140 - 1s - loss: 0.5413 - acc: 0.7198 - val_loss: 0.4777 - val_acc: 0.7848\n",
      "Epoch 15/30\n",
      "4140/4140 - 1s - loss: 0.5158 - acc: 0.7229 - val_loss: 0.4705 - val_acc: 0.8109\n",
      "Epoch 16/30\n",
      "4140/4140 - 1s - loss: 0.5023 - acc: 0.7372 - val_loss: 0.4295 - val_acc: 0.8196\n",
      "Epoch 17/30\n",
      "4140/4140 - 1s - loss: 0.4737 - acc: 0.7604 - val_loss: 0.4185 - val_acc: 0.8326\n",
      "Epoch 18/30\n",
      "4140/4140 - 1s - loss: 0.4858 - acc: 0.7507 - val_loss: 0.4349 - val_acc: 0.8413\n",
      "Epoch 19/30\n",
      "4140/4140 - 1s - loss: 0.4751 - acc: 0.7606 - val_loss: 0.4296 - val_acc: 0.8435\n",
      "Epoch 20/30\n",
      "4140/4140 - 1s - loss: 0.4423 - acc: 0.7761 - val_loss: 0.4428 - val_acc: 0.8304\n",
      "Epoch 21/30\n",
      "4140/4140 - 1s - loss: 0.4445 - acc: 0.7691 - val_loss: 0.4333 - val_acc: 0.8348\n",
      "Epoch 22/30\n",
      "4140/4140 - 1s - loss: 0.4346 - acc: 0.7647 - val_loss: 0.4689 - val_acc: 0.8435\n",
      "Epoch 23/30\n",
      "4140/4140 - 1s - loss: 0.4246 - acc: 0.7758 - val_loss: 0.5258 - val_acc: 0.8370\n",
      "Epoch 24/30\n",
      "4140/4140 - 2s - loss: 0.4331 - acc: 0.7809 - val_loss: 0.4999 - val_acc: 0.8435\n",
      "Epoch 25/30\n",
      "4140/4140 - 2s - loss: 0.4219 - acc: 0.7713 - val_loss: 0.4333 - val_acc: 0.8478\n",
      "Epoch 26/30\n",
      "4140/4140 - 4s - loss: 0.4031 - acc: 0.7845 - val_loss: 0.5413 - val_acc: 0.8391\n",
      "Epoch 27/30\n",
      "4140/4140 - 4s - loss: 0.3992 - acc: 0.7862 - val_loss: 0.7295 - val_acc: 0.8457\n",
      "Epoch 28/30\n",
      "4140/4140 - 4s - loss: 0.4049 - acc: 0.7790 - val_loss: 0.7096 - val_acc: 0.8413\n",
      "Epoch 29/30\n",
      "4140/4140 - 6s - loss: 0.3952 - acc: 0.7816 - val_loss: 0.7575 - val_acc: 0.8435\n",
      "Epoch 30/30\n",
      "4140/4140 - 7s - loss: 0.3848 - acc: 0.7906 - val_loss: 0.5832 - val_acc: 0.8391\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 2.6144 - acc: 0.8700\n",
      "logs/fit/glorot__wobn_lstm/kfold9\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 19s - loss: 0.6913 - acc: 0.5773 - val_loss: 0.6888 - val_acc: 0.5696\n",
      "Epoch 2/30\n",
      "4140/4140 - 7s - loss: 0.6802 - acc: 0.5713 - val_loss: 0.6639 - val_acc: 0.5696\n",
      "Epoch 3/30\n",
      "4140/4140 - 7s - loss: 0.6422 - acc: 0.5691 - val_loss: 0.5980 - val_acc: 0.6261\n",
      "Epoch 4/30\n",
      "4140/4140 - 7s - loss: 0.6056 - acc: 0.6174 - val_loss: 0.5740 - val_acc: 0.6609\n",
      "Epoch 5/30\n",
      "4140/4140 - 7s - loss: 0.6685 - acc: 0.6249 - val_loss: 0.6189 - val_acc: 0.5957\n",
      "Epoch 6/30\n",
      "4140/4140 - 7s - loss: 0.6243 - acc: 0.6106 - val_loss: 0.6097 - val_acc: 0.5826\n",
      "Epoch 7/30\n",
      "4140/4140 - 7s - loss: 0.6160 - acc: 0.6080 - val_loss: 0.5989 - val_acc: 0.5978\n",
      "Epoch 8/30\n",
      "4140/4140 - 7s - loss: 0.6073 - acc: 0.6080 - val_loss: 0.5881 - val_acc: 0.6087\n",
      "Epoch 9/30\n",
      "4140/4140 - 7s - loss: 0.6026 - acc: 0.6203 - val_loss: 0.5783 - val_acc: 0.6457\n",
      "Epoch 10/30\n",
      "4140/4140 - 7s - loss: 0.5957 - acc: 0.6261 - val_loss: 0.5683 - val_acc: 0.6804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "4140/4140 - 7s - loss: 0.5809 - acc: 0.6217 - val_loss: 0.5571 - val_acc: 0.7065\n",
      "Epoch 12/30\n",
      "4140/4140 - 7s - loss: 0.5721 - acc: 0.6377 - val_loss: 0.5471 - val_acc: 0.7500\n",
      "Epoch 13/30\n",
      "4140/4140 - 7s - loss: 0.5762 - acc: 0.6587 - val_loss: 0.5390 - val_acc: 0.7783\n",
      "Epoch 14/30\n",
      "4140/4140 - 7s - loss: 0.5619 - acc: 0.6758 - val_loss: 0.5282 - val_acc: 0.7891\n",
      "Epoch 15/30\n",
      "4140/4140 - 7s - loss: 0.5659 - acc: 0.7046 - val_loss: 0.5211 - val_acc: 0.7826\n",
      "Epoch 16/30\n",
      "4140/4140 - 7s - loss: 0.5504 - acc: 0.7143 - val_loss: 0.5112 - val_acc: 0.7913\n",
      "Epoch 17/30\n",
      "4140/4140 - 8s - loss: 0.5405 - acc: 0.7258 - val_loss: 0.5027 - val_acc: 0.7957\n",
      "Epoch 18/30\n",
      "4140/4140 - 7s - loss: 0.5340 - acc: 0.7370 - val_loss: 0.4989 - val_acc: 0.8043\n",
      "Epoch 19/30\n",
      "4140/4140 - 7s - loss: 0.5344 - acc: 0.7464 - val_loss: 0.4880 - val_acc: 0.8109\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.6019 - acc: 0.7486 - val_loss: 0.4947 - val_acc: 0.8174\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.5299 - acc: 0.7536 - val_loss: 0.4782 - val_acc: 0.8130\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.5251 - acc: 0.7551 - val_loss: 0.4678 - val_acc: 0.8196\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.5188 - acc: 0.7611 - val_loss: 0.4615 - val_acc: 0.8283\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.5099 - acc: 0.7754 - val_loss: 0.4548 - val_acc: 0.8326\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.5071 - acc: 0.7652 - val_loss: 0.4488 - val_acc: 0.8326\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.4996 - acc: 0.7787 - val_loss: 0.4425 - val_acc: 0.8304\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.5031 - acc: 0.7597 - val_loss: 0.4314 - val_acc: 0.8239\n",
      "Epoch 28/30\n",
      "4140/4140 - 7s - loss: 0.4837 - acc: 0.7751 - val_loss: 0.4320 - val_acc: 0.8304\n",
      "Epoch 29/30\n",
      "4140/4140 - 7s - loss: 0.6322 - acc: 0.7227 - val_loss: 0.4481 - val_acc: 0.8239\n",
      "Epoch 30/30\n",
      "4140/4140 - 7s - loss: 0.5044 - acc: 0.7751 - val_loss: 0.4547 - val_acc: 0.8261\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 0.5207 - acc: 0.8500\n",
      "logs/fit/glorot__wobn_lstm/kfold10\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 3s - loss: 0.6918 - acc: 0.5773 - val_loss: 0.6896 - val_acc: 0.5870\n",
      "Epoch 2/30\n",
      "4140/4140 - 1s - loss: 0.6889 - acc: 0.6251 - val_loss: 0.6538 - val_acc: 0.6935\n",
      "Epoch 3/30\n",
      "4140/4140 - 1s - loss: 0.6755 - acc: 0.6386 - val_loss: 0.6504 - val_acc: 0.6978\n",
      "Epoch 4/30\n",
      "4140/4140 - 1s - loss: 0.6598 - acc: 0.6522 - val_loss: 0.6402 - val_acc: 0.6696\n",
      "Epoch 5/30\n",
      "4140/4140 - 1s - loss: 0.6536 - acc: 0.6669 - val_loss: 0.6186 - val_acc: 0.7348\n",
      "Epoch 6/30\n",
      "4140/4140 - 1s - loss: 0.6352 - acc: 0.6829 - val_loss: 0.6013 - val_acc: 0.7500\n",
      "Epoch 7/30\n",
      "4140/4140 - 1s - loss: 0.6194 - acc: 0.6923 - val_loss: 0.5916 - val_acc: 0.7609\n",
      "Epoch 8/30\n",
      "4140/4140 - 1s - loss: 0.6095 - acc: 0.6928 - val_loss: 0.5798 - val_acc: 0.7630\n",
      "Epoch 9/30\n",
      "4140/4140 - 1s - loss: 0.6099 - acc: 0.7012 - val_loss: 0.5801 - val_acc: 0.7413\n",
      "Epoch 10/30\n",
      "4140/4140 - 1s - loss: 0.5870 - acc: 0.7179 - val_loss: 0.5710 - val_acc: 0.7652\n",
      "Epoch 11/30\n",
      "4140/4140 - 1s - loss: 0.5926 - acc: 0.7167 - val_loss: 0.5849 - val_acc: 0.7109\n",
      "Epoch 12/30\n",
      "4140/4140 - 1s - loss: 0.5774 - acc: 0.7167 - val_loss: 0.5618 - val_acc: 0.7696\n",
      "Epoch 13/30\n",
      "4140/4140 - 1s - loss: 0.5649 - acc: 0.7319 - val_loss: 0.5448 - val_acc: 0.7674\n",
      "Epoch 14/30\n",
      "4140/4140 - 1s - loss: 0.5640 - acc: 0.7316 - val_loss: 0.5323 - val_acc: 0.7652\n",
      "Epoch 15/30\n",
      "4140/4140 - 1s - loss: 0.5417 - acc: 0.7507 - val_loss: 0.5175 - val_acc: 0.7848\n",
      "Epoch 16/30\n",
      "4140/4140 - 1s - loss: 0.5429 - acc: 0.7522 - val_loss: 0.5012 - val_acc: 0.7848\n",
      "Epoch 17/30\n",
      "4140/4140 - 2s - loss: 0.5296 - acc: 0.7507 - val_loss: 0.4919 - val_acc: 0.7848\n",
      "Epoch 18/30\n",
      "4140/4140 - 2s - loss: 0.5105 - acc: 0.7671 - val_loss: 0.4831 - val_acc: 0.7826\n",
      "Epoch 19/30\n",
      "4140/4140 - 4s - loss: 0.5069 - acc: 0.7686 - val_loss: 0.4768 - val_acc: 0.7913\n",
      "Epoch 20/30\n",
      "4140/4140 - 4s - loss: 0.4995 - acc: 0.7729 - val_loss: 0.4759 - val_acc: 0.7870\n",
      "Epoch 21/30\n",
      "4140/4140 - 5s - loss: 0.6118 - acc: 0.7829 - val_loss: 0.5200 - val_acc: 0.7957\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.5633 - acc: 0.7367 - val_loss: 0.5213 - val_acc: 0.7826\n",
      "Epoch 23/30\n",
      "4140/4140 - 7s - loss: 0.5217 - acc: 0.7688 - val_loss: 0.5044 - val_acc: 0.8043\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.5137 - acc: 0.7739 - val_loss: 0.5027 - val_acc: 0.7783\n",
      "Epoch 25/30\n",
      "4140/4140 - 7s - loss: 0.4996 - acc: 0.7780 - val_loss: 0.4874 - val_acc: 0.8022\n",
      "Epoch 26/30\n",
      "4140/4140 - 7s - loss: 0.4886 - acc: 0.7838 - val_loss: 0.4853 - val_acc: 0.8043\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.4816 - acc: 0.7877 - val_loss: 0.4877 - val_acc: 0.8109\n",
      "Epoch 28/30\n",
      "4140/4140 - 7s - loss: 0.4879 - acc: 0.7860 - val_loss: 0.4820 - val_acc: 0.7848\n",
      "Epoch 29/30\n",
      "4140/4140 - 7s - loss: 0.4779 - acc: 0.7872 - val_loss: 0.4869 - val_acc: 0.8109\n",
      "Epoch 30/30\n",
      "4140/4140 - 7s - loss: 0.4670 - acc: 0.7899 - val_loss: 0.4873 - val_acc: 0.8000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 0.4222 - acc: 0.8200\n"
     ]
    }
   ],
   "source": [
    "def glorot_model_wo_bn():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(10, kernel_initializer='glorot_normal', activation='relu', input_shape=(28, 300), name='lstm'),\n",
    "        tf.keras.layers.Dropout(0.7),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='glorot_normal', name='dense')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "gl__wobn_hist, gl_wobn_evas = kfold_train(glorot_model_wo_bn, 'glorot__wobn_lstm', batch_size=128, epochs=30, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "aba7843f-5430-41ca-83c1-df1b6a7185ba",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6910588785070152,
          0.6849754578825357,
          0.6669782422015057,
          0.6323823656436902,
          0.6060546815683301,
          0.5818668727137616,
          0.545672877572009,
          0.5191585745788426,
          0.5022705399471781,
          0.4856304219379517,
          0.47137244300565856,
          0.4638202021663316,
          0.4363032557538166,
          0.4381326670807917,
          0.42277660726925026,
          0.43590368009419833,
          0.44122430353924846,
          0.4172569934296723,
          0.4282561476967761,
          0.4126085908804539,
          0.4001526845250153,
          0.382184749611334,
          0.3880229527823591,
          0.38656748726172147,
          0.37903671834779823,
          0.3791216866117745,
          0.3900499053047475,
          0.39153277298102634,
          0.3791087868996864,
          0.36262703586891654
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "41edd05d-68d7-4ddb-a907-ffa19c61b21e",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6864219043565833,
          0.6735905191172724,
          0.623420816919078,
          0.5718728853308637,
          0.5503663363664046,
          0.47301488052243773,
          0.4478995937368144,
          0.42635978434396826,
          0.413340817845386,
          0.40023159980773926,
          0.39241808989773624,
          0.3892368508421856,
          0.3982999967492145,
          0.4069353691909624,
          0.4689468637756679,
          0.38824908318726914,
          0.4041681566964025,
          0.44236626521400785,
          0.42671118171318717,
          0.40992237018502276,
          0.515269737917444,
          0.5863229857838672,
          0.5008632706559223,
          0.5214278044907943,
          0.8101360284763833,
          0.8035941870316216,
          0.6141287788100864,
          0.4118563278861668,
          0.6070777333301046,
          0.5502468357915463
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "51ea281a-5ac1-43f6-88b5-0baf2e3ddaec",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6913462333057238,
          0.6845991913823114,
          0.6765916816854246,
          0.6644272378677332,
          0.6563327256608125,
          0.6240175236250467,
          0.5939687032054588,
          0.5640995723037904,
          0.5691952576959767,
          0.5361039231940744,
          0.5145213204881419,
          0.5071996931292585,
          0.537358083817118,
          0.4962339804944209,
          0.4796813738806812,
          0.4716588580665957,
          0.46202528272274035,
          0.46226336072032576,
          0.45322191251648797,
          0.44447730336212304,
          0.45041853710649093,
          0.4370103020886868,
          0.43435377688799504,
          0.43728454141801104,
          0.42577777268805944,
          0.41729385622457604,
          0.4018655157031644,
          0.394843215873276,
          0.39854222230865183,
          0.3976725912036527
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "91e07065-484e-4fec-9066-e1999caceed6",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6895005065461863,
          0.6825879838155664,
          0.6608139095099076,
          0.6571818693824436,
          0.6356260180473328,
          0.5812310291373212,
          0.5698878537053648,
          0.6269389365030371,
          0.5152838437453561,
          0.5304642462212107,
          0.5205325297687364,
          0.5755074972691743,
          0.47018717527389525,
          0.46901426989099254,
          0.44629563715146936,
          0.457401430606842,
          0.4386819005012512,
          0.4449193272901618,
          0.43657460264537645,
          0.4252649081789929,
          0.44331568038981894,
          0.4317315539588099,
          0.4737660553144372,
          0.4337749781815902,
          0.46775789675505264,
          0.46263235237287437,
          0.4772318897039994,
          0.5129020315149556,
          0.48955850056979966,
          0.4563826571340146
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "07ea4998-b906-41a9-9224-60e6071ddf39",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6909495729755089,
          0.7012078179253473,
          0.6800460005727943,
          0.6676446125703157,
          0.6591182093113517,
          0.6558753727138906,
          0.64742321945043,
          0.6376674380279393,
          0.6130843517285038,
          0.6056772722714189,
          0.5970959594860169,
          0.5705910292800498,
          0.5689686844890244,
          0.5554703138876652,
          0.5404314712625771,
          0.5611753095751223,
          0.5491168790969296,
          0.5461884492261398,
          0.5245506353424367,
          0.5198867407397948,
          0.5004227244911562,
          0.48900343617379377,
          0.46154733916411655,
          0.46576474522046996,
          0.46019172029218813,
          0.465835390171567,
          0.44386381256407587,
          0.4496354654215384,
          0.43800976616172976,
          0.44552717191585595
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "d78975e5-7ded-479d-b425-b70c2b2c601f",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6857161299042079,
          0.6773321991381438,
          0.6635142176047616,
          0.6304964454277702,
          0.6189803973488186,
          0.6139802813529969,
          0.6130875411240951,
          0.5933918859647668,
          0.5770746692367222,
          0.5589531152144722,
          0.5677523929139842,
          0.5125113580537879,
          0.5055041520491891,
          0.4905316244000974,
          0.5159704799237459,
          0.5030635025190271,
          0.49170959540035414,
          0.5017292898634206,
          0.46830538070720173,
          0.46653357562811476,
          0.4361522747122723,
          0.4229609435019286,
          0.4096627105837283,
          0.40238498164259867,
          0.3882493037244548,
          0.39961471350296685,
          0.3968386253584986,
          0.3848882024702818,
          0.36981013365413834,
          0.3731140931015429
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "621f3c48-3ccc-4b7d-ae7f-e1e8c48ea518",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6910425851310509,
          0.6874801356435398,
          0.6895275149944324,
          0.6699161972976537,
          0.6628374851844161,
          0.6728158019015179,
          0.6651955635075408,
          0.6449533501684953,
          0.6208824074786642,
          0.5740434728958757,
          0.5738056815764754,
          0.5454707288799654,
          0.5298234125842218,
          0.5047643725710791,
          0.48824436658822395,
          0.4779125620489535,
          0.4833109557052741,
          0.45451470256427634,
          0.4498876931010813,
          0.44787532341653025,
          0.43761927946178236,
          0.4413389886922882,
          0.4249547477793578,
          0.42915312572953784,
          0.4338306048354089,
          0.41257366754006647,
          0.4043231931861472,
          0.4103202924348306,
          0.41058674273283585,
          0.4027119114491099
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "479cd1a7-fafa-4a35-9202-857b8f79f232",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6913683740989022,
          0.686084578866544,
          0.6722553045853324,
          0.6729858434718589,
          0.6717756343924481,
          0.6770122870155003,
          0.6453009786813155,
          0.6068196939385455,
          0.5670689199281775,
          0.501876746053281,
          0.48254493397215137,
          0.4818898071413455,
          0.48528794153876925,
          0.44311349443767384,
          0.45357141857561856,
          0.42551127646280373,
          0.46177782908729886,
          0.422600851888242,
          0.41262588760127195,
          0.46036654581194336,
          0.4349504680737205,
          0.415322206331336,
          0.39850761786751127,
          0.43075289311616316,
          0.3903322009936623,
          0.4103661835193634,
          0.4236538099206012,
          0.38503692927567856,
          0.4623044952102329,
          0.4352831177089525
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "a10f88ac-18b5-4185-aaeb-c4db71094eb2",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6906762673659025,
          0.679922632491531,
          0.6640965925322638,
          0.6337953211604685,
          0.6210348073411103,
          0.5785762503527213,
          0.5437790331633194,
          0.522812100827406,
          0.5059458098261829,
          0.4852724656390683,
          0.4793771698279081,
          0.4604265725267106,
          0.4470055843896912,
          0.4470877023998666,
          0.4401052908908918,
          0.4402065590095981,
          0.4271351500697758,
          0.4504777341649152,
          0.4217759368788217,
          0.41174596029779187,
          0.4022179588891458,
          0.39699179008963026,
          0.39705885815735603,
          0.3867087848808454,
          0.38224020367083344,
          0.3743519635880051,
          0.37379375365045336,
          0.37596569645807937,
          0.3813289122880945,
          0.3464554059908586
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "2e22a2c1-121a-4cc2-a863-06bce875f184",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6864931749260944,
          0.6757779142130976,
          0.6548361897468566,
          0.6248707175254822,
          0.6103566029797429,
          0.5690947371980418,
          0.5656094488890274,
          0.5545270660649175,
          0.5860626977422964,
          0.5337316038815871,
          0.5343980955040973,
          0.5368166633274244,
          0.5346352927062823,
          0.5396244391151096,
          0.5300920924414759,
          0.5901737985403641,
          0.6386129959769871,
          0.6622594921485238,
          0.5838250922120136,
          0.6627069563969322,
          0.6035576706347259,
          0.5860550616098487,
          0.570944591190504,
          0.5493625594222027,
          0.5406300184519395,
          0.5358403729355854,
          0.5458845739779266,
          0.5642572034960208,
          0.691319899973662,
          0.7573553992354352
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "5b9dee8a-d51f-4991-a8ab-ca86a78eca96",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6907909716384998,
          0.686349906667995,
          0.6782733791116355,
          0.6717700146822537,
          0.6407167999640755,
          0.5976145710922094,
          0.567864109467769,
          0.5428812928821729,
          0.5181566304054813,
          0.5046610980506104,
          0.47820909052079424,
          0.4833377147354366,
          0.4762956205197578,
          0.4586051596535577,
          0.45275304812740014,
          0.44943214099188356,
          0.4428571935725097,
          0.42904851134272587,
          0.41889769671043914,
          0.41774228684568177,
          0.41747673090529325,
          0.40153567747793334,
          0.39825622845387115,
          0.38683977826781896,
          0.4035234688560744,
          0.38223260563352834,
          0.38448525770850805,
          0.3850572928138401,
          0.3569857512407257,
          0.3709758428271842
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "a2d1304d-217f-4192-b824-7f52907c7e36",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6885062720464623,
          0.6823834999747899,
          0.668569468933603,
          0.6443194182022758,
          0.5879970415778782,
          0.5467729490736256,
          0.506767793841984,
          0.5000652111094931,
          0.4825686755387679,
          0.449577418099279,
          0.42996569094450576,
          0.4347570326017297,
          0.4260899600775345,
          0.4192254698794821,
          0.5076115421626879,
          0.4822941894116609,
          0.4412246351656706,
          0.442808315028315,
          0.4795170348623525,
          0.4633292548034502,
          0.405201736740444,
          0.433089904681496,
          0.4276421510654947,
          0.540861776082412,
          0.4822313604147538,
          0.5900901524916939,
          0.5029027809267459,
          0.5599138928496319,
          0.7622336537941642,
          0.6768896854442099
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "65cc77f1-b2d9-4303-9d03-a58cc842f89c",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.690494405820174,
          0.680607519345583,
          0.6688142811618565,
          0.6406622625779415,
          0.6007394056965187,
          0.581925808634735,
          0.5532137717025868,
          0.5408033386520718,
          0.5229946529231786,
          0.512590539743359,
          0.4960288075433261,
          0.4943983715513478,
          0.48451958393705064,
          0.46765532286270806,
          0.4735842257306196,
          0.46839564652834537,
          0.46188848750026906,
          0.47233113511173047,
          0.4467479447523753,
          0.4532595502293628,
          0.43170655064536756,
          0.43054084792229286,
          0.44673543321913567,
          0.4104186637390063,
          0.4345502838420407,
          0.42985239509799056,
          0.4293553162312162,
          0.42205219741028865,
          0.41077221398768216,
          0.40463486737099247
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "8ecafa77-327a-4684-b8b5-30b6c8a591df",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6890450026678002,
          0.6698199811189071,
          0.6516618816748909,
          0.5775664028914078,
          0.5213509678840638,
          0.4841629041277844,
          0.4702449941116831,
          0.4442262556241906,
          0.45531954791234885,
          0.4355937465377476,
          0.4226896114971327,
          0.43984814726788063,
          0.4374493565248406,
          0.40966894808022875,
          0.4127300534559333,
          0.42688246939493263,
          0.4114329861558002,
          0.4163870119530222,
          0.42347268021625023,
          0.39918372009111486,
          0.4013402959574824,
          0.3939353618932807,
          0.45773554573888364,
          0.4156626151955646,
          0.42158866576526477,
          0.44216733626697374,
          0.4032152165537295,
          0.3903986816820891,
          0.4319803815820943,
          0.46925391088361323
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "b14813aa-3e4c-4490-a607-4166ed81fd7f",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6911335560434683,
          0.732980205471389,
          0.6675790646225934,
          0.6661939425168982,
          0.6576133826504583,
          0.6457303749766327,
          0.6470684153446252,
          0.6230699030673447,
          0.6018004320093975,
          0.5891430184461068,
          0.5982923386753469,
          0.585970401763916,
          0.5562711956996272,
          0.5412647006016422,
          0.5158405549860231,
          0.5023296513707165,
          0.4736964516593638,
          0.48582333470312294,
          0.47507179151986534,
          0.44227664542658895,
          0.4444725848050509,
          0.4346493742892132,
          0.4246205316649543,
          0.4330781568939559,
          0.4219466693447408,
          0.4031008560300449,
          0.3992236560381553,
          0.40485360982337437,
          0.3952000717897922,
          0.38481252202089283
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "050321be-cc01-422a-b076-a1769eba2a40",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6854903480281,
          0.659219901976378,
          0.659855476151342,
          0.6576434575993082,
          0.6324390302533689,
          0.6144850554673568,
          0.6159332928450211,
          0.6028816259425619,
          0.5667919231497723,
          0.5488430748815122,
          0.6089827952177628,
          0.5088829779106637,
          0.5212957687999891,
          0.47765758970509403,
          0.47047381426977075,
          0.429471513758535,
          0.41853585398715476,
          0.4349240673624951,
          0.42956688093102496,
          0.44275972765424976,
          0.43334730319354847,
          0.46894779853198837,
          0.5257739530957264,
          0.49987388952918677,
          0.43333443817885026,
          0.5412876460863196,
          0.7295354444047679,
          0.7096221871997999,
          0.7574776545814846,
          0.5831870607707812
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "4fd80dd6-8262-43b2-baad-e05f54eea689",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6912948200092224,
          0.6802397245946138,
          0.6422013211941373,
          0.6056114575137262,
          0.6685001417058678,
          0.6243338835988068,
          0.6160198398258375,
          0.6072793456667287,
          0.60263258708272,
          0.5956816846621785,
          0.5808631696562836,
          0.5721376997261232,
          0.5761640291858986,
          0.5618871252893826,
          0.5658791943448753,
          0.5503980094108029,
          0.5404526971388555,
          0.5340177621818395,
          0.5343814935949114,
          0.6018613519875899,
          0.5298765417170409,
          0.5250526913122279,
          0.5187674148935051,
          0.5098972597559869,
          0.5070595237943861,
          0.49963867298646825,
          0.5031243080966139,
          0.48371121546496515,
          0.6321886445013222,
          0.5043955908881294
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "cdb8a9d0-e0ce-4ec5-96af-7a9fe1d57ee2",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6888292276340983,
          0.6639407074969748,
          0.5979828197023143,
          0.5740209144094716,
          0.6189063445381496,
          0.6096609742745109,
          0.5988631378049436,
          0.5880537660225578,
          0.5783012094705001,
          0.5682993816292804,
          0.5570988284504932,
          0.5471069693565369,
          0.5390090144198874,
          0.5281520382217739,
          0.5211412440175596,
          0.5111857307993848,
          0.5026721607083859,
          0.49892810427624246,
          0.48802187131798785,
          0.4947187426297561,
          0.4782334055589593,
          0.46777998053509257,
          0.46146609316701476,
          0.4547854879628057,
          0.44875642553619716,
          0.44245347562043563,
          0.43135788725770036,
          0.4319986307102701,
          0.4481228082076363,
          0.4546791099983713
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "f09dff91-87ee-4ae6-8509-c1473be93850",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.691752719015315,
          0.6888581795968871,
          0.6754927503889886,
          0.6598268996690206,
          0.6536118412363356,
          0.6352295426930782,
          0.6194396697380693,
          0.6094588830851126,
          0.6099049500221215,
          0.5869984744827529,
          0.5926494541951424,
          0.5774193470604754,
          0.5649041625036709,
          0.5640312451671287,
          0.5417098806100191,
          0.5429393842600394,
          0.5296132857672834,
          0.5105433988974291,
          0.5069017241542466,
          0.4994660182563579,
          0.6118006001923971,
          0.5633293863079974,
          0.5217100975594083,
          0.5137353916674996,
          0.49964662980342256,
          0.48858676964534076,
          0.48155287915957723,
          0.4879486490274973,
          0.4778679033120473,
          0.4669706330207235
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "61958c94-99d8-478a-be14-8a83f3c232c6",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6896016789519268,
          0.6538460529368857,
          0.650369682001031,
          0.6401792536611143,
          0.6185783857884615,
          0.6012975319572117,
          0.5915755966435308,
          0.5798412307449009,
          0.5801303298577019,
          0.571048222935718,
          0.5849378269651662,
          0.5617799038472383,
          0.5447587702585304,
          0.5322724269784015,
          0.5174774211385976,
          0.5012370524199112,
          0.4918869930764903,
          0.48312598985174426,
          0.47682782282,
          0.4758603077867757,
          0.5199968607529349,
          0.521272771773131,
          0.5043831034846927,
          0.5027166776035144,
          0.48738346099853513,
          0.4852819929952207,
          0.48765488318775013,
          0.4819537473761517,
          0.48686824518701305,
          0.48728761387907943
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"9d99e487-7272-464c-a64f-763e34101d2e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"9d99e487-7272-464c-a64f-763e34101d2e\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '9d99e487-7272-464c-a64f-763e34101d2e',\n",
       "                        [{\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"aba7843f-5430-41ca-83c1-df1b6a7185ba\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6910588785070152, 0.6849754578825357, 0.6669782422015057, 0.6323823656436902, 0.6060546815683301, 0.5818668727137616, 0.545672877572009, 0.5191585745788426, 0.5022705399471781, 0.4856304219379517, 0.47137244300565856, 0.4638202021663316, 0.4363032557538166, 0.4381326670807917, 0.42277660726925026, 0.43590368009419833, 0.44122430353924846, 0.4172569934296723, 0.4282561476967761, 0.4126085908804539, 0.4001526845250153, 0.382184749611334, 0.3880229527823591, 0.38656748726172147, 0.37903671834779823, 0.3791216866117745, 0.3900499053047475, 0.39153277298102634, 0.3791087868996864, 0.36262703586891654]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"41edd05d-68d7-4ddb-a907-ffa19c61b21e\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6864219043565833, 0.6735905191172724, 0.623420816919078, 0.5718728853308637, 0.5503663363664046, 0.47301488052243773, 0.4478995937368144, 0.42635978434396826, 0.413340817845386, 0.40023159980773926, 0.39241808989773624, 0.3892368508421856, 0.3982999967492145, 0.4069353691909624, 0.4689468637756679, 0.38824908318726914, 0.4041681566964025, 0.44236626521400785, 0.42671118171318717, 0.40992237018502276, 0.515269737917444, 0.5863229857838672, 0.5008632706559223, 0.5214278044907943, 0.8101360284763833, 0.8035941870316216, 0.6141287788100864, 0.4118563278861668, 0.6070777333301046, 0.5502468357915463]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"51ea281a-5ac1-43f6-88b5-0baf2e3ddaec\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6913462333057238, 0.6845991913823114, 0.6765916816854246, 0.6644272378677332, 0.6563327256608125, 0.6240175236250467, 0.5939687032054588, 0.5640995723037904, 0.5691952576959767, 0.5361039231940744, 0.5145213204881419, 0.5071996931292585, 0.537358083817118, 0.4962339804944209, 0.4796813738806812, 0.4716588580665957, 0.46202528272274035, 0.46226336072032576, 0.45322191251648797, 0.44447730336212304, 0.45041853710649093, 0.4370103020886868, 0.43435377688799504, 0.43728454141801104, 0.42577777268805944, 0.41729385622457604, 0.4018655157031644, 0.394843215873276, 0.39854222230865183, 0.3976725912036527]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"91e07065-484e-4fec-9066-e1999caceed6\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6895005065461863, 0.6825879838155664, 0.6608139095099076, 0.6571818693824436, 0.6356260180473328, 0.5812310291373212, 0.5698878537053648, 0.6269389365030371, 0.5152838437453561, 0.5304642462212107, 0.5205325297687364, 0.5755074972691743, 0.47018717527389525, 0.46901426989099254, 0.44629563715146936, 0.457401430606842, 0.4386819005012512, 0.4449193272901618, 0.43657460264537645, 0.4252649081789929, 0.44331568038981894, 0.4317315539588099, 0.4737660553144372, 0.4337749781815902, 0.46775789675505264, 0.46263235237287437, 0.4772318897039994, 0.5129020315149556, 0.48955850056979966, 0.4563826571340146]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"07ea4998-b906-41a9-9224-60e6071ddf39\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6909495729755089, 0.7012078179253473, 0.6800460005727943, 0.6676446125703157, 0.6591182093113517, 0.6558753727138906, 0.64742321945043, 0.6376674380279393, 0.6130843517285038, 0.6056772722714189, 0.5970959594860169, 0.5705910292800498, 0.5689686844890244, 0.5554703138876652, 0.5404314712625771, 0.5611753095751223, 0.5491168790969296, 0.5461884492261398, 0.5245506353424367, 0.5198867407397948, 0.5004227244911562, 0.48900343617379377, 0.46154733916411655, 0.46576474522046996, 0.46019172029218813, 0.465835390171567, 0.44386381256407587, 0.4496354654215384, 0.43800976616172976, 0.44552717191585595]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"d78975e5-7ded-479d-b425-b70c2b2c601f\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6857161299042079, 0.6773321991381438, 0.6635142176047616, 0.6304964454277702, 0.6189803973488186, 0.6139802813529969, 0.6130875411240951, 0.5933918859647668, 0.5770746692367222, 0.5589531152144722, 0.5677523929139842, 0.5125113580537879, 0.5055041520491891, 0.4905316244000974, 0.5159704799237459, 0.5030635025190271, 0.49170959540035414, 0.5017292898634206, 0.46830538070720173, 0.46653357562811476, 0.4361522747122723, 0.4229609435019286, 0.4096627105837283, 0.40238498164259867, 0.3882493037244548, 0.39961471350296685, 0.3968386253584986, 0.3848882024702818, 0.36981013365413834, 0.3731140931015429]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"621f3c48-3ccc-4b7d-ae7f-e1e8c48ea518\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6910425851310509, 0.6874801356435398, 0.6895275149944324, 0.6699161972976537, 0.6628374851844161, 0.6728158019015179, 0.6651955635075408, 0.6449533501684953, 0.6208824074786642, 0.5740434728958757, 0.5738056815764754, 0.5454707288799654, 0.5298234125842218, 0.5047643725710791, 0.48824436658822395, 0.4779125620489535, 0.4833109557052741, 0.45451470256427634, 0.4498876931010813, 0.44787532341653025, 0.43761927946178236, 0.4413389886922882, 0.4249547477793578, 0.42915312572953784, 0.4338306048354089, 0.41257366754006647, 0.4043231931861472, 0.4103202924348306, 0.41058674273283585, 0.4027119114491099]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"479cd1a7-fafa-4a35-9202-857b8f79f232\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6913683740989022, 0.686084578866544, 0.6722553045853324, 0.6729858434718589, 0.6717756343924481, 0.6770122870155003, 0.6453009786813155, 0.6068196939385455, 0.5670689199281775, 0.501876746053281, 0.48254493397215137, 0.4818898071413455, 0.48528794153876925, 0.44311349443767384, 0.45357141857561856, 0.42551127646280373, 0.46177782908729886, 0.422600851888242, 0.41262588760127195, 0.46036654581194336, 0.4349504680737205, 0.415322206331336, 0.39850761786751127, 0.43075289311616316, 0.3903322009936623, 0.4103661835193634, 0.4236538099206012, 0.38503692927567856, 0.4623044952102329, 0.4352831177089525]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"a10f88ac-18b5-4185-aaeb-c4db71094eb2\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6906762673659025, 0.679922632491531, 0.6640965925322638, 0.6337953211604685, 0.6210348073411103, 0.5785762503527213, 0.5437790331633194, 0.522812100827406, 0.5059458098261829, 0.4852724656390683, 0.4793771698279081, 0.4604265725267106, 0.4470055843896912, 0.4470877023998666, 0.4401052908908918, 0.4402065590095981, 0.4271351500697758, 0.4504777341649152, 0.4217759368788217, 0.41174596029779187, 0.4022179588891458, 0.39699179008963026, 0.39705885815735603, 0.3867087848808454, 0.38224020367083344, 0.3743519635880051, 0.37379375365045336, 0.37596569645807937, 0.3813289122880945, 0.3464554059908586]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"2e22a2c1-121a-4cc2-a863-06bce875f184\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6864931749260944, 0.6757779142130976, 0.6548361897468566, 0.6248707175254822, 0.6103566029797429, 0.5690947371980418, 0.5656094488890274, 0.5545270660649175, 0.5860626977422964, 0.5337316038815871, 0.5343980955040973, 0.5368166633274244, 0.5346352927062823, 0.5396244391151096, 0.5300920924414759, 0.5901737985403641, 0.6386129959769871, 0.6622594921485238, 0.5838250922120136, 0.6627069563969322, 0.6035576706347259, 0.5860550616098487, 0.570944591190504, 0.5493625594222027, 0.5406300184519395, 0.5358403729355854, 0.5458845739779266, 0.5642572034960208, 0.691319899973662, 0.7573553992354352]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"5b9dee8a-d51f-4991-a8ab-ca86a78eca96\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6907909716384998, 0.686349906667995, 0.6782733791116355, 0.6717700146822537, 0.6407167999640755, 0.5976145710922094, 0.567864109467769, 0.5428812928821729, 0.5181566304054813, 0.5046610980506104, 0.47820909052079424, 0.4833377147354366, 0.4762956205197578, 0.4586051596535577, 0.45275304812740014, 0.44943214099188356, 0.4428571935725097, 0.42904851134272587, 0.41889769671043914, 0.41774228684568177, 0.41747673090529325, 0.40153567747793334, 0.39825622845387115, 0.38683977826781896, 0.4035234688560744, 0.38223260563352834, 0.38448525770850805, 0.3850572928138401, 0.3569857512407257, 0.3709758428271842]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"a2d1304d-217f-4192-b824-7f52907c7e36\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6885062720464623, 0.6823834999747899, 0.668569468933603, 0.6443194182022758, 0.5879970415778782, 0.5467729490736256, 0.506767793841984, 0.5000652111094931, 0.4825686755387679, 0.449577418099279, 0.42996569094450576, 0.4347570326017297, 0.4260899600775345, 0.4192254698794821, 0.5076115421626879, 0.4822941894116609, 0.4412246351656706, 0.442808315028315, 0.4795170348623525, 0.4633292548034502, 0.405201736740444, 0.433089904681496, 0.4276421510654947, 0.540861776082412, 0.4822313604147538, 0.5900901524916939, 0.5029027809267459, 0.5599138928496319, 0.7622336537941642, 0.6768896854442099]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"65cc77f1-b2d9-4303-9d03-a58cc842f89c\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.690494405820174, 0.680607519345583, 0.6688142811618565, 0.6406622625779415, 0.6007394056965187, 0.581925808634735, 0.5532137717025868, 0.5408033386520718, 0.5229946529231786, 0.512590539743359, 0.4960288075433261, 0.4943983715513478, 0.48451958393705064, 0.46765532286270806, 0.4735842257306196, 0.46839564652834537, 0.46188848750026906, 0.47233113511173047, 0.4467479447523753, 0.4532595502293628, 0.43170655064536756, 0.43054084792229286, 0.44673543321913567, 0.4104186637390063, 0.4345502838420407, 0.42985239509799056, 0.4293553162312162, 0.42205219741028865, 0.41077221398768216, 0.40463486737099247]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"8ecafa77-327a-4684-b8b5-30b6c8a591df\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6890450026678002, 0.6698199811189071, 0.6516618816748909, 0.5775664028914078, 0.5213509678840638, 0.4841629041277844, 0.4702449941116831, 0.4442262556241906, 0.45531954791234885, 0.4355937465377476, 0.4226896114971327, 0.43984814726788063, 0.4374493565248406, 0.40966894808022875, 0.4127300534559333, 0.42688246939493263, 0.4114329861558002, 0.4163870119530222, 0.42347268021625023, 0.39918372009111486, 0.4013402959574824, 0.3939353618932807, 0.45773554573888364, 0.4156626151955646, 0.42158866576526477, 0.44216733626697374, 0.4032152165537295, 0.3903986816820891, 0.4319803815820943, 0.46925391088361323]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"b14813aa-3e4c-4490-a607-4166ed81fd7f\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6911335560434683, 0.732980205471389, 0.6675790646225934, 0.6661939425168982, 0.6576133826504583, 0.6457303749766327, 0.6470684153446252, 0.6230699030673447, 0.6018004320093975, 0.5891430184461068, 0.5982923386753469, 0.585970401763916, 0.5562711956996272, 0.5412647006016422, 0.5158405549860231, 0.5023296513707165, 0.4736964516593638, 0.48582333470312294, 0.47507179151986534, 0.44227664542658895, 0.4444725848050509, 0.4346493742892132, 0.4246205316649543, 0.4330781568939559, 0.4219466693447408, 0.4031008560300449, 0.3992236560381553, 0.40485360982337437, 0.3952000717897922, 0.38481252202089283]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"050321be-cc01-422a-b076-a1769eba2a40\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6854903480281, 0.659219901976378, 0.659855476151342, 0.6576434575993082, 0.6324390302533689, 0.6144850554673568, 0.6159332928450211, 0.6028816259425619, 0.5667919231497723, 0.5488430748815122, 0.6089827952177628, 0.5088829779106637, 0.5212957687999891, 0.47765758970509403, 0.47047381426977075, 0.429471513758535, 0.41853585398715476, 0.4349240673624951, 0.42956688093102496, 0.44275972765424976, 0.43334730319354847, 0.46894779853198837, 0.5257739530957264, 0.49987388952918677, 0.43333443817885026, 0.5412876460863196, 0.7295354444047679, 0.7096221871997999, 0.7574776545814846, 0.5831870607707812]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"4fd80dd6-8262-43b2-baad-e05f54eea689\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6912948200092224, 0.6802397245946138, 0.6422013211941373, 0.6056114575137262, 0.6685001417058678, 0.6243338835988068, 0.6160198398258375, 0.6072793456667287, 0.60263258708272, 0.5956816846621785, 0.5808631696562836, 0.5721376997261232, 0.5761640291858986, 0.5618871252893826, 0.5658791943448753, 0.5503980094108029, 0.5404526971388555, 0.5340177621818395, 0.5343814935949114, 0.6018613519875899, 0.5298765417170409, 0.5250526913122279, 0.5187674148935051, 0.5098972597559869, 0.5070595237943861, 0.49963867298646825, 0.5031243080966139, 0.48371121546496515, 0.6321886445013222, 0.5043955908881294]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"cdb8a9d0-e0ce-4ec5-96af-7a9fe1d57ee2\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6888292276340983, 0.6639407074969748, 0.5979828197023143, 0.5740209144094716, 0.6189063445381496, 0.6096609742745109, 0.5988631378049436, 0.5880537660225578, 0.5783012094705001, 0.5682993816292804, 0.5570988284504932, 0.5471069693565369, 0.5390090144198874, 0.5281520382217739, 0.5211412440175596, 0.5111857307993848, 0.5026721607083859, 0.49892810427624246, 0.48802187131798785, 0.4947187426297561, 0.4782334055589593, 0.46777998053509257, 0.46146609316701476, 0.4547854879628057, 0.44875642553619716, 0.44245347562043563, 0.43135788725770036, 0.4319986307102701, 0.4481228082076363, 0.4546791099983713]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"f09dff91-87ee-4ae6-8509-c1473be93850\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.691752719015315, 0.6888581795968871, 0.6754927503889886, 0.6598268996690206, 0.6536118412363356, 0.6352295426930782, 0.6194396697380693, 0.6094588830851126, 0.6099049500221215, 0.5869984744827529, 0.5926494541951424, 0.5774193470604754, 0.5649041625036709, 0.5640312451671287, 0.5417098806100191, 0.5429393842600394, 0.5296132857672834, 0.5105433988974291, 0.5069017241542466, 0.4994660182563579, 0.6118006001923971, 0.5633293863079974, 0.5217100975594083, 0.5137353916674996, 0.49964662980342256, 0.48858676964534076, 0.48155287915957723, 0.4879486490274973, 0.4778679033120473, 0.4669706330207235]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"61958c94-99d8-478a-be14-8a83f3c232c6\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6896016789519268, 0.6538460529368857, 0.650369682001031, 0.6401792536611143, 0.6185783857884615, 0.6012975319572117, 0.5915755966435308, 0.5798412307449009, 0.5801303298577019, 0.571048222935718, 0.5849378269651662, 0.5617799038472383, 0.5447587702585304, 0.5322724269784015, 0.5174774211385976, 0.5012370524199112, 0.4918869930764903, 0.48312598985174426, 0.47682782282, 0.4758603077867757, 0.5199968607529349, 0.521272771773131, 0.5043831034846927, 0.5027166776035144, 0.48738346099853513, 0.4852819929952207, 0.48765488318775013, 0.4819537473761517, 0.48686824518701305, 0.48728761387907943]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('9d99e487-7272-464c-a64f-763e34101d2e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean  acc         0.727967\n",
      "loss        0.518230\n",
      "val_acc     0.765014\n",
      "val_loss    0.524105\n",
      "dtype: float64\n",
      "std  acc         0.075186\n",
      "loss        0.097495\n",
      "val_acc     0.082013\n",
      "val_loss    0.095106\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "1",
         "text": "",
         "type": "scatter",
         "uid": "79314944-9077-464a-aa86-713a1e96299e",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.8700000047683716,
          0.8600000143051147,
          0.8399999737739563,
          0.8600000143051147,
          0.8299999833106995,
          0.800000011920929,
          0.8500000238418579,
          0.8700000047683716,
          0.8500000238418579,
          0.8199999928474426
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"4475bdaf-238a-4bd7-bdbb-7e3ba2c96b38\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"4475bdaf-238a-4bd7-bdbb-7e3ba2c96b38\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '4475bdaf-238a-4bd7-bdbb-7e3ba2c96b38',\n",
       "                        [{\"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"1\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"79314944-9077-464a-aa86-713a1e96299e\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.8700000047683716, 0.8600000143051147, 0.8399999737739563, 0.8600000143051147, 0.8299999833106995, 0.800000011920929, 0.8500000238418579, 0.8700000047683716, 0.8500000238418579, 0.8199999928474426]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4475bdaf-238a-4bd7-bdbb-7e3ba2c96b38');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media  0.8450000047683716\n",
      "std  0.022730307373557055\n"
     ]
    }
   ],
   "source": [
    "process_results(gl__wobn_hist, gl_wobn_evas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas con topologías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.093897Z",
     "start_time": "2019-06-14T06:36:08.324Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 10:33:18.378517 140412910548800 nn_ops.py:4230] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0623 10:33:18.589042 140412910548800 deprecation.py:323] From /home/suampa/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:182: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/double_lstm/kfold1\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 4s - loss: 0.6875 - acc: 0.5920 - val_loss: 0.6651 - val_acc: 0.7043\n",
      "Epoch 2/30\n",
      "4140/4140 - 2s - loss: 0.6469 - acc: 0.6679 - val_loss: 0.5975 - val_acc: 0.7196\n",
      "Epoch 3/30\n",
      "4140/4140 - 2s - loss: 0.5605 - acc: 0.7229 - val_loss: 0.4615 - val_acc: 0.7587\n",
      "Epoch 4/30\n",
      "4140/4140 - 2s - loss: 0.5143 - acc: 0.7630 - val_loss: 0.5105 - val_acc: 0.7826\n",
      "Epoch 5/30\n",
      "4140/4140 - 2s - loss: 0.5129 - acc: 0.7853 - val_loss: 0.4425 - val_acc: 0.8087\n",
      "Epoch 6/30\n",
      "4140/4140 - 2s - loss: 0.4303 - acc: 0.8024 - val_loss: 0.4137 - val_acc: 0.8130\n",
      "Epoch 7/30\n",
      "4140/4140 - 2s - loss: 0.4116 - acc: 0.8184 - val_loss: 0.4092 - val_acc: 0.8196\n",
      "Epoch 8/30\n",
      "4140/4140 - 2s - loss: 0.3895 - acc: 0.8278 - val_loss: 0.4064 - val_acc: 0.8152\n",
      "Epoch 9/30\n",
      "4140/4140 - 2s - loss: 0.3844 - acc: 0.8278 - val_loss: 0.4116 - val_acc: 0.8087\n",
      "Epoch 10/30\n",
      "4140/4140 - 4s - loss: 0.3872 - acc: 0.8319 - val_loss: 0.4111 - val_acc: 0.8087\n",
      "Epoch 11/30\n",
      "4140/4140 - 5s - loss: 0.3695 - acc: 0.8391 - val_loss: 0.4204 - val_acc: 0.8109\n",
      "Epoch 12/30\n",
      "4140/4140 - 9s - loss: 0.3620 - acc: 0.8432 - val_loss: 0.4224 - val_acc: 0.8130\n",
      "Epoch 13/30\n",
      "4140/4140 - 13s - loss: 0.3580 - acc: 0.8471 - val_loss: 0.4234 - val_acc: 0.8109\n",
      "Epoch 14/30\n",
      "4140/4140 - 16s - loss: 0.3482 - acc: 0.8522 - val_loss: 0.4195 - val_acc: 0.8130\n",
      "Epoch 15/30\n",
      "4140/4140 - 17s - loss: 0.3357 - acc: 0.8572 - val_loss: 0.4318 - val_acc: 0.8130\n",
      "Epoch 16/30\n",
      "4140/4140 - 14s - loss: 0.3272 - acc: 0.8676 - val_loss: 0.4409 - val_acc: 0.8087\n",
      "Epoch 17/30\n",
      "4140/4140 - 15s - loss: 0.3186 - acc: 0.8686 - val_loss: 0.4414 - val_acc: 0.8152\n",
      "Epoch 18/30\n",
      "4140/4140 - 15s - loss: 0.3062 - acc: 0.8739 - val_loss: 0.4525 - val_acc: 0.8022\n",
      "Epoch 19/30\n",
      "4140/4140 - 15s - loss: 0.3040 - acc: 0.8792 - val_loss: 0.4532 - val_acc: 0.8065\n",
      "Epoch 20/30\n",
      "4140/4140 - 14s - loss: 0.2952 - acc: 0.8845 - val_loss: 0.4551 - val_acc: 0.8022\n",
      "Epoch 21/30\n",
      "4140/4140 - 15s - loss: 0.2838 - acc: 0.8913 - val_loss: 0.4582 - val_acc: 0.8000\n",
      "Epoch 22/30\n",
      "4140/4140 - 14s - loss: 0.2713 - acc: 0.8954 - val_loss: 0.4774 - val_acc: 0.8022\n",
      "Epoch 23/30\n",
      "4140/4140 - 15s - loss: 0.2685 - acc: 0.8981 - val_loss: 0.4750 - val_acc: 0.8109\n",
      "Epoch 24/30\n",
      "4140/4140 - 2s - loss: 0.2619 - acc: 0.9002 - val_loss: 0.4768 - val_acc: 0.8087\n",
      "Epoch 25/30\n",
      "4140/4140 - 2s - loss: 0.2621 - acc: 0.9012 - val_loss: 0.4884 - val_acc: 0.8022\n",
      "Epoch 26/30\n",
      "4140/4140 - 2s - loss: 0.2617 - acc: 0.9034 - val_loss: 0.4737 - val_acc: 0.7913\n",
      "Epoch 27/30\n",
      "4140/4140 - 2s - loss: 0.2685 - acc: 0.8961 - val_loss: 0.4590 - val_acc: 0.7891\n",
      "Epoch 28/30\n",
      "4140/4140 - 2s - loss: 0.2480 - acc: 0.9114 - val_loss: 0.4840 - val_acc: 0.8109\n",
      "Epoch 29/30\n",
      "4140/4140 - 2s - loss: 0.2323 - acc: 0.9174 - val_loss: 0.5006 - val_acc: 0.8130\n",
      "Epoch 30/30\n",
      "4140/4140 - 2s - loss: 0.2269 - acc: 0.9198 - val_loss: 0.4981 - val_acc: 0.7891\n",
      "100/100 [==============================] - 0s 1ms/sample - loss: 0.3638 - acc: 0.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 10:37:09.167119 140412910548800 nn_ops.py:4230] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/double_lstm/kfold2\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 3s - loss: 0.6978 - acc: 0.5816 - val_loss: 0.6812 - val_acc: 0.5652\n",
      "Epoch 2/30\n",
      "4140/4140 - 2s - loss: 0.6811 - acc: 0.5838 - val_loss: 0.6809 - val_acc: 0.5609\n",
      "Epoch 3/30\n",
      "4140/4140 - 4s - loss: 0.6843 - acc: 0.5783 - val_loss: 0.6806 - val_acc: 0.5609\n",
      "Epoch 4/30\n",
      "4140/4140 - 7s - loss: 0.6759 - acc: 0.5807 - val_loss: 0.6762 - val_acc: 0.5609\n",
      "Epoch 5/30\n",
      "4140/4140 - 13s - loss: 0.6529 - acc: 0.6092 - val_loss: 0.5834 - val_acc: 0.7022\n",
      "Epoch 6/30\n",
      "4140/4140 - 15s - loss: 0.6111 - acc: 0.7466 - val_loss: 0.6187 - val_acc: 0.6652\n",
      "Epoch 7/30\n",
      "4140/4140 - 18s - loss: 0.5899 - acc: 0.6954 - val_loss: 0.5374 - val_acc: 0.7174\n",
      "Epoch 8/30\n",
      "4140/4140 - 17s - loss: 0.5041 - acc: 0.7490 - val_loss: 0.5173 - val_acc: 0.7261\n",
      "Epoch 9/30\n",
      "4140/4140 - 15s - loss: 0.4673 - acc: 0.7696 - val_loss: 0.4995 - val_acc: 0.7261\n",
      "Epoch 10/30\n",
      "4140/4140 - 15s - loss: 0.4582 - acc: 0.7720 - val_loss: 0.4889 - val_acc: 0.7587\n",
      "Epoch 11/30\n",
      "4140/4140 - 15s - loss: 0.4412 - acc: 0.7884 - val_loss: 0.4816 - val_acc: 0.7674\n",
      "Epoch 12/30\n",
      "4140/4140 - 15s - loss: 0.4320 - acc: 0.7930 - val_loss: 0.4690 - val_acc: 0.7826\n",
      "Epoch 13/30\n",
      "4140/4140 - 17s - loss: 0.4094 - acc: 0.8046 - val_loss: 0.4931 - val_acc: 0.7848\n",
      "Epoch 14/30\n",
      "4140/4140 - 16s - loss: 0.4097 - acc: 0.8048 - val_loss: 0.4657 - val_acc: 0.7870\n",
      "Epoch 15/30\n",
      "4140/4140 - 16s - loss: 0.4003 - acc: 0.8101 - val_loss: 0.4534 - val_acc: 0.7870\n",
      "Epoch 16/30\n",
      "4140/4140 - 16s - loss: 0.3905 - acc: 0.8176 - val_loss: 0.4718 - val_acc: 0.7870\n",
      "Epoch 17/30\n",
      "4140/4140 - 16s - loss: 0.3909 - acc: 0.8210 - val_loss: 0.4429 - val_acc: 0.7957\n",
      "Epoch 18/30\n",
      "4140/4140 - 17s - loss: 0.3790 - acc: 0.8273 - val_loss: 0.4593 - val_acc: 0.8000\n",
      "Epoch 19/30\n",
      "4140/4140 - 15s - loss: 0.3694 - acc: 0.8312 - val_loss: 0.4674 - val_acc: 0.8043\n",
      "Epoch 20/30\n",
      "4140/4140 - 15s - loss: 0.3742 - acc: 0.8309 - val_loss: 0.4745 - val_acc: 0.8174\n",
      "Epoch 21/30\n",
      "4140/4140 - 15s - loss: 0.3602 - acc: 0.8343 - val_loss: 0.4662 - val_acc: 0.8174\n",
      "Epoch 22/30\n",
      "4140/4140 - 15s - loss: 0.3607 - acc: 0.8382 - val_loss: 0.4442 - val_acc: 0.8174\n",
      "Epoch 23/30\n",
      "4140/4140 - 15s - loss: 0.3490 - acc: 0.8401 - val_loss: 0.4725 - val_acc: 0.8174\n",
      "Epoch 24/30\n",
      "4140/4140 - 16s - loss: 0.3476 - acc: 0.8382 - val_loss: 0.4555 - val_acc: 0.8196\n",
      "Epoch 25/30\n",
      "4140/4140 - 15s - loss: 0.3383 - acc: 0.8403 - val_loss: 0.4597 - val_acc: 0.8196\n",
      "Epoch 26/30\n",
      "4140/4140 - 16s - loss: 0.3329 - acc: 0.8493 - val_loss: 0.4651 - val_acc: 0.8217\n",
      "Epoch 27/30\n",
      "4140/4140 - 7s - loss: 0.3284 - acc: 0.8529 - val_loss: 0.4784 - val_acc: 0.8283\n",
      "Epoch 28/30\n",
      "4140/4140 - 2s - loss: 0.3261 - acc: 0.8507 - val_loss: 0.4599 - val_acc: 0.8304\n",
      "Epoch 29/30\n",
      "4140/4140 - 2s - loss: 0.3190 - acc: 0.8556 - val_loss: 0.4596 - val_acc: 0.8261\n",
      "Epoch 30/30\n",
      "4140/4140 - 2s - loss: 0.3122 - acc: 0.8592 - val_loss: 0.4489 - val_acc: 0.8174\n",
      "100/100 [==============================] - 0s 1ms/sample - loss: 0.3122 - acc: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 10:43:25.719881 140412910548800 nn_ops.py:4230] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/double_lstm/kfold3\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 3s - loss: 0.6898 - acc: 0.5754 - val_loss: 0.6786 - val_acc: 0.6109\n",
      "Epoch 2/30\n",
      "4140/4140 - 2s - loss: 0.6630 - acc: 0.5749 - val_loss: 0.6481 - val_acc: 0.6109\n",
      "Epoch 3/30\n",
      "4140/4140 - 2s - loss: 0.6303 - acc: 0.5749 - val_loss: 0.5566 - val_acc: 0.6109\n",
      "Epoch 4/30\n",
      "4140/4140 - 2s - loss: 0.5528 - acc: 0.6005 - val_loss: 0.5392 - val_acc: 0.7391\n",
      "Epoch 5/30\n",
      "4140/4140 - 2s - loss: 0.5188 - acc: 0.7365 - val_loss: 0.5015 - val_acc: 0.7630\n",
      "Epoch 6/30\n",
      "4140/4140 - 3s - loss: 0.4754 - acc: 0.7688 - val_loss: 0.4858 - val_acc: 0.7804\n",
      "Epoch 7/30\n",
      "4140/4140 - 6s - loss: 0.4360 - acc: 0.7911 - val_loss: 0.4727 - val_acc: 0.8130\n",
      "Epoch 8/30\n",
      "4140/4140 - 10s - loss: 0.4196 - acc: 0.8094 - val_loss: 0.4510 - val_acc: 0.8109\n",
      "Epoch 9/30\n",
      "4140/4140 - 16s - loss: 0.4009 - acc: 0.8210 - val_loss: 0.4778 - val_acc: 0.8304\n",
      "Epoch 10/30\n",
      "4140/4140 - 17s - loss: 0.4028 - acc: 0.8242 - val_loss: 0.4318 - val_acc: 0.8326\n",
      "Epoch 11/30\n",
      "4140/4140 - 15s - loss: 0.3801 - acc: 0.8321 - val_loss: 0.4228 - val_acc: 0.8478\n",
      "Epoch 12/30\n",
      "4140/4140 - 15s - loss: 0.3700 - acc: 0.8391 - val_loss: 0.3993 - val_acc: 0.8326\n",
      "Epoch 13/30\n",
      "4140/4140 - 15s - loss: 0.3686 - acc: 0.8415 - val_loss: 0.4152 - val_acc: 0.8500\n",
      "Epoch 14/30\n",
      "4140/4140 - 17s - loss: 0.3705 - acc: 0.8444 - val_loss: 0.3876 - val_acc: 0.8478\n",
      "Epoch 15/30\n",
      "4140/4140 - 15s - loss: 0.3559 - acc: 0.8514 - val_loss: 0.3957 - val_acc: 0.8565\n",
      "Epoch 16/30\n",
      "4140/4140 - 15s - loss: 0.3418 - acc: 0.8536 - val_loss: 0.3938 - val_acc: 0.8435\n",
      "Epoch 17/30\n",
      "4140/4140 - 15s - loss: 0.3341 - acc: 0.8570 - val_loss: 0.3799 - val_acc: 0.8435\n",
      "Epoch 18/30\n",
      "4140/4140 - 15s - loss: 0.3322 - acc: 0.8575 - val_loss: 0.3744 - val_acc: 0.8457\n",
      "Epoch 19/30\n",
      "4140/4140 - 16s - loss: 0.3253 - acc: 0.8570 - val_loss: 0.3604 - val_acc: 0.8500\n",
      "Epoch 20/30\n",
      "4140/4140 - 18s - loss: 0.3148 - acc: 0.8640 - val_loss: 0.3755 - val_acc: 0.8500\n",
      "Epoch 21/30\n",
      "4140/4140 - 17s - loss: 0.3143 - acc: 0.8650 - val_loss: 0.3751 - val_acc: 0.8457\n",
      "Epoch 22/30\n",
      "4140/4140 - 16s - loss: 0.3039 - acc: 0.8696 - val_loss: 0.3636 - val_acc: 0.8457\n",
      "Epoch 23/30\n",
      "4140/4140 - 15s - loss: 0.2984 - acc: 0.8739 - val_loss: 0.3813 - val_acc: 0.8565\n",
      "Epoch 24/30\n",
      "4140/4140 - 17s - loss: 0.2955 - acc: 0.8746 - val_loss: 0.3728 - val_acc: 0.8478\n",
      "Epoch 25/30\n",
      "4140/4140 - 16s - loss: 0.2910 - acc: 0.8749 - val_loss: 0.3608 - val_acc: 0.8413\n",
      "Epoch 26/30\n",
      "4140/4140 - 16s - loss: 0.2911 - acc: 0.8775 - val_loss: 0.3684 - val_acc: 0.8500\n",
      "Epoch 27/30\n",
      "4140/4140 - 17s - loss: 0.2795 - acc: 0.8797 - val_loss: 0.3892 - val_acc: 0.8565\n",
      "Epoch 28/30\n",
      "4140/4140 - 17s - loss: 0.2741 - acc: 0.8826 - val_loss: 0.3833 - val_acc: 0.8522\n",
      "Epoch 29/30\n",
      "4140/4140 - 17s - loss: 0.2691 - acc: 0.8877 - val_loss: 0.3662 - val_acc: 0.8478\n",
      "Epoch 30/30\n",
      "4140/4140 - 17s - loss: 0.2727 - acc: 0.8862 - val_loss: 0.3565 - val_acc: 0.8478\n",
      "100/100 [==============================] - 1s 13ms/sample - loss: 0.3759 - acc: 0.8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 10:49:53.974105 140412910548800 nn_ops.py:4230] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/double_lstm/kfold4\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 26s - loss: 0.6979 - acc: 0.6046 - val_loss: 0.6947 - val_acc: 0.6130\n",
      "Epoch 2/30\n",
      "4140/4140 - 16s - loss: 0.6841 - acc: 0.6010 - val_loss: 0.6849 - val_acc: 0.5348\n",
      "Epoch 3/30\n",
      "4140/4140 - 16s - loss: 0.6632 - acc: 0.6077 - val_loss: 0.6328 - val_acc: 0.5891\n",
      "Epoch 4/30\n",
      "4140/4140 - 16s - loss: 0.5912 - acc: 0.6908 - val_loss: 0.5716 - val_acc: 0.6804\n",
      "Epoch 5/30\n",
      "4140/4140 - 16s - loss: 0.5136 - acc: 0.7425 - val_loss: 0.5103 - val_acc: 0.7478\n",
      "Epoch 6/30\n",
      "4140/4140 - 16s - loss: 0.4747 - acc: 0.7643 - val_loss: 0.4772 - val_acc: 0.7543\n",
      "Epoch 7/30\n",
      "4140/4140 - 16s - loss: 0.4304 - acc: 0.7947 - val_loss: 0.4133 - val_acc: 0.8174\n",
      "Epoch 8/30\n",
      "4140/4140 - 15s - loss: 0.4274 - acc: 0.8041 - val_loss: 0.4366 - val_acc: 0.7935\n",
      "Epoch 9/30\n",
      "4140/4140 - 14s - loss: 0.3952 - acc: 0.8234 - val_loss: 0.3865 - val_acc: 0.8261\n",
      "Epoch 10/30\n",
      "4140/4140 - 3s - loss: 0.3778 - acc: 0.8278 - val_loss: 0.3881 - val_acc: 0.8391\n",
      "Epoch 11/30\n",
      "4140/4140 - 2s - loss: 0.3711 - acc: 0.8362 - val_loss: 0.3813 - val_acc: 0.8391\n",
      "Epoch 12/30\n",
      "4140/4140 - 2s - loss: 0.3614 - acc: 0.8408 - val_loss: 0.3850 - val_acc: 0.8435\n",
      "Epoch 13/30\n",
      "4140/4140 - 2s - loss: 0.3560 - acc: 0.8469 - val_loss: 0.3711 - val_acc: 0.8500\n",
      "Epoch 14/30\n",
      "4140/4140 - 2s - loss: 0.3415 - acc: 0.8502 - val_loss: 0.3705 - val_acc: 0.8457\n",
      "Epoch 15/30\n",
      "4140/4140 - 2s - loss: 0.3395 - acc: 0.8551 - val_loss: 0.3847 - val_acc: 0.8478\n",
      "Epoch 16/30\n",
      "4140/4140 - 2s - loss: 0.3300 - acc: 0.8548 - val_loss: 0.3754 - val_acc: 0.8522\n",
      "Epoch 17/30\n",
      "4140/4140 - 2s - loss: 0.3326 - acc: 0.8657 - val_loss: 0.4154 - val_acc: 0.8391\n",
      "Epoch 18/30\n",
      "4140/4140 - 2s - loss: 0.3387 - acc: 0.8611 - val_loss: 0.3658 - val_acc: 0.8565\n",
      "Epoch 19/30\n",
      "4140/4140 - 2s - loss: 0.3097 - acc: 0.8662 - val_loss: 0.3619 - val_acc: 0.8478\n",
      "Epoch 20/30\n",
      "4140/4140 - 2s - loss: 0.3027 - acc: 0.8674 - val_loss: 0.3556 - val_acc: 0.8500\n",
      "Epoch 21/30\n",
      "4140/4140 - 4s - loss: 0.2926 - acc: 0.8703 - val_loss: 0.3732 - val_acc: 0.8435\n",
      "Epoch 22/30\n",
      "4140/4140 - 7s - loss: 0.2853 - acc: 0.8797 - val_loss: 0.3709 - val_acc: 0.8435\n",
      "Epoch 23/30\n",
      "4140/4140 - 12s - loss: 0.2804 - acc: 0.8809 - val_loss: 0.3660 - val_acc: 0.8391\n",
      "Epoch 24/30\n",
      "4140/4140 - 14s - loss: 0.2715 - acc: 0.8843 - val_loss: 0.4124 - val_acc: 0.8478\n",
      "Epoch 25/30\n",
      "4140/4140 - 14s - loss: 0.2629 - acc: 0.8947 - val_loss: 0.3658 - val_acc: 0.8500\n",
      "Epoch 26/30\n",
      "4140/4140 - 15s - loss: 0.2614 - acc: 0.8923 - val_loss: 0.3779 - val_acc: 0.8435\n",
      "Epoch 27/30\n",
      "4140/4140 - 15s - loss: 0.2492 - acc: 0.9019 - val_loss: 0.3997 - val_acc: 0.8391\n",
      "Epoch 28/30\n",
      "4140/4140 - 14s - loss: 0.2481 - acc: 0.9031 - val_loss: 0.3730 - val_acc: 0.8478\n",
      "Epoch 29/30\n",
      "4140/4140 - 14s - loss: 0.2435 - acc: 0.9017 - val_loss: 0.4061 - val_acc: 0.8435\n",
      "Epoch 30/30\n",
      "4140/4140 - 14s - loss: 0.2393 - acc: 0.9027 - val_loss: 0.4473 - val_acc: 0.8478\n",
      "100/100 [==============================] - 1s 9ms/sample - loss: 0.4138 - acc: 0.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0623 10:55:11.599130 140412910548800 nn_ops.py:4230] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/double_lstm/kfold5\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 23s - loss: 0.6895 - acc: 0.5771 - val_loss: 0.6683 - val_acc: 0.5804\n",
      "Epoch 2/30\n",
      "4140/4140 - 14s - loss: 0.6541 - acc: 0.5932 - val_loss: 0.6082 - val_acc: 0.6913\n",
      "Epoch 3/30\n",
      "4140/4140 - 14s - loss: 0.5702 - acc: 0.7181 - val_loss: 0.5334 - val_acc: 0.7196\n",
      "Epoch 4/30\n",
      "4140/4140 - 15s - loss: 0.4872 - acc: 0.7652 - val_loss: 0.4915 - val_acc: 0.7543\n",
      "Epoch 5/30\n",
      "4140/4140 - 15s - loss: 0.4436 - acc: 0.7942 - val_loss: 0.4729 - val_acc: 0.7696\n",
      "Epoch 6/30\n",
      "4140/4140 - 15s - loss: 0.4053 - acc: 0.8164 - val_loss: 0.4992 - val_acc: 0.7761\n",
      "Epoch 7/30\n",
      "4140/4140 - 15s - loss: 0.3776 - acc: 0.8309 - val_loss: 0.5425 - val_acc: 0.7761\n",
      "Epoch 8/30\n",
      "4140/4140 - 14s - loss: 0.3613 - acc: 0.8382 - val_loss: 0.4926 - val_acc: 0.7826\n",
      "Epoch 9/30\n",
      "4140/4140 - 15s - loss: 0.3482 - acc: 0.8505 - val_loss: 0.4970 - val_acc: 0.7826\n",
      "Epoch 10/30\n",
      "4140/4140 - 14s - loss: 0.3384 - acc: 0.8543 - val_loss: 0.5132 - val_acc: 0.7848\n",
      "Epoch 11/30\n",
      "4140/4140 - 8s - loss: 0.3287 - acc: 0.8565 - val_loss: 0.5310 - val_acc: 0.7804\n",
      "Epoch 12/30\n",
      "4140/4140 - 2s - loss: 0.3214 - acc: 0.8640 - val_loss: 0.5298 - val_acc: 0.7826\n",
      "Epoch 13/30\n",
      "4140/4140 - 2s - loss: 0.3122 - acc: 0.8655 - val_loss: 0.5391 - val_acc: 0.7848\n",
      "Epoch 14/30\n",
      "4140/4140 - 2s - loss: 0.3037 - acc: 0.8729 - val_loss: 0.5208 - val_acc: 0.7913\n",
      "Epoch 15/30\n",
      "4140/4140 - 2s - loss: 0.2939 - acc: 0.8778 - val_loss: 0.5158 - val_acc: 0.7957\n",
      "Epoch 16/30\n",
      "4140/4140 - 2s - loss: 0.2898 - acc: 0.8800 - val_loss: 0.5240 - val_acc: 0.7935\n",
      "Epoch 17/30\n",
      "4140/4140 - 2s - loss: 0.2784 - acc: 0.8824 - val_loss: 0.4938 - val_acc: 0.8043\n",
      "Epoch 18/30\n",
      "4140/4140 - 2s - loss: 0.2739 - acc: 0.8845 - val_loss: 0.5568 - val_acc: 0.7957\n",
      "Epoch 19/30\n",
      "4140/4140 - 2s - loss: 0.2653 - acc: 0.8915 - val_loss: 0.4953 - val_acc: 0.8022\n",
      "Epoch 20/30\n",
      "4140/4140 - 2s - loss: 0.2579 - acc: 0.8918 - val_loss: 0.5319 - val_acc: 0.8043\n",
      "Epoch 21/30\n",
      "4140/4140 - 2s - loss: 0.2790 - acc: 0.8903 - val_loss: 0.5545 - val_acc: 0.8022\n",
      "Epoch 22/30\n",
      "4140/4140 - 3s - loss: 0.2526 - acc: 0.8988 - val_loss: 0.5569 - val_acc: 0.8043\n",
      "Epoch 23/30\n",
      "4140/4140 - 5s - loss: 0.2449 - acc: 0.9002 - val_loss: 0.5579 - val_acc: 0.8043\n",
      "Epoch 24/30\n",
      "4140/4140 - 8s - loss: 0.2381 - acc: 0.9046 - val_loss: 0.5734 - val_acc: 0.8043\n",
      "Epoch 25/30\n",
      "4140/4140 - 13s - loss: 0.2253 - acc: 0.9118 - val_loss: 0.5868 - val_acc: 0.7957\n",
      "Epoch 26/30\n",
      "4140/4140 - 14s - loss: 0.2197 - acc: 0.9138 - val_loss: 0.6412 - val_acc: 0.7957\n",
      "Epoch 27/30\n",
      "4140/4140 - 13s - loss: 0.2115 - acc: 0.9171 - val_loss: 0.6444 - val_acc: 0.7978\n",
      "Epoch 28/30\n",
      "4140/4140 - 13s - loss: 0.2075 - acc: 0.9191 - val_loss: 0.5911 - val_acc: 0.8000\n",
      "Epoch 29/30\n",
      "4140/4140 - 13s - loss: 0.2012 - acc: 0.9256 - val_loss: 0.6674 - val_acc: 0.8000\n",
      "Epoch 30/30\n",
      "4140/4140 - 13s - loss: 0.1910 - acc: 0.9254 - val_loss: 0.6266 - val_acc: 0.8043\n",
      "100/100 [==============================] - 1s 7ms/sample - loss: 0.4685 - acc: 0.8400\n",
      "logs/fit/double_lstm/kfold6\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 22s - loss: 0.6894 - acc: 0.5795 - val_loss: 0.6846 - val_acc: 0.5717\n",
      "Epoch 2/30\n",
      "4140/4140 - 13s - loss: 0.6556 - acc: 0.5800 - val_loss: 0.6264 - val_acc: 0.5761\n",
      "Epoch 3/30\n",
      "4140/4140 - 14s - loss: 0.5518 - acc: 0.6599 - val_loss: 0.5299 - val_acc: 0.7500\n",
      "Epoch 4/30\n",
      "4140/4140 - 14s - loss: 0.4959 - acc: 0.7413 - val_loss: 0.4873 - val_acc: 0.7783\n",
      "Epoch 5/30\n",
      "4140/4140 - 13s - loss: 0.4653 - acc: 0.7872 - val_loss: 0.4254 - val_acc: 0.8152\n",
      "Epoch 6/30\n",
      "4140/4140 - 13s - loss: 0.4339 - acc: 0.8019 - val_loss: 0.4104 - val_acc: 0.8217\n",
      "Epoch 7/30\n",
      "4140/4140 - 14s - loss: 0.4086 - acc: 0.8297 - val_loss: 0.3920 - val_acc: 0.8304\n",
      "Epoch 8/30\n",
      "4140/4140 - 14s - loss: 0.3918 - acc: 0.8304 - val_loss: 0.3813 - val_acc: 0.8304\n",
      "Epoch 9/30\n",
      "4140/4140 - 13s - loss: 0.3774 - acc: 0.8394 - val_loss: 0.3790 - val_acc: 0.8370\n",
      "Epoch 10/30\n",
      "4140/4140 - 13s - loss: 0.3633 - acc: 0.8452 - val_loss: 0.3745 - val_acc: 0.8435\n",
      "Epoch 11/30\n",
      "4140/4140 - 9s - loss: 0.3529 - acc: 0.8490 - val_loss: 0.3742 - val_acc: 0.8370\n",
      "Epoch 12/30\n",
      "4140/4140 - 2s - loss: 0.3432 - acc: 0.8543 - val_loss: 0.3825 - val_acc: 0.8457\n",
      "Epoch 13/30\n",
      "4140/4140 - 2s - loss: 0.3384 - acc: 0.8551 - val_loss: 0.3921 - val_acc: 0.8478\n",
      "Epoch 14/30\n",
      "4140/4140 - 2s - loss: 0.3209 - acc: 0.8645 - val_loss: 0.3893 - val_acc: 0.8391\n",
      "Epoch 15/30\n",
      "4140/4140 - 2s - loss: 0.3072 - acc: 0.8708 - val_loss: 0.4003 - val_acc: 0.8391\n",
      "Epoch 16/30\n",
      "4140/4140 - 2s - loss: 0.3011 - acc: 0.8787 - val_loss: 0.4053 - val_acc: 0.8370\n",
      "Epoch 17/30\n",
      "4140/4140 - 2s - loss: 0.2870 - acc: 0.8843 - val_loss: 0.4004 - val_acc: 0.8304\n",
      "Epoch 18/30\n",
      "4140/4140 - 2s - loss: 0.2749 - acc: 0.8896 - val_loss: 0.4175 - val_acc: 0.8304\n",
      "Epoch 19/30\n",
      "4140/4140 - 2s - loss: 0.2683 - acc: 0.8973 - val_loss: 0.4642 - val_acc: 0.8370\n",
      "Epoch 20/30\n",
      "4140/4140 - 2s - loss: 0.2745 - acc: 0.8932 - val_loss: 0.4409 - val_acc: 0.8326\n",
      "Epoch 21/30\n",
      "4140/4140 - 2s - loss: 0.2607 - acc: 0.8981 - val_loss: 0.4632 - val_acc: 0.8326\n",
      "Epoch 22/30\n",
      "4140/4140 - 3s - loss: 0.2492 - acc: 0.9048 - val_loss: 0.4716 - val_acc: 0.8304\n",
      "Epoch 23/30\n",
      "4140/4140 - 5s - loss: 0.2435 - acc: 0.9065 - val_loss: 0.4765 - val_acc: 0.8304\n",
      "Epoch 24/30\n",
      "4140/4140 - 7s - loss: 0.2404 - acc: 0.9111 - val_loss: 0.5445 - val_acc: 0.8152\n",
      "Epoch 25/30\n",
      "4140/4140 - 11s - loss: 0.2970 - acc: 0.9060 - val_loss: 0.4712 - val_acc: 0.8283\n",
      "Epoch 26/30\n",
      "4140/4140 - 14s - loss: 0.2679 - acc: 0.8954 - val_loss: 0.4567 - val_acc: 0.8326\n",
      "Epoch 27/30\n",
      "4140/4140 - 13s - loss: 0.2471 - acc: 0.9041 - val_loss: 0.4908 - val_acc: 0.8370\n",
      "Epoch 28/30\n",
      "4140/4140 - 14s - loss: 0.2352 - acc: 0.9106 - val_loss: 0.5361 - val_acc: 0.8261\n",
      "Epoch 29/30\n",
      "4140/4140 - 13s - loss: 0.2400 - acc: 0.9092 - val_loss: 0.5773 - val_acc: 0.8261\n",
      "Epoch 30/30\n",
      "4140/4140 - 13s - loss: 0.2358 - acc: 0.9063 - val_loss: 0.5669 - val_acc: 0.8152\n",
      "100/100 [==============================] - 1s 8ms/sample - loss: 0.3464 - acc: 0.8500\n",
      "logs/fit/double_lstm/kfold7\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 22s - loss: 0.6933 - acc: 0.5814 - val_loss: 0.7229 - val_acc: 0.5565\n",
      "Epoch 2/30\n",
      "4140/4140 - 13s - loss: 0.6829 - acc: 0.5814 - val_loss: 0.6856 - val_acc: 0.5565\n",
      "Epoch 3/30\n",
      "4140/4140 - 13s - loss: 0.6796 - acc: 0.5814 - val_loss: 0.6827 - val_acc: 0.5565\n",
      "Epoch 4/30\n",
      "4140/4140 - 13s - loss: 0.6672 - acc: 0.5814 - val_loss: 0.6357 - val_acc: 0.5565\n",
      "Epoch 5/30\n",
      "4140/4140 - 14s - loss: 0.5776 - acc: 0.6459 - val_loss: 0.4766 - val_acc: 0.7674\n",
      "Epoch 6/30\n",
      "4140/4140 - 13s - loss: 0.4789 - acc: 0.7505 - val_loss: 0.4791 - val_acc: 0.7935\n",
      "Epoch 7/30\n",
      "4140/4140 - 13s - loss: 0.4494 - acc: 0.7845 - val_loss: 0.4477 - val_acc: 0.8174\n",
      "Epoch 8/30\n",
      "4140/4140 - 12s - loss: 0.4199 - acc: 0.8075 - val_loss: 0.4853 - val_acc: 0.8109\n",
      "Epoch 9/30\n",
      "4140/4140 - 2s - loss: 0.3989 - acc: 0.8254 - val_loss: 0.4301 - val_acc: 0.8152\n",
      "Epoch 10/30\n",
      "4140/4140 - 2s - loss: 0.3855 - acc: 0.8331 - val_loss: 0.4350 - val_acc: 0.8065\n",
      "Epoch 11/30\n",
      "4140/4140 - 2s - loss: 0.3681 - acc: 0.8384 - val_loss: 0.4331 - val_acc: 0.8087\n",
      "Epoch 12/30\n",
      "4140/4140 - 2s - loss: 0.3550 - acc: 0.8454 - val_loss: 0.4147 - val_acc: 0.8152\n",
      "Epoch 13/30\n",
      "4140/4140 - 2s - loss: 0.3519 - acc: 0.8490 - val_loss: 0.4087 - val_acc: 0.8196\n",
      "Epoch 14/30\n",
      "4140/4140 - 2s - loss: 0.3435 - acc: 0.8510 - val_loss: 0.4482 - val_acc: 0.8304\n",
      "Epoch 15/30\n",
      "4140/4140 - 2s - loss: 0.3415 - acc: 0.8531 - val_loss: 0.5088 - val_acc: 0.8304\n",
      "Epoch 16/30\n",
      "4140/4140 - 2s - loss: 0.3424 - acc: 0.8493 - val_loss: 0.4575 - val_acc: 0.8174\n",
      "Epoch 17/30\n",
      "4140/4140 - 2s - loss: 0.3304 - acc: 0.8531 - val_loss: 0.4746 - val_acc: 0.8130\n",
      "Epoch 18/30\n",
      "4140/4140 - 2s - loss: 0.3285 - acc: 0.8565 - val_loss: 0.4775 - val_acc: 0.8174\n",
      "Epoch 19/30\n",
      "4140/4140 - 2s - loss: 0.3091 - acc: 0.8643 - val_loss: 0.5143 - val_acc: 0.8304\n",
      "Epoch 20/30\n",
      "4140/4140 - 3s - loss: 0.2988 - acc: 0.8691 - val_loss: 0.5556 - val_acc: 0.8304\n",
      "Epoch 21/30\n",
      "4140/4140 - 7s - loss: 0.2898 - acc: 0.8722 - val_loss: 0.5470 - val_acc: 0.8326\n",
      "Epoch 22/30\n",
      "4140/4140 - 10s - loss: 0.2802 - acc: 0.8814 - val_loss: 0.5540 - val_acc: 0.8348\n",
      "Epoch 23/30\n",
      "4140/4140 - 13s - loss: 0.2796 - acc: 0.8785 - val_loss: 0.5595 - val_acc: 0.8304\n",
      "Epoch 24/30\n",
      "4140/4140 - 13s - loss: 0.2669 - acc: 0.8857 - val_loss: 0.5589 - val_acc: 0.8391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "4140/4140 - 14s - loss: 0.2717 - acc: 0.8795 - val_loss: 0.5703 - val_acc: 0.8283\n",
      "Epoch 26/30\n",
      "4140/4140 - 13s - loss: 0.2655 - acc: 0.8867 - val_loss: 0.5688 - val_acc: 0.8239\n",
      "Epoch 27/30\n",
      "4140/4140 - 13s - loss: 0.2898 - acc: 0.8768 - val_loss: 0.6594 - val_acc: 0.8196\n",
      "Epoch 28/30\n",
      "4140/4140 - 13s - loss: 0.2845 - acc: 0.8792 - val_loss: 0.6584 - val_acc: 0.8174\n",
      "Epoch 29/30\n",
      "4140/4140 - 13s - loss: 0.2616 - acc: 0.8908 - val_loss: 0.6473 - val_acc: 0.8152\n",
      "Epoch 30/30\n",
      "4140/4140 - 13s - loss: 0.2670 - acc: 0.8872 - val_loss: 0.7104 - val_acc: 0.8065\n",
      "100/100 [==============================] - 1s 7ms/sample - loss: 0.5510 - acc: 0.8500\n",
      "logs/fit/double_lstm/kfold8\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 23s - loss: 0.6902 - acc: 0.5935 - val_loss: 0.6837 - val_acc: 0.6370\n",
      "Epoch 2/30\n",
      "4140/4140 - 14s - loss: 0.6800 - acc: 0.6635 - val_loss: 0.6615 - val_acc: 0.6587\n",
      "Epoch 3/30\n",
      "4140/4140 - 13s - loss: 0.6424 - acc: 0.6899 - val_loss: 0.5937 - val_acc: 0.6870\n",
      "Epoch 4/30\n",
      "4140/4140 - 14s - loss: 0.5297 - acc: 0.7408 - val_loss: 0.4968 - val_acc: 0.7587\n",
      "Epoch 5/30\n",
      "4140/4140 - 14s - loss: 0.4612 - acc: 0.7732 - val_loss: 0.4362 - val_acc: 0.7913\n",
      "Epoch 6/30\n",
      "4140/4140 - 13s - loss: 0.4353 - acc: 0.7990 - val_loss: 0.4241 - val_acc: 0.8043\n",
      "Epoch 7/30\n",
      "4140/4140 - 14s - loss: 0.4026 - acc: 0.8205 - val_loss: 0.3728 - val_acc: 0.8196\n",
      "Epoch 8/30\n",
      "4140/4140 - 7s - loss: 0.3854 - acc: 0.8275 - val_loss: 0.3610 - val_acc: 0.8283\n",
      "Epoch 9/30\n",
      "4140/4140 - 2s - loss: 0.3738 - acc: 0.8336 - val_loss: 0.3559 - val_acc: 0.8391\n",
      "Epoch 10/30\n",
      "4140/4140 - 2s - loss: 0.3609 - acc: 0.8471 - val_loss: 0.3770 - val_acc: 0.8478\n",
      "Epoch 11/30\n",
      "4140/4140 - 2s - loss: 0.4005 - acc: 0.8408 - val_loss: 0.4071 - val_acc: 0.8348\n",
      "Epoch 12/30\n",
      "4140/4140 - 2s - loss: 0.3500 - acc: 0.8471 - val_loss: 0.3791 - val_acc: 0.8391\n",
      "Epoch 13/30\n",
      "4140/4140 - 2s - loss: 0.3392 - acc: 0.8534 - val_loss: 0.3825 - val_acc: 0.8283\n",
      "Epoch 14/30\n",
      "4140/4140 - 2s - loss: 0.3353 - acc: 0.8580 - val_loss: 0.3676 - val_acc: 0.8391\n",
      "Epoch 15/30\n",
      "4140/4140 - 2s - loss: 0.3199 - acc: 0.8604 - val_loss: 0.3503 - val_acc: 0.8543\n",
      "Epoch 16/30\n",
      "4140/4140 - 2s - loss: 0.3172 - acc: 0.8609 - val_loss: 0.3571 - val_acc: 0.8543\n",
      "Epoch 17/30\n",
      "4140/4140 - 2s - loss: 0.3073 - acc: 0.8681 - val_loss: 0.3487 - val_acc: 0.8543\n",
      "Epoch 18/30\n",
      "4140/4140 - 2s - loss: 0.3025 - acc: 0.8696 - val_loss: 0.3511 - val_acc: 0.8543\n",
      "Epoch 19/30\n",
      "4140/4140 - 3s - loss: 0.2967 - acc: 0.8700 - val_loss: 0.3455 - val_acc: 0.8587\n",
      "Epoch 20/30\n",
      "4140/4140 - 5s - loss: 0.2881 - acc: 0.8797 - val_loss: 0.3544 - val_acc: 0.8609\n",
      "Epoch 21/30\n",
      "4140/4140 - 8s - loss: 0.2823 - acc: 0.8780 - val_loss: 0.3509 - val_acc: 0.8587\n",
      "Epoch 22/30\n",
      "4140/4140 - 13s - loss: 0.2745 - acc: 0.8860 - val_loss: 0.3578 - val_acc: 0.8565\n",
      "Epoch 23/30\n",
      "4140/4140 - 13s - loss: 0.2672 - acc: 0.8833 - val_loss: 0.3540 - val_acc: 0.8587\n",
      "Epoch 24/30\n",
      "4140/4140 - 13s - loss: 0.2648 - acc: 0.8884 - val_loss: 0.3516 - val_acc: 0.8522\n",
      "Epoch 25/30\n",
      "4140/4140 - 13s - loss: 0.2516 - acc: 0.8947 - val_loss: 0.3718 - val_acc: 0.8543\n",
      "Epoch 26/30\n",
      "4140/4140 - 13s - loss: 0.2451 - acc: 0.8971 - val_loss: 0.4209 - val_acc: 0.8587\n",
      "Epoch 27/30\n",
      "4140/4140 - 14s - loss: 0.2386 - acc: 0.8998 - val_loss: 0.4260 - val_acc: 0.8543\n",
      "Epoch 28/30\n",
      "4140/4140 - 13s - loss: 0.2394 - acc: 0.9022 - val_loss: 0.7568 - val_acc: 0.8674\n",
      "Epoch 29/30\n",
      "4140/4140 - 14s - loss: 0.2346 - acc: 0.9053 - val_loss: 0.4727 - val_acc: 0.8174\n",
      "Epoch 30/30\n",
      "4140/4140 - 14s - loss: 0.2246 - acc: 0.9070 - val_loss: 0.4197 - val_acc: 0.8239\n",
      "100/100 [==============================] - 1s 8ms/sample - loss: 0.3543 - acc: 0.8600\n",
      "logs/fit/double_lstm/kfold9\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 24s - loss: 0.6891 - acc: 0.5800 - val_loss: 0.6841 - val_acc: 0.5696\n",
      "Epoch 2/30\n",
      "4140/4140 - 13s - loss: 0.6632 - acc: 0.5800 - val_loss: 0.6691 - val_acc: 0.5696\n",
      "Epoch 3/30\n",
      "4140/4140 - 13s - loss: 0.6124 - acc: 0.5800 - val_loss: 0.6080 - val_acc: 0.5696\n",
      "Epoch 4/30\n",
      "4140/4140 - 13s - loss: 0.5646 - acc: 0.5800 - val_loss: 0.5568 - val_acc: 0.5696\n",
      "Epoch 5/30\n",
      "4140/4140 - 13s - loss: 0.5365 - acc: 0.5797 - val_loss: 0.5883 - val_acc: 0.6478\n",
      "Epoch 6/30\n",
      "4140/4140 - 14s - loss: 0.5577 - acc: 0.5981 - val_loss: 0.5384 - val_acc: 0.6326\n",
      "Epoch 7/30\n",
      "4140/4140 - 14s - loss: 0.5128 - acc: 0.6804 - val_loss: 0.5147 - val_acc: 0.7565\n",
      "Epoch 8/30\n",
      "4140/4140 - 6s - loss: 0.4977 - acc: 0.7829 - val_loss: 0.4914 - val_acc: 0.8000\n",
      "Epoch 9/30\n",
      "4140/4140 - 2s - loss: 0.4794 - acc: 0.8080 - val_loss: 0.4803 - val_acc: 0.8130\n",
      "Epoch 10/30\n",
      "4140/4140 - 2s - loss: 0.4704 - acc: 0.8169 - val_loss: 0.4697 - val_acc: 0.8065\n",
      "Epoch 11/30\n",
      "4140/4140 - 2s - loss: 0.5127 - acc: 0.7990 - val_loss: 0.4769 - val_acc: 0.7761\n",
      "Epoch 12/30\n",
      "4140/4140 - 2s - loss: 0.4533 - acc: 0.8256 - val_loss: 0.4598 - val_acc: 0.8152\n",
      "Epoch 13/30\n",
      "4140/4140 - 2s - loss: 0.4403 - acc: 0.8333 - val_loss: 0.4463 - val_acc: 0.8152\n",
      "Epoch 14/30\n",
      "4140/4140 - 2s - loss: 0.4293 - acc: 0.8329 - val_loss: 0.4286 - val_acc: 0.8348\n",
      "Epoch 15/30\n",
      "4140/4140 - 2s - loss: 0.4141 - acc: 0.8350 - val_loss: 0.4105 - val_acc: 0.8261\n",
      "Epoch 16/30\n",
      "4140/4140 - 2s - loss: 0.4059 - acc: 0.8360 - val_loss: 0.4075 - val_acc: 0.8239\n",
      "Epoch 17/30\n",
      "4140/4140 - 2s - loss: 0.3923 - acc: 0.8382 - val_loss: 0.3920 - val_acc: 0.8261\n",
      "Epoch 18/30\n",
      "4140/4140 - 2s - loss: 0.3746 - acc: 0.8486 - val_loss: 0.3845 - val_acc: 0.8239\n",
      "Epoch 19/30\n",
      "4140/4140 - 3s - loss: 0.3697 - acc: 0.8449 - val_loss: 0.3770 - val_acc: 0.8348\n",
      "Epoch 20/30\n",
      "4140/4140 - 7s - loss: 0.3620 - acc: 0.8522 - val_loss: 0.3674 - val_acc: 0.8435\n",
      "Epoch 21/30\n",
      "4140/4140 - 9s - loss: 0.3536 - acc: 0.8524 - val_loss: 0.3599 - val_acc: 0.8500\n",
      "Epoch 22/30\n",
      "4140/4140 - 14s - loss: 0.3448 - acc: 0.8618 - val_loss: 0.3574 - val_acc: 0.8478\n",
      "Epoch 23/30\n",
      "4140/4140 - 13s - loss: 0.3407 - acc: 0.8645 - val_loss: 0.3550 - val_acc: 0.8478\n",
      "Epoch 24/30\n",
      "4140/4140 - 13s - loss: 0.3341 - acc: 0.8669 - val_loss: 0.3549 - val_acc: 0.8500\n",
      "Epoch 25/30\n",
      "4140/4140 - 13s - loss: 0.3310 - acc: 0.8727 - val_loss: 0.3588 - val_acc: 0.8500\n",
      "Epoch 26/30\n",
      "4140/4140 - 14s - loss: 0.3280 - acc: 0.8720 - val_loss: 0.3551 - val_acc: 0.8652\n",
      "Epoch 27/30\n",
      "4140/4140 - 13s - loss: 0.3205 - acc: 0.8766 - val_loss: 0.3522 - val_acc: 0.8652\n",
      "Epoch 28/30\n",
      "4140/4140 - 13s - loss: 0.3099 - acc: 0.8792 - val_loss: 0.3609 - val_acc: 0.8543\n",
      "Epoch 29/30\n",
      "4140/4140 - 13s - loss: 0.3014 - acc: 0.8860 - val_loss: 0.3625 - val_acc: 0.8565\n",
      "Epoch 30/30\n",
      "4140/4140 - 13s - loss: 0.3010 - acc: 0.8867 - val_loss: 0.3572 - val_acc: 0.8522\n",
      "100/100 [==============================] - 1s 8ms/sample - loss: 0.3708 - acc: 0.8400\n",
      "logs/fit/double_lstm/kfold10\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 25s - loss: 0.6905 - acc: 0.5739 - val_loss: 0.6843 - val_acc: 0.5870\n",
      "Epoch 2/30\n",
      "4140/4140 - 14s - loss: 0.6986 - acc: 0.5915 - val_loss: 0.6726 - val_acc: 0.6087\n",
      "Epoch 3/30\n",
      "4140/4140 - 13s - loss: 0.6524 - acc: 0.5800 - val_loss: 0.6432 - val_acc: 0.5870\n",
      "Epoch 4/30\n",
      "4140/4140 - 13s - loss: 0.6173 - acc: 0.5780 - val_loss: 0.5911 - val_acc: 0.5870\n",
      "Epoch 5/30\n",
      "4140/4140 - 3s - loss: 0.5737 - acc: 0.5785 - val_loss: 0.5878 - val_acc: 0.6130\n",
      "Epoch 6/30\n",
      "4140/4140 - 2s - loss: 0.5399 - acc: 0.6232 - val_loss: 0.5160 - val_acc: 0.7870\n",
      "Epoch 7/30\n",
      "4140/4140 - 2s - loss: 0.5116 - acc: 0.7428 - val_loss: 0.4782 - val_acc: 0.8348\n",
      "Epoch 8/30\n",
      "4140/4140 - 2s - loss: 0.4812 - acc: 0.7913 - val_loss: 0.4309 - val_acc: 0.8609\n",
      "Epoch 9/30\n",
      "4140/4140 - 2s - loss: 0.4530 - acc: 0.8101 - val_loss: 0.4132 - val_acc: 0.8500\n",
      "Epoch 10/30\n",
      "4140/4140 - 2s - loss: 0.4201 - acc: 0.8082 - val_loss: 0.3738 - val_acc: 0.8391\n",
      "Epoch 11/30\n",
      "4140/4140 - 2s - loss: 0.4049 - acc: 0.8193 - val_loss: 0.3677 - val_acc: 0.8565\n",
      "Epoch 12/30\n",
      "4140/4140 - 2s - loss: 0.3883 - acc: 0.8237 - val_loss: 0.3619 - val_acc: 0.8457\n",
      "Epoch 13/30\n",
      "4140/4140 - 2s - loss: 0.3726 - acc: 0.8331 - val_loss: 0.3591 - val_acc: 0.8457\n",
      "Epoch 14/30\n",
      "4140/4140 - 2s - loss: 0.3614 - acc: 0.8384 - val_loss: 0.3460 - val_acc: 0.8565\n",
      "Epoch 15/30\n",
      "4140/4140 - 2s - loss: 0.3514 - acc: 0.8411 - val_loss: 0.3565 - val_acc: 0.8435\n",
      "Epoch 16/30\n",
      "4140/4140 - 3s - loss: 0.3601 - acc: 0.8372 - val_loss: 0.3637 - val_acc: 0.8391\n",
      "Epoch 17/30\n",
      "4140/4140 - 7s - loss: 0.3479 - acc: 0.8534 - val_loss: 0.3483 - val_acc: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "4140/4140 - 9s - loss: 0.3416 - acc: 0.8490 - val_loss: 0.3414 - val_acc: 0.8565\n",
      "Epoch 19/30\n",
      "4140/4140 - 14s - loss: 0.3433 - acc: 0.8505 - val_loss: 0.3405 - val_acc: 0.8543\n",
      "Epoch 20/30\n",
      "4140/4140 - 14s - loss: 0.3256 - acc: 0.8606 - val_loss: 0.3410 - val_acc: 0.8543\n",
      "Epoch 21/30\n",
      "4140/4140 - 13s - loss: 0.3219 - acc: 0.8630 - val_loss: 0.3371 - val_acc: 0.8543\n",
      "Epoch 22/30\n",
      "4140/4140 - 14s - loss: 0.3201 - acc: 0.8708 - val_loss: 0.3397 - val_acc: 0.8543\n",
      "Epoch 23/30\n",
      "4140/4140 - 13s - loss: 0.3154 - acc: 0.8681 - val_loss: 0.3373 - val_acc: 0.8565\n",
      "Epoch 24/30\n",
      "4140/4140 - 14s - loss: 0.3064 - acc: 0.8749 - val_loss: 0.3401 - val_acc: 0.8522\n",
      "Epoch 25/30\n",
      "4140/4140 - 14s - loss: 0.3008 - acc: 0.8785 - val_loss: 0.3473 - val_acc: 0.8543\n",
      "Epoch 26/30\n",
      "4140/4140 - 14s - loss: 0.2914 - acc: 0.8829 - val_loss: 0.3422 - val_acc: 0.8522\n",
      "Epoch 27/30\n",
      "4140/4140 - 13s - loss: 0.2931 - acc: 0.8838 - val_loss: 0.3450 - val_acc: 0.8522\n",
      "Epoch 28/30\n",
      "4140/4140 - 13s - loss: 0.2876 - acc: 0.8841 - val_loss: 0.3497 - val_acc: 0.8587\n",
      "Epoch 29/30\n",
      "4140/4140 - 13s - loss: 0.2801 - acc: 0.8920 - val_loss: 0.3565 - val_acc: 0.8522\n",
      "Epoch 30/30\n",
      "4140/4140 - 14s - loss: 0.2775 - acc: 0.8908 - val_loss: 0.3427 - val_acc: 0.8609\n",
      "100/100 [==============================] - 1s 8ms/sample - loss: 0.3418 - acc: 0.8600\n"
     ]
    }
   ],
   "source": [
    "def double_lstm_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(10, kernel_initializer='glorot_normal', activation='relu', return_sequences=True, input_shape=(28, 300), name='lstm'),\n",
    "        tf.keras.layers.Dropout(0.7),\n",
    "        tf.keras.layers.LSTM(10, activation='relu', name='2lstm'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='glorot_normal', name='dense')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "double_hist, double_evas = kfold_train(double_lstm_model, 'double_lstm', batch_size=128, epochs=30, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "1107abc5-de77-4b30-b4ed-cf6abf519663",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6875464363950462,
          0.646910596181805,
          0.5604764308906408,
          0.5142764807323327,
          0.5129378755311459,
          0.4303116354965357,
          0.4115524226340695,
          0.38953438113277083,
          0.3844158085072098,
          0.387178937882041,
          0.36945680918324975,
          0.36197600796602775,
          0.3579606253743748,
          0.3482324198536251,
          0.33572146693865457,
          0.3271594583124354,
          0.3185608146559213,
          0.3061599757936266,
          0.3039729956267537,
          0.2952045002421319,
          0.2837965686540097,
          0.2713050658432182,
          0.26850437658708454,
          0.26190003564104364,
          0.26211415949651007,
          0.2616921267359729,
          0.2684933081773168,
          0.24800106222214907,
          0.23229477654620645,
          0.22690271106031207
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "cbba7c7a-b621-46a7-8dc2-69bbd4ad3ecb",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6650812853937563,
          0.5974668704945109,
          0.4615111783794735,
          0.5105485853941544,
          0.4425061368423959,
          0.4136924432671588,
          0.4091802244601042,
          0.4063732302707175,
          0.41160900307738263,
          0.4110576621864153,
          0.4203991786293361,
          0.4223823448886042,
          0.4233989461608555,
          0.41945742679678877,
          0.43178690931071406,
          0.4409150346465733,
          0.4413710117340088,
          0.4525304410768592,
          0.45324900176214133,
          0.4550924327062524,
          0.45819505764090496,
          0.4774426035259081,
          0.4750073904576509,
          0.47683370217033055,
          0.4884163887604423,
          0.47365056069000905,
          0.4589815331541974,
          0.4840126079061757,
          0.5005890955095705,
          0.49806944805642833
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "22fe8b60-92c2-452e-80d0-ee7aca0ab8c2",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6977970786140737,
          0.6811422448227371,
          0.684286571931148,
          0.6759150713538202,
          0.652924765077766,
          0.6110579658821585,
          0.5899042912727392,
          0.5041025031591959,
          0.46726626123207204,
          0.45817085596674306,
          0.4412255211728782,
          0.4320071669016483,
          0.40941253883251244,
          0.4096935415037588,
          0.4002962178654141,
          0.39054562034814255,
          0.39091673173766206,
          0.3790330185694395,
          0.369395343174681,
          0.3742467038297423,
          0.3602210173284374,
          0.36066513692123303,
          0.34898137320642886,
          0.34760866712256905,
          0.33827641171533707,
          0.33289807559787365,
          0.32839405608637895,
          0.3260726620897579,
          0.31900610154953557,
          0.3121807050877723
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "ef34ac9b-8dbd-4fc6-9b3d-f9bb35a7aecc",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6812212845553522,
          0.6809112357056659,
          0.6806021280910658,
          0.676234881774239,
          0.5834055568860925,
          0.6186755125937254,
          0.5374324741570846,
          0.5173277805680814,
          0.4995277757230012,
          0.48890599789826766,
          0.4815557847852292,
          0.46900313729825227,
          0.4931174221246139,
          0.4657176733016968,
          0.45336541533470154,
          0.4718378087748652,
          0.44291443980258444,
          0.4592751541863317,
          0.46744948444159135,
          0.47446642414383267,
          0.4662012351595837,
          0.4442477265129919,
          0.4725492744342141,
          0.45553873155428015,
          0.4597111992214037,
          0.46505815620007723,
          0.47844466100568356,
          0.45992528614790545,
          0.45962085672046826,
          0.44889592476513074
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "3f71512d-0106-4cc2-b4b8-b2cc59d460af",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6897904406999045,
          0.6629510319175351,
          0.6302915012778867,
          0.5528195431842896,
          0.5188232979912689,
          0.4754012098058986,
          0.43601878294046376,
          0.41958385423761635,
          0.40090340082196224,
          0.40282583778031206,
          0.38013303455523245,
          0.3699922521621133,
          0.3686041020828745,
          0.3705263033869186,
          0.3558753155567796,
          0.3417852356813956,
          0.3340710635058546,
          0.3322071291974201,
          0.325281787638503,
          0.31483590772762393,
          0.3143275541095918,
          0.30389922874561254,
          0.2984049115204005,
          0.2955413530414231,
          0.29102225395792347,
          0.29114247239442265,
          0.2795130996600441,
          0.27411212902426146,
          0.26912548282872073,
          0.27268394725622186
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "a026a504-37b2-48bc-9358-e7569e669102",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6786276687746463,
          0.6481192754662555,
          0.5566251303838647,
          0.5391508745110554,
          0.5015335570210996,
          0.48579332076984905,
          0.4726657139218372,
          0.45103278807971786,
          0.477758747080098,
          0.43175663948059084,
          0.4228137887042502,
          0.39931230959684955,
          0.4151992515377376,
          0.38759617235349575,
          0.395668567781863,
          0.393753837502521,
          0.3798943102359772,
          0.3743661774241406,
          0.36040975244148915,
          0.37550319640532787,
          0.37506276602330413,
          0.3635756718075794,
          0.3813255468140478,
          0.37277298802914827,
          0.360810219982396,
          0.3684405705203181,
          0.3891945009646208,
          0.383291655001433,
          0.36623279763304667,
          0.3565325667028842
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "646e0878-68d1-4909-a7c7-7535f234c8fa",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6979102960531263,
          0.6840654237834728,
          0.6632131662921629,
          0.591167241882011,
          0.5135650600212208,
          0.4747449442960214,
          0.43042327401718655,
          0.42742523813017325,
          0.39523351785641364,
          0.37784665719322535,
          0.371109394059665,
          0.36138007468071537,
          0.355995920430059,
          0.34146949303322943,
          0.3395123353902844,
          0.33003849122259354,
          0.33262270133276495,
          0.3387405795463617,
          0.30966289701381167,
          0.3026599962354282,
          0.2926070279977172,
          0.28532001292647946,
          0.2804468929335691,
          0.2715212128876488,
          0.2628771608722383,
          0.2614406472962836,
          0.24920575074527573,
          0.24807841166637945,
          0.24348081296336824,
          0.23931830540515375
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "abcf5586-de78-43da-ba89-75f1f833c098",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6946785506994828,
          0.684927541276683,
          0.6328399621922037,
          0.5716074487437373,
          0.5103030272152113,
          0.47721028431602147,
          0.4132607216420381,
          0.43658870899158975,
          0.38652328123217045,
          0.3880965460901675,
          0.3812964413477027,
          0.3850219905376434,
          0.37109805993411854,
          0.37051237303277723,
          0.3846729708754498,
          0.3754416859668234,
          0.41538271411605504,
          0.36575242669686026,
          0.361922143853229,
          0.3555831598198932,
          0.3732438507287399,
          0.37093838608783225,
          0.36597526177116063,
          0.41241827853347945,
          0.3658290287722712,
          0.37790976399960724,
          0.39968771105227263,
          0.37304216260495393,
          0.40609441995620726,
          0.4472566342872122
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "7d8a18bc-a2c2-40d7-849c-641578acacf6",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6894910059689323,
          0.654106913154252,
          0.5702409707981607,
          0.48719733337273347,
          0.4435800360308753,
          0.4052572126549799,
          0.37760840009376045,
          0.36127470498499664,
          0.3482152314865647,
          0.3383500951499755,
          0.32873581267785335,
          0.32141417443464343,
          0.31215362782063694,
          0.3037161063456881,
          0.29389815586776546,
          0.2897729174526417,
          0.27840907504593115,
          0.27392484927235017,
          0.2652597526565266,
          0.25788330802882925,
          0.2789822509035396,
          0.2526123336547815,
          0.24485697612382362,
          0.23805531883873227,
          0.2253214061980086,
          0.2196626230714402,
          0.21146289580974026,
          0.20753956260024636,
          0.20121037876548398,
          0.19097882070115224
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "1f5a4a65-4064-4e68-ba40-622fbd2a5f09",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.66833205430404,
          0.6081701957661173,
          0.5334273771099423,
          0.49151356583056244,
          0.4728802561759949,
          0.4992105815721595,
          0.5425343959227852,
          0.49262822037157805,
          0.49697758399921915,
          0.513173234462738,
          0.5310482755951259,
          0.5298417785893316,
          0.5391333294951397,
          0.5207888481409654,
          0.5157748999802962,
          0.5239587731983351,
          0.4937710575435473,
          0.5567780129287554,
          0.4952586583469225,
          0.5319391224695289,
          0.5545092064401378,
          0.5569136692130048,
          0.5579195660093557,
          0.5733779694723047,
          0.5868190127870311,
          0.6411605674287547,
          0.6443622879360034,
          0.5911456610845482,
          0.6673845418121503,
          0.6266096908113231
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "70c2e65c-1786-43ac-92b1-60666301d1f6",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6894118507127255,
          0.6555907380753669,
          0.5517967128523306,
          0.49593871054442035,
          0.4652879909616738,
          0.43394280148013203,
          0.40859505810599395,
          0.3918008895887845,
          0.37742037781770676,
          0.3633403025387566,
          0.3529403809476014,
          0.3432042071784752,
          0.33842702985961653,
          0.3209111973139399,
          0.307190040041859,
          0.30108857710580317,
          0.28703401262921413,
          0.27490955966970193,
          0.2682555316295025,
          0.27454116152968383,
          0.260748333501931,
          0.24918433417732588,
          0.2435330958901972,
          0.24040889594577936,
          0.29699162246236477,
          0.26789396575107666,
          0.24708872647677066,
          0.23523805898744704,
          0.240036572739122,
          0.23584410016951354
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "1b14360f-2d66-4369-8351-a3cfbc0b6af0",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6846283477285634,
          0.6264360381209332,
          0.5298625435518182,
          0.4873159382654273,
          0.42544887998829717,
          0.4104325418886931,
          0.39197558605152627,
          0.38132767107175747,
          0.3790484775667605,
          0.37454991833023404,
          0.3741800917231518,
          0.3825274897658307,
          0.3921239917692931,
          0.3893170421538146,
          0.40030270218849184,
          0.40525348601133926,
          0.4004479978395545,
          0.4175245349821837,
          0.4641501405964727,
          0.44086549256158913,
          0.46317024023636527,
          0.47161579339400583,
          0.47652525461238365,
          0.5444722833840744,
          0.4712317985037099,
          0.45671645402908323,
          0.49075206440428026,
          0.536114513874054,
          0.5772930168587228,
          0.5668934428173563
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "b7076893-f3da-42b3-8dbc-5fdc2702eee2",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6933469442929623,
          0.6828543132054057,
          0.6796117200943583,
          0.6672387751404214,
          0.5775855484216109,
          0.4789034748998817,
          0.44935164339300515,
          0.4199102466809001,
          0.3988530661460858,
          0.3855463360818688,
          0.3680671282436537,
          0.3550336011365992,
          0.35185040932346656,
          0.34346562736276265,
          0.34148578030475674,
          0.342372521167792,
          0.33037648915092727,
          0.3285369669469658,
          0.3090548342840683,
          0.2987664149579219,
          0.2897733817209944,
          0.28017636980987404,
          0.27955105311916645,
          0.2668857094746281,
          0.27168982457999447,
          0.26552650332450867,
          0.2898002297262063,
          0.2844855640533466,
          0.26155465667086525,
          0.2670257480536106
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "184037ff-a4a9-48bb-9f6b-d1a195b38ca4",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.7228513261546259,
          0.6855543867401455,
          0.682728231989819,
          0.6357073120448901,
          0.4766367064869922,
          0.4790541879508806,
          0.44765178872191386,
          0.4852504087531048,
          0.4301454271959222,
          0.43502412049666694,
          0.43307650426159733,
          0.4146581587584122,
          0.4086673987948376,
          0.44821238388185913,
          0.5087693831195002,
          0.45751840990522635,
          0.47458838017090504,
          0.4775361734887828,
          0.5143433156220809,
          0.555550960354183,
          0.5469512270844501,
          0.5540468506191087,
          0.5594957045886828,
          0.5588726251021675,
          0.5702639336171358,
          0.5687908385110938,
          0.6594093260557755,
          0.6584409322427667,
          0.6472796561925308,
          0.7103503823280335
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "89f88b82-5401-4330-ba50-c7816d49335b",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6901633717011715,
          0.6800395004415282,
          0.6424070631824254,
          0.5297084627520059,
          0.4612249556370979,
          0.4352904127703773,
          0.40259783331322785,
          0.3853574910313611,
          0.3738322482304873,
          0.36087834420411485,
          0.4005450392978779,
          0.34998790878028685,
          0.33919184585124396,
          0.33532415124529225,
          0.3199139382240277,
          0.3171689740989519,
          0.3073456317042383,
          0.3025470261124597,
          0.2966775734643429,
          0.2881447833229378,
          0.28229423355365146,
          0.27449583792744053,
          0.2672317117884539,
          0.26480726385174164,
          0.25158699832964637,
          0.24507693187626087,
          0.2386440355564661,
          0.23936472925299032,
          0.2345913375777323,
          0.2246202985589631
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "acb9d15c-c1ea-4278-b613-ddf395e99920",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.683697539827098,
          0.6614786500516145,
          0.5937107246855031,
          0.4967937301034513,
          0.43621836797050806,
          0.4240631917248601,
          0.37278208603029667,
          0.36102833125902256,
          0.355863646838976,
          0.37697625471198043,
          0.40713987842850063,
          0.3790924979292828,
          0.38251635872799417,
          0.36764108175816745,
          0.3502806754215904,
          0.3570563873519068,
          0.34872465289157367,
          0.3511321065218552,
          0.34545830384544707,
          0.35440434036047563,
          0.3509193829868151,
          0.35783655202907066,
          0.3539511880149012,
          0.3516280757344287,
          0.37176625547201736,
          0.42085067837134654,
          0.4260380182577216,
          0.7567959601464479,
          0.4727007889229318,
          0.41972132558407993
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "79ae6bf4-7553-4794-8d80-7dbb880466d4",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6890593876009402,
          0.6632410319531021,
          0.6124143368955971,
          0.5645874975384145,
          0.5365115100058957,
          0.557650743993584,
          0.5128238336475575,
          0.49773585226224815,
          0.4794074681646006,
          0.47040024670425823,
          0.5127052713419504,
          0.4532568245118367,
          0.44034536100816035,
          0.42934728365589453,
          0.41413319364262086,
          0.40592675738864475,
          0.39227655996447025,
          0.374572515660438,
          0.3696507063464842,
          0.3619567782694591,
          0.3536234923894855,
          0.34480029095486164,
          0.34067414768652066,
          0.33409901077044757,
          0.3309565480204596,
          0.3279636345623772,
          0.32051445741008444,
          0.30989713858867035,
          0.30138780605677823,
          0.30102303681742165
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "be308b95-a809-469d-b81b-fc2820389167",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.684116456301316,
          0.6691160912099092,
          0.6079954556796862,
          0.5567588261936022,
          0.5883410505626513,
          0.5384251672288646,
          0.5146856079930845,
          0.4913983785587808,
          0.4802968209204466,
          0.4697250283282736,
          0.47694582602252134,
          0.4598294607971026,
          0.44629429708356444,
          0.42859959731931274,
          0.41052941887275035,
          0.4074521342049474,
          0.3919561875903088,
          0.38451096234114274,
          0.3769596610380256,
          0.3674130092496457,
          0.35987111874248673,
          0.35742662030717604,
          0.3550263702869415,
          0.3549472119497216,
          0.35882408541181815,
          0.3551407508228136,
          0.35215036972709324,
          0.36089120222174603,
          0.3624954034452853,
          0.35716401727303215
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "7b300fc0-46a3-4c1c-9f59-03c37a7d9195",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6905346458084918,
          0.6986227932183638,
          0.6524194761174889,
          0.6172932685285375,
          0.5736826571865358,
          0.5398553738271556,
          0.511560651300034,
          0.48121863689975464,
          0.4529897174685474,
          0.420139859955092,
          0.4049161520269182,
          0.38826482362217374,
          0.37256203175742847,
          0.36135513886161474,
          0.35136048335959946,
          0.3600684207994581,
          0.34794786946785045,
          0.34163660119121203,
          0.3433087480528919,
          0.32558227210229146,
          0.3218849287516829,
          0.32014770196831743,
          0.31544362673724907,
          0.3063916961496003,
          0.3007744346551849,
          0.29138417421043783,
          0.2930566536343616,
          0.2876210995774338,
          0.2801155302691575,
          0.2774863954327533
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "bec0ebbe-7f4d-441b-86c1-9e3ac9b01710",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6842962529348291,
          0.6725668705028036,
          0.6431703951047815,
          0.5910542026810024,
          0.5877529056175895,
          0.5159578364828359,
          0.47822792918785756,
          0.43087498519731604,
          0.4131982515687528,
          0.37375328126160995,
          0.36774608648341633,
          0.3619207900503407,
          0.359058083658633,
          0.3460429194180862,
          0.35650157202845034,
          0.36365448599276334,
          0.34832933156386664,
          0.34138904162075207,
          0.3404969925465791,
          0.341045118673988,
          0.33707172585570294,
          0.3397440272828807,
          0.33729692619779833,
          0.3401186880858048,
          0.3473155578841334,
          0.3421969685865485,
          0.3450406797554182,
          0.34972457134205365,
          0.3565341532230377,
          0.34265185309493024
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"43cbd589-49a6-4f34-994e-24156f81e160\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"43cbd589-49a6-4f34-994e-24156f81e160\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '43cbd589-49a6-4f34-994e-24156f81e160',\n",
       "                        [{\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"1107abc5-de77-4b30-b4ed-cf6abf519663\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6875464363950462, 0.646910596181805, 0.5604764308906408, 0.5142764807323327, 0.5129378755311459, 0.4303116354965357, 0.4115524226340695, 0.38953438113277083, 0.3844158085072098, 0.387178937882041, 0.36945680918324975, 0.36197600796602775, 0.3579606253743748, 0.3482324198536251, 0.33572146693865457, 0.3271594583124354, 0.3185608146559213, 0.3061599757936266, 0.3039729956267537, 0.2952045002421319, 0.2837965686540097, 0.2713050658432182, 0.26850437658708454, 0.26190003564104364, 0.26211415949651007, 0.2616921267359729, 0.2684933081773168, 0.24800106222214907, 0.23229477654620645, 0.22690271106031207]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"cbba7c7a-b621-46a7-8dc2-69bbd4ad3ecb\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6650812853937563, 0.5974668704945109, 0.4615111783794735, 0.5105485853941544, 0.4425061368423959, 0.4136924432671588, 0.4091802244601042, 0.4063732302707175, 0.41160900307738263, 0.4110576621864153, 0.4203991786293361, 0.4223823448886042, 0.4233989461608555, 0.41945742679678877, 0.43178690931071406, 0.4409150346465733, 0.4413710117340088, 0.4525304410768592, 0.45324900176214133, 0.4550924327062524, 0.45819505764090496, 0.4774426035259081, 0.4750073904576509, 0.47683370217033055, 0.4884163887604423, 0.47365056069000905, 0.4589815331541974, 0.4840126079061757, 0.5005890955095705, 0.49806944805642833]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"22fe8b60-92c2-452e-80d0-ee7aca0ab8c2\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6977970786140737, 0.6811422448227371, 0.684286571931148, 0.6759150713538202, 0.652924765077766, 0.6110579658821585, 0.5899042912727392, 0.5041025031591959, 0.46726626123207204, 0.45817085596674306, 0.4412255211728782, 0.4320071669016483, 0.40941253883251244, 0.4096935415037588, 0.4002962178654141, 0.39054562034814255, 0.39091673173766206, 0.3790330185694395, 0.369395343174681, 0.3742467038297423, 0.3602210173284374, 0.36066513692123303, 0.34898137320642886, 0.34760866712256905, 0.33827641171533707, 0.33289807559787365, 0.32839405608637895, 0.3260726620897579, 0.31900610154953557, 0.3121807050877723]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"ef34ac9b-8dbd-4fc6-9b3d-f9bb35a7aecc\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6812212845553522, 0.6809112357056659, 0.6806021280910658, 0.676234881774239, 0.5834055568860925, 0.6186755125937254, 0.5374324741570846, 0.5173277805680814, 0.4995277757230012, 0.48890599789826766, 0.4815557847852292, 0.46900313729825227, 0.4931174221246139, 0.4657176733016968, 0.45336541533470154, 0.4718378087748652, 0.44291443980258444, 0.4592751541863317, 0.46744948444159135, 0.47446642414383267, 0.4662012351595837, 0.4442477265129919, 0.4725492744342141, 0.45553873155428015, 0.4597111992214037, 0.46505815620007723, 0.47844466100568356, 0.45992528614790545, 0.45962085672046826, 0.44889592476513074]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"3f71512d-0106-4cc2-b4b8-b2cc59d460af\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6897904406999045, 0.6629510319175351, 0.6302915012778867, 0.5528195431842896, 0.5188232979912689, 0.4754012098058986, 0.43601878294046376, 0.41958385423761635, 0.40090340082196224, 0.40282583778031206, 0.38013303455523245, 0.3699922521621133, 0.3686041020828745, 0.3705263033869186, 0.3558753155567796, 0.3417852356813956, 0.3340710635058546, 0.3322071291974201, 0.325281787638503, 0.31483590772762393, 0.3143275541095918, 0.30389922874561254, 0.2984049115204005, 0.2955413530414231, 0.29102225395792347, 0.29114247239442265, 0.2795130996600441, 0.27411212902426146, 0.26912548282872073, 0.27268394725622186]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"a026a504-37b2-48bc-9358-e7569e669102\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6786276687746463, 0.6481192754662555, 0.5566251303838647, 0.5391508745110554, 0.5015335570210996, 0.48579332076984905, 0.4726657139218372, 0.45103278807971786, 0.477758747080098, 0.43175663948059084, 0.4228137887042502, 0.39931230959684955, 0.4151992515377376, 0.38759617235349575, 0.395668567781863, 0.393753837502521, 0.3798943102359772, 0.3743661774241406, 0.36040975244148915, 0.37550319640532787, 0.37506276602330413, 0.3635756718075794, 0.3813255468140478, 0.37277298802914827, 0.360810219982396, 0.3684405705203181, 0.3891945009646208, 0.383291655001433, 0.36623279763304667, 0.3565325667028842]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"646e0878-68d1-4909-a7c7-7535f234c8fa\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6979102960531263, 0.6840654237834728, 0.6632131662921629, 0.591167241882011, 0.5135650600212208, 0.4747449442960214, 0.43042327401718655, 0.42742523813017325, 0.39523351785641364, 0.37784665719322535, 0.371109394059665, 0.36138007468071537, 0.355995920430059, 0.34146949303322943, 0.3395123353902844, 0.33003849122259354, 0.33262270133276495, 0.3387405795463617, 0.30966289701381167, 0.3026599962354282, 0.2926070279977172, 0.28532001292647946, 0.2804468929335691, 0.2715212128876488, 0.2628771608722383, 0.2614406472962836, 0.24920575074527573, 0.24807841166637945, 0.24348081296336824, 0.23931830540515375]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"abcf5586-de78-43da-ba89-75f1f833c098\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6946785506994828, 0.684927541276683, 0.6328399621922037, 0.5716074487437373, 0.5103030272152113, 0.47721028431602147, 0.4132607216420381, 0.43658870899158975, 0.38652328123217045, 0.3880965460901675, 0.3812964413477027, 0.3850219905376434, 0.37109805993411854, 0.37051237303277723, 0.3846729708754498, 0.3754416859668234, 0.41538271411605504, 0.36575242669686026, 0.361922143853229, 0.3555831598198932, 0.3732438507287399, 0.37093838608783225, 0.36597526177116063, 0.41241827853347945, 0.3658290287722712, 0.37790976399960724, 0.39968771105227263, 0.37304216260495393, 0.40609441995620726, 0.4472566342872122]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"7d8a18bc-a2c2-40d7-849c-641578acacf6\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6894910059689323, 0.654106913154252, 0.5702409707981607, 0.48719733337273347, 0.4435800360308753, 0.4052572126549799, 0.37760840009376045, 0.36127470498499664, 0.3482152314865647, 0.3383500951499755, 0.32873581267785335, 0.32141417443464343, 0.31215362782063694, 0.3037161063456881, 0.29389815586776546, 0.2897729174526417, 0.27840907504593115, 0.27392484927235017, 0.2652597526565266, 0.25788330802882925, 0.2789822509035396, 0.2526123336547815, 0.24485697612382362, 0.23805531883873227, 0.2253214061980086, 0.2196626230714402, 0.21146289580974026, 0.20753956260024636, 0.20121037876548398, 0.19097882070115224]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"1f5a4a65-4064-4e68-ba40-622fbd2a5f09\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.66833205430404, 0.6081701957661173, 0.5334273771099423, 0.49151356583056244, 0.4728802561759949, 0.4992105815721595, 0.5425343959227852, 0.49262822037157805, 0.49697758399921915, 0.513173234462738, 0.5310482755951259, 0.5298417785893316, 0.5391333294951397, 0.5207888481409654, 0.5157748999802962, 0.5239587731983351, 0.4937710575435473, 0.5567780129287554, 0.4952586583469225, 0.5319391224695289, 0.5545092064401378, 0.5569136692130048, 0.5579195660093557, 0.5733779694723047, 0.5868190127870311, 0.6411605674287547, 0.6443622879360034, 0.5911456610845482, 0.6673845418121503, 0.6266096908113231]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"70c2e65c-1786-43ac-92b1-60666301d1f6\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6894118507127255, 0.6555907380753669, 0.5517967128523306, 0.49593871054442035, 0.4652879909616738, 0.43394280148013203, 0.40859505810599395, 0.3918008895887845, 0.37742037781770676, 0.3633403025387566, 0.3529403809476014, 0.3432042071784752, 0.33842702985961653, 0.3209111973139399, 0.307190040041859, 0.30108857710580317, 0.28703401262921413, 0.27490955966970193, 0.2682555316295025, 0.27454116152968383, 0.260748333501931, 0.24918433417732588, 0.2435330958901972, 0.24040889594577936, 0.29699162246236477, 0.26789396575107666, 0.24708872647677066, 0.23523805898744704, 0.240036572739122, 0.23584410016951354]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"1b14360f-2d66-4369-8351-a3cfbc0b6af0\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6846283477285634, 0.6264360381209332, 0.5298625435518182, 0.4873159382654273, 0.42544887998829717, 0.4104325418886931, 0.39197558605152627, 0.38132767107175747, 0.3790484775667605, 0.37454991833023404, 0.3741800917231518, 0.3825274897658307, 0.3921239917692931, 0.3893170421538146, 0.40030270218849184, 0.40525348601133926, 0.4004479978395545, 0.4175245349821837, 0.4641501405964727, 0.44086549256158913, 0.46317024023636527, 0.47161579339400583, 0.47652525461238365, 0.5444722833840744, 0.4712317985037099, 0.45671645402908323, 0.49075206440428026, 0.536114513874054, 0.5772930168587228, 0.5668934428173563]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"b7076893-f3da-42b3-8dbc-5fdc2702eee2\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6933469442929623, 0.6828543132054057, 0.6796117200943583, 0.6672387751404214, 0.5775855484216109, 0.4789034748998817, 0.44935164339300515, 0.4199102466809001, 0.3988530661460858, 0.3855463360818688, 0.3680671282436537, 0.3550336011365992, 0.35185040932346656, 0.34346562736276265, 0.34148578030475674, 0.342372521167792, 0.33037648915092727, 0.3285369669469658, 0.3090548342840683, 0.2987664149579219, 0.2897733817209944, 0.28017636980987404, 0.27955105311916645, 0.2668857094746281, 0.27168982457999447, 0.26552650332450867, 0.2898002297262063, 0.2844855640533466, 0.26155465667086525, 0.2670257480536106]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"184037ff-a4a9-48bb-9f6b-d1a195b38ca4\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.7228513261546259, 0.6855543867401455, 0.682728231989819, 0.6357073120448901, 0.4766367064869922, 0.4790541879508806, 0.44765178872191386, 0.4852504087531048, 0.4301454271959222, 0.43502412049666694, 0.43307650426159733, 0.4146581587584122, 0.4086673987948376, 0.44821238388185913, 0.5087693831195002, 0.45751840990522635, 0.47458838017090504, 0.4775361734887828, 0.5143433156220809, 0.555550960354183, 0.5469512270844501, 0.5540468506191087, 0.5594957045886828, 0.5588726251021675, 0.5702639336171358, 0.5687908385110938, 0.6594093260557755, 0.6584409322427667, 0.6472796561925308, 0.7103503823280335]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"89f88b82-5401-4330-ba50-c7816d49335b\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6901633717011715, 0.6800395004415282, 0.6424070631824254, 0.5297084627520059, 0.4612249556370979, 0.4352904127703773, 0.40259783331322785, 0.3853574910313611, 0.3738322482304873, 0.36087834420411485, 0.4005450392978779, 0.34998790878028685, 0.33919184585124396, 0.33532415124529225, 0.3199139382240277, 0.3171689740989519, 0.3073456317042383, 0.3025470261124597, 0.2966775734643429, 0.2881447833229378, 0.28229423355365146, 0.27449583792744053, 0.2672317117884539, 0.26480726385174164, 0.25158699832964637, 0.24507693187626087, 0.2386440355564661, 0.23936472925299032, 0.2345913375777323, 0.2246202985589631]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"acb9d15c-c1ea-4278-b613-ddf395e99920\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.683697539827098, 0.6614786500516145, 0.5937107246855031, 0.4967937301034513, 0.43621836797050806, 0.4240631917248601, 0.37278208603029667, 0.36102833125902256, 0.355863646838976, 0.37697625471198043, 0.40713987842850063, 0.3790924979292828, 0.38251635872799417, 0.36764108175816745, 0.3502806754215904, 0.3570563873519068, 0.34872465289157367, 0.3511321065218552, 0.34545830384544707, 0.35440434036047563, 0.3509193829868151, 0.35783655202907066, 0.3539511880149012, 0.3516280757344287, 0.37176625547201736, 0.42085067837134654, 0.4260380182577216, 0.7567959601464479, 0.4727007889229318, 0.41972132558407993]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"79ae6bf4-7553-4794-8d80-7dbb880466d4\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6890593876009402, 0.6632410319531021, 0.6124143368955971, 0.5645874975384145, 0.5365115100058957, 0.557650743993584, 0.5128238336475575, 0.49773585226224815, 0.4794074681646006, 0.47040024670425823, 0.5127052713419504, 0.4532568245118367, 0.44034536100816035, 0.42934728365589453, 0.41413319364262086, 0.40592675738864475, 0.39227655996447025, 0.374572515660438, 0.3696507063464842, 0.3619567782694591, 0.3536234923894855, 0.34480029095486164, 0.34067414768652066, 0.33409901077044757, 0.3309565480204596, 0.3279636345623772, 0.32051445741008444, 0.30989713858867035, 0.30138780605677823, 0.30102303681742165]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"be308b95-a809-469d-b81b-fc2820389167\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.684116456301316, 0.6691160912099092, 0.6079954556796862, 0.5567588261936022, 0.5883410505626513, 0.5384251672288646, 0.5146856079930845, 0.4913983785587808, 0.4802968209204466, 0.4697250283282736, 0.47694582602252134, 0.4598294607971026, 0.44629429708356444, 0.42859959731931274, 0.41052941887275035, 0.4074521342049474, 0.3919561875903088, 0.38451096234114274, 0.3769596610380256, 0.3674130092496457, 0.35987111874248673, 0.35742662030717604, 0.3550263702869415, 0.3549472119497216, 0.35882408541181815, 0.3551407508228136, 0.35215036972709324, 0.36089120222174603, 0.3624954034452853, 0.35716401727303215]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"7b300fc0-46a3-4c1c-9f59-03c37a7d9195\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6905346458084918, 0.6986227932183638, 0.6524194761174889, 0.6172932685285375, 0.5736826571865358, 0.5398553738271556, 0.511560651300034, 0.48121863689975464, 0.4529897174685474, 0.420139859955092, 0.4049161520269182, 0.38826482362217374, 0.37256203175742847, 0.36135513886161474, 0.35136048335959946, 0.3600684207994581, 0.34794786946785045, 0.34163660119121203, 0.3433087480528919, 0.32558227210229146, 0.3218849287516829, 0.32014770196831743, 0.31544362673724907, 0.3063916961496003, 0.3007744346551849, 0.29138417421043783, 0.2930566536343616, 0.2876210995774338, 0.2801155302691575, 0.2774863954327533]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"bec0ebbe-7f4d-441b-86c1-9e3ac9b01710\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6842962529348291, 0.6725668705028036, 0.6431703951047815, 0.5910542026810024, 0.5877529056175895, 0.5159578364828359, 0.47822792918785756, 0.43087498519731604, 0.4131982515687528, 0.37375328126160995, 0.36774608648341633, 0.3619207900503407, 0.359058083658633, 0.3460429194180862, 0.35650157202845034, 0.36365448599276334, 0.34832933156386664, 0.34138904162075207, 0.3404969925465791, 0.341045118673988, 0.33707172585570294, 0.3397440272828807, 0.33729692619779833, 0.3401186880858048, 0.3473155578841334, 0.3421969685865485, 0.3450406797554182, 0.34972457134205365, 0.3565341532230377, 0.34265185309493024]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('43cbd589-49a6-4f34-994e-24156f81e160');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean  acc         0.817933\n",
      "loss        0.382986\n",
      "val_acc     0.795370\n",
      "val_loss    0.465998\n",
      "dtype: float64\n",
      "std  acc         0.096047\n",
      "loss        0.128176\n",
      "val_acc     0.078048\n",
      "val_loss    0.099289\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "1",
         "text": "",
         "type": "scatter",
         "uid": "dd15be84-b54c-4190-80bc-d28285d20df0",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.8700000047683716,
          0.8799999952316284,
          0.8600000143051147,
          0.8700000047683716,
          0.8399999737739563,
          0.8500000238418579,
          0.8500000238418579,
          0.8600000143051147,
          0.8399999737739563,
          0.8600000143051147
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"f2471295-8868-47b7-a1e4-d7bfaed44e23\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"f2471295-8868-47b7-a1e4-d7bfaed44e23\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'f2471295-8868-47b7-a1e4-d7bfaed44e23',\n",
       "                        [{\"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"1\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"dd15be84-b54c-4190-80bc-d28285d20df0\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.8700000047683716, 0.8799999952316284, 0.8600000143051147, 0.8700000047683716, 0.8399999737739563, 0.8500000238418579, 0.8500000238418579, 0.8600000143051147, 0.8399999737739563, 0.8600000143051147]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f2471295-8868-47b7-a1e4-d7bfaed44e23');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media  0.8580000042915344\n",
      "std  0.013165617325584458\n"
     ]
    }
   ],
   "source": [
    "process_results(double_hist, double_evas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit/triple_lstm/kfold1\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 11s - loss: 0.6891 - acc: 0.5771 - val_loss: 0.6720 - val_acc: 0.5957\n",
      "Epoch 2/30\n",
      "4140/4140 - 4s - loss: 0.6544 - acc: 0.5771 - val_loss: 0.5975 - val_acc: 0.5957\n",
      "Epoch 3/30\n",
      "4140/4140 - 4s - loss: 0.5850 - acc: 0.5771 - val_loss: 0.5421 - val_acc: 0.5957\n",
      "Epoch 4/30\n",
      "4140/4140 - 4s - loss: 0.5308 - acc: 0.6234 - val_loss: 0.5039 - val_acc: 0.7543\n",
      "Epoch 5/30\n",
      "4140/4140 - 5s - loss: 0.4928 - acc: 0.7601 - val_loss: 0.4826 - val_acc: 0.8239\n",
      "Epoch 6/30\n",
      "4140/4140 - 12s - loss: 0.4694 - acc: 0.8022 - val_loss: 0.5408 - val_acc: 0.7913\n",
      "Epoch 7/30\n",
      "4140/4140 - 25s - loss: 0.4790 - acc: 0.7838 - val_loss: 0.4740 - val_acc: 0.8196\n",
      "Epoch 8/30\n",
      "4140/4140 - 26s - loss: 0.4321 - acc: 0.8034 - val_loss: 0.4493 - val_acc: 0.8304\n",
      "Epoch 9/30\n",
      "4140/4140 - 28s - loss: 0.4016 - acc: 0.8244 - val_loss: 0.4612 - val_acc: 0.8130\n",
      "Epoch 10/30\n",
      "4140/4140 - 28s - loss: 0.3995 - acc: 0.8285 - val_loss: 0.4296 - val_acc: 0.8000\n",
      "Epoch 11/30\n",
      "4140/4140 - 28s - loss: 0.3910 - acc: 0.8319 - val_loss: 0.4340 - val_acc: 0.8174\n",
      "Epoch 12/30\n",
      "4140/4140 - 23s - loss: 0.3759 - acc: 0.8319 - val_loss: 0.4160 - val_acc: 0.8217\n",
      "Epoch 13/30\n",
      "4140/4140 - 14s - loss: 0.3675 - acc: 0.8353 - val_loss: 0.4164 - val_acc: 0.8217\n",
      "Epoch 14/30\n",
      "4140/4140 - 3s - loss: 0.3627 - acc: 0.8406 - val_loss: 0.4194 - val_acc: 0.8196\n",
      "Epoch 15/30\n",
      "4140/4140 - 3s - loss: 0.3634 - acc: 0.8403 - val_loss: 0.4248 - val_acc: 0.8196\n",
      "Epoch 16/30\n",
      "4140/4140 - 3s - loss: 0.3481 - acc: 0.8488 - val_loss: 0.4121 - val_acc: 0.8087\n",
      "Epoch 17/30\n",
      "4140/4140 - 3s - loss: 0.3359 - acc: 0.8514 - val_loss: 0.4224 - val_acc: 0.8130\n",
      "Epoch 18/30\n",
      "4140/4140 - 3s - loss: 0.3397 - acc: 0.8507 - val_loss: 0.4280 - val_acc: 0.8174\n",
      "Epoch 19/30\n",
      "4140/4140 - 3s - loss: 0.3292 - acc: 0.8577 - val_loss: 0.4338 - val_acc: 0.8174\n",
      "Epoch 20/30\n",
      "4140/4140 - 4s - loss: 0.3214 - acc: 0.8616 - val_loss: 0.4313 - val_acc: 0.8196\n",
      "Epoch 21/30\n",
      "4140/4140 - 8s - loss: 0.3088 - acc: 0.8679 - val_loss: 0.4416 - val_acc: 0.8152\n",
      "Epoch 22/30\n",
      "4140/4140 - 17s - loss: 0.3098 - acc: 0.8635 - val_loss: 0.4358 - val_acc: 0.8043\n",
      "Epoch 23/30\n",
      "4140/4140 - 22s - loss: 0.2985 - acc: 0.8732 - val_loss: 0.4410 - val_acc: 0.8065\n",
      "Epoch 24/30\n",
      "4140/4140 - 22s - loss: 0.2926 - acc: 0.8795 - val_loss: 0.4473 - val_acc: 0.8109\n",
      "Epoch 25/30\n",
      "4140/4140 - 22s - loss: 0.2887 - acc: 0.8824 - val_loss: 0.4519 - val_acc: 0.8043\n",
      "Epoch 26/30\n",
      "4140/4140 - 22s - loss: 0.2870 - acc: 0.8850 - val_loss: 0.4482 - val_acc: 0.8087\n",
      "Epoch 27/30\n",
      "4140/4140 - 22s - loss: 0.2835 - acc: 0.8845 - val_loss: 0.4462 - val_acc: 0.7609\n",
      "Epoch 28/30\n",
      "4140/4140 - 22s - loss: 0.2974 - acc: 0.8758 - val_loss: 0.4779 - val_acc: 0.8109\n",
      "Epoch 29/30\n",
      "4140/4140 - 22s - loss: 0.2866 - acc: 0.8833 - val_loss: 0.4518 - val_acc: 0.8043\n",
      "Epoch 30/30\n",
      "4140/4140 - 22s - loss: 0.2833 - acc: 0.8838 - val_loss: 0.4890 - val_acc: 0.8000\n",
      "100/100 [==============================] - 1s 13ms/sample - loss: 0.4684 - acc: 0.8300\n",
      "logs/fit/triple_lstm/kfold2\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 10s - loss: 0.6899 - acc: 0.6312 - val_loss: 0.6855 - val_acc: 0.6370\n",
      "Epoch 2/30\n",
      "4140/4140 - 3s - loss: 0.6606 - acc: 0.6884 - val_loss: 0.6422 - val_acc: 0.7152\n",
      "Epoch 3/30\n",
      "4140/4140 - 4s - loss: 0.6346 - acc: 0.7155 - val_loss: 0.6471 - val_acc: 0.6348\n",
      "Epoch 4/30\n",
      "4140/4140 - 11s - loss: 0.5539 - acc: 0.7556 - val_loss: 0.5141 - val_acc: 0.7500\n",
      "Epoch 5/30\n",
      "4140/4140 - 19s - loss: 0.5006 - acc: 0.7727 - val_loss: 0.7699 - val_acc: 0.7457\n",
      "Epoch 6/30\n",
      "4140/4140 - 20s - loss: 0.4406 - acc: 0.8010 - val_loss: 0.5116 - val_acc: 0.7739\n",
      "Epoch 7/30\n",
      "4140/4140 - 20s - loss: 0.4008 - acc: 0.8198 - val_loss: 0.4854 - val_acc: 0.7935\n",
      "Epoch 8/30\n",
      "4140/4140 - 20s - loss: 0.3905 - acc: 0.8314 - val_loss: 0.4981 - val_acc: 0.7978\n",
      "Epoch 9/30\n",
      "4140/4140 - 21s - loss: 0.3810 - acc: 0.8326 - val_loss: 0.5426 - val_acc: 0.8043\n",
      "Epoch 10/30\n",
      "4140/4140 - 20s - loss: 0.3655 - acc: 0.8444 - val_loss: 0.4962 - val_acc: 0.8239\n",
      "Epoch 11/30\n",
      "4140/4140 - 20s - loss: 0.3548 - acc: 0.8440 - val_loss: 0.4761 - val_acc: 0.8261\n",
      "Epoch 12/30\n",
      "4140/4140 - 20s - loss: 0.3471 - acc: 0.8478 - val_loss: 0.4902 - val_acc: 0.8217\n",
      "Epoch 13/30\n",
      "4140/4140 - 20s - loss: 0.3370 - acc: 0.8543 - val_loss: 0.4798 - val_acc: 0.8217\n",
      "Epoch 14/30\n",
      "4140/4140 - 20s - loss: 0.3248 - acc: 0.8587 - val_loss: 0.4826 - val_acc: 0.8391\n",
      "Epoch 15/30\n",
      "4140/4140 - 16s - loss: 0.3191 - acc: 0.8626 - val_loss: 0.4937 - val_acc: 0.8370\n",
      "Epoch 16/30\n",
      "4140/4140 - 3s - loss: 0.3128 - acc: 0.8681 - val_loss: 0.4849 - val_acc: 0.8391\n",
      "Epoch 17/30\n",
      "4140/4140 - 3s - loss: 0.3068 - acc: 0.8715 - val_loss: 0.4839 - val_acc: 0.8391\n",
      "Epoch 18/30\n",
      "4140/4140 - 3s - loss: 0.2952 - acc: 0.8768 - val_loss: 0.5293 - val_acc: 0.8435\n",
      "Epoch 19/30\n",
      "4140/4140 - 3s - loss: 0.2872 - acc: 0.8768 - val_loss: 0.5119 - val_acc: 0.8457\n",
      "Epoch 20/30\n",
      "4140/4140 - 3s - loss: 0.2793 - acc: 0.8809 - val_loss: 0.5361 - val_acc: 0.8435\n",
      "Epoch 21/30\n",
      "4140/4140 - 3s - loss: 0.2729 - acc: 0.8838 - val_loss: 0.5404 - val_acc: 0.8522\n",
      "Epoch 22/30\n",
      "4140/4140 - 3s - loss: 0.2654 - acc: 0.8884 - val_loss: 0.5560 - val_acc: 0.8478\n",
      "Epoch 23/30\n",
      "4140/4140 - 6s - loss: 0.2538 - acc: 0.8918 - val_loss: 0.5945 - val_acc: 0.8500\n",
      "Epoch 24/30\n",
      "4140/4140 - 12s - loss: 0.2464 - acc: 0.8952 - val_loss: 0.6238 - val_acc: 0.8522\n",
      "Epoch 25/30\n",
      "4140/4140 - 20s - loss: 0.2398 - acc: 0.9002 - val_loss: 0.6258 - val_acc: 0.8457\n",
      "Epoch 26/30\n",
      "4140/4140 - 20s - loss: 0.2305 - acc: 0.9022 - val_loss: 0.6282 - val_acc: 0.8478\n",
      "Epoch 27/30\n",
      "4140/4140 - 20s - loss: 0.2329 - acc: 0.8998 - val_loss: 0.5712 - val_acc: 0.8413\n",
      "Epoch 28/30\n",
      "4140/4140 - 21s - loss: 0.2387 - acc: 0.8981 - val_loss: 0.5616 - val_acc: 0.8370\n",
      "Epoch 29/30\n",
      "4140/4140 - 20s - loss: 0.2329 - acc: 0.9014 - val_loss: 0.6387 - val_acc: 0.8435\n",
      "Epoch 30/30\n",
      "4140/4140 - 20s - loss: 0.2210 - acc: 0.9068 - val_loss: 0.6951 - val_acc: 0.8435\n",
      "100/100 [==============================] - 1s 11ms/sample - loss: 0.5912 - acc: 0.8800\n",
      "logs/fit/triple_lstm/kfold3\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 14s - loss: 0.6891 - acc: 0.5749 - val_loss: 0.6760 - val_acc: 0.6109\n",
      "Epoch 2/30\n",
      "4140/4140 - 3s - loss: 0.6763 - acc: 0.5751 - val_loss: 0.6437 - val_acc: 0.6109\n",
      "Epoch 3/30\n",
      "4140/4140 - 3s - loss: 0.6044 - acc: 0.6360 - val_loss: 0.5131 - val_acc: 0.7370\n",
      "Epoch 4/30\n",
      "4140/4140 - 3s - loss: 0.5303 - acc: 0.7464 - val_loss: 0.4782 - val_acc: 0.7739\n",
      "Epoch 5/30\n",
      "4140/4140 - 3s - loss: 0.4796 - acc: 0.7693 - val_loss: 0.4314 - val_acc: 0.7978\n",
      "Epoch 6/30\n",
      "4140/4140 - 4s - loss: 0.4398 - acc: 0.8039 - val_loss: 0.4188 - val_acc: 0.8217\n",
      "Epoch 7/30\n",
      "4140/4140 - 10s - loss: 0.4212 - acc: 0.8065 - val_loss: 0.3973 - val_acc: 0.7978\n",
      "Epoch 8/30\n",
      "4140/4140 - 19s - loss: 0.4014 - acc: 0.8268 - val_loss: 0.3903 - val_acc: 0.8348\n",
      "Epoch 9/30\n",
      "4140/4140 - 20s - loss: 0.3879 - acc: 0.8336 - val_loss: 0.3819 - val_acc: 0.8348\n",
      "Epoch 10/30\n",
      "4140/4140 - 20s - loss: 0.3799 - acc: 0.8348 - val_loss: 0.3769 - val_acc: 0.8261\n",
      "Epoch 11/30\n",
      "4140/4140 - 21s - loss: 0.3711 - acc: 0.8338 - val_loss: 0.3719 - val_acc: 0.8348\n",
      "Epoch 12/30\n",
      "4140/4140 - 20s - loss: 0.3527 - acc: 0.8408 - val_loss: 0.3677 - val_acc: 0.8413\n",
      "Epoch 13/30\n",
      "4140/4140 - 20s - loss: 0.3555 - acc: 0.8418 - val_loss: 0.3636 - val_acc: 0.8500\n",
      "Epoch 14/30\n",
      "4140/4140 - 20s - loss: 0.3492 - acc: 0.8464 - val_loss: 0.3624 - val_acc: 0.8478\n",
      "Epoch 15/30\n",
      "4140/4140 - 20s - loss: 0.3370 - acc: 0.8577 - val_loss: 0.3606 - val_acc: 0.8413\n",
      "Epoch 16/30\n",
      "4140/4140 - 20s - loss: 0.3389 - acc: 0.8514 - val_loss: 0.3568 - val_acc: 0.8478\n",
      "Epoch 17/30\n",
      "4140/4140 - 21s - loss: 0.3293 - acc: 0.8592 - val_loss: 0.3513 - val_acc: 0.8413\n",
      "Epoch 18/30\n",
      "4140/4140 - 20s - loss: 0.3193 - acc: 0.8638 - val_loss: 0.3463 - val_acc: 0.8522\n",
      "Epoch 19/30\n",
      "4140/4140 - 20s - loss: 0.3142 - acc: 0.8659 - val_loss: 0.3508 - val_acc: 0.8391\n",
      "Epoch 20/30\n",
      "4140/4140 - 6s - loss: 0.3101 - acc: 0.8715 - val_loss: 0.3505 - val_acc: 0.8413\n",
      "Epoch 21/30\n",
      "4140/4140 - 3s - loss: 0.3027 - acc: 0.8676 - val_loss: 0.3494 - val_acc: 0.8413\n",
      "Epoch 22/30\n",
      "4140/4140 - 3s - loss: 0.2902 - acc: 0.8787 - val_loss: 0.3458 - val_acc: 0.8478\n",
      "Epoch 23/30\n",
      "4140/4140 - 3s - loss: 0.2880 - acc: 0.8821 - val_loss: 0.3709 - val_acc: 0.8543\n",
      "Epoch 24/30\n",
      "4140/4140 - 3s - loss: 0.2769 - acc: 0.8899 - val_loss: 0.3500 - val_acc: 0.8630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "4140/4140 - 3s - loss: 0.2648 - acc: 0.8928 - val_loss: 0.3556 - val_acc: 0.8609\n",
      "Epoch 26/30\n",
      "4140/4140 - 3s - loss: 0.2545 - acc: 0.8976 - val_loss: 0.3571 - val_acc: 0.8696\n",
      "Epoch 27/30\n",
      "4140/4140 - 4s - loss: 0.2466 - acc: 0.9022 - val_loss: 0.3539 - val_acc: 0.8587\n",
      "Epoch 28/30\n",
      "4140/4140 - 9s - loss: 0.2348 - acc: 0.9104 - val_loss: 0.3601 - val_acc: 0.8587\n",
      "Epoch 29/30\n",
      "4140/4140 - 17s - loss: 0.2462 - acc: 0.8995 - val_loss: 0.3502 - val_acc: 0.8652\n",
      "Epoch 30/30\n",
      "4140/4140 - 20s - loss: 0.2269 - acc: 0.9140 - val_loss: 0.4028 - val_acc: 0.8609\n",
      "100/100 [==============================] - 1s 11ms/sample - loss: 0.3085 - acc: 0.9100\n",
      "logs/fit/triple_lstm/kfold4\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 59s - loss: 0.6889 - acc: 0.6239 - val_loss: 0.6670 - val_acc: 0.6848\n",
      "Epoch 2/30\n",
      "4140/4140 - 20s - loss: 0.6583 - acc: 0.6932 - val_loss: 0.6642 - val_acc: 0.6587\n",
      "Epoch 3/30\n",
      "4140/4140 - 6s - loss: 0.6071 - acc: 0.7546 - val_loss: 0.6555 - val_acc: 0.7370\n",
      "Epoch 4/30\n",
      "4140/4140 - 3s - loss: 0.5253 - acc: 0.7609 - val_loss: 0.5051 - val_acc: 0.7522\n",
      "Epoch 5/30\n",
      "4140/4140 - 3s - loss: 0.4330 - acc: 0.8019 - val_loss: 0.5152 - val_acc: 0.8022\n",
      "Epoch 6/30\n",
      "4140/4140 - 3s - loss: 0.4303 - acc: 0.8140 - val_loss: 0.4866 - val_acc: 0.7826\n",
      "Epoch 7/30\n",
      "4140/4140 - 3s - loss: 0.3847 - acc: 0.8307 - val_loss: 0.4842 - val_acc: 0.8043\n",
      "Epoch 8/30\n",
      "4140/4140 - 3s - loss: 0.3782 - acc: 0.8345 - val_loss: 0.4665 - val_acc: 0.7891\n",
      "Epoch 9/30\n",
      "4140/4140 - 3s - loss: 0.3610 - acc: 0.8442 - val_loss: 0.4599 - val_acc: 0.8043\n",
      "Epoch 10/30\n",
      "4140/4140 - 4s - loss: 0.3498 - acc: 0.8524 - val_loss: 0.4632 - val_acc: 0.8087\n",
      "Epoch 11/30\n",
      "4140/4140 - 9s - loss: 0.3472 - acc: 0.8517 - val_loss: 0.4491 - val_acc: 0.8217\n",
      "Epoch 12/30\n",
      "4140/4140 - 18s - loss: 0.3344 - acc: 0.8556 - val_loss: 0.4501 - val_acc: 0.8174\n",
      "Epoch 13/30\n",
      "4140/4140 - 20s - loss: 0.3293 - acc: 0.8626 - val_loss: 0.4458 - val_acc: 0.8239\n",
      "Epoch 14/30\n",
      "4140/4140 - 20s - loss: 0.3207 - acc: 0.8643 - val_loss: 0.4497 - val_acc: 0.8239\n",
      "Epoch 15/30\n",
      "4140/4140 - 20s - loss: 0.3150 - acc: 0.8628 - val_loss: 0.4879 - val_acc: 0.8217\n",
      "Epoch 16/30\n",
      "4140/4140 - 20s - loss: 0.3011 - acc: 0.8681 - val_loss: 0.4900 - val_acc: 0.8239\n",
      "Epoch 17/30\n",
      "4140/4140 - 20s - loss: 0.2935 - acc: 0.8768 - val_loss: 0.4925 - val_acc: 0.8217\n",
      "Epoch 18/30\n",
      "4140/4140 - 20s - loss: 0.2905 - acc: 0.8749 - val_loss: 0.4907 - val_acc: 0.8152\n",
      "Epoch 19/30\n",
      "4140/4140 - 20s - loss: 0.2743 - acc: 0.8853 - val_loss: 0.4783 - val_acc: 0.8174\n",
      "Epoch 20/30\n",
      "4140/4140 - 21s - loss: 0.2712 - acc: 0.8872 - val_loss: 0.4889 - val_acc: 0.8152\n",
      "Epoch 21/30\n",
      "4140/4140 - 20s - loss: 0.2645 - acc: 0.8886 - val_loss: 0.5220 - val_acc: 0.8130\n",
      "Epoch 22/30\n",
      "4140/4140 - 20s - loss: 0.2549 - acc: 0.8913 - val_loss: 0.4908 - val_acc: 0.8283\n",
      "Epoch 23/30\n",
      "4140/4140 - 20s - loss: 0.2512 - acc: 0.8884 - val_loss: 0.5405 - val_acc: 0.8217\n",
      "Epoch 24/30\n",
      "4140/4140 - 20s - loss: 0.2417 - acc: 0.8959 - val_loss: 0.5974 - val_acc: 0.8152\n",
      "Epoch 25/30\n",
      "4140/4140 - 19s - loss: 0.2503 - acc: 0.8954 - val_loss: 0.5274 - val_acc: 0.8261\n",
      "Epoch 26/30\n",
      "4140/4140 - 3s - loss: 0.2399 - acc: 0.8973 - val_loss: 1.3789 - val_acc: 0.8152\n",
      "Epoch 27/30\n",
      "4140/4140 - 3s - loss: 0.6625 - acc: 0.8377 - val_loss: 0.9790 - val_acc: 0.7478\n",
      "Epoch 28/30\n",
      "4140/4140 - 3s - loss: 0.4147 - acc: 0.8200 - val_loss: 0.5555 - val_acc: 0.7826\n",
      "Epoch 29/30\n",
      "4140/4140 - 3s - loss: 0.3537 - acc: 0.8478 - val_loss: 0.5570 - val_acc: 0.7870\n",
      "Epoch 30/30\n",
      "4140/4140 - 3s - loss: 0.3332 - acc: 0.8577 - val_loss: 0.6218 - val_acc: 0.7935\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.6373 - acc: 0.8000\n",
      "logs/fit/triple_lstm/kfold5\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 59s - loss: 0.6933 - acc: 0.5787 - val_loss: 0.6848 - val_acc: 0.5804\n",
      "Epoch 2/30\n",
      "4140/4140 - 20s - loss: 0.6699 - acc: 0.5787 - val_loss: 0.6685 - val_acc: 0.5804\n",
      "Epoch 3/30\n",
      "4140/4140 - 20s - loss: 0.6338 - acc: 0.5785 - val_loss: 0.6184 - val_acc: 0.5804\n",
      "Epoch 4/30\n",
      "4140/4140 - 20s - loss: 0.5912 - acc: 0.5787 - val_loss: 0.5896 - val_acc: 0.5804\n",
      "Epoch 5/30\n",
      "4140/4140 - 20s - loss: 0.5773 - acc: 0.5800 - val_loss: 0.5955 - val_acc: 0.7348\n",
      "Epoch 6/30\n",
      "4140/4140 - 20s - loss: 0.5303 - acc: 0.6176 - val_loss: 0.5472 - val_acc: 0.7370\n",
      "Epoch 7/30\n",
      "4140/4140 - 20s - loss: 0.4939 - acc: 0.7780 - val_loss: 0.5519 - val_acc: 0.7652\n",
      "Epoch 8/30\n",
      "4140/4140 - 18s - loss: 0.4814 - acc: 0.8085 - val_loss: 0.5547 - val_acc: 0.7630\n",
      "Epoch 9/30\n",
      "4140/4140 - 3s - loss: 0.4612 - acc: 0.8196 - val_loss: 0.5508 - val_acc: 0.7587\n",
      "Epoch 10/30\n",
      "4140/4140 - 3s - loss: 0.4519 - acc: 0.8297 - val_loss: 0.5283 - val_acc: 0.7674\n",
      "Epoch 11/30\n",
      "4140/4140 - 3s - loss: 0.4415 - acc: 0.8345 - val_loss: 0.5192 - val_acc: 0.7696\n",
      "Epoch 12/30\n",
      "4140/4140 - 3s - loss: 0.4313 - acc: 0.8389 - val_loss: 0.5143 - val_acc: 0.7630\n",
      "Epoch 13/30\n",
      "4140/4140 - 3s - loss: 0.3961 - acc: 0.8386 - val_loss: 0.4874 - val_acc: 0.7478\n",
      "Epoch 14/30\n",
      "4140/4140 - 3s - loss: 0.3719 - acc: 0.8394 - val_loss: 0.5068 - val_acc: 0.7674\n",
      "Epoch 15/30\n",
      "4140/4140 - 3s - loss: 0.3494 - acc: 0.8498 - val_loss: 0.4876 - val_acc: 0.7783\n",
      "Epoch 16/30\n",
      "4140/4140 - 4s - loss: 0.3414 - acc: 0.8565 - val_loss: 0.5009 - val_acc: 0.7696\n",
      "Epoch 17/30\n",
      "4140/4140 - 10s - loss: 0.3233 - acc: 0.8594 - val_loss: 0.5243 - val_acc: 0.7717\n",
      "Epoch 18/30\n",
      "4140/4140 - 18s - loss: 0.3252 - acc: 0.8667 - val_loss: 0.4957 - val_acc: 0.7717\n",
      "Epoch 19/30\n",
      "4140/4140 - 20s - loss: 0.3083 - acc: 0.8681 - val_loss: 0.5101 - val_acc: 0.7674\n",
      "Epoch 20/30\n",
      "4140/4140 - 20s - loss: 0.3073 - acc: 0.8742 - val_loss: 0.4925 - val_acc: 0.7696\n",
      "Epoch 21/30\n",
      "4140/4140 - 20s - loss: 0.2952 - acc: 0.8797 - val_loss: 0.5199 - val_acc: 0.7609\n",
      "Epoch 22/30\n",
      "4140/4140 - 20s - loss: 0.2980 - acc: 0.8775 - val_loss: 0.4980 - val_acc: 0.7696\n",
      "Epoch 23/30\n",
      "4140/4140 - 21s - loss: 0.2931 - acc: 0.8812 - val_loss: 0.5202 - val_acc: 0.7674\n",
      "Epoch 24/30\n",
      "4140/4140 - 20s - loss: 0.2836 - acc: 0.8886 - val_loss: 0.5478 - val_acc: 0.7652\n",
      "Epoch 25/30\n",
      "4140/4140 - 20s - loss: 0.2808 - acc: 0.8915 - val_loss: 0.5395 - val_acc: 0.7609\n",
      "Epoch 26/30\n",
      "4140/4140 - 20s - loss: 0.2725 - acc: 0.8923 - val_loss: 0.5301 - val_acc: 0.7717\n",
      "Epoch 27/30\n",
      "4140/4140 - 20s - loss: 0.2721 - acc: 0.8976 - val_loss: 0.5614 - val_acc: 0.7674\n",
      "Epoch 28/30\n",
      "4140/4140 - 20s - loss: 0.2716 - acc: 0.8993 - val_loss: 0.5518 - val_acc: 0.7717\n",
      "Epoch 29/30\n",
      "4140/4140 - 21s - loss: 0.2745 - acc: 0.8940 - val_loss: 0.5466 - val_acc: 0.7696\n",
      "Epoch 30/30\n",
      "4140/4140 - 20s - loss: 0.2849 - acc: 0.8877 - val_loss: 0.5357 - val_acc: 0.7978\n",
      "100/100 [==============================] - 1s 11ms/sample - loss: 0.3656 - acc: 0.8400\n",
      "logs/fit/triple_lstm/kfold6\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 11s - loss: 0.6857 - acc: 0.6196 - val_loss: 0.6607 - val_acc: 0.7109\n",
      "Epoch 2/30\n",
      "4140/4140 - 5s - loss: 0.6648 - acc: 0.6763 - val_loss: 0.6379 - val_acc: 0.7174\n",
      "Epoch 3/30\n",
      "4140/4140 - 11s - loss: 0.6153 - acc: 0.7080 - val_loss: 0.5808 - val_acc: 0.7130\n",
      "Epoch 4/30\n",
      "4140/4140 - 19s - loss: 0.5337 - acc: 0.7440 - val_loss: 0.4891 - val_acc: 0.7826\n",
      "Epoch 5/30\n",
      "4140/4140 - 21s - loss: 0.4851 - acc: 0.7710 - val_loss: 0.4437 - val_acc: 0.7870\n",
      "Epoch 6/30\n",
      "4140/4140 - 20s - loss: 0.4327 - acc: 0.8085 - val_loss: 0.4773 - val_acc: 0.7891\n",
      "Epoch 7/30\n",
      "4140/4140 - 20s - loss: 0.3889 - acc: 0.8283 - val_loss: 0.4418 - val_acc: 0.8109\n",
      "Epoch 8/30\n",
      "4140/4140 - 20s - loss: 0.3637 - acc: 0.8447 - val_loss: 0.4212 - val_acc: 0.8196\n",
      "Epoch 9/30\n",
      "4140/4140 - 20s - loss: 0.3589 - acc: 0.8440 - val_loss: 0.3990 - val_acc: 0.8152\n",
      "Epoch 10/30\n",
      "4140/4140 - 20s - loss: 0.3464 - acc: 0.8531 - val_loss: 0.4263 - val_acc: 0.8239\n",
      "Epoch 11/30\n",
      "4140/4140 - 21s - loss: 0.3290 - acc: 0.8524 - val_loss: 0.4340 - val_acc: 0.8283\n",
      "Epoch 12/30\n",
      "4140/4140 - 20s - loss: 0.3289 - acc: 0.8604 - val_loss: 0.4894 - val_acc: 0.8217\n",
      "Epoch 13/30\n",
      "4140/4140 - 20s - loss: 0.3176 - acc: 0.8652 - val_loss: 0.4906 - val_acc: 0.8283\n",
      "Epoch 14/30\n",
      "4140/4140 - 20s - loss: 0.3143 - acc: 0.8647 - val_loss: 0.5086 - val_acc: 0.8283\n",
      "Epoch 15/30\n",
      "4140/4140 - 20s - loss: 0.2987 - acc: 0.8700 - val_loss: 0.5329 - val_acc: 0.8196\n",
      "Epoch 16/30\n",
      "4140/4140 - 20s - loss: 0.2916 - acc: 0.8749 - val_loss: 0.5911 - val_acc: 0.8261\n",
      "Epoch 17/30\n",
      "4140/4140 - 21s - loss: 0.2826 - acc: 0.8766 - val_loss: 0.5660 - val_acc: 0.8196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "4140/4140 - 17s - loss: 0.2701 - acc: 0.8865 - val_loss: 0.6099 - val_acc: 0.8261\n",
      "Epoch 19/30\n",
      "4140/4140 - 3s - loss: 0.2661 - acc: 0.8870 - val_loss: 0.6695 - val_acc: 0.8304\n",
      "Epoch 20/30\n",
      "4140/4140 - 3s - loss: 0.2591 - acc: 0.8913 - val_loss: 0.6615 - val_acc: 0.8239\n",
      "Epoch 21/30\n",
      "4140/4140 - 3s - loss: 0.2513 - acc: 0.8947 - val_loss: 0.7281 - val_acc: 0.8348\n",
      "Epoch 22/30\n",
      "4140/4140 - 3s - loss: 0.2427 - acc: 0.8961 - val_loss: 0.8586 - val_acc: 0.8435\n",
      "Epoch 23/30\n",
      "4140/4140 - 3s - loss: 0.2342 - acc: 0.9019 - val_loss: 1.0567 - val_acc: 0.8283\n",
      "Epoch 24/30\n",
      "4140/4140 - 3s - loss: 0.2258 - acc: 0.9094 - val_loss: 1.2122 - val_acc: 0.8283\n",
      "Epoch 25/30\n",
      "4140/4140 - 3s - loss: 0.2198 - acc: 0.9114 - val_loss: 0.9960 - val_acc: 0.8326\n",
      "Epoch 26/30\n",
      "4140/4140 - 5s - loss: 0.2109 - acc: 0.9171 - val_loss: 1.0688 - val_acc: 0.8239\n",
      "Epoch 27/30\n",
      "4140/4140 - 11s - loss: 0.2045 - acc: 0.9174 - val_loss: 1.0619 - val_acc: 0.8217\n",
      "Epoch 28/30\n",
      "4140/4140 - 19s - loss: 0.2018 - acc: 0.9208 - val_loss: 1.1006 - val_acc: 0.8174\n",
      "Epoch 29/30\n",
      "4140/4140 - 20s - loss: 0.1926 - acc: 0.9222 - val_loss: 1.1583 - val_acc: 0.8130\n",
      "Epoch 30/30\n",
      "4140/4140 - 20s - loss: 0.1979 - acc: 0.9205 - val_loss: 1.3314 - val_acc: 0.8022\n",
      "100/100 [==============================] - 1s 12ms/sample - loss: 1.4239 - acc: 0.7700\n",
      "logs/fit/triple_lstm/kfold7\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 62s - loss: 0.6864 - acc: 0.5812 - val_loss: 0.6723 - val_acc: 0.5565\n",
      "Epoch 2/30\n",
      "4140/4140 - 8s - loss: 0.8945 - acc: 0.5812 - val_loss: 0.6625 - val_acc: 0.5565\n",
      "Epoch 3/30\n",
      "4140/4140 - 3s - loss: 0.6711 - acc: 0.5814 - val_loss: 0.6767 - val_acc: 0.5565\n",
      "Epoch 4/30\n",
      "4140/4140 - 3s - loss: 0.6728 - acc: 0.5814 - val_loss: 0.6747 - val_acc: 0.5565\n",
      "Epoch 5/30\n",
      "4140/4140 - 3s - loss: 0.6702 - acc: 0.5814 - val_loss: 0.6724 - val_acc: 0.5565\n",
      "Epoch 6/30\n",
      "4140/4140 - 3s - loss: 0.6675 - acc: 0.5814 - val_loss: 0.6698 - val_acc: 0.5565\n",
      "Epoch 7/30\n",
      "4140/4140 - 3s - loss: 0.6648 - acc: 0.5814 - val_loss: 0.6664 - val_acc: 0.5565\n",
      "Epoch 8/30\n",
      "4140/4140 - 3s - loss: 0.6609 - acc: 0.5814 - val_loss: 0.6612 - val_acc: 0.5565\n",
      "Epoch 9/30\n",
      "4140/4140 - 4s - loss: 0.6547 - acc: 0.5814 - val_loss: 0.6493 - val_acc: 0.5565\n",
      "Epoch 10/30\n",
      "4140/4140 - 8s - loss: 0.6415 - acc: 0.5814 - val_loss: 0.6454 - val_acc: 0.5565\n",
      "Epoch 11/30\n",
      "4140/4140 - 16s - loss: 0.6358 - acc: 0.5814 - val_loss: 0.6150 - val_acc: 0.5565\n",
      "Epoch 12/30\n",
      "4140/4140 - 20s - loss: 0.6062 - acc: 0.5814 - val_loss: 0.5888 - val_acc: 0.5565\n",
      "Epoch 13/30\n",
      "4140/4140 - 20s - loss: 0.6116 - acc: 0.5814 - val_loss: 0.5952 - val_acc: 0.5565\n",
      "Epoch 14/30\n",
      "4140/4140 - 20s - loss: 0.5848 - acc: 0.5814 - val_loss: 0.5604 - val_acc: 0.6391\n",
      "Epoch 15/30\n",
      "4140/4140 - 20s - loss: 0.5832 - acc: 0.5872 - val_loss: 0.5674 - val_acc: 0.7391\n",
      "Epoch 16/30\n",
      "4140/4140 - 20s - loss: 0.5533 - acc: 0.6138 - val_loss: 0.5148 - val_acc: 0.7652\n",
      "Epoch 17/30\n",
      "4140/4140 - 20s - loss: 0.4995 - acc: 0.7720 - val_loss: 0.5062 - val_acc: 0.8130\n",
      "Epoch 18/30\n",
      "4140/4140 - 20s - loss: 0.4635 - acc: 0.8034 - val_loss: 0.4395 - val_acc: 0.8196\n",
      "Epoch 19/30\n",
      "4140/4140 - 20s - loss: 0.4262 - acc: 0.8167 - val_loss: 0.4208 - val_acc: 0.8130\n",
      "Epoch 20/30\n",
      "4140/4140 - 21s - loss: 0.4077 - acc: 0.8268 - val_loss: 0.3913 - val_acc: 0.8239\n",
      "Epoch 21/30\n",
      "4140/4140 - 20s - loss: 0.3939 - acc: 0.8345 - val_loss: 0.3885 - val_acc: 0.8152\n",
      "Epoch 22/30\n",
      "4140/4140 - 20s - loss: 0.3881 - acc: 0.8304 - val_loss: 0.3848 - val_acc: 0.8130\n",
      "Epoch 23/30\n",
      "4140/4140 - 20s - loss: 0.3726 - acc: 0.8423 - val_loss: 0.3838 - val_acc: 0.8304\n",
      "Epoch 24/30\n",
      "4140/4140 - 19s - loss: 0.3607 - acc: 0.8486 - val_loss: 0.3804 - val_acc: 0.8283\n",
      "Epoch 25/30\n",
      "4140/4140 - 3s - loss: 0.3641 - acc: 0.8449 - val_loss: 0.3746 - val_acc: 0.8370\n",
      "Epoch 26/30\n",
      "4140/4140 - 3s - loss: 0.3574 - acc: 0.8483 - val_loss: 0.3746 - val_acc: 0.8370\n",
      "Epoch 27/30\n",
      "4140/4140 - 3s - loss: 0.3514 - acc: 0.8486 - val_loss: 0.3763 - val_acc: 0.8370\n",
      "Epoch 28/30\n",
      "4140/4140 - 3s - loss: 0.3470 - acc: 0.8531 - val_loss: 0.3778 - val_acc: 0.8370\n",
      "Epoch 29/30\n",
      "4140/4140 - 3s - loss: 0.3451 - acc: 0.8592 - val_loss: 0.3797 - val_acc: 0.8326\n",
      "Epoch 30/30\n",
      "4140/4140 - 3s - loss: 0.3392 - acc: 0.8597 - val_loss: 0.3762 - val_acc: 0.8391\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.3447 - acc: 0.8700\n",
      "logs/fit/triple_lstm/kfold8\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 63s - loss: 0.6912 - acc: 0.5662 - val_loss: 0.6849 - val_acc: 0.6217\n",
      "Epoch 2/30\n",
      "4140/4140 - 20s - loss: 0.6829 - acc: 0.5942 - val_loss: 0.6675 - val_acc: 0.6217\n",
      "Epoch 3/30\n",
      "4140/4140 - 20s - loss: 0.6794 - acc: 0.6749 - val_loss: 0.5695 - val_acc: 0.6978\n",
      "Epoch 4/30\n",
      "4140/4140 - 20s - loss: 0.5831 - acc: 0.7297 - val_loss: 0.5806 - val_acc: 0.7109\n",
      "Epoch 5/30\n",
      "4140/4140 - 20s - loss: 0.6241 - acc: 0.6768 - val_loss: 0.6470 - val_acc: 0.6217\n",
      "Epoch 6/30\n",
      "4140/4140 - 20s - loss: 0.6282 - acc: 0.6159 - val_loss: 0.6020 - val_acc: 0.6565\n",
      "Epoch 7/30\n",
      "4140/4140 - 20s - loss: 0.5586 - acc: 0.7432 - val_loss: 0.5180 - val_acc: 0.7435\n",
      "Epoch 8/30\n",
      "4140/4140 - 20s - loss: 0.5486 - acc: 0.7572 - val_loss: 0.5254 - val_acc: 0.7609\n",
      "Epoch 9/30\n",
      "4140/4140 - 3s - loss: 0.4925 - acc: 0.7787 - val_loss: 0.4906 - val_acc: 0.7522\n",
      "Epoch 10/30\n",
      "4140/4140 - 3s - loss: 0.4527 - acc: 0.7884 - val_loss: 0.4832 - val_acc: 0.7674\n",
      "Epoch 11/30\n",
      "4140/4140 - 3s - loss: 0.4420 - acc: 0.7983 - val_loss: 0.4579 - val_acc: 0.7935\n",
      "Epoch 12/30\n",
      "4140/4140 - 3s - loss: 0.4281 - acc: 0.8063 - val_loss: 0.4426 - val_acc: 0.8109\n",
      "Epoch 13/30\n",
      "4140/4140 - 3s - loss: 0.4124 - acc: 0.8126 - val_loss: 0.4404 - val_acc: 0.8130\n",
      "Epoch 14/30\n",
      "4140/4140 - 3s - loss: 0.4022 - acc: 0.8237 - val_loss: 0.4513 - val_acc: 0.8174\n",
      "Epoch 15/30\n",
      "4140/4140 - 3s - loss: 0.4439 - acc: 0.8249 - val_loss: 0.4384 - val_acc: 0.8065\n",
      "Epoch 16/30\n",
      "4140/4140 - 4s - loss: 0.4008 - acc: 0.8184 - val_loss: 0.4315 - val_acc: 0.8065\n",
      "Epoch 17/30\n",
      "4140/4140 - 11s - loss: 0.3963 - acc: 0.8283 - val_loss: 0.4187 - val_acc: 0.8065\n",
      "Epoch 18/30\n",
      "4140/4140 - 19s - loss: 0.3929 - acc: 0.8295 - val_loss: 0.4359 - val_acc: 0.8087\n",
      "Epoch 19/30\n",
      "4140/4140 - 20s - loss: 0.3717 - acc: 0.8394 - val_loss: 0.4271 - val_acc: 0.8217\n",
      "Epoch 20/30\n",
      "4140/4140 - 20s - loss: 0.3726 - acc: 0.8319 - val_loss: 0.3859 - val_acc: 0.8391\n",
      "Epoch 21/30\n",
      "4140/4140 - 20s - loss: 0.3641 - acc: 0.8403 - val_loss: 0.3919 - val_acc: 0.8370\n",
      "Epoch 22/30\n",
      "4140/4140 - 20s - loss: 0.3587 - acc: 0.8406 - val_loss: 0.4065 - val_acc: 0.8348\n",
      "Epoch 23/30\n",
      "4140/4140 - 20s - loss: 0.3480 - acc: 0.8493 - val_loss: 0.4117 - val_acc: 0.8370\n",
      "Epoch 24/30\n",
      "4140/4140 - 20s - loss: 0.3547 - acc: 0.8469 - val_loss: 0.4043 - val_acc: 0.8370\n",
      "Epoch 25/30\n",
      "4140/4140 - 20s - loss: 0.3447 - acc: 0.8522 - val_loss: 0.3921 - val_acc: 0.8391\n",
      "Epoch 26/30\n",
      "4140/4140 - 20s - loss: 0.3382 - acc: 0.8543 - val_loss: 0.3997 - val_acc: 0.8391\n",
      "Epoch 27/30\n",
      "4140/4140 - 20s - loss: 0.3298 - acc: 0.8628 - val_loss: 0.4055 - val_acc: 0.8413\n",
      "Epoch 28/30\n",
      "4140/4140 - 20s - loss: 0.3298 - acc: 0.8659 - val_loss: 0.3986 - val_acc: 0.8435\n",
      "Epoch 29/30\n",
      "4140/4140 - 20s - loss: 0.3276 - acc: 0.8592 - val_loss: 0.4246 - val_acc: 0.8413\n",
      "Epoch 30/30\n",
      "4140/4140 - 20s - loss: 0.3211 - acc: 0.8623 - val_loss: 0.4176 - val_acc: 0.8457\n",
      "100/100 [==============================] - 1s 5ms/sample - loss: 0.4200 - acc: 0.8000\n",
      "logs/fit/triple_lstm/kfold9\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 15s - loss: 0.6969 - acc: 0.5795 - val_loss: 0.6866 - val_acc: 0.5696\n",
      "Epoch 2/30\n",
      "4140/4140 - 13s - loss: 0.6814 - acc: 0.5800 - val_loss: 0.6826 - val_acc: 0.5696\n",
      "Epoch 3/30\n",
      "4140/4140 - 20s - loss: 0.6776 - acc: 0.5800 - val_loss: 0.6788 - val_acc: 0.5696\n",
      "Epoch 4/30\n",
      "4140/4140 - 20s - loss: 0.6664 - acc: 0.5795 - val_loss: 0.6791 - val_acc: 0.5696\n",
      "Epoch 5/30\n",
      "4140/4140 - 20s - loss: 0.6648 - acc: 0.5800 - val_loss: 0.6680 - val_acc: 0.5696\n",
      "Epoch 6/30\n",
      "4140/4140 - 20s - loss: 0.6376 - acc: 0.5800 - val_loss: 0.6600 - val_acc: 0.5696\n",
      "Epoch 7/30\n",
      "4140/4140 - 20s - loss: 0.6102 - acc: 0.5800 - val_loss: 0.6531 - val_acc: 0.5804\n",
      "Epoch 8/30\n",
      "4140/4140 - 20s - loss: 0.5940 - acc: 0.5819 - val_loss: 0.6207 - val_acc: 0.6978\n",
      "Epoch 9/30\n",
      "4140/4140 - 20s - loss: 0.5725 - acc: 0.6430 - val_loss: 0.6042 - val_acc: 0.7565\n",
      "Epoch 10/30\n",
      "4140/4140 - 20s - loss: 0.5558 - acc: 0.6850 - val_loss: 0.5915 - val_acc: 0.7674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "4140/4140 - 20s - loss: 0.5338 - acc: 0.7244 - val_loss: 0.5951 - val_acc: 0.7304\n",
      "Epoch 12/30\n",
      "4140/4140 - 7s - loss: 0.5177 - acc: 0.7548 - val_loss: 0.5565 - val_acc: 0.7630\n",
      "Epoch 13/30\n",
      "4140/4140 - 3s - loss: 0.4891 - acc: 0.7932 - val_loss: 0.5382 - val_acc: 0.7609\n",
      "Epoch 14/30\n",
      "4140/4140 - 3s - loss: 0.4682 - acc: 0.8068 - val_loss: 0.4976 - val_acc: 0.7826\n",
      "Epoch 15/30\n",
      "4140/4140 - 3s - loss: 0.4546 - acc: 0.8162 - val_loss: 0.4884 - val_acc: 0.7870\n",
      "Epoch 16/30\n",
      "4140/4140 - 3s - loss: 0.4464 - acc: 0.8283 - val_loss: 0.4792 - val_acc: 0.7957\n",
      "Epoch 17/30\n",
      "4140/4140 - 3s - loss: 0.4319 - acc: 0.8370 - val_loss: 0.4670 - val_acc: 0.7957\n",
      "Epoch 18/30\n",
      "4140/4140 - 3s - loss: 0.4224 - acc: 0.8348 - val_loss: 0.4967 - val_acc: 0.7848\n",
      "Epoch 19/30\n",
      "4140/4140 - 4s - loss: 0.4101 - acc: 0.8372 - val_loss: 0.4682 - val_acc: 0.7804\n",
      "Epoch 20/30\n",
      "4140/4140 - 9s - loss: 0.3796 - acc: 0.8428 - val_loss: 0.4527 - val_acc: 0.7696\n",
      "Epoch 21/30\n",
      "4140/4140 - 16s - loss: 0.3562 - acc: 0.8425 - val_loss: 0.4747 - val_acc: 0.7543\n",
      "Epoch 22/30\n",
      "4140/4140 - 20s - loss: 0.3491 - acc: 0.8522 - val_loss: 0.4572 - val_acc: 0.7804\n",
      "Epoch 23/30\n",
      "4140/4140 - 21s - loss: 0.3343 - acc: 0.8551 - val_loss: 0.4506 - val_acc: 0.7870\n",
      "Epoch 24/30\n",
      "4140/4140 - 20s - loss: 0.3338 - acc: 0.8604 - val_loss: 0.4221 - val_acc: 0.8087\n",
      "Epoch 25/30\n",
      "4140/4140 - 20s - loss: 0.3280 - acc: 0.8614 - val_loss: 0.4199 - val_acc: 0.8152\n",
      "Epoch 26/30\n",
      "4140/4140 - 20s - loss: 0.3220 - acc: 0.8664 - val_loss: 0.4008 - val_acc: 0.8196\n",
      "Epoch 27/30\n",
      "4140/4140 - 20s - loss: 0.3196 - acc: 0.8630 - val_loss: 0.3922 - val_acc: 0.8239\n",
      "Epoch 28/30\n",
      "4140/4140 - 20s - loss: 0.3205 - acc: 0.8633 - val_loss: 0.3710 - val_acc: 0.8348\n",
      "Epoch 29/30\n",
      "4140/4140 - 21s - loss: 0.3058 - acc: 0.8746 - val_loss: 0.3770 - val_acc: 0.8283\n",
      "Epoch 30/30\n",
      "4140/4140 - 20s - loss: 0.3071 - acc: 0.8749 - val_loss: 0.3676 - val_acc: 0.8370\n",
      "100/100 [==============================] - 1s 11ms/sample - loss: 0.3265 - acc: 0.8600\n",
      "logs/fit/triple_lstm/kfold10\n",
      "Train on 4140 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4140/4140 - 10s - loss: 0.6921 - acc: 0.5771 - val_loss: 0.6780 - val_acc: 0.5870\n",
      "Epoch 2/30\n",
      "4140/4140 - 3s - loss: 0.6769 - acc: 0.5780 - val_loss: 0.6475 - val_acc: 0.5870\n",
      "Epoch 3/30\n",
      "4140/4140 - 4s - loss: 0.6408 - acc: 0.5778 - val_loss: 0.5698 - val_acc: 0.5870\n",
      "Epoch 4/30\n",
      "4140/4140 - 5s - loss: 0.5849 - acc: 0.5771 - val_loss: 0.6058 - val_acc: 0.5870\n",
      "Epoch 5/30\n",
      "4140/4140 - 11s - loss: 0.5963 - acc: 0.7058 - val_loss: 0.5947 - val_acc: 0.8130\n",
      "Epoch 6/30\n",
      "4140/4140 - 20s - loss: 0.5380 - acc: 0.7734 - val_loss: 0.5511 - val_acc: 0.8239\n",
      "Epoch 7/30\n",
      "4140/4140 - 20s - loss: 0.5013 - acc: 0.7826 - val_loss: 0.4998 - val_acc: 0.8174\n",
      "Epoch 8/30\n",
      "4140/4140 - 20s - loss: 0.4901 - acc: 0.7935 - val_loss: 0.4967 - val_acc: 0.8370\n",
      "Epoch 9/30\n",
      "4140/4140 - 20s - loss: 0.4543 - acc: 0.8027 - val_loss: 0.4710 - val_acc: 0.8370\n",
      "Epoch 10/30\n",
      "4140/4140 - 20s - loss: 0.4399 - acc: 0.8068 - val_loss: 0.4959 - val_acc: 0.8435\n",
      "Epoch 11/30\n",
      "4140/4140 - 20s - loss: 0.4432 - acc: 0.8017 - val_loss: 0.4518 - val_acc: 0.8543\n",
      "Epoch 12/30\n",
      "4140/4140 - 20s - loss: 0.4266 - acc: 0.8135 - val_loss: 0.4175 - val_acc: 0.8522\n",
      "Epoch 13/30\n",
      "4140/4140 - 20s - loss: 0.3971 - acc: 0.8249 - val_loss: 0.3862 - val_acc: 0.8587\n",
      "Epoch 14/30\n",
      "4140/4140 - 20s - loss: 0.3854 - acc: 0.8314 - val_loss: 0.3862 - val_acc: 0.8565\n",
      "Epoch 15/30\n",
      "4140/4140 - 20s - loss: 0.3736 - acc: 0.8399 - val_loss: 0.4049 - val_acc: 0.8543\n",
      "Epoch 16/30\n",
      "4140/4140 - 20s - loss: 0.3652 - acc: 0.8459 - val_loss: 0.3857 - val_acc: 0.8522\n",
      "Epoch 17/30\n",
      "4140/4140 - 25s - loss: 0.3600 - acc: 0.8454 - val_loss: 0.3676 - val_acc: 0.8587\n",
      "Epoch 18/30\n",
      "4140/4140 - 22s - loss: 0.3475 - acc: 0.8519 - val_loss: 0.3586 - val_acc: 0.8674\n",
      "Epoch 19/30\n",
      "4140/4140 - 22s - loss: 0.3446 - acc: 0.8543 - val_loss: 0.3748 - val_acc: 0.8630\n",
      "Epoch 20/30\n",
      "4140/4140 - 22s - loss: 0.3408 - acc: 0.8585 - val_loss: 0.3828 - val_acc: 0.8674\n",
      "Epoch 21/30\n",
      "4140/4140 - 22s - loss: 0.3254 - acc: 0.8686 - val_loss: 0.3666 - val_acc: 0.8717\n",
      "Epoch 22/30\n",
      "4140/4140 - 5s - loss: 0.3172 - acc: 0.8722 - val_loss: 0.3610 - val_acc: 0.8739\n",
      "Epoch 23/30\n",
      "4140/4140 - 3s - loss: 0.3100 - acc: 0.8739 - val_loss: 0.3870 - val_acc: 0.8696\n",
      "Epoch 24/30\n",
      "4140/4140 - 3s - loss: 0.3064 - acc: 0.8754 - val_loss: 0.3757 - val_acc: 0.8739\n",
      "Epoch 25/30\n",
      "4140/4140 - 3s - loss: 0.2960 - acc: 0.8790 - val_loss: 0.3824 - val_acc: 0.8739\n",
      "Epoch 26/30\n",
      "4140/4140 - 3s - loss: 0.2873 - acc: 0.8865 - val_loss: 0.3751 - val_acc: 0.8609\n",
      "Epoch 27/30\n",
      "4140/4140 - 3s - loss: 0.2939 - acc: 0.8850 - val_loss: 0.3601 - val_acc: 0.8717\n",
      "Epoch 28/30\n",
      "4140/4140 - 3s - loss: 0.2847 - acc: 0.8860 - val_loss: 0.3832 - val_acc: 0.8630\n",
      "Epoch 29/30\n",
      "4140/4140 - 5s - loss: 0.2758 - acc: 0.8913 - val_loss: 0.3844 - val_acc: 0.8587\n",
      "Epoch 30/30\n",
      "4140/4140 - 11s - loss: 0.2705 - acc: 0.8908 - val_loss: 0.3717 - val_acc: 0.8609\n",
      "100/100 [==============================] - 1s 8ms/sample - loss: 0.4188 - acc: 0.8600\n"
     ]
    }
   ],
   "source": [
    "def triple_lstm_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(10, kernel_initializer='glorot_normal', activation='relu', return_sequences=True, input_shape=(28, 300), name='lstm'),\n",
    "        tf.keras.layers.Dropout(0.7),\n",
    "        tf.keras.layers.LSTM(10, activation='relu', name='2lstm', return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.7),\n",
    "        tf.keras.layers.LSTM(10, activation='relu', name='3lstm'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='glorot_normal', name='dense')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "triple_hist, triple_evas = kfold_train(triple_lstm_model, 'triple_lstm', batch_size=128, epochs=30, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "7a4d13c9-42e8-4236-a3dc-17692bc0405a",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.691234642929501,
          0.6854343240963664,
          0.6506405745727428,
          0.5432549658604866,
          0.4771836929851108,
          0.4847192315087802,
          0.42163309803331533,
          0.4054363177018465,
          0.4012616788995439,
          0.37268063492245146,
          0.36500024490310373,
          0.35520974535872973,
          0.35095649306900834,
          0.33401360796845475,
          0.3356647999678257,
          0.3226612389087677,
          0.31348176515044796,
          0.30171782083557425,
          0.2953948636273831,
          0.29619208806090885,
          0.279438438464478,
          0.28405194078090684,
          0.28350706625963756,
          0.2595840963188577,
          0.24967485600047643,
          0.24849302453407343,
          0.24034162297628928,
          0.22809478005637293,
          0.2210160241322817,
          0.23242313677562032
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step1', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "fa7adebb-9924-4aca-8cdb-a8cc6cd28c5b",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6869504850843678,
          0.6752959406894187,
          0.6009969224100528,
          0.48404760127482205,
          0.4939457375070323,
          0.45987418138462566,
          0.408728958212811,
          0.4024177984051082,
          0.42152947705724964,
          0.4131510130737139,
          0.43478596780611123,
          0.3915075589781222,
          0.43788767586583677,
          0.3985961255819901,
          0.3987043310766635,
          0.40117069586463594,
          0.428788983044417,
          0.41658428518668467,
          0.45475454589594966,
          0.4407342135906219,
          0.47165144059969033,
          0.5046142661053201,
          0.5267510960931363,
          0.4985546547433604,
          0.497649784191795,
          0.504563228721204,
          0.5643075067064036,
          0.4956960473371589,
          0.5205906411875849,
          0.5053187867869502
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "9e7c6917-f8f9-450a-95e1-28f78b625aba",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6886369588870357,
          0.7151937319460698,
          0.6448626999693792,
          0.5673177128828666,
          0.5231189674801296,
          0.4896644581343241,
          0.45194198420082315,
          0.43192991694966376,
          0.40997648362952155,
          0.410185833800818,
          0.3951132436881319,
          0.38425701571547466,
          0.3670972242447489,
          0.3627604439638663,
          0.3671487604938268,
          0.34848171723061716,
          0.35032686527800444,
          0.3418788668902024,
          0.34381439887383136,
          0.33367956536979493,
          0.32469670524919664,
          0.3160045396014688,
          0.3318495822701477,
          0.3627208325022085,
          0.31465871359990993,
          0.30732787971335335,
          0.30061529232683964,
          0.30124756653527707,
          0.29260920778564786,
          0.2893848436178217
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step2', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "f64d4d6f-77a6-4634-b901-85ea3ab801e4",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6850316560786703,
          0.6671034035475357,
          0.6231176993121271,
          0.6013144944025123,
          0.565127312100452,
          0.5546975431234941,
          0.5246954570645871,
          0.49865922720535943,
          0.48251488830732264,
          0.5178787931152012,
          0.5339215879854948,
          0.48676087519396904,
          0.4833118578662043,
          0.488960830025051,
          0.5042549376902373,
          0.4857603036839029,
          0.4898430015729821,
          0.47876584478046585,
          0.5090619180513465,
          0.488116861426312,
          0.5221789150134377,
          0.5043734851090804,
          0.45649589144665265,
          0.5217286055502685,
          0.5552302751852118,
          0.49871604442596434,
          0.5112506778343864,
          0.5120561304299728,
          0.5041731704836306,
          0.5193219558052394
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "280a4b41-4b80-44c2-bd74-1f8dac5a77cb",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.685094870634125,
          0.6722271133736136,
          0.6541766731059494,
          0.5945113259237169,
          0.566689758197121,
          0.563818163226768,
          0.49820967604572647,
          0.44114571107182526,
          0.40937112183962465,
          0.3746419969388252,
          0.3767946239830791,
          0.364260956313875,
          0.35299211107014455,
          0.3464413098379034,
          0.33761660462416315,
          0.32929305681859816,
          0.31989148201573875,
          0.3157842185186303,
          0.3120342845502107,
          0.2970959853866826,
          0.2904804626524736,
          0.28599047499578356,
          0.27688730772278736,
          0.2678966043364023,
          0.2609409302473068,
          0.2512421783041839,
          0.25024210825058574,
          0.23897609180874294,
          0.23921664601938736,
          0.23247706373244667
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step3', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "e3c3fe7b-d124-4b97-b89a-1ca9b1befd61",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6456125679223433,
          0.6650446979895882,
          0.6100253773772198,
          0.6688102867292322,
          0.7711266595384348,
          0.5019684299178745,
          0.45621361110521397,
          0.4172560329022615,
          0.3829838636128799,
          0.37476379767708157,
          0.3612844381643378,
          0.3587460323520329,
          0.35592661370401796,
          0.35124319454898006,
          0.3434163871018783,
          0.34267013280288033,
          0.34470000681669816,
          0.3405753742093625,
          0.33690664249917734,
          0.33012241954388827,
          0.33332857981972075,
          0.3318237579387167,
          0.3357396338296973,
          0.33923295218011607,
          0.3424390235672826,
          0.34489134835160296,
          0.3473987032537875,
          0.3578660630661508,
          0.36349126411520916,
          0.3870463324629742
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "29d56866-a30f-4308-ba08-79ce557073eb",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6891028673752494,
          0.6716973900219093,
          0.6312471185329456,
          0.5743082627582089,
          0.5293294729242002,
          0.5488252793533215,
          0.4940507244372713,
          0.476746184900763,
          0.47796293880052615,
          0.45124493653071673,
          0.4129903277625208,
          0.3999085385730301,
          0.38293618605908564,
          0.382719036605623,
          0.37190230454223744,
          0.3654478409440045,
          0.3555685498576233,
          0.3474880466858546,
          0.3410930327747179,
          0.3320350550223088,
          0.326521036475177,
          0.31489821511190297,
          0.311530157002274,
          0.30359154238505065,
          0.30275009628655253,
          0.2951986460726042,
          0.2876338815631498,
          0.2845820954888339,
          0.2756864375250351,
          0.2753477689004751
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step4', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "f4a1add1-068f-4838-a30b-26612290dd68",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6851218233937802,
          0.6809403004853621,
          0.635597997126372,
          0.5594261293825896,
          0.5319049653799638,
          0.6050456643104554,
          0.5447835315828738,
          0.5206819878972095,
          0.47834072164867236,
          0.43902750067088914,
          0.4535312048766924,
          0.4670725412990736,
          0.42073170827782674,
          0.42181925773620604,
          0.41593774894009466,
          0.42369321144145466,
          0.4162120072737984,
          0.3859481868536576,
          0.3810729485491048,
          0.3871965670067331,
          0.38845591052718786,
          0.3898425693097322,
          0.38703017597613126,
          0.3978960905386054,
          0.38749016678851583,
          0.3951959850995437,
          0.40534644697023475,
          0.40480254344318223,
          0.4031579473744268,
          0.40531976482142573
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "68bf222a-2961-43ca-bd08-c1c137f5e8f2",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6889927720102135,
          0.6583075116222031,
          0.6146592649860658,
          0.5142306668746874,
          0.4711827771675184,
          0.40726702737347514,
          0.389385406838523,
          0.37817121182662855,
          0.35745603776208446,
          0.34086177622638464,
          0.34133955922679626,
          0.3294742234375166,
          0.3181091270872936,
          0.30684391916662024,
          0.2956232180342006,
          0.29313878736634186,
          0.28470677336057026,
          0.26978945185020925,
          0.2746477734927394,
          0.2626337291249906,
          0.24689752273801444,
          0.24753780670212086,
          0.23869933788327202,
          0.24548203218098424,
          0.23728909177192745,
          0.21573798794677293,
          0.2221200056841984,
          0.21181390059455005,
          0.2162006258820566,
          0.20196368160167177
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step5', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "f4c9fe15-7109-4d48-851c-ab90a069ce8f",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.661149659882421,
          0.6624870124070541,
          0.5770749584488247,
          0.5136195118012635,
          0.4724950868150462,
          0.46250466730283657,
          0.4627545732518901,
          0.45906080836835117,
          0.47047468631163886,
          0.4801720139772996,
          0.4534562624019125,
          0.4631574490795965,
          0.4750412002853725,
          0.4974569898584615,
          0.5018767134003017,
          0.5052839159965515,
          0.48838482369547304,
          0.5021935278954713,
          0.487003449253414,
          0.492544294440228,
          0.5350327134132385,
          0.5294429281483526,
          0.5755920596744704,
          0.5746570784112681,
          0.6092434732810311,
          0.6223850644153097,
          0.5555728396643763,
          0.6179669717083807,
          0.5751638091128806,
          0.6830305488213249
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "a55b44c8-93d1-48a2-b0d6-d88cbc61a1e7",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6902845938424558,
          0.6696182618970457,
          0.6225619053495103,
          0.5410739293996839,
          0.47943213135723906,
          0.4409493107150718,
          0.40906768035197605,
          0.3811940547636742,
          0.35982083684004446,
          0.3524670117719162,
          0.34080831195421263,
          0.33166694249507883,
          0.32894583908832015,
          0.32449062672502177,
          0.3151749785107691,
          0.30222928495222817,
          0.33897251354323493,
          0.33321670158473765,
          0.3113887645772114,
          0.30483304976265213,
          0.2923046538507305,
          0.2857747556650696,
          0.28032652073436315,
          0.2801191843794164,
          0.2721461954324142,
          0.2634599391389008,
          0.2610889800936704,
          0.25531896689663763,
          0.24876411195826414,
          0.24394307254593153
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step6', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "b8ba26df-0eaa-478b-92b0-525d7b44e813",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6813707984012106,
          0.6357009016949198,
          0.5171922777010047,
          0.45659027281014813,
          0.433579153859097,
          0.4099910197050675,
          0.38750298437864883,
          0.3699034379876178,
          0.3531768148360045,
          0.35412547095962194,
          0.36519083976745603,
          0.37666477820147637,
          0.3817651310692663,
          0.42878415558649147,
          0.44078706554744557,
          0.43425644584324047,
          0.4555314857026805,
          0.40973840563193614,
          0.3873310838056647,
          0.38168999112170676,
          0.39487649435582367,
          0.3922223399514737,
          0.41230450557625814,
          0.4109307232110397,
          0.41263743768567623,
          0.4200488792813343,
          0.4243987368500751,
          0.436546454222306,
          0.4290316949719968,
          0.46030149252518365
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "30e6cfb8-a2d3-4956-8e40-cfa1dd53ddd3",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6904347619572699,
          0.6701183512590934,
          0.635157797417203,
          0.5733811235658213,
          0.47786836814189304,
          0.45089969577420735,
          0.4511605769539801,
          0.41273467995694296,
          0.40259607275902937,
          0.3830840501520369,
          0.37375970384924884,
          0.36247625201220673,
          0.3660170860048653,
          0.3514701929933207,
          0.3432977355044821,
          0.336248977460723,
          0.329929597798177,
          0.3325274987785137,
          0.3177768201355773,
          0.31705608955328013,
          0.31361957226974374,
          0.3053027838612524,
          0.29897303301931005,
          0.2989728661838937,
          0.2866116730199344,
          0.2824656822255268,
          0.2753575451420125,
          0.2712668889098697,
          0.2664026337977193,
          0.25362992675408075
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step7', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "b163c4b3-e3ee-4176-9bed-d210a6142014",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6836548639380413,
          0.6680678160294242,
          0.6139069702314294,
          0.5318846681843633,
          0.48017178773880004,
          0.4501707665298296,
          0.43793319774710615,
          0.42700253750966943,
          0.4163138501022173,
          0.40438248152318207,
          0.4021564729835676,
          0.3985140279583309,
          0.40481213979099107,
          0.39151841091073075,
          0.39487409280694047,
          0.38053601410077964,
          0.3770988052305968,
          0.3803131598493327,
          0.38919848359149434,
          0.38265753206999403,
          0.3763126751650935,
          0.3834900964861331,
          0.3830111379208772,
          0.3789616602918376,
          0.39725648838540784,
          0.3947485301805579,
          0.3962536824786145,
          0.3985955616702204,
          0.4123876778975777,
          0.4069251532139985
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "5d1c4e14-97ca-4314-ba25-3bbfeafff674",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6903182190973401,
          0.6698787120805271,
          0.6249013822435757,
          0.5731216622435529,
          0.47449579138110803,
          0.4231523499108743,
          0.40531554783599966,
          0.42800125021865404,
          0.3855326777782993,
          0.36618482631761673,
          0.3584367787780393,
          0.34576414385855486,
          0.3355388839175736,
          0.3298584715755665,
          0.31949214477469956,
          0.30898358944245585,
          0.3058315506591889,
          0.30003947144833165,
          0.30081159041987526,
          0.29467877302192835,
          0.28425893043550315,
          0.2818886019901377,
          0.2819473897633345,
          0.2991434838892757,
          0.30821055366797145,
          0.3122358700071556,
          0.2802258560910893,
          0.2637201000958825,
          0.25379570482145763,
          0.2496518240602696
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step8', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "8c6098fd-bec2-4903-a187-27fdbb376b5c",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6681084161219389,
          0.641485749638599,
          0.5951298941736636,
          0.5015143378921177,
          0.4458786140317502,
          0.4516877796338952,
          0.45463338779366536,
          0.5172371947247049,
          0.40801085674244425,
          0.39045274672300917,
          0.39566241269526276,
          0.3849148110203121,
          0.37645575041356294,
          0.38316444754600526,
          0.3758321616960608,
          0.3883263137029565,
          0.4076462325842484,
          0.39717419769452966,
          0.3869886805181918,
          0.3851705790861793,
          0.42448775094488395,
          0.43980026219202123,
          0.4186660927274953,
          0.4262874608454497,
          0.41388054904730426,
          0.41948140108067056,
          0.4749360978603363,
          0.47333562944246377,
          0.5098350001418073,
          0.44089757204055785
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "2e625f38-e61d-47f8-9afe-df816756c433",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6858872295577745,
          0.7152223835820737,
          0.6659246759714136,
          0.617662084908877,
          0.5985646200064876,
          0.5622421414379912,
          0.5314400380360331,
          0.5316178796947866,
          0.48770093825704236,
          0.4886862508340734,
          0.46774047175467304,
          0.45612912465984695,
          0.4337603226663986,
          0.4229891375355099,
          0.41815297237916843,
          0.4040236685011122,
          0.38827825298055935,
          0.3840170043390154,
          0.3659105371737826,
          0.3641566584939542,
          0.3609121840933095,
          0.3481111911471915,
          0.33747690990927137,
          0.32854169725219984,
          0.32635644576399797,
          0.3191928833867041,
          0.3160695647271935,
          0.30690232100694076,
          0.2999852268448199,
          0.2926895342587273
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step9', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "9183f28e-a9ca-41be-9047-3a9488102141",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6700837130131929,
          0.6765747547149659,
          0.6473378290300784,
          0.5959565986757693,
          0.5521929808284926,
          0.5104439548824145,
          0.49213586916094243,
          0.47229911840480304,
          0.4379003631032031,
          0.4280991100746652,
          0.4132254167743351,
          0.4075049016786658,
          0.3887233371319978,
          0.3979933793130128,
          0.3914214349311331,
          0.385685765484105,
          0.3727349934370621,
          0.36798958285995154,
          0.3765147820762966,
          0.3741841295491094,
          0.35378911883934683,
          0.3601492767748625,
          0.36145073693731555,
          0.3622553623240927,
          0.36044940222864563,
          0.36028656544892684,
          0.35700067670448965,
          0.3571574195571568,
          0.3603291042473005,
          0.3599445560704107
         ]
        },
        {
         "line": {
          "color": "rgba(219, 64, 82, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'loss')",
         "text": "",
         "type": "scatter",
         "uid": "3f229216-295b-44d6-940c-53310caf6cc7",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6908517639418155,
          0.6644222212298481,
          0.6044370405339964,
          0.5289821216449645,
          0.4810893320231046,
          0.46050557393382713,
          0.4270155279532723,
          0.40536388671340573,
          0.3980928070303323,
          0.3779432904317183,
          0.3502409243353323,
          0.3415870629934873,
          0.33150202922774974,
          0.3109874406298577,
          0.31635990617931753,
          0.2966743172654783,
          0.2888232696171544,
          0.2726333887968662,
          0.2636521625633977,
          0.2554382722878802,
          0.24419017772455723,
          0.2358018375825191,
          0.23382210177211946,
          0.24929828602046783,
          0.22868710078191065,
          0.2360497024756123,
          0.20997136035115246,
          0.20528475591094023,
          0.1994415624274148,
          0.20492879640364992
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "('step10', 'val_loss')",
         "text": "",
         "type": "scatter",
         "uid": "4403a182-e75b-4ceb-8a94-533107a42c6b",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29
         ],
         "y": [
          0.6864399391671886,
          0.6581083790115688,
          0.6710411408673163,
          0.4663199813469597,
          0.42618088463078374,
          0.40166596744371497,
          0.4010888296624889,
          0.38771169885345125,
          0.37390572739684064,
          0.35909300083699436,
          0.3558042173800261,
          0.36126471213672473,
          0.3522986536440642,
          0.3452384396739628,
          0.33466389075569486,
          0.33250255662461986,
          0.336273650760236,
          0.34382065456846483,
          0.34799591458362084,
          0.350471330984779,
          0.3769768686398216,
          0.36089809044547705,
          0.37224324345588683,
          0.3682357010634049,
          0.404698007910148,
          0.40930577050084654,
          0.431707006952037,
          0.4133410376051198,
          0.38818272404048754,
          0.4110473220762999
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"c9339e8a-b3f0-4dfd-8ae9-57dfd45dcf00\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"c9339e8a-b3f0-4dfd-8ae9-57dfd45dcf00\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'c9339e8a-b3f0-4dfd-8ae9-57dfd45dcf00',\n",
       "                        [{\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"7a4d13c9-42e8-4236-a3dc-17692bc0405a\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.691234642929501, 0.6854343240963664, 0.6506405745727428, 0.5432549658604866, 0.4771836929851108, 0.4847192315087802, 0.42163309803331533, 0.4054363177018465, 0.4012616788995439, 0.37268063492245146, 0.36500024490310373, 0.35520974535872973, 0.35095649306900834, 0.33401360796845475, 0.3356647999678257, 0.3226612389087677, 0.31348176515044796, 0.30171782083557425, 0.2953948636273831, 0.29619208806090885, 0.279438438464478, 0.28405194078090684, 0.28350706625963756, 0.2595840963188577, 0.24967485600047643, 0.24849302453407343, 0.24034162297628928, 0.22809478005637293, 0.2210160241322817, 0.23242313677562032]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step1', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"fa7adebb-9924-4aca-8cdb-a8cc6cd28c5b\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6869504850843678, 0.6752959406894187, 0.6009969224100528, 0.48404760127482205, 0.4939457375070323, 0.45987418138462566, 0.408728958212811, 0.4024177984051082, 0.42152947705724964, 0.4131510130737139, 0.43478596780611123, 0.3915075589781222, 0.43788767586583677, 0.3985961255819901, 0.3987043310766635, 0.40117069586463594, 0.428788983044417, 0.41658428518668467, 0.45475454589594966, 0.4407342135906219, 0.47165144059969033, 0.5046142661053201, 0.5267510960931363, 0.4985546547433604, 0.497649784191795, 0.504563228721204, 0.5643075067064036, 0.4956960473371589, 0.5205906411875849, 0.5053187867869502]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"9e7c6917-f8f9-450a-95e1-28f78b625aba\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6886369588870357, 0.7151937319460698, 0.6448626999693792, 0.5673177128828666, 0.5231189674801296, 0.4896644581343241, 0.45194198420082315, 0.43192991694966376, 0.40997648362952155, 0.410185833800818, 0.3951132436881319, 0.38425701571547466, 0.3670972242447489, 0.3627604439638663, 0.3671487604938268, 0.34848171723061716, 0.35032686527800444, 0.3418788668902024, 0.34381439887383136, 0.33367956536979493, 0.32469670524919664, 0.3160045396014688, 0.3318495822701477, 0.3627208325022085, 0.31465871359990993, 0.30732787971335335, 0.30061529232683964, 0.30124756653527707, 0.29260920778564786, 0.2893848436178217]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step2', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"f64d4d6f-77a6-4634-b901-85ea3ab801e4\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6850316560786703, 0.6671034035475357, 0.6231176993121271, 0.6013144944025123, 0.565127312100452, 0.5546975431234941, 0.5246954570645871, 0.49865922720535943, 0.48251488830732264, 0.5178787931152012, 0.5339215879854948, 0.48676087519396904, 0.4833118578662043, 0.488960830025051, 0.5042549376902373, 0.4857603036839029, 0.4898430015729821, 0.47876584478046585, 0.5090619180513465, 0.488116861426312, 0.5221789150134377, 0.5043734851090804, 0.45649589144665265, 0.5217286055502685, 0.5552302751852118, 0.49871604442596434, 0.5112506778343864, 0.5120561304299728, 0.5041731704836306, 0.5193219558052394]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"280a4b41-4b80-44c2-bd74-1f8dac5a77cb\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.685094870634125, 0.6722271133736136, 0.6541766731059494, 0.5945113259237169, 0.566689758197121, 0.563818163226768, 0.49820967604572647, 0.44114571107182526, 0.40937112183962465, 0.3746419969388252, 0.3767946239830791, 0.364260956313875, 0.35299211107014455, 0.3464413098379034, 0.33761660462416315, 0.32929305681859816, 0.31989148201573875, 0.3157842185186303, 0.3120342845502107, 0.2970959853866826, 0.2904804626524736, 0.28599047499578356, 0.27688730772278736, 0.2678966043364023, 0.2609409302473068, 0.2512421783041839, 0.25024210825058574, 0.23897609180874294, 0.23921664601938736, 0.23247706373244667]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step3', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"e3c3fe7b-d124-4b97-b89a-1ca9b1befd61\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6456125679223433, 0.6650446979895882, 0.6100253773772198, 0.6688102867292322, 0.7711266595384348, 0.5019684299178745, 0.45621361110521397, 0.4172560329022615, 0.3829838636128799, 0.37476379767708157, 0.3612844381643378, 0.3587460323520329, 0.35592661370401796, 0.35124319454898006, 0.3434163871018783, 0.34267013280288033, 0.34470000681669816, 0.3405753742093625, 0.33690664249917734, 0.33012241954388827, 0.33332857981972075, 0.3318237579387167, 0.3357396338296973, 0.33923295218011607, 0.3424390235672826, 0.34489134835160296, 0.3473987032537875, 0.3578660630661508, 0.36349126411520916, 0.3870463324629742]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"29d56866-a30f-4308-ba08-79ce557073eb\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6891028673752494, 0.6716973900219093, 0.6312471185329456, 0.5743082627582089, 0.5293294729242002, 0.5488252793533215, 0.4940507244372713, 0.476746184900763, 0.47796293880052615, 0.45124493653071673, 0.4129903277625208, 0.3999085385730301, 0.38293618605908564, 0.382719036605623, 0.37190230454223744, 0.3654478409440045, 0.3555685498576233, 0.3474880466858546, 0.3410930327747179, 0.3320350550223088, 0.326521036475177, 0.31489821511190297, 0.311530157002274, 0.30359154238505065, 0.30275009628655253, 0.2951986460726042, 0.2876338815631498, 0.2845820954888339, 0.2756864375250351, 0.2753477689004751]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step4', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"f4a1add1-068f-4838-a30b-26612290dd68\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6851218233937802, 0.6809403004853621, 0.635597997126372, 0.5594261293825896, 0.5319049653799638, 0.6050456643104554, 0.5447835315828738, 0.5206819878972095, 0.47834072164867236, 0.43902750067088914, 0.4535312048766924, 0.4670725412990736, 0.42073170827782674, 0.42181925773620604, 0.41593774894009466, 0.42369321144145466, 0.4162120072737984, 0.3859481868536576, 0.3810729485491048, 0.3871965670067331, 0.38845591052718786, 0.3898425693097322, 0.38703017597613126, 0.3978960905386054, 0.38749016678851583, 0.3951959850995437, 0.40534644697023475, 0.40480254344318223, 0.4031579473744268, 0.40531976482142573]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"68bf222a-2961-43ca-bd08-c1c137f5e8f2\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6889927720102135, 0.6583075116222031, 0.6146592649860658, 0.5142306668746874, 0.4711827771675184, 0.40726702737347514, 0.389385406838523, 0.37817121182662855, 0.35745603776208446, 0.34086177622638464, 0.34133955922679626, 0.3294742234375166, 0.3181091270872936, 0.30684391916662024, 0.2956232180342006, 0.29313878736634186, 0.28470677336057026, 0.26978945185020925, 0.2746477734927394, 0.2626337291249906, 0.24689752273801444, 0.24753780670212086, 0.23869933788327202, 0.24548203218098424, 0.23728909177192745, 0.21573798794677293, 0.2221200056841984, 0.21181390059455005, 0.2162006258820566, 0.20196368160167177]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step5', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"f4c9fe15-7109-4d48-851c-ab90a069ce8f\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.661149659882421, 0.6624870124070541, 0.5770749584488247, 0.5136195118012635, 0.4724950868150462, 0.46250466730283657, 0.4627545732518901, 0.45906080836835117, 0.47047468631163886, 0.4801720139772996, 0.4534562624019125, 0.4631574490795965, 0.4750412002853725, 0.4974569898584615, 0.5018767134003017, 0.5052839159965515, 0.48838482369547304, 0.5021935278954713, 0.487003449253414, 0.492544294440228, 0.5350327134132385, 0.5294429281483526, 0.5755920596744704, 0.5746570784112681, 0.6092434732810311, 0.6223850644153097, 0.5555728396643763, 0.6179669717083807, 0.5751638091128806, 0.6830305488213249]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"a55b44c8-93d1-48a2-b0d6-d88cbc61a1e7\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6902845938424558, 0.6696182618970457, 0.6225619053495103, 0.5410739293996839, 0.47943213135723906, 0.4409493107150718, 0.40906768035197605, 0.3811940547636742, 0.35982083684004446, 0.3524670117719162, 0.34080831195421263, 0.33166694249507883, 0.32894583908832015, 0.32449062672502177, 0.3151749785107691, 0.30222928495222817, 0.33897251354323493, 0.33321670158473765, 0.3113887645772114, 0.30483304976265213, 0.2923046538507305, 0.2857747556650696, 0.28032652073436315, 0.2801191843794164, 0.2721461954324142, 0.2634599391389008, 0.2610889800936704, 0.25531896689663763, 0.24876411195826414, 0.24394307254593153]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step6', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"b8ba26df-0eaa-478b-92b0-525d7b44e813\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6813707984012106, 0.6357009016949198, 0.5171922777010047, 0.45659027281014813, 0.433579153859097, 0.4099910197050675, 0.38750298437864883, 0.3699034379876178, 0.3531768148360045, 0.35412547095962194, 0.36519083976745603, 0.37666477820147637, 0.3817651310692663, 0.42878415558649147, 0.44078706554744557, 0.43425644584324047, 0.4555314857026805, 0.40973840563193614, 0.3873310838056647, 0.38168999112170676, 0.39487649435582367, 0.3922223399514737, 0.41230450557625814, 0.4109307232110397, 0.41263743768567623, 0.4200488792813343, 0.4243987368500751, 0.436546454222306, 0.4290316949719968, 0.46030149252518365]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"30e6cfb8-a2d3-4956-8e40-cfa1dd53ddd3\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6904347619572699, 0.6701183512590934, 0.635157797417203, 0.5733811235658213, 0.47786836814189304, 0.45089969577420735, 0.4511605769539801, 0.41273467995694296, 0.40259607275902937, 0.3830840501520369, 0.37375970384924884, 0.36247625201220673, 0.3660170860048653, 0.3514701929933207, 0.3432977355044821, 0.336248977460723, 0.329929597798177, 0.3325274987785137, 0.3177768201355773, 0.31705608955328013, 0.31361957226974374, 0.3053027838612524, 0.29897303301931005, 0.2989728661838937, 0.2866116730199344, 0.2824656822255268, 0.2753575451420125, 0.2712668889098697, 0.2664026337977193, 0.25362992675408075]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step7', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"b163c4b3-e3ee-4176-9bed-d210a6142014\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6836548639380413, 0.6680678160294242, 0.6139069702314294, 0.5318846681843633, 0.48017178773880004, 0.4501707665298296, 0.43793319774710615, 0.42700253750966943, 0.4163138501022173, 0.40438248152318207, 0.4021564729835676, 0.3985140279583309, 0.40481213979099107, 0.39151841091073075, 0.39487409280694047, 0.38053601410077964, 0.3770988052305968, 0.3803131598493327, 0.38919848359149434, 0.38265753206999403, 0.3763126751650935, 0.3834900964861331, 0.3830111379208772, 0.3789616602918376, 0.39725648838540784, 0.3947485301805579, 0.3962536824786145, 0.3985955616702204, 0.4123876778975777, 0.4069251532139985]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"5d1c4e14-97ca-4314-ba25-3bbfeafff674\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6903182190973401, 0.6698787120805271, 0.6249013822435757, 0.5731216622435529, 0.47449579138110803, 0.4231523499108743, 0.40531554783599966, 0.42800125021865404, 0.3855326777782993, 0.36618482631761673, 0.3584367787780393, 0.34576414385855486, 0.3355388839175736, 0.3298584715755665, 0.31949214477469956, 0.30898358944245585, 0.3058315506591889, 0.30003947144833165, 0.30081159041987526, 0.29467877302192835, 0.28425893043550315, 0.2818886019901377, 0.2819473897633345, 0.2991434838892757, 0.30821055366797145, 0.3122358700071556, 0.2802258560910893, 0.2637201000958825, 0.25379570482145763, 0.2496518240602696]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step8', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"8c6098fd-bec2-4903-a187-27fdbb376b5c\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6681084161219389, 0.641485749638599, 0.5951298941736636, 0.5015143378921177, 0.4458786140317502, 0.4516877796338952, 0.45463338779366536, 0.5172371947247049, 0.40801085674244425, 0.39045274672300917, 0.39566241269526276, 0.3849148110203121, 0.37645575041356294, 0.38316444754600526, 0.3758321616960608, 0.3883263137029565, 0.4076462325842484, 0.39717419769452966, 0.3869886805181918, 0.3851705790861793, 0.42448775094488395, 0.43980026219202123, 0.4186660927274953, 0.4262874608454497, 0.41388054904730426, 0.41948140108067056, 0.4749360978603363, 0.47333562944246377, 0.5098350001418073, 0.44089757204055785]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"2e625f38-e61d-47f8-9afe-df816756c433\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6858872295577745, 0.7152223835820737, 0.6659246759714136, 0.617662084908877, 0.5985646200064876, 0.5622421414379912, 0.5314400380360331, 0.5316178796947866, 0.48770093825704236, 0.4886862508340734, 0.46774047175467304, 0.45612912465984695, 0.4337603226663986, 0.4229891375355099, 0.41815297237916843, 0.4040236685011122, 0.38827825298055935, 0.3840170043390154, 0.3659105371737826, 0.3641566584939542, 0.3609121840933095, 0.3481111911471915, 0.33747690990927137, 0.32854169725219984, 0.32635644576399797, 0.3191928833867041, 0.3160695647271935, 0.30690232100694076, 0.2999852268448199, 0.2926895342587273]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step9', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"9183f28e-a9ca-41be-9047-3a9488102141\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6700837130131929, 0.6765747547149659, 0.6473378290300784, 0.5959565986757693, 0.5521929808284926, 0.5104439548824145, 0.49213586916094243, 0.47229911840480304, 0.4379003631032031, 0.4280991100746652, 0.4132254167743351, 0.4075049016786658, 0.3887233371319978, 0.3979933793130128, 0.3914214349311331, 0.385685765484105, 0.3727349934370621, 0.36798958285995154, 0.3765147820762966, 0.3741841295491094, 0.35378911883934683, 0.3601492767748625, 0.36145073693731555, 0.3622553623240927, 0.36044940222864563, 0.36028656544892684, 0.35700067670448965, 0.3571574195571568, 0.3603291042473005, 0.3599445560704107]}, {\"line\": {\"color\": \"rgba(219, 64, 82, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"3f229216-295b-44d6-940c-53310caf6cc7\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6908517639418155, 0.6644222212298481, 0.6044370405339964, 0.5289821216449645, 0.4810893320231046, 0.46050557393382713, 0.4270155279532723, 0.40536388671340573, 0.3980928070303323, 0.3779432904317183, 0.3502409243353323, 0.3415870629934873, 0.33150202922774974, 0.3109874406298577, 0.31635990617931753, 0.2966743172654783, 0.2888232696171544, 0.2726333887968662, 0.2636521625633977, 0.2554382722878802, 0.24419017772455723, 0.2358018375825191, 0.23382210177211946, 0.24929828602046783, 0.22868710078191065, 0.2360497024756123, 0.20997136035115246, 0.20528475591094023, 0.1994415624274148, 0.20492879640364992]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"('step10', 'val_loss')\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"4403a182-e75b-4ceb-8a94-533107a42c6b\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], \"y\": [0.6864399391671886, 0.6581083790115688, 0.6710411408673163, 0.4663199813469597, 0.42618088463078374, 0.40166596744371497, 0.4010888296624889, 0.38771169885345125, 0.37390572739684064, 0.35909300083699436, 0.3558042173800261, 0.36126471213672473, 0.3522986536440642, 0.3452384396739628, 0.33466389075569486, 0.33250255662461986, 0.336273650760236, 0.34382065456846483, 0.34799591458362084, 0.350471330984779, 0.3769768686398216, 0.36089809044547705, 0.37224324345588683, 0.3682357010634049, 0.404698007910148, 0.40930577050084654, 0.431707006952037, 0.4133410376051198, 0.38818272404048754, 0.4110473220762999]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('c9339e8a-b3f0-4dfd-8ae9-57dfd45dcf00');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean  acc         0.823099\n",
      "loss        0.378627\n",
      "val_acc     0.797746\n",
      "val_loss    0.455723\n",
      "dtype: float64\n",
      "std  acc         0.092829\n",
      "loss        0.128274\n",
      "val_acc     0.075640\n",
      "val_loss    0.094572\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "1",
         "text": "",
         "type": "scatter",
         "uid": "e07f94f5-1fd3-415c-925d-11b461bc2bdd",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.8399999737739563,
          0.8399999737739563,
          0.8700000047683716,
          0.8500000238418579,
          0.8299999833106995,
          0.8500000238418579,
          0.8600000143051147,
          0.8100000023841858,
          0.8899999856948853,
          0.8399999737739563
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         }
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"7d40c985-4846-404a-b2a3-d0325e5b48b3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"7d40c985-4846-404a-b2a3-d0325e5b48b3\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '7d40c985-4846-404a-b2a3-d0325e5b48b3',\n",
       "                        [{\"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"1\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"e07f94f5-1fd3-415c-925d-11b461bc2bdd\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"y\": [0.8399999737739563, 0.8399999737739563, 0.8700000047683716, 0.8500000238418579, 0.8299999833106995, 0.8500000238418579, 0.8600000143051147, 0.8100000023841858, 0.8899999856948853, 0.8399999737739563]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('7d40c985-4846-404a-b2a3-d0325e5b48b3');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media  0.8479999959468841\n",
      "std  0.022010101773470788\n"
     ]
    }
   ],
   "source": [
    "process_results(tiple_hist, triple_evas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.133418Z",
     "start_time": "2019-06-14T06:36:08.336Z"
    }
   },
   "outputs": [],
   "source": [
    "model_lstm = Sequential()\n",
    "model_2lstm = Sequential()\n",
    "model_2dcnn = Sequential()\n",
    "model_2dcnnLstm = Sequential()\n",
    "model_cnn = Sequential()\n",
    "model_bidi = Sequential()\n",
    "\n",
    "model_lstm.add(LSTM(28, activation='relu', input_shape=(elements, features), name='lstm'))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(polarity_dim, activation='sigmoid', name='dense'))\n",
    "model_lstm.compile(loss=\"categorical_crossentropy\", optimizer='adagrad', metrics=['accuracy'])\n",
    "\n",
    "model_2lstm.add(LSTM(neurons, activation='tanh', input_shape=input_shape, return_sequences=True, name='lstm'))\n",
    "model_2lstm.add(Dropout(0.5))\n",
    "model_2lstm.add(LSTM(neurons, activation='tanh'))\n",
    "model_2lstm.add(Dropout(0.5))\n",
    "model_2lstm.add(Dense(polarity_dim, activation='softmax', name='dense'))\n",
    "model_2lstm.compile(loss=\"categorical_crossentropy\", optimizer='adagrad', metrics=['accuracy'])\n",
    "\n",
    "model_2dcnn.add(Reshape((1, timesteps, features), input_shape=input_shape))\n",
    "model_2dcnn.add(Conv2D(128, (4, 300), padding='same', name='conv_layer'))\n",
    "model_2dcnn.add(Activation('relu'))\n",
    "model_2dcnn.add(MaxPooling2D(pool_size=(2,2), strides=None))\n",
    "model_2dcnn.add(Flatten())\n",
    "model_2dcnn.add(Dropout(0.5))\n",
    "model_2dcnn.add(Dense(polarity_dim, activation='softmax', name='dense'))\n",
    "model_2dcnn.compile(loss=\"categorical_crossentropy\", optimizer='adagrad', metrics=['accuracy'])\n",
    "\n",
    "model_2dcnnLstm.add(Reshape((1, timesteps, features), input_shape=input_shape))\n",
    "model_2dcnnLstm.add(Conv2D(128, (4, 300), padding='same', name='conv_layer'))\n",
    "model_2dcnnLstm.add(Activation('relu'))\n",
    "model_2dcnnLstm.add(MaxPooling2D(pool_size=(2,2), strides=None))\n",
    "model_2dcnnLstm.add(TimeDistributed(Flatten()))\n",
    "model_2dcnnLstm.add(LSTM(neurons))\n",
    "model_2dcnnLstm.add(Dropout(0.5))\n",
    "model_2dcnnLstm.add(Dense(polarity_dim, activation='softmax', name='dense'))\n",
    "model_2dcnnLstm.compile(loss=\"categorical_crossentropy\", optimizer='adagrad', metrics=['accuracy'])\n",
    "\n",
    "model_cnn.add(Convolution1D(128, 3, padding='same', name='conv_layer', input_shape=input_shape))\n",
    "model_cnn.add(Activation('tanh'))\n",
    "model_cnn.add(MaxPooling1D(4))\n",
    "model_cnn.add(LSTM(neurons, dropout=0.5))\n",
    "model_cnn.add(Dense(polarity_dim, activation='softmax', name='dense'))\n",
    "model_cnn.compile(loss=\"categorical_crossentropy\", optimizer='adagrad', metrics=['accuracy'])\n",
    "\n",
    "model_bidi.add(Bidirectional(LSTM(neurons), input_shape=input_shape))\n",
    "model_bidi.add(Dense(polarity_dim, activation='softmax', name='dense'))\n",
    "model_bidi.compile(loss=\"categorical_crossentropy\", optimizer='adagrad', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.136397Z",
     "start_time": "2019-06-14T06:36:08.339Z"
    }
   },
   "outputs": [],
   "source": [
    "monitor = 'val_loss'\n",
    "patience = 5\n",
    "cbks = [callbacks.EarlyStopping(monitor=monitor, patience=patience)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularización de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.139468Z",
     "start_time": "2019-06-14T06:36:08.342Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = {\n",
    "    'lstm': model_lstm,\n",
    "    '2lstm': model_2lstm,\n",
    "    '2dcnn': model_2dcnn,\n",
    "    '2dcnn+lstm': model_2dcnnLstm,\n",
    "    'cnn+lstm': model_cnn,\n",
    "    'bidirectionalLstm': model_bidi\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.096753Z",
     "start_time": "2019-06-14T06:36:08.327Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model_lstm_reg3():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, return_sequences=True, recurrent_initializer='normal', kernel_initializer='normal', activation='relu', input_shape=(x_train.shape[1], x_train.shape[2]), name='lstm'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(10))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='normal', name='dense'))\n",
    "    optimizer = Adam(lr=0.001, decay=0.01)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "model = create_model_lstm_reg3()\n",
    "hist_reg3 = model.fit(x_train, y_train, shuffle=False, validation_split=0.2, verbose=2, batch_size=128, epochs=30)\n",
    "# reg3_hist, reg3_evas = kfold_train(create_reg_model3, batch_size=128, epochs=30, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.126947Z",
     "start_time": "2019-06-14T06:36:08.330Z"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.130414Z",
     "start_time": "2019-06-14T06:36:08.333Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(hist_reg3.history)[['loss', 'val_loss']].iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.142361Z",
     "start_time": "2019-06-14T06:36:08.345Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "with tqdm(total=len(clasificadores) * 10) as pbar:\n",
    "    for c in clasificadores:\n",
    "        results[c] = { 'real': {}, 'predicted': {} }\n",
    "        i = 0\n",
    "        for train_index, test_index in kf.split(train_corpus.content):\n",
    "            train_x = X[train_index]\n",
    "            train_y = Y[train_index]\n",
    "            test_x = X[test_index]\n",
    "            test_y = Y[test_index]\n",
    "            print(train_y)\n",
    "            if c == 'bidiLstm':\n",
    "                train_x = [train_x, np.flipud(train_x)]\n",
    "                \n",
    "            pipeline[c].fit(train_x, train_y, batch_size=64, callbacks=cbks, epochs=1000, validation_split=0.25, shuffle=False, verbose=1)\n",
    "\n",
    "            predicted = pipeline[c].predict(test_x)\n",
    "\n",
    "            results[c]['real'][i] = test_y.tolist()\n",
    "            results[c]['predicted'][i] = predicted.tolist()\n",
    "            i = i + 1\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.145643Z",
     "start_time": "2019-06-14T06:36:08.348Z"
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T07:08:55.172871Z",
     "start_time": "2019-06-14T06:36:08.352Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_pickle('data/results/'+name+'/cine/' + base_dir + '/' + name + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "317.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
